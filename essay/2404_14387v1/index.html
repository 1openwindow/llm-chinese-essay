<!DOCTYPE html>

<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>A Survey on Self-Evolution of Large Language Models</title>
<!--Generated on Mon Apr 22 17:35:34 2024 by LaTeXML (version 0.8.7) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="resource/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="resource/ar5iv_0.7.4.min.css" rel="stylesheet" type="text/css"/>
<link href="resource/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="resource/bootstrap.bundle.min.js"></script>
<script src="resource/html2canvas.min.js"></script>
<script src="resource/addons.js"></script>
<script src="resource/feedbackOverlay.js"></script>
</head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="#S1" title="1 Introduction ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="#S2" title="2 Overview ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Overview</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="#S2.SS1" title="2.1 Background ‣ 2 Overview ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Background</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="#S2.SS2" title="2.2 Conceptual Framework ‣ 2 Overview ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Conceptual Framework</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="#S2.SS2.SSS0.Px1" title="Experience Acquisition ‣ 2.2 Conceptual Framework ‣ 2 Overview ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_title">Experience Acquisition</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="#S2.SS2.SSS0.Px2" title="Experience Refinement ‣ 2.2 Conceptual Framework ‣ 2 Overview ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_title">Experience Refinement</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="#S2.SS2.SSS0.Px3" title="Updating ‣ 2.2 Conceptual Framework ‣ 2 Overview ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_title">Updating</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="#S2.SS2.SSS0.Px4" title="Evaluation ‣ 2.2 Conceptual Framework ‣ 2 Overview ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_title">Evaluation</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="#S3" title="3 Evolution Objectives ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Evolution Objectives</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="#S3.SS1" title="3.1 Evolving Abilities ‣ 3 Evolution Objectives ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Evolving Abilities</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="#S3.SS1.SSS1" title="3.1.1 LLMs ‣ 3.1 Evolving Abilities ‣ 3 Evolution Objectives ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.1 </span>LLMs</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="#S3.SS1.SSS2" title="3.1.2 LLM-based Agents ‣ 3.1 Evolving Abilities ‣ 3 Evolution Objectives ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.2 </span>LLM-based Agents</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="#S3.SS2" title="3.2 Evolution Directions ‣ 3 Evolution Objectives ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Evolution Directions</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="#S4" title="4 Experience Acquisition ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experience Acquisition</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="#S4.SS1" title="4.1 Task Evolution ‣ 4 Experience Acquisition ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Task Evolution</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="#S4.SS1.SSS0.Px1" title="Knowledge-Based ‣ 4.1 Task Evolution ‣ 4 Experience Acquisition ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_title">Knowledge-Based</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="#S4.SS1.SSS0.Px2" title="Knowledge-Free ‣ 4.1 Task Evolution ‣ 4 Experience Acquisition ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_title">Knowledge-Free</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="#S4.SS1.SSS0.Px3" title="Selective ‣ 4.1 Task Evolution ‣ 4 Experience Acquisition ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_title">Selective</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="#S4.SS2" title="4.2 Solution Evolution ‣ 4 Experience Acquisition ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Solution Evolution</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection">
<a class="ltx_ref" href="#S4.SS2.SSS1" title="4.2.1 Positive ‣ 4.2 Solution Evolution ‣ 4 Experience Acquisition ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.1 </span>Positive</span></a>
<ol class="ltx_toclist ltx_toclist_subsubsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="#S4.SS2.SSS1.Px1" title="Rationale-Based ‣ 4.2.1 Positive ‣ 4.2 Solution Evolution ‣ 4 Experience Acquisition ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_title">Rationale-Based</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="#S4.SS2.SSS1.Px2" title="Interactive ‣ 4.2.1 Positive ‣ 4.2 Solution Evolution ‣ 4 Experience Acquisition ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_title">Interactive</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="#S4.SS2.SSS1.Px3" title="Self-Play ‣ 4.2.1 Positive ‣ 4.2 Solution Evolution ‣ 4 Experience Acquisition ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_title">Self-Play</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="#S4.SS2.SSS1.Px4" title="Grounded ‣ 4.2.1 Positive ‣ 4.2 Solution Evolution ‣ 4 Experience Acquisition ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_title">Grounded</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsubsection">
<a class="ltx_ref" href="#S4.SS2.SSS2" title="4.2.2 Negative ‣ 4.2 Solution Evolution ‣ 4 Experience Acquisition ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.2 </span>Negative</span></a>
<ol class="ltx_toclist ltx_toclist_subsubsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="#S4.SS2.SSS2.Px1" title="Contrastive ‣ 4.2.2 Negative ‣ 4.2 Solution Evolution ‣ 4 Experience Acquisition ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_title">Contrastive</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="#S4.SS2.SSS2.Px2" title="Perturbative ‣ 4.2.2 Negative ‣ 4.2 Solution Evolution ‣ 4 Experience Acquisition ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_title">Perturbative</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="#S4.SS3" title="4.3 Feedback ‣ 4 Experience Acquisition ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Feedback</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="#S4.SS3.SSS1" title="4.3.1 Model ‣ 4.3 Feedback ‣ 4 Experience Acquisition ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3.1 </span>Model</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="#S4.SS3.SSS2" title="4.3.2 Environment ‣ 4.3 Feedback ‣ 4 Experience Acquisition ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3.2 </span>Environment</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="#S5" title="5 Experience Refinement ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Experience Refinement</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="#S5.SS1" title="5.1 Filtering ‣ 5 Experience Refinement ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Filtering</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="#S5.SS1.SSS1" title="5.1.1 Metric-Based ‣ 5.1 Filtering ‣ 5 Experience Refinement ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1.1 </span>Metric-Based</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="#S5.SS1.SSS2" title="5.1.2 Metric-Free ‣ 5.1 Filtering ‣ 5 Experience Refinement ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1.2 </span>Metric-Free</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="#S5.SS2" title="5.2 Correcting ‣ 5 Experience Refinement ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Correcting</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="#S5.SS2.SSS1" title="5.2.1 Critique-Based ‣ 5.2 Correcting ‣ 5 Experience Refinement ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2.1 </span>Critique-Based</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="#S5.SS2.SSS2" title="5.2.2 Critique-Free ‣ 5.2 Correcting ‣ 5 Experience Refinement ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2.2 </span>Critique-Free</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="#S6" title="6 Updating ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Updating</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="#S6.SS1" title="6.1 In-Weight ‣ 6 Updating ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.1 </span>In-Weight</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="#S6.SS1.SSS1" title="6.1.1 Replay-based ‣ 6.1 In-Weight ‣ 6 Updating ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.1.1 </span>Replay-based</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="#S6.SS1.SSS2" title="6.1.2 Regularization-based ‣ 6.1 In-Weight ‣ 6 Updating ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.1.2 </span>Regularization-based</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="#S6.SS1.SSS3" title="6.1.3 Architecture-based ‣ 6.1 In-Weight ‣ 6 Updating ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.1.3 </span>Architecture-based</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="#S6.SS2" title="6.2 In-Context ‣ 6 Updating ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.2 </span>In-Context</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="#S6.SS2.SSS0.Px1" title="External Memory ‣ 6.2 In-Context ‣ 6 Updating ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_title">External Memory</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="#S6.SS2.SSS0.Px2" title="Working Memory ‣ 6.2 In-Context ‣ 6 Updating ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_title">Working Memory</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="#S7" title="7 Evaluation ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Evaluation</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="#S7.SS1" title="7.1 Quantitative Evaluation ‣ 7 Evaluation ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.1 </span>Quantitative Evaluation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="#S7.SS2" title="7.2 Qualitative Evaluation ‣ 7 Evaluation ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.2 </span>Qualitative Evaluation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="#S8" title="8 Open Problems ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8 </span>Open Problems</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="#S8.SS1" title="8.1 Objectives: Diversity and Hierarchy ‣ 8 Open Problems ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8.1 </span>Objectives: Diversity and Hierarchy</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="#S8.SS2" title="8.2 Level of Autonomy: From Low to High ‣ 8 Open Problems ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8.2 </span>Level of Autonomy: From Low to High</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="#S8.SS2.SSS0.Px1" title="Low-level ‣ 8.2 Level of Autonomy: From Low to High ‣ 8 Open Problems ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_title">Low-level</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="#S8.SS2.SSS0.Px2" title="Medium-level ‣ 8.2 Level of Autonomy: From Low to High ‣ 8 Open Problems ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_title">Medium-level</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="#S8.SS2.SSS0.Px3" title="High-level ‣ 8.2 Level of Autonomy: From Low to High ‣ 8 Open Problems ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_title">High-level</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="#S8.SS3" title="8.3 Experience Acquisition and Refinement: From Empirical to Theoretical ‣ 8 Open Problems ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8.3 </span>Experience Acquisition and Refinement: From Empirical to Theoretical</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="#S8.SS4" title="8.4 Updating: Stability-Plasticity Dilemma ‣ 8 Open Problems ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8.4 </span>Updating: Stability-Plasticity Dilemma</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="#S8.SS5" title="8.5 Evaluation: Systematic and Evolving ‣ 8 Open Problems ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8.5 </span>Evaluation: Systematic and Evolving</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="#S8.SS6" title="8.6 Safety and Superalignment ‣ 8 Open Problems ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8.6 </span>Safety and Superalignment</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="#S9" title="9 Conclusion ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">9 </span>Conclusion</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<div class="section" id="target-section"><div id="license-tr">License: arXiv.org perpetual non-exclusive license</div><div id="watermark-tr">arXiv:2404.14387v1 [cs.CL] 22 Apr 2024</div></div>
<script>
            function closePopup() {
                document.querySelector('.package-alerts').style.display = 'none';
            }
        </script>
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">大语言模型自我进化调查</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Zhengwei Tao<math alttext="{}^{12}" class="ltx_Math" display="inline" id="id1.1.m1.1"><semantics id="id1.1.m1.1a"><msup id="id1.1.m1.1.1" xref="id1.1.m1.1.1.cmml"><mi id="id1.1.m1.1.1a" xref="id1.1.m1.1.1.cmml"></mi><mn id="id1.1.m1.1.1.1" xref="id1.1.m1.1.1.1.cmml">12</mn></msup><annotation-xml encoding="MathML-Content" id="id1.1.m1.1b"><apply id="id1.1.m1.1.1.cmml" xref="id1.1.m1.1.1"><cn id="id1.1.m1.1.1.1.cmml" type="integer" xref="id1.1.m1.1.1.1">12</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id1.1.m1.1c">{}^{12}</annotation><annotation encoding="application/x-llamapun" id="id1.1.m1.1d">start_FLOATSUPERSCRIPT 12 end_FLOATSUPERSCRIPT</annotation></semantics></math>, Ting-En Lin<math alttext="{}^{2}" class="ltx_Math" display="inline" id="id2.2.m2.1"><semantics id="id2.2.m2.1a"><msup id="id2.2.m2.1.1" xref="id2.2.m2.1.1.cmml"><mi id="id2.2.m2.1.1a" xref="id2.2.m2.1.1.cmml"></mi><mn id="id2.2.m2.1.1.1" xref="id2.2.m2.1.1.1.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="id2.2.m2.1b"><apply id="id2.2.m2.1.1.cmml" xref="id2.2.m2.1.1"><cn id="id2.2.m2.1.1.1.cmml" type="integer" xref="id2.2.m2.1.1.1">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id2.2.m2.1c">{}^{2}</annotation><annotation encoding="application/x-llamapun" id="id2.2.m2.1d">start_FLOATSUPERSCRIPT 2 end_FLOATSUPERSCRIPT</annotation></semantics></math>, Xiancai Chen<math alttext="{}^{1}" class="ltx_Math" display="inline" id="id3.3.m3.1"><semantics id="id3.3.m3.1a"><msup id="id3.3.m3.1.1" xref="id3.3.m3.1.1.cmml"><mi id="id3.3.m3.1.1a" xref="id3.3.m3.1.1.cmml"></mi><mn id="id3.3.m3.1.1.1" xref="id3.3.m3.1.1.1.cmml">1</mn></msup><annotation-xml encoding="MathML-Content" id="id3.3.m3.1b"><apply id="id3.3.m3.1.1.cmml" xref="id3.3.m3.1.1"><cn id="id3.3.m3.1.1.1.cmml" type="integer" xref="id3.3.m3.1.1.1">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id3.3.m3.1c">{}^{1}</annotation><annotation encoding="application/x-llamapun" id="id3.3.m3.1d">start_FLOATSUPERSCRIPT 1 end_FLOATSUPERSCRIPT</annotation></semantics></math>, Hangyu Li<math alttext="{}^{2}" class="ltx_Math" display="inline" id="id4.4.m4.1"><semantics id="id4.4.m4.1a"><msup id="id4.4.m4.1.1" xref="id4.4.m4.1.1.cmml"><mi id="id4.4.m4.1.1a" xref="id4.4.m4.1.1.cmml"></mi><mn id="id4.4.m4.1.1.1" xref="id4.4.m4.1.1.1.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="id4.4.m4.1b"><apply id="id4.4.m4.1.1.cmml" xref="id4.4.m4.1.1"><cn id="id4.4.m4.1.1.1.cmml" type="integer" xref="id4.4.m4.1.1.1">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id4.4.m4.1c">{}^{2}</annotation><annotation encoding="application/x-llamapun" id="id4.4.m4.1d">start_FLOATSUPERSCRIPT 2 end_FLOATSUPERSCRIPT</annotation></semantics></math>, Yuchuan Wu<math alttext="{}^{2}" class="ltx_Math" display="inline" id="id5.5.m5.1"><semantics id="id5.5.m5.1a"><msup id="id5.5.m5.1.1" xref="id5.5.m5.1.1.cmml"><mi id="id5.5.m5.1.1a" xref="id5.5.m5.1.1.cmml"></mi><mn id="id5.5.m5.1.1.1" xref="id5.5.m5.1.1.1.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="id5.5.m5.1b"><apply id="id5.5.m5.1.1.cmml" xref="id5.5.m5.1.1"><cn id="id5.5.m5.1.1.1.cmml" type="integer" xref="id5.5.m5.1.1.1">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id5.5.m5.1c">{}^{2}</annotation><annotation encoding="application/x-llamapun" id="id5.5.m5.1d">start_FLOATSUPERSCRIPT 2 end_FLOATSUPERSCRIPT</annotation></semantics></math>, 
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="id6.6.1">Yongbin Li<math alttext="{}^{2}" class="ltx_Math" display="inline" id="id6.6.1.m1.1"><semantics id="id6.6.1.m1.1a"><msup id="id6.6.1.m1.1.1" xref="id6.6.1.m1.1.1.cmml"><mi id="id6.6.1.m1.1.1a" xref="id6.6.1.m1.1.1.cmml"></mi><mn id="id6.6.1.m1.1.1.1" mathvariant="normal" xref="id6.6.1.m1.1.1.1.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="id6.6.1.m1.1b"><apply id="id6.6.1.m1.1.1.cmml" xref="id6.6.1.m1.1.1"><cn id="id6.6.1.m1.1.1.1.cmml" type="integer" xref="id6.6.1.m1.1.1.1">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id6.6.1.m1.1c">{}^{2}</annotation><annotation encoding="application/x-llamapun" id="id6.6.1.m1.1d">start_FLOATSUPERSCRIPT 2 end_FLOATSUPERSCRIPT</annotation></semantics></math></span>, <span class="ltx_text ltx_font_bold" id="id7.7.2"> Zhi Jin<math alttext="{}^{1\dagger}" class="ltx_Math" display="inline" id="id7.7.2.m1.2"><semantics id="id7.7.2.m1.2a"><msup id="id7.7.2.m1.2.2" xref="id7.7.2.m1.2.2.cmml"><mi id="id7.7.2.m1.2.2a" xref="id7.7.2.m1.2.2.cmml"></mi><mrow id="id7.7.2.m1.2.2.2.4" xref="id7.7.2.m1.2.2.2.3.cmml"><mn id="id7.7.2.m1.1.1.1.1" mathvariant="normal" xref="id7.7.2.m1.1.1.1.1.cmml">1</mn><mo id="id7.7.2.m1.2.2.2.4.1" lspace="0.222em" mathvariant="bold" xref="id7.7.2.m1.2.2.2.3.cmml">⁣</mo><mo id="id7.7.2.m1.2.2.2.2" mathvariant="normal" xref="id7.7.2.m1.2.2.2.2.cmml">†</mo></mrow></msup><annotation-xml encoding="MathML-Content" id="id7.7.2.m1.2b"><apply id="id7.7.2.m1.2.2.cmml" xref="id7.7.2.m1.2.2"><list id="id7.7.2.m1.2.2.2.3.cmml" xref="id7.7.2.m1.2.2.2.4"><cn id="id7.7.2.m1.1.1.1.1.cmml" type="integer" xref="id7.7.2.m1.1.1.1.1">1</cn><ci id="id7.7.2.m1.2.2.2.2.cmml" xref="id7.7.2.m1.2.2.2.2">normal-†</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="id7.7.2.m1.2c">{}^{1\dagger}</annotation><annotation encoding="application/x-llamapun" id="id7.7.2.m1.2d">start_FLOATSUPERSCRIPT 1 † end_FLOATSUPERSCRIPT</annotation></semantics></math></span>, <span class="ltx_text ltx_font_bold" id="id8.8.3">Fei Huang<math alttext="{}^{2}" class="ltx_Math" display="inline" id="id8.8.3.m1.1"><semantics id="id8.8.3.m1.1a"><msup id="id8.8.3.m1.1.1" xref="id8.8.3.m1.1.1.cmml"><mi id="id8.8.3.m1.1.1a" xref="id8.8.3.m1.1.1.cmml"></mi><mn id="id8.8.3.m1.1.1.1" mathvariant="normal" xref="id8.8.3.m1.1.1.1.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="id8.8.3.m1.1b"><apply id="id8.8.3.m1.1.1.cmml" xref="id8.8.3.m1.1.1"><cn id="id8.8.3.m1.1.1.1.cmml" type="integer" xref="id8.8.3.m1.1.1.1">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id8.8.3.m1.1c">{}^{2}</annotation><annotation encoding="application/x-llamapun" id="id8.8.3.m1.1d">start_FLOATSUPERSCRIPT 2 end_FLOATSUPERSCRIPT</annotation></semantics></math></span>, <span class="ltx_text ltx_font_bold" id="id9.9.4">Dacheng Tao<math alttext="{}^{3}" class="ltx_Math" display="inline" id="id9.9.4.m1.1"><semantics id="id9.9.4.m1.1a"><msup id="id9.9.4.m1.1.1" xref="id9.9.4.m1.1.1.cmml"><mi id="id9.9.4.m1.1.1a" xref="id9.9.4.m1.1.1.cmml"></mi><mn id="id9.9.4.m1.1.1.1" mathvariant="normal" xref="id9.9.4.m1.1.1.1.cmml">3</mn></msup><annotation-xml encoding="MathML-Content" id="id9.9.4.m1.1b"><apply id="id9.9.4.m1.1.1.cmml" xref="id9.9.4.m1.1.1"><cn id="id9.9.4.m1.1.1.1.cmml" type="integer" xref="id9.9.4.m1.1.1.1">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id9.9.4.m1.1c">{}^{3}</annotation><annotation encoding="application/x-llamapun" id="id9.9.4.m1.1d">start_FLOATSUPERSCRIPT 3 end_FLOATSUPERSCRIPT</annotation></semantics></math></span>, <span class="ltx_text ltx_font_bold" id="id10.10.5">Jingren Zhou<math alttext="{}^{2}" class="ltx_Math" display="inline" id="id10.10.5.m1.1"><semantics id="id10.10.5.m1.1a"><msup id="id10.10.5.m1.1.1" xref="id10.10.5.m1.1.1.cmml"><mi id="id10.10.5.m1.1.1a" xref="id10.10.5.m1.1.1.cmml"></mi><mn id="id10.10.5.m1.1.1.1" mathvariant="normal" xref="id10.10.5.m1.1.1.1.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="id10.10.5.m1.1b"><apply id="id10.10.5.m1.1.1.cmml" xref="id10.10.5.m1.1.1"><cn id="id10.10.5.m1.1.1.1.cmml" type="integer" xref="id10.10.5.m1.1.1.1">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id10.10.5.m1.1c">{}^{2}</annotation><annotation encoding="application/x-llamapun" id="id10.10.5.m1.1d">start_FLOATSUPERSCRIPT 2 end_FLOATSUPERSCRIPT</annotation></semantics></math></span>
<br class="ltx_break"/><math alttext="{}^{1}" class="ltx_Math" display="inline" id="id11.11.m6.1"><semantics id="id11.11.m6.1a"><msup id="id11.11.m6.1.1" xref="id11.11.m6.1.1.cmml"><mi id="id11.11.m6.1.1a" xref="id11.11.m6.1.1.cmml"></mi><mn id="id11.11.m6.1.1.1" xref="id11.11.m6.1.1.1.cmml">1</mn></msup><annotation-xml encoding="MathML-Content" id="id11.11.m6.1b"><apply id="id11.11.m6.1.1.cmml" xref="id11.11.m6.1.1"><cn id="id11.11.m6.1.1.1.cmml" type="integer" xref="id11.11.m6.1.1.1">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id11.11.m6.1c">{}^{1}</annotation><annotation encoding="application/x-llamapun" id="id11.11.m6.1d">start_FLOATSUPERSCRIPT 1 end_FLOATSUPERSCRIPT</annotation></semantics></math> Key Lab of HCST (PKU), MOE; School of Computer Science, Peking University 
<br class="ltx_break"/><math alttext="{}^{2}" class="ltx_Math" display="inline" id="id12.12.m7.1"><semantics id="id12.12.m7.1a"><msup id="id12.12.m7.1.1" xref="id12.12.m7.1.1.cmml"><mi id="id12.12.m7.1.1a" xref="id12.12.m7.1.1.cmml"></mi><mn id="id12.12.m7.1.1.1" xref="id12.12.m7.1.1.1.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="id12.12.m7.1b"><apply id="id12.12.m7.1.1.cmml" xref="id12.12.m7.1.1"><cn id="id12.12.m7.1.1.1.cmml" type="integer" xref="id12.12.m7.1.1.1">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id12.12.m7.1c">{}^{2}</annotation><annotation encoding="application/x-llamapun" id="id12.12.m7.1d">start_FLOATSUPERSCRIPT 2 end_FLOATSUPERSCRIPT</annotation></semantics></math>Alibaba Group  <math alttext="{}^{3}" class="ltx_Math" display="inline" id="id13.13.m8.1"><semantics id="id13.13.m8.1a"><msup id="id13.13.m8.1.1" xref="id13.13.m8.1.1.cmml"><mi id="id13.13.m8.1.1a" xref="id13.13.m8.1.1.cmml"></mi><mn id="id13.13.m8.1.1.1" xref="id13.13.m8.1.1.1.cmml">3</mn></msup><annotation-xml encoding="MathML-Content" id="id13.13.m8.1b"><apply id="id13.13.m8.1.1.cmml" xref="id13.13.m8.1.1"><cn id="id13.13.m8.1.1.1.cmml" type="integer" xref="id13.13.m8.1.1.1">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id13.13.m8.1c">{}^{3}</annotation><annotation encoding="application/x-llamapun" id="id13.13.m8.1d">start_FLOATSUPERSCRIPT 3 end_FLOATSUPERSCRIPT</annotation></semantics></math>Nanyang Technological University 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id14.14.id1">{tttzw, xiancaich}@stu.pku.edu.cn</span>,  <span class="ltx_text ltx_font_typewriter" id="id15.15.id2">zhijin@pku.edu.cn</span>
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id16.16.id3">{ting-en.lte, shengxiu.wyc, shuide.lyb, jingren.zhou}@alibaba-inc.com</span>
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id17.17.id4">dacheng.tao@ntu.edu.sg</span>
<br class="ltx_break"/>
</span><span class="ltx_author_notes">Work done while interning at Alibaba Group.Corresponding authors.</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">摘要</h6>
<p class="ltx_p" id="id18.id1">大型语言模型（LLMs）在各个领域和智能代理应用中取得了显著进展。然而，目前从人类或外部模型监督中学习的LLMs成本高，随着任务复杂性和多样性的增加可能面临性能瓶颈。为了解决这个问题，使LLM能够自主获取、完善和学习模型自身生成的经验的自我演化方法正在迅速发展。这种受人类经验学习过程启发的新训练范式为将LLMs扩展到超级智能提供了潜力。在这项工作中，我们提出了LLMs中自我演化方法的综合调查。首先，我们提出了自我演化的概念框架，并将演化过程概述为由四个阶段组成的迭代循环：经验获取、经验完善、更新和评估。其次，我们对LLMs和基于LLM的代理的演化目标进行分类；然后，我们总结了文献，为每个模块提供了分类法和见解。最后，我们指出了现有的挑战，并提出了改进自我演化框架的未来方向，为研究人员提供了关键见解，以加快自我演化LLMs的发展。我们相应的GitHub存储库可在<a class="ltx_ref ltx_href" href="https://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/Awesome-Self-Evolution-of-LLM" title="">https://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/Awesome-Self-Evolution-of-LLM</a>上找到。</p>
</div>
<div class="ltx_para ltx_noindent" id="p1">
<p class="ltx_p ltx_align_center ltx_align_bottom" id="p1.1"><span class="ltx_text ltx_font_bold" id="p1.1.1">大型语言模型自我演变调查</span></p>
</div>
<div class="ltx_para" id="p2">
<br class="ltx_break"/>
<p class="ltx_p" id="p2.13"><span class="ltx_text" id="p2.13.13" style="width:433.6pt;"><span class="ltx_text" id="p2.13.13.13" style="width:0.0pt;">
<span class="ltx_tabular ltx_align_top" id="p2.13.13.13.13">
<span class="ltx_tbody">
<span class="ltx_tr" id="p2.5.5.5.5.5">
<span class="ltx_td ltx_align_center" id="p2.5.5.5.5.5.5"><span class="ltx_text ltx_font_bold" id="p2.5.5.5.5.5.5.5">陶正伟<math alttext="{}^{12}" class="ltx_Math" display="inline" id="p2.1.1.1.1.1.1.1.m1.1"><semantics id="p2.1.1.1.1.1.1.1.m1.1a"><msup id="p2.1.1.1.1.1.1.1.m1.1.1" xref="p2.1.1.1.1.1.1.1.m1.1.1.cmml"><mi id="p2.1.1.1.1.1.1.1.m1.1.1a" xref="p2.1.1.1.1.1.1.1.m1.1.1.cmml"></mi><mn id="p2.1.1.1.1.1.1.1.m1.1.1.1" mathvariant="normal" xref="p2.1.1.1.1.1.1.1.m1.1.1.1.cmml">12</mn></msup><annotation-xml encoding="MathML-Content" id="p2.1.1.1.1.1.1.1.m1.1b"><apply id="p2.1.1.1.1.1.1.1.m1.1.1.cmml" xref="p2.1.1.1.1.1.1.1.m1.1.1"><cn id="p2.1.1.1.1.1.1.1.m1.1.1.1.cmml" type="integer" xref="p2.1.1.1.1.1.1.1.m1.1.1.1">12</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="p2.1.1.1.1.1.1.1.m1.1c">{}^{12}</annotation><annotation encoding="application/x-llamapun" id="p2.1.1.1.1.1.1.1.m1.1d">start_FLOATSUPERSCRIPT 12 end_FLOATSUPERSCRIPT</annotation></semantics></math><span class="ltx_note ltx_role_thanks" id="p2.5.5.5.5.5.5.5.1"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">致谢： </span>实习期间在阿里巴巴集团完成的工作。</span></span></span>, 林廷恩<math alttext="{}^{2}" class="ltx_Math" display="inline" id="p2.2.2.2.2.2.2.2.m2.1"><semantics id="p2.2.2.2.2.2.2.2.m2.1a"><msup id="p2.2.2.2.2.2.2.2.m2.1.1" xref="p2.2.2.2.2.2.2.2.m2.1.1.cmml"><mi id="p2.2.2.2.2.2.2.2.m2.1.1a" xref="p2.2.2.2.2.2.2.2.m2.1.1.cmml"></mi><mn id="p2.2.2.2.2.2.2.2.m2.1.1.1" mathvariant="normal" xref="p2.2.2.2.2.2.2.2.m2.1.1.1.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="p2.2.2.2.2.2.2.2.m2.1b"><apply id="p2.2.2.2.2.2.2.2.m2.1.1.cmml" xref="p2.2.2.2.2.2.2.2.m2.1.1"><cn id="p2.2.2.2.2.2.2.2.m2.1.1.1.cmml" type="integer" xref="p2.2.2.2.2.2.2.2.m2.1.1.1">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="p2.2.2.2.2.2.2.2.m2.1c">{}^{2}</annotation><annotation encoding="application/x-llamapun" id="p2.2.2.2.2.2.2.2.m2.1d">start_FLOATSUPERSCRIPT 2 end_FLOATSUPERSCRIPT</annotation></semantics></math>, 陈贤才<math alttext="{}^{1}" class="ltx_Math" display="inline" id="p2.3.3.3.3.3.3.3.m3.1"><semantics id="p2.3.3.3.3.3.3.3.m3.1a"><msup id="p2.3.3.3.3.3.3.3.m3.1.1" xref="p2.3.3.3.3.3.3.3.m3.1.1.cmml"><mi id="p2.3.3.3.3.3.3.3.m3.1.1a" xref="p2.3.3.3.3.3.3.3.m3.1.1.cmml"></mi><mn id="p2.3.3.3.3.3.3.3.m3.1.1.1" mathvariant="normal" xref="p2.3.3.3.3.3.3.3.m3.1.1.1.cmml">1</mn></msup><annotation-xml encoding="MathML-Content" id="p2.3.3.3.3.3.3.3.m3.1b"><apply id="p2.3.3.3.3.3.3.3.m3.1.1.cmml" xref="p2.3.3.3.3.3.3.3.m3.1.1"><cn id="p2.3.3.3.3.3.3.3.m3.1.1.1.cmml" type="integer" xref="p2.3.3.3.3.3.3.3.m3.1.1.1">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="p2.3.3.3.3.3.3.3.m3.1c">{}^{1}</annotation><annotation encoding="application/x-llamapun" id="p2.3.3.3.3.3.3.3.m3.1d">start_FLOATSUPERSCRIPT 1 end_FLOATSUPERSCRIPT</annotation></semantics></math>, 李航宇<math alttext="{}^{2}" class="ltx_Math" display="inline" id="p2.4.4.4.4.4.4.4.m4.1"><semantics id="p2.4.4.4.4.4.4.4.m4.1a"><msup id="p2.4.4.4.4.4.4.4.m4.1.1" xref="p2.4.4.4.4.4.4.4.m4.1.1.cmml"><mi id="p2.4.4.4.4.4.4.4.m4.1.1a" xref="p2.4.4.4.4.4.4.4.m4.1.1.cmml"></mi><mn id="p2.4.4.4.4.4.4.4.m4.1.1.1" mathvariant="normal" xref="p2.4.4.4.4.4.4.4.m4.1.1.1.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="p2.4.4.4.4.4.4.4.m4.1b"><apply id="p2.4.4.4.4.4.4.4.m4.1.1.cmml" xref="p2.4.4.4.4.4.4.4.m4.1.1"><cn id="p2.4.4.4.4.4.4.4.m4.1.1.1.cmml" type="integer" xref="p2.4.4.4.4.4.4.4.m4.1.1.1">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="p2.4.4.4.4.4.4.4.m4.1c">{}^{2}</annotation><annotation encoding="application/x-llamapun" id="p2.4.4.4.4.4.4.4.m4.1d">start_FLOATSUPERSCRIPT 2 end_FLOATSUPERSCRIPT</annotation></semantics></math>, 吴宇川<math alttext="{}^{2}" class="ltx_Math" display="inline" id="p2.5.5.5.5.5.5.5.m5.1"><semantics id="p2.5.5.5.5.5.5.5.m5.1a"><msup id="p2.5.5.5.5.5.5.5.m5.1.1" xref="p2.5.5.5.5.5.5.5.m5.1.1.cmml"><mi id="p2.5.5.5.5.5.5.5.m5.1.1a" xref="p2.5.5.5.5.5.5.5.m5.1.1.cmml"></mi><mn id="p2.5.5.5.5.5.5.5.m5.1.1.1" mathvariant="normal" xref="p2.5.5.5.5.5.5.5.m5.1.1.1.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="p2.5.5.5.5.5.5.5.m5.1b"><apply id="p2.5.5.5.5.5.5.5.m5.1.1.cmml" xref="p2.5.5.5.5.5.5.5.m5.1.1"><cn id="p2.5.5.5.5.5.5.5.m5.1.1.1.cmml" type="integer" xref="p2.5.5.5.5.5.5.5.m5.1.1.1">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="p2.5.5.5.5.5.5.5.m5.1c">{}^{2}</annotation><annotation encoding="application/x-llamapun" id="p2.5.5.5.5.5.5.5.m5.1d">start_FLOATSUPERSCRIPT 2 end_FLOATSUPERSCRIPT</annotation></semantics></math>,</span></span></span>
<span class="ltx_tr" id="p2.10.10.10.10.10">
<span class="ltx_td ltx_align_center" id="p2.10.10.10.10.10.5"><span class="ltx_text ltx_font_bold" id="p2.6.6.6.6.6.1.1">李永斌<math alttext="{}^{2}" class="ltx_Math" display="inline" id="p2.6.6.6.6.6.1.1.m1.1"><semantics id="p2.6.6.6.6.6.1.1.m1.1a"><msup id="p2.6.6.6.6.6.1.1.m1.1.1" xref="p2.6.6.6.6.6.1.1.m1.1.1.cmml"><mi id="p2.6.6.6.6.6.1.1.m1.1.1a" xref="p2.6.6.6.6.6.1.1.m1.1.1.cmml"></mi><mn id="p2.6.6.6.6.6.1.1.m1.1.1.1" mathvariant="normal" xref="p2.6.6.6.6.6.1.1.m1.1.1.1.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="p2.6.6.6.6.6.1.1.m1.1b"><apply id="p2.6.6.6.6.6.1.1.m1.1.1.cmml" xref="p2.6.6.6.6.6.1.1.m1.1.1"><cn id="p2.6.6.6.6.6.1.1.m1.1.1.1.cmml" type="integer" xref="p2.6.6.6.6.6.1.1.m1.1.1.1">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="p2.6.6.6.6.6.1.1.m1.1c">{}^{2}</annotation><annotation encoding="application/x-llamapun" id="p2.6.6.6.6.6.1.1.m1.1d">start_FLOATSUPERSCRIPT 2 end_FLOATSUPERSCRIPT</annotation></semantics></math><span class="ltx_note ltx_role_thanks" id="p2.6.6.6.6.6.1.1.1"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">致谢： </span><span class="ltx_text ltx_font_medium" id="p2.6.6.6.6.6.1.1.1.1">通讯作者。</span></span></span></span></span>, <span class="ltx_text ltx_font_bold" id="p2.7.7.7.7.7.2.2"> 金智<math alttext="{}^{1\dagger}" class="ltx_Math" display="inline" id="p2.7.7.7.7.7.2.2.m1.2"><semantics id="p2.7.7.7.7.7.2.2.m1.2a"><msup id="p2.7.7.7.7.7.2.2.m1.2.2" xref="p2.7.7.7.7.7.2.2.m1.2.2.cmml"><mi id="p2.7.7.7.7.7.2.2.m1.2.2a" xref="p2.7.7.7.7.7.2.2.m1.2.2.cmml"></mi><mrow id="p2.7.7.7.7.7.2.2.m1.2.2.2.4" xref="p2.7.7.7.7.7.2.2.m1.2.2.2.3.cmml"><mn id="p2.7.7.7.7.7.2.2.m1.1.1.1.1" mathvariant="normal" xref="p2.7.7.7.7.7.2.2.m1.1.1.1.1.cmml">1</mn><mo id="p2.7.7.7.7.7.2.2.m1.2.2.2.4.1" lspace="0.222em" mathvariant="bold" xref="p2.7.7.7.7.7.2.2.m1.2.2.2.3.cmml">⁣</mo><mo id="p2.7.7.7.7.7.2.2.m1.2.2.2.2" mathvariant="normal" xref="p2.7.7.7.7.7.2.2.m1.2.2.2.2.cmml">†</mo></mrow></msup><annotation-xml encoding="MathML-Content" id="p2.7.7.7.7.7.2.2.m1.2b"><apply id="p2.7.7.7.7.7.2.2.m1.2.2.cmml" xref="p2.7.7.7.7.7.2.2.m1.2.2"><list id="p2.7.7.7.7.7.2.2.m1.2.2.2.3.cmml" xref="p2.7.7.7.7.7.2.2.m1.2.2.2.4"><cn id="p2.7.7.7.7.7.2.2.m1.1.1.1.1.cmml" type="integer" xref="p2.7.7.7.7.7.2.2.m1.1.1.1.1">1</cn><ci id="p2.7.7.7.7.7.2.2.m1.2.2.2.2.cmml" xref="p2.7.7.7.7.7.2.2.m1.2.2.2.2">normal-†</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="p2.7.7.7.7.7.2.2.m1.2c">{}^{1\dagger}</annotation><annotation encoding="application/x-llamapun" id="p2.7.7.7.7.7.2.2.m1.2d">start_FLOATSUPERSCRIPT 1 † end_FLOATSUPERSCRIPT</annotation></semantics></math></span>, <span class="ltx_text ltx_font_bold" id="p2.8.8.8.8.8.3.3">黄菲<math alttext="{}^{2}" class="ltx_Math" display="inline" id="p2.8.8.8.8.8.3.3.m1.1"><semantics id="p2.8.8.8.8.8.3.3.m1.1a"><msup id="p2.8.8.8.8.8.3.3.m1.1.1" xref="p2.8.8.8.8.8.3.3.m1.1.1.cmml"><mi id="p2.8.8.8.8.8.3.3.m1.1.1a" xref="p2.8.8.8.8.8.3.3.m1.1.1.cmml"></mi><mn id="p2.8.8.8.8.8.3.3.m1.1.1.1" mathvariant="normal" xref="p2.8.8.8.8.8.3.3.m1.1.1.1.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="p2.8.8.8.8.8.3.3.m1.1b"><apply id="p2.8.8.8.8.8.3.3.m1.1.1.cmml" xref="p2.8.8.8.8.8.3.3.m1.1.1"><cn id="p2.8.8.8.8.8.3.3.m1.1.1.1.cmml" type="integer" xref="p2.8.8.8.8.8.3.3.m1.1.1.1">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="p2.8.8.8.8.8.3.3.m1.1c">{}^{2}</annotation><annotation encoding="application/x-llamapun" id="p2.8.8.8.8.8.3.3.m1.1d">start_FLOATSUPERSCRIPT 2 end_FLOATSUPERSCRIPT</annotation></semantics></math></span>, <span class="ltx_text ltx_font_bold" id="p2.9.9.9.9.9.4.4">陶大成<math alttext="{}^{3}" class="ltx_Math" display="inline" id="p2.9.9.9.9.9.4.4.m1.1"><semantics id="p2.9.9.9.9.9.4.4.m1.1a"><msup id="p2.9.9.9.9.9.4.4.m1.1.1" xref="p2.9.9.9.9.9.4.4.m1.1.1.cmml"><mi id="p2.9.9.9.9.9.4.4.m1.1.1a" xref="p2.9.9.9.9.9.4.4.m1.1.1.cmml"></mi><mn id="p2.9.9.9.9.9.4.4.m1.1.1.1" mathvariant="normal" xref="p2.9.9.9.9.9.4.4.m1.1.1.1.cmml">3</mn></msup><annotation-xml encoding="MathML-Content" id="p2.9.9.9.9.9.4.4.m1.1b"><apply id="p2.9.9.9.9.9.4.4.m1.1.1.cmml" xref="p2.9.9.9.9.9.4.4.m1.1.1"><cn id="p2.9.9.9.9.9.4.4.m1.1.1.1.cmml" type="integer" xref="p2.9.9.9.9.9.4.4.m1.1.1.1">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="p2.9.9.9.9.9.4.4.m1.1c">{}^{3}</annotation><annotation encoding="application/x-llamapun" id="p2.9.9.9.9.9.4.4.m1.1d">start_FLOATSUPERSCRIPT 3 end_FLOATSUPERSCRIPT</annotation></semantics></math></span>, <span class="ltx_text ltx_font_bold" id="p2.10.10.10.10.10.5.5">周靖仁<math alttext="{}^{2}" class="ltx_Math" display="inline" id="p2.10.10.10.10.10.5.5.m1.1"><semantics id="p2.10.10.10.10.10.5.5.m1.1a"><msup id="p2.10.10.10.10.10.5.5.m1.1.1" xref="p2.10.10.10.10.10.5.5.m1.1.1.cmml"><mi id="p2.10.10.10.10.10.5.5.m1.1.1a" xref="p2.10.10.10.10.10.5.5.m1.1.1.cmml"></mi><mn id="p2.10.10.10.10.10.5.5.m1.1.1.1" mathvariant="normal" xref="p2.10.10.10.10.10.5.5.m1.1.1.1.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="p2.10.10.10.10.10.5.5.m1.1b"><apply id="p2.10.10.10.10.10.5.5.m1.1.1.cmml" xref="p2.10.10.10.10.10.5.5.m1.1.1"><cn id="p2.10.10.10.10.10.5.5.m1.1.1.1.cmml" type="integer" xref="p2.10.10.10.10.10.5.5.m1.1.1.1">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="p2.10.10.10.10.10.5.5.m1.1c">{}^{2}</annotation><annotation encoding="application/x-llamapun" id="p2.10.10.10.10.10.5.5.m1.1d">start_FLOATSUPERSCRIPT 2 end_FLOATSUPERSCRIPT</annotation></semantics></math></span></span></span>
<span class="ltx_tr" id="p2.11.11.11.11.11">
<span class="ltx_td ltx_align_center" id="p2.11.11.11.11.11.1"><math alttext="{}^{1}" class="ltx_Math" display="inline" id="p2.11.11.11.11.11.1.m1.1"><semantics id="p2.11.11.11.11.11.1.m1.1a"><msup id="p2.11.11.11.11.11.1.m1.1.1" xref="p2.11.11.11.11.11.1.m1.1.1.cmml"><mi id="p2.11.11.11.11.11.1.m1.1.1a" xref="p2.11.11.11.11.11.1.m1.1.1.cmml"></mi><mn id="p2.11.11.11.11.11.1.m1.1.1.1" xref="p2.11.11.11.11.11.1.m1.1.1.1.cmml">1</mn></msup><annotation-xml encoding="MathML-Content" id="p2.11.11.11.11.11.1.m1.1b"><apply id="p2.11.11.11.11.11.1.m1.1.1.cmml" xref="p2.11.11.11.11.11.1.m1.1.1"><cn id="p2.11.11.11.11.11.1.m1.1.1.1.cmml" type="integer" xref="p2.11.11.11.11.11.1.m1.1.1.1">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="p2.11.11.11.11.11.1.m1.1c">{}^{1}</annotation><annotation encoding="application/x-llamapun" id="p2.11.11.11.11.11.1.m1.1d">start_FLOATSUPERSCRIPT 1 end_FLOATSUPERSCRIPT</annotation></semantics></math> 北京大学计算机学院 HCST重点实验室; 阿里巴巴集团</span></span>
<span class="ltx_tr" id="p2.13.13.13.13.13">
<span class="ltx_td ltx_align_center" id="p2.13.13.13.13.13.2"><math alttext="{}^{2}" class="ltx_Math" display="inline" id="p2.12.12.12.12.12.1.m1.1"><semantics id="p2.12.12.12.12.12.1.m1.1a"><msup id="p2.12.12.12.12.12.1.m1.1.1" xref="p2.12.12.12.12.12.1.m1.1.1.cmml"><mi id="p2.12.12.12.12.12.1.m1.1.1a" xref="p2.12.12.12.12.12.1.m1.1.1.cmml"></mi><mn id="p2.12.12.12.12.12.1.m1.1.1.1" xref="p2.12.12.12.12.12.1.m1.1.1.1.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="p2.12.12.12.12.12.1.m1.1b"><apply id="p2.12.12.12.12.12.1.m1.1.1.cmml" xref="p2.12.12.12.12.12.1.m1.1.1"><cn id="p2.12.12.12.12.12.1.m1.1.1.1.cmml" type="integer" xref="p2.12.12.12.12.12.1.m1.1.1.1">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="p2.12.12.12.12.12.1.m1.1c">{}^{2}</annotation><annotation encoding="application/x-llamapun" id="p2.12.12.12.12.12.1.m1.1d">start_FLOATSUPERSCRIPT 2 end_FLOATSUPERSCRIPT</annotation></semantics></math>阿里巴巴集团  新加坡南洋理工大学</span></span>
<span class="ltx_tr" id="p2.13.13.13.13.14.1">
<span class="ltx_td ltx_align_center" id="p2.13.13.13.13.14.1.1"><span class="ltx_text ltx_font_typewriter" id="p2.13.13.13.13.14.1.1.1">{tttzw, xiancaich}@stu.pku.edu.cn</span>,  <span class="ltx_text ltx_font_typewriter" id="p2.13.13.13.13.14.1.1.2">zhijin@pku.edu.cn</span></span></span>
<span class="ltx_tr" id="p2.13.13.13.13.15.2">
<span class="ltx_td ltx_align_center" id="p2.13.13.13.13.15.2.1"><span class="ltx_text ltx_font_typewriter" id="p2.13.13.13.13.15.2.1.1">{ting-en.lte, shengxiu.wyc, shuide.lyb, jingren.zhou}@alibaba-inc.com</span></span></span>
<span class="ltx_tr" id="p2.13.13.13.13.16.3">
<span class="ltx_td ltx_align_center" id="p2.13.13.13.13.16.3.1"><span class="ltx_text ltx_font_typewriter" id="p2.13.13.13.13.16.3.1.1">dacheng.tao@ntu.edu.sg</span></span></span>
</span>
</span></span> </span></p>
</div>
<figure class="ltx_figure" id="S0.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="211" id="S0.F1.g1" src="resource/x1.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">图1： </span>LLM的训练范式转变。</figcaption>
</figure>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">1 </span>介绍</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">随着人工智能的迅速发展，像GPT-3.5 <cite class="ltx_cite ltx_citemacro_cite">Ouyang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib83" title="">2022</a>)</cite>，GPT-4 <cite class="ltx_cite ltx_citemacro_cite">Achiam et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib1" title="">2023</a>)</cite>，Gemini <cite class="ltx_cite ltx_citemacro_cite">Team et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib113" title="">2023</a>)</cite>，LLaMA <cite class="ltx_cite ltx_citemacro_cite">Touvron et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib115" title="">2023a</a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib116" title="">b</a>)</cite>和Qwen <cite class="ltx_cite ltx_citemacro_cite">Bai et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib8" title="">2023</a>)</cite>这样的大型语言模型（LLMs）标志着语言理解和生成的重大转变。这些模型经历了三个发展阶段，如图<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#S0.F1" title="Figure 1 ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_tag">1</span></a>所示：在大型和多样化语料库上进行预训练，以获得对语言和世界知识的普遍理解<cite class="ltx_cite ltx_citemacro_cite">Devlin et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib30" title="">2018</a>); Brown et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib14" title="">2020</a>)</cite>，然后进行监督微调以引出下游任务的能力<cite class="ltx_cite ltx_citemacro_cite">Raffel et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib91" title="">2020</a>); Chung et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib25" title="">2022</a>)</cite>。最后，人类偏好对齐训练使LLMs能够以人类行为做出响应<cite class="ltx_cite ltx_citemacro_cite">Ouyang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib83" title="">2022</a>)</cite>。这种连续的训练范式取得了重大突破，使LLMs能够以令人瞩目的零-shot和上下文能力执行各种任务，如问答<cite class="ltx_cite ltx_citemacro_cite">Tan et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib109" title="">2023</a>)</cite>，数学推理<cite class="ltx_cite ltx_citemacro_cite">Collins et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib26" title="">2023</a>)</cite>，代码生成<cite class="ltx_cite ltx_citemacro_cite">Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib71" title="">2024b</a>)</cite>，以及需要与环境互动的任务解决<cite class="ltx_cite ltx_citemacro_cite">Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib73" title="">2023b</a>)</cite>。</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">尽管取得了这些进展，人们期待新一代LLM可以被分配更复杂的任务，比如科学发现<cite class="ltx_cite ltx_citemacro_cite">Miret and Krishnan (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib81" title="">2024</a>)</cite>和未来事件预测<cite class="ltx_cite ltx_citemacro_cite">Schoenegger et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib95" title="">2024</a>)</cite>。然而，由于现有训练范式中建模、注释和评估的固有困难，当前的LLM在这些复杂任务中遇到挑战<cite class="ltx_cite ltx_citemacro_cite">Burns et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib15" title="">2023</a>)</cite>。
此外，最近开发的Llama-3模型已经在包含15万亿标记的广泛语料库上进行了训练<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>https://huggingface.co/meta-llama/Meta-Llama-3-70B-Instruct</span></span></span>。这是一个巨大的数据量，表明通过增加更多真实世界的数据来显著提高模型性能可能会受到限制。
这引起了对LLM自我进化机制的兴趣，类似于人类智能的自然演化，并在游戏中体现为AI的发展，比如从AlphaGo<cite class="ltx_cite ltx_citemacro_cite">Silver et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib101" title="">2016</a>)</cite>到AlphaZero<cite class="ltx_cite ltx_citemacro_cite">Silver et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib102" title="">2017</a>)</cite>的转变。AlphaZero的自我对弈方法，不需要标记的数据，展示了LLM超越当前限制、实现超人类表现的路径，而无需进行大量人类监督。</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">受上述范例的启发，关于LLM自我演化的研究在模型开发的不同阶段迅速增加，例如自我指导<cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib127" title="">2023b</a>)</cite>，自我对弈<cite class="ltx_cite ltx_citemacro_cite">Tu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib117" title="">2024</a>)</cite>，自我改进<cite class="ltx_cite ltx_citemacro_cite">Huang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib52" title="">2022</a>)</cite>和自我训练<cite class="ltx_cite ltx_citemacro_cite">Gulcehre et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib42" title="">2023</a>)</cite>。值得注意的是，DeepMind的AMIE系统<cite class="ltx_cite ltx_citemacro_cite">Tu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib117" title="">2024</a>)</cite>在诊断准确性上胜过了初级保健医生，而微软的WizardLM-2<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>https://wizardlm.github.io/WizardLM2/</span></span></span>超过了GPT-4的初始版本的性能。这两种模型都是使用具有自主学习能力的自我演化框架开发的，并代表了潜在的LLM训练模式转变。然而，这些方法之间的关系仍不清楚，缺乏系统的组织和分析。</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">因此，我们首先全面调查了LLMs中的自我演化过程，并建立了它们发展的概念框架。这种自我演化的特点是通过涉及经验获取、经验优化、更新和评估的迭代循环来展现的，如图<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#S1.F2" title="Figure 2 ‣ 1 Introduction ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_tag">2</span></a>所示。在这个循环中，LLM最初通过演化新任务和生成相应的解决方案来获取经验，随后优化这些经验以获得更好的监督信号。在更新模型的内部权重或上下文后，LLM被评估以衡量进展并设定新的目标。</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">LLM中自我进化的概念在各种研究社区中引起了相当大的兴奋，承诺了一个新时代的模型，能够自适应、学习和自主改进，类似于人类对不断变化的环境和挑战的进化。自我进化的LLM不仅能够超越当前静态的、数据绑定的模型的限制，而且标志着向更加动态、强大和智能的系统的转变。这项调查通过一个结构化的概念框架全面地深化了对自我进化LLM新兴领域的理解。我们追溯了该领域从过去到最新的前沿方法和应用的发展，同时审视了现有的挑战并勾勒了未来的研究方向，为开发自我进化框架和下一代模型的重大进展铺平了道路。</p>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">调查分为以下几个部分：首先，我们首先介绍自我进化的概述（§ <a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#S2" title="2 Overview ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_tag">2</span></a>），包括背景和概念框架。
我们总结了当前方法的现有演化能力和领域（§ <a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#S3" title="3 Evolution Objectives ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_tag">3</span></a>）。
然后，我们对自我进化过程的不同阶段的最新进展进行了深入分析和讨论，包括经验获取（§ <a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#S4" title="4 Experience Acquisition ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_tag">4</span></a>），经验完善（§ <a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#S5" title="5 Experience Refinement ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_tag">5</span></a>），更新（§ <a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#S6" title="6 Updating ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_tag">6</span></a>），和评估（§ <a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#S7" title="7 Evaluation ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_tag">7</span></a>）。
最后，我们概述了开放的问题和未来的发展方向（§ <a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#S8" title="8 Open Problems ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_tag">8</span></a>）。</p>
</div>
<figure class="ltx_figure" id="S1.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="747" id="S1.F2.g1" src="resource/x2.png" width="1743"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">图2：</span>自我进化的概念框架。对于<math alttext="t^{th}" class="ltx_Math" display="inline" id="S1.F2.12.m1.1"><semantics id="S1.F2.12.m1.1b"><msup id="S1.F2.12.m1.1.1" xref="S1.F2.12.m1.1.1.cmml"><mi id="S1.F2.12.m1.1.1.2" xref="S1.F2.12.m1.1.1.2.cmml">t</mi><mrow id="S1.F2.12.m1.1.1.3" xref="S1.F2.12.m1.1.1.3.cmml"><mi id="S1.F2.12.m1.1.1.3.2" xref="S1.F2.12.m1.1.1.3.2.cmml">t</mi><mo id="S1.F2.12.m1.1.1.3.1" xref="S1.F2.12.m1.1.1.3.1.cmml">⁢</mo><mi id="S1.F2.12.m1.1.1.3.3" xref="S1.F2.12.m1.1.1.3.3.cmml">h</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S1.F2.12.m1.1c"><apply id="S1.F2.12.m1.1.1.cmml" xref="S1.F2.12.m1.1.1"><csymbol cd="ambiguous" id="S1.F2.12.m1.1.1.1.cmml" xref="S1.F2.12.m1.1.1">superscript</csymbol><ci id="S1.F2.12.m1.1.1.2.cmml" xref="S1.F2.12.m1.1.1.2">𝑡</ci><apply id="S1.F2.12.m1.1.1.3.cmml" xref="S1.F2.12.m1.1.1.3"><times id="S1.F2.12.m1.1.1.3.1.cmml" xref="S1.F2.12.m1.1.1.3.1"></times><ci id="S1.F2.12.m1.1.1.3.2.cmml" xref="S1.F2.12.m1.1.1.3.2">𝑡</ci><ci id="S1.F2.12.m1.1.1.3.3.cmml" xref="S1.F2.12.m1.1.1.3.3">ℎ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.12.m1.1d">t^{th}</annotation><annotation encoding="application/x-llamapun" id="S1.F2.12.m1.1e">italic_t start_POSTSUPERSCRIPT italic_t italic_h end_POSTSUPERSCRIPT</annotation></semantics></math>迭代：<math alttext="{\mathcal{E}}^{t}" class="ltx_Math" display="inline" id="S1.F2.13.m2.1"><semantics id="S1.F2.13.m2.1b"><msup id="S1.F2.13.m2.1.1" xref="S1.F2.13.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S1.F2.13.m2.1.1.2" xref="S1.F2.13.m2.1.1.2.cmml">ℰ</mi><mi id="S1.F2.13.m2.1.1.3" xref="S1.F2.13.m2.1.1.3.cmml">t</mi></msup><annotation-xml encoding="MathML-Content" id="S1.F2.13.m2.1c"><apply id="S1.F2.13.m2.1.1.cmml" xref="S1.F2.13.m2.1.1"><csymbol cd="ambiguous" id="S1.F2.13.m2.1.1.1.cmml" xref="S1.F2.13.m2.1.1">superscript</csymbol><ci id="S1.F2.13.m2.1.1.2.cmml" xref="S1.F2.13.m2.1.1.2">ℰ</ci><ci id="S1.F2.13.m2.1.1.3.cmml" xref="S1.F2.13.m2.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.13.m2.1d">{\mathcal{E}}^{t}</annotation><annotation encoding="application/x-llamapun" id="S1.F2.13.m2.1e">caligraphic_E start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT</annotation></semantics></math>是进化目标；<math alttext="{\mathcal{T}}^{t}" class="ltx_Math" display="inline" id="S1.F2.14.m3.1"><semantics id="S1.F2.14.m3.1b"><msup id="S1.F2.14.m3.1.1" xref="S1.F2.14.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S1.F2.14.m3.1.1.2" xref="S1.F2.14.m3.1.1.2.cmml">𝒯</mi><mi id="S1.F2.14.m3.1.1.3" xref="S1.F2.14.m3.1.1.3.cmml">t</mi></msup><annotation-xml encoding="MathML-Content" id="S1.F2.14.m3.1c"><apply id="S1.F2.14.m3.1.1.cmml" xref="S1.F2.14.m3.1.1"><csymbol cd="ambiguous" id="S1.F2.14.m3.1.1.1.cmml" xref="S1.F2.14.m3.1.1">superscript</csymbol><ci id="S1.F2.14.m3.1.1.2.cmml" xref="S1.F2.14.m3.1.1.2">𝒯</ci><ci id="S1.F2.14.m3.1.1.3.cmml" xref="S1.F2.14.m3.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.14.m3.1d">{\mathcal{T}}^{t}</annotation><annotation encoding="application/x-llamapun" id="S1.F2.14.m3.1e">caligraphic_T start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT</annotation></semantics></math>和<math alttext="{\mathcal{Y}}^{t}" class="ltx_Math" display="inline" id="S1.F2.15.m4.1"><semantics id="S1.F2.15.m4.1b"><msup id="S1.F2.15.m4.1.1" xref="S1.F2.15.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S1.F2.15.m4.1.1.2" xref="S1.F2.15.m4.1.1.2.cmml">𝒴</mi><mi id="S1.F2.15.m4.1.1.3" xref="S1.F2.15.m4.1.1.3.cmml">t</mi></msup><annotation-xml encoding="MathML-Content" id="S1.F2.15.m4.1c"><apply id="S1.F2.15.m4.1.1.cmml" xref="S1.F2.15.m4.1.1"><csymbol cd="ambiguous" id="S1.F2.15.m4.1.1.1.cmml" xref="S1.F2.15.m4.1.1">superscript</csymbol><ci id="S1.F2.15.m4.1.1.2.cmml" xref="S1.F2.15.m4.1.1.2">𝒴</ci><ci id="S1.F2.15.m4.1.1.3.cmml" xref="S1.F2.15.m4.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.15.m4.1d">{\mathcal{Y}}^{t}</annotation><annotation encoding="application/x-llamapun" id="S1.F2.15.m4.1e">caligraphic_Y start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT</annotation></semantics></math>表示任务和解决方案；<math alttext="{\mathcal{F}}^{t}" class="ltx_Math" display="inline" id="S1.F2.16.m5.1"><semantics id="S1.F2.16.m5.1b"><msup id="S1.F2.16.m5.1.1" xref="S1.F2.16.m5.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S1.F2.16.m5.1.1.2" xref="S1.F2.16.m5.1.1.2.cmml">ℱ</mi><mi id="S1.F2.16.m5.1.1.3" xref="S1.F2.16.m5.1.1.3.cmml">t</mi></msup><annotation-xml encoding="MathML-Content" id="S1.F2.16.m5.1c"><apply id="S1.F2.16.m5.1.1.cmml" xref="S1.F2.16.m5.1.1"><csymbol cd="ambiguous" id="S1.F2.16.m5.1.1.1.cmml" xref="S1.F2.16.m5.1.1">superscript</csymbol><ci id="S1.F2.16.m5.1.1.2.cmml" xref="S1.F2.16.m5.1.1.2">ℱ</ci><ci id="S1.F2.16.m5.1.1.3.cmml" xref="S1.F2.16.m5.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.16.m5.1d">{\mathcal{F}}^{t}</annotation><annotation encoding="application/x-llamapun" id="S1.F2.16.m5.1e">caligraphic_F start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT</annotation></semantics></math>代表反馈；<math alttext="M^{t}" class="ltx_Math" display="inline" id="S1.F2.17.m6.1"><semantics id="S1.F2.17.m6.1b"><msup id="S1.F2.17.m6.1.1" xref="S1.F2.17.m6.1.1.cmml"><mi id="S1.F2.17.m6.1.1.2" xref="S1.F2.17.m6.1.1.2.cmml">M</mi><mi id="S1.F2.17.m6.1.1.3" xref="S1.F2.17.m6.1.1.3.cmml">t</mi></msup><annotation-xml encoding="MathML-Content" id="S1.F2.17.m6.1c"><apply id="S1.F2.17.m6.1.1.cmml" xref="S1.F2.17.m6.1.1"><csymbol cd="ambiguous" id="S1.F2.17.m6.1.1.1.cmml" xref="S1.F2.17.m6.1.1">superscript</csymbol><ci id="S1.F2.17.m6.1.1.2.cmml" xref="S1.F2.17.m6.1.1.2">𝑀</ci><ci id="S1.F2.17.m6.1.1.3.cmml" xref="S1.F2.17.m6.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.17.m6.1d">M^{t}</annotation><annotation encoding="application/x-llamapun" id="S1.F2.17.m6.1e">italic_M start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT</annotation></semantics></math>是当前模型。经过改进的经验标记为<math alttext="\tilde{{\mathcal{T}}}^{t}" class="ltx_Math" display="inline" id="S1.F2.18.m7.1"><semantics id="S1.F2.18.m7.1b"><msup id="S1.F2.18.m7.1.1" xref="S1.F2.18.m7.1.1.cmml"><mover accent="true" id="S1.F2.18.m7.1.1.2" xref="S1.F2.18.m7.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S1.F2.18.m7.1.1.2.2" xref="S1.F2.18.m7.1.1.2.2.cmml">𝒯</mi><mo id="S1.F2.18.m7.1.1.2.1" xref="S1.F2.18.m7.1.1.2.1.cmml">~</mo></mover><mi id="S1.F2.18.m7.1.1.3" xref="S1.F2.18.m7.1.1.3.cmml">t</mi></msup><annotation-xml encoding="MathML-Content" id="S1.F2.18.m7.1c"><apply id="S1.F2.18.m7.1.1.cmml" xref="S1.F2.18.m7.1.1"><csymbol cd="ambiguous" id="S1.F2.18.m7.1.1.1.cmml" xref="S1.F2.18.m7.1.1">superscript</csymbol><apply id="S1.F2.18.m7.1.1.2.cmml" xref="S1.F2.18.m7.1.1.2"><ci id="S1.F2.18.m7.1.1.2.1.cmml" xref="S1.F2.18.m7.1.1.2.1">~</ci><ci id="S1.F2.18.m7.1.1.2.2.cmml" xref="S1.F2.18.m7.1.1.2.2">𝒯</ci></apply><ci id="S1.F2.18.m7.1.1.3.cmml" xref="S1.F2.18.m7.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.18.m7.1d">\tilde{{\mathcal{T}}}^{t}</annotation><annotation encoding="application/x-llamapun" id="S1.F2.18.m7.1e">over~ start_ARG caligraphic_T end_ARG start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT</annotation></semantics></math>和<math alttext="\tilde{{\mathcal{Y}}}^{t}" class="ltx_Math" display="inline" id="S1.F2.19.m8.1"><semantics id="S1.F2.19.m8.1b"><msup id="S1.F2.19.m8.1.1" xref="S1.F2.19.m8.1.1.cmml"><mover accent="true" id="S1.F2.19.m8.1.1.2" xref="S1.F2.19.m8.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S1.F2.19.m8.1.1.2.2" xref="S1.F2.19.m8.1.1.2.2.cmml">𝒴</mi><mo id="S1.F2.19.m8.1.1.2.1" xref="S1.F2.19.m8.1.1.2.1.cmml">~</mo></mover><mi id="S1.F2.19.m8.1.1.3" xref="S1.F2.19.m8.1.1.3.cmml">t</mi></msup><annotation-xml encoding="MathML-Content" id="S1.F2.19.m8.1c"><apply id="S1.F2.19.m8.1.1.cmml" xref="S1.F2.19.m8.1.1"><csymbol cd="ambiguous" id="S1.F2.19.m8.1.1.1.cmml" xref="S1.F2.19.m8.1.1">superscript</csymbol><apply id="S1.F2.19.m8.1.1.2.cmml" xref="S1.F2.19.m8.1.1.2"><ci id="S1.F2.19.m8.1.1.2.1.cmml" xref="S1.F2.19.m8.1.1.2.1">~</ci><ci id="S1.F2.19.m8.1.1.2.2.cmml" xref="S1.F2.19.m8.1.1.2.2">𝒴</ci></apply><ci id="S1.F2.19.m8.1.1.3.cmml" xref="S1.F2.19.m8.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.19.m8.1d">\tilde{{\mathcal{Y}}}^{t}</annotation><annotation encoding="application/x-llamapun" id="S1.F2.19.m8.1e">over~ start_ARG caligraphic_Y end_ARG start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT</annotation></semantics></math>，导致进化的模型<math alttext="\tilde{M}" class="ltx_Math" display="inline" id="S1.F2.20.m9.1"><semantics id="S1.F2.20.m9.1b"><mover accent="true" id="S1.F2.20.m9.1.1" xref="S1.F2.20.m9.1.1.cmml"><mi id="S1.F2.20.m9.1.1.2" xref="S1.F2.20.m9.1.1.2.cmml">M</mi><mo id="S1.F2.20.m9.1.1.1" xref="S1.F2.20.m9.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S1.F2.20.m9.1c"><apply id="S1.F2.20.m9.1.1.cmml" xref="S1.F2.20.m9.1.1"><ci id="S1.F2.20.m9.1.1.1.cmml" xref="S1.F2.20.m9.1.1.1">~</ci><ci id="S1.F2.20.m9.1.1.2.cmml" xref="S1.F2.20.m9.1.1.2">𝑀</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.20.m9.1d">\tilde{M}</annotation><annotation encoding="application/x-llamapun" id="S1.F2.20.m9.1e">over~ start_ARG italic_M end_ARG</annotation></semantics></math>。<math alttext="\mathrm{ENV}" class="ltx_Math" display="inline" id="S1.F2.21.m10.1"><semantics id="S1.F2.21.m10.1b"><mi id="S1.F2.21.m10.1.1" xref="S1.F2.21.m10.1.1.cmml">ENV</mi><annotation-xml encoding="MathML-Content" id="S1.F2.21.m10.1c"><ci id="S1.F2.21.m10.1.1.cmml" xref="S1.F2.21.m10.1.1">ENV</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.21.m10.1d">\mathrm{ENV}</annotation><annotation encoding="application/x-llamapun" id="S1.F2.21.m10.1e">roman_ENV</annotation></semantics></math>是环境。整个自我进化始于<math alttext="{\mathcal{E}}^{1}" class="ltx_Math" display="inline" id="S1.F2.22.m11.1"><semantics id="S1.F2.22.m11.1b"><msup id="S1.F2.22.m11.1.1" xref="S1.F2.22.m11.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S1.F2.22.m11.1.1.2" xref="S1.F2.22.m11.1.1.2.cmml">ℰ</mi><mn id="S1.F2.22.m11.1.1.3" xref="S1.F2.22.m11.1.1.3.cmml">1</mn></msup><annotation-xml encoding="MathML-Content" id="S1.F2.22.m11.1c"><apply id="S1.F2.22.m11.1.1.cmml" xref="S1.F2.22.m11.1.1"><csymbol cd="ambiguous" id="S1.F2.22.m11.1.1.1.cmml" xref="S1.F2.22.m11.1.1">superscript</csymbol><ci id="S1.F2.22.m11.1.1.2.cmml" xref="S1.F2.22.m11.1.1.2">ℰ</ci><cn id="S1.F2.22.m11.1.1.3.cmml" type="integer" xref="S1.F2.22.m11.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.22.m11.1d">{\mathcal{E}}^{1}</annotation><annotation encoding="application/x-llamapun" id="S1.F2.22.m11.1e">caligraphic_E start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT</annotation></semantics></math>。</figcaption>
</figure>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">2 </span>概述</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">在这一部分，我们将首先讨论自我进化的背景，然后介绍提出的概念框架。</p>
</div>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">2.1 </span>背景</h3>
<div class="ltx_para ltx_noindent" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1"><span class="ltx_text ltx_font_bold" id="S2.SS1.p1.1.1">人工智能中的自我进化。</span>
人工智能代表了智能代理的高级形式，配备了类似于人类的认知能力和行为。 AI开发者的愿望在于使AI能够利用自我进化的能力，与人类发展特征性的经验学习过程相媲美。
AI中的自我进化概念源自机器学习和进化算法的更广泛领域。最初受自然进化原则的影响，如选择、突变和繁殖，研究人员开发了模拟这些过程以优化复杂问题解决方案的算法。引入遗传算法的具有里程碑意义的论文，标志着AI自我进化能力历史上的基础时刻。神经网络和深度学习的后续发展进一步增强了这种能力，使AI系统能够修改自己的架构并在没有人类干预的情况下改进性能。</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1"><span class="ltx_text ltx_font_bold" id="S2.SS1.p2.1.1">人工实体能自我进化吗？</span> 从哲学上讲，关于人工实体能否自我进化的问题涉及到自治、意识和代理的问题。一些哲学家认为，AI中真正的自我进化需要某种形式的意识或自我意识，而另一些人认为通过算法进行机械自我改进并不构成真正的进化<cite class="ltx_cite ltx_citemacro_cite">Chalmers (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib16" title="">1997</a>)</cite>。这场辩论经常引用像<cite class="ltx_cite ltx_citemacro_citet">Dennett (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib28" title="">1993</a>)</cite>这样的思想家的作品，他们探讨了人类意识下的认知过程，并将其与人工系统进行对比。最终，对AI自我进化能力的哲学探究仍然与对“进化”意味着什么以及这些过程纯粹可以是算法的还是必须涉及新兴意识的解释息息相关<cite class="ltx_cite ltx_citemacro_cite">Searle (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib97" title="">1986</a>)</cite>。</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">2.2 </span>概念框架</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">在自我进化的概念框架中，我们描述了一个动态的迭代过程，反映了人类获取和完善技能和知识的能力。这个框架被封装在图<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#S1.F2" title="Figure 2 ‣ 1 Introduction ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_tag">2</span></a>中，强调了学习和改进的循环性质。过程的每次迭代都专注于特定的进化目标，使模型能够参与相关任务，优化其经验，更新其架构，并在进入下一个周期之前评估其进展。</p>
</div>
<section class="ltx_paragraph" id="S2.SS2.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">经验获取</h5>
<div class="ltx_para" id="S2.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="S2.SS2.SSS0.Px1.p1.7">在<math alttext="t^{th}" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px1.p1.1.m1.1"><semantics id="S2.SS2.SSS0.Px1.p1.1.m1.1a"><msup id="S2.SS2.SSS0.Px1.p1.1.m1.1.1" xref="S2.SS2.SSS0.Px1.p1.1.m1.1.1.cmml"><mi id="S2.SS2.SSS0.Px1.p1.1.m1.1.1.2" xref="S2.SS2.SSS0.Px1.p1.1.m1.1.1.2.cmml">t</mi><mrow id="S2.SS2.SSS0.Px1.p1.1.m1.1.1.3" xref="S2.SS2.SSS0.Px1.p1.1.m1.1.1.3.cmml"><mi id="S2.SS2.SSS0.Px1.p1.1.m1.1.1.3.2" xref="S2.SS2.SSS0.Px1.p1.1.m1.1.1.3.2.cmml">t</mi><mo id="S2.SS2.SSS0.Px1.p1.1.m1.1.1.3.1" xref="S2.SS2.SSS0.Px1.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S2.SS2.SSS0.Px1.p1.1.m1.1.1.3.3" xref="S2.SS2.SSS0.Px1.p1.1.m1.1.1.3.3.cmml">h</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p1.1.m1.1b"><apply id="S2.SS2.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p1.1.m1.1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.1.m1.1.1">superscript</csymbol><ci id="S2.SS2.SSS0.Px1.p1.1.m1.1.1.2.cmml" xref="S2.SS2.SSS0.Px1.p1.1.m1.1.1.2">𝑡</ci><apply id="S2.SS2.SSS0.Px1.p1.1.m1.1.1.3.cmml" xref="S2.SS2.SSS0.Px1.p1.1.m1.1.1.3"><times id="S2.SS2.SSS0.Px1.p1.1.m1.1.1.3.1.cmml" xref="S2.SS2.SSS0.Px1.p1.1.m1.1.1.3.1"></times><ci id="S2.SS2.SSS0.Px1.p1.1.m1.1.1.3.2.cmml" xref="S2.SS2.SSS0.Px1.p1.1.m1.1.1.3.2">𝑡</ci><ci id="S2.SS2.SSS0.Px1.p1.1.m1.1.1.3.3.cmml" xref="S2.SS2.SSS0.Px1.p1.1.m1.1.1.3.3">ℎ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p1.1.m1.1c">t^{th}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px1.p1.1.m1.1d">italic_t start_POSTSUPERSCRIPT italic_t italic_h end_POSTSUPERSCRIPT</annotation></semantics></math>迭代中，模型确定了一个演化目标<math alttext="{\mathcal{E}}^{t}" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px1.p1.2.m2.1"><semantics id="S2.SS2.SSS0.Px1.p1.2.m2.1a"><msup id="S2.SS2.SSS0.Px1.p1.2.m2.1.1" xref="S2.SS2.SSS0.Px1.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.SSS0.Px1.p1.2.m2.1.1.2" xref="S2.SS2.SSS0.Px1.p1.2.m2.1.1.2.cmml">ℰ</mi><mi id="S2.SS2.SSS0.Px1.p1.2.m2.1.1.3" xref="S2.SS2.SSS0.Px1.p1.2.m2.1.1.3.cmml">t</mi></msup><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p1.2.m2.1b"><apply id="S2.SS2.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p1.2.m2.1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.2.m2.1.1">superscript</csymbol><ci id="S2.SS2.SSS0.Px1.p1.2.m2.1.1.2.cmml" xref="S2.SS2.SSS0.Px1.p1.2.m2.1.1.2">ℰ</ci><ci id="S2.SS2.SSS0.Px1.p1.2.m2.1.1.3.cmml" xref="S2.SS2.SSS0.Px1.p1.2.m2.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p1.2.m2.1c">{\mathcal{E}}^{t}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px1.p1.2.m2.1d">caligraphic_E start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT</annotation></semantics></math>。在这个目标的指导下，模型着手进行新任务<math alttext="{\mathcal{T}}^{t}" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px1.p1.3.m3.1"><semantics id="S2.SS2.SSS0.Px1.p1.3.m3.1a"><msup id="S2.SS2.SSS0.Px1.p1.3.m3.1.1" xref="S2.SS2.SSS0.Px1.p1.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.SSS0.Px1.p1.3.m3.1.1.2" xref="S2.SS2.SSS0.Px1.p1.3.m3.1.1.2.cmml">𝒯</mi><mi id="S2.SS2.SSS0.Px1.p1.3.m3.1.1.3" xref="S2.SS2.SSS0.Px1.p1.3.m3.1.1.3.cmml">t</mi></msup><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p1.3.m3.1b"><apply id="S2.SS2.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p1.3.m3.1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.3.m3.1.1">superscript</csymbol><ci id="S2.SS2.SSS0.Px1.p1.3.m3.1.1.2.cmml" xref="S2.SS2.SSS0.Px1.p1.3.m3.1.1.2">𝒯</ci><ci id="S2.SS2.SSS0.Px1.p1.3.m3.1.1.3.cmml" xref="S2.SS2.SSS0.Px1.p1.3.m3.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p1.3.m3.1c">{\mathcal{T}}^{t}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px1.p1.3.m3.1d">caligraphic_T start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT</annotation></semantics></math>，生成解决方案<math alttext="{\mathcal{Y}}^{t}" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px1.p1.4.m4.1"><semantics id="S2.SS2.SSS0.Px1.p1.4.m4.1a"><msup id="S2.SS2.SSS0.Px1.p1.4.m4.1.1" xref="S2.SS2.SSS0.Px1.p1.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.SSS0.Px1.p1.4.m4.1.1.2" xref="S2.SS2.SSS0.Px1.p1.4.m4.1.1.2.cmml">𝒴</mi><mi id="S2.SS2.SSS0.Px1.p1.4.m4.1.1.3" xref="S2.SS2.SSS0.Px1.p1.4.m4.1.1.3.cmml">t</mi></msup><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p1.4.m4.1b"><apply id="S2.SS2.SSS0.Px1.p1.4.m4.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.4.m4.1.1">superscript</csymbol><ci id="S2.SS2.SSS0.Px1.p1.4.m4.1.1.2.cmml" xref="S2.SS2.SSS0.Px1.p1.4.m4.1.1.2">𝒴</ci><ci id="S2.SS2.SSS0.Px1.p1.4.m4.1.1.3.cmml" xref="S2.SS2.SSS0.Px1.p1.4.m4.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p1.4.m4.1c">{\mathcal{Y}}^{t}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px1.p1.4.m4.1d">caligraphic_Y start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT</annotation></semantics></math>并从环境<math alttext="\mathrm{ENV}" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px1.p1.6.m6.1"><semantics id="S2.SS2.SSS0.Px1.p1.6.m6.1a"><mi id="S2.SS2.SSS0.Px1.p1.6.m6.1.1" xref="S2.SS2.SSS0.Px1.p1.6.m6.1.1.cmml">ENV</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p1.6.m6.1b"><ci id="S2.SS2.SSS0.Px1.p1.6.m6.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.6.m6.1.1">ENV</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p1.6.m6.1c">\mathrm{ENV}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px1.p1.6.m6.1d">roman_ENV</annotation></semantics></math>中接收反馈<math alttext="{\mathcal{F}}^{t}" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px1.p1.5.m5.1"><semantics id="S2.SS2.SSS0.Px1.p1.5.m5.1a"><msup id="S2.SS2.SSS0.Px1.p1.5.m5.1.1" xref="S2.SS2.SSS0.Px1.p1.5.m5.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.SSS0.Px1.p1.5.m5.1.1.2" xref="S2.SS2.SSS0.Px1.p1.5.m5.1.1.2.cmml">ℱ</mi><mi id="S2.SS2.SSS0.Px1.p1.5.m5.1.1.3" xref="S2.SS2.SSS0.Px1.p1.5.m5.1.1.3.cmml">t</mi></msup><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p1.5.m5.1b"><apply id="S2.SS2.SSS0.Px1.p1.5.m5.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p1.5.m5.1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.5.m5.1.1">superscript</csymbol><ci id="S2.SS2.SSS0.Px1.p1.5.m5.1.1.2.cmml" xref="S2.SS2.SSS0.Px1.p1.5.m5.1.1.2">ℱ</ci><ci id="S2.SS2.SSS0.Px1.p1.5.m5.1.1.3.cmml" xref="S2.SS2.SSS0.Px1.p1.5.m5.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p1.5.m5.1c">{\mathcal{F}}^{t}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px1.p1.5.m5.1d">caligraphic_F start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT</annotation></semantics></math>。这个阶段最终导致了新经验的获取<math alttext="{({\mathcal{T}}^{t},{\mathcal{Y}}^{t},{\mathcal{F}}^{t})}" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px1.p1.7.m7.3"><semantics id="S2.SS2.SSS0.Px1.p1.7.m7.3a"><mrow id="S2.SS2.SSS0.Px1.p1.7.m7.3.3.3" xref="S2.SS2.SSS0.Px1.p1.7.m7.3.3.4.cmml"><mo id="S2.SS2.SSS0.Px1.p1.7.m7.3.3.3.4" stretchy="false" xref="S2.SS2.SSS0.Px1.p1.7.m7.3.3.4.cmml">(</mo><msup id="S2.SS2.SSS0.Px1.p1.7.m7.1.1.1.1" xref="S2.SS2.SSS0.Px1.p1.7.m7.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.SSS0.Px1.p1.7.m7.1.1.1.1.2" xref="S2.SS2.SSS0.Px1.p1.7.m7.1.1.1.1.2.cmml">𝒯</mi><mi id="S2.SS2.SSS0.Px1.p1.7.m7.1.1.1.1.3" xref="S2.SS2.SSS0.Px1.p1.7.m7.1.1.1.1.3.cmml">t</mi></msup><mo id="S2.SS2.SSS0.Px1.p1.7.m7.3.3.3.5" xref="S2.SS2.SSS0.Px1.p1.7.m7.3.3.4.cmml">,</mo><msup id="S2.SS2.SSS0.Px1.p1.7.m7.2.2.2.2" xref="S2.SS2.SSS0.Px1.p1.7.m7.2.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.SSS0.Px1.p1.7.m7.2.2.2.2.2" xref="S2.SS2.SSS0.Px1.p1.7.m7.2.2.2.2.2.cmml">𝒴</mi><mi id="S2.SS2.SSS0.Px1.p1.7.m7.2.2.2.2.3" xref="S2.SS2.SSS0.Px1.p1.7.m7.2.2.2.2.3.cmml">t</mi></msup><mo id="S2.SS2.SSS0.Px1.p1.7.m7.3.3.3.6" xref="S2.SS2.SSS0.Px1.p1.7.m7.3.3.4.cmml">,</mo><msup id="S2.SS2.SSS0.Px1.p1.7.m7.3.3.3.3" xref="S2.SS2.SSS0.Px1.p1.7.m7.3.3.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.SSS0.Px1.p1.7.m7.3.3.3.3.2" xref="S2.SS2.SSS0.Px1.p1.7.m7.3.3.3.3.2.cmml">ℱ</mi><mi id="S2.SS2.SSS0.Px1.p1.7.m7.3.3.3.3.3" xref="S2.SS2.SSS0.Px1.p1.7.m7.3.3.3.3.3.cmml">t</mi></msup><mo id="S2.SS2.SSS0.Px1.p1.7.m7.3.3.3.7" stretchy="false" xref="S2.SS2.SSS0.Px1.p1.7.m7.3.3.4.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p1.7.m7.3b"><vector id="S2.SS2.SSS0.Px1.p1.7.m7.3.3.4.cmml" xref="S2.SS2.SSS0.Px1.p1.7.m7.3.3.3"><apply id="S2.SS2.SSS0.Px1.p1.7.m7.1.1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.7.m7.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p1.7.m7.1.1.1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.7.m7.1.1.1.1">superscript</csymbol><ci id="S2.SS2.SSS0.Px1.p1.7.m7.1.1.1.1.2.cmml" xref="S2.SS2.SSS0.Px1.p1.7.m7.1.1.1.1.2">𝒯</ci><ci id="S2.SS2.SSS0.Px1.p1.7.m7.1.1.1.1.3.cmml" xref="S2.SS2.SSS0.Px1.p1.7.m7.1.1.1.1.3">𝑡</ci></apply><apply id="S2.SS2.SSS0.Px1.p1.7.m7.2.2.2.2.cmml" xref="S2.SS2.SSS0.Px1.p1.7.m7.2.2.2.2"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p1.7.m7.2.2.2.2.1.cmml" xref="S2.SS2.SSS0.Px1.p1.7.m7.2.2.2.2">superscript</csymbol><ci id="S2.SS2.SSS0.Px1.p1.7.m7.2.2.2.2.2.cmml" xref="S2.SS2.SSS0.Px1.p1.7.m7.2.2.2.2.2">𝒴</ci><ci id="S2.SS2.SSS0.Px1.p1.7.m7.2.2.2.2.3.cmml" xref="S2.SS2.SSS0.Px1.p1.7.m7.2.2.2.2.3">𝑡</ci></apply><apply id="S2.SS2.SSS0.Px1.p1.7.m7.3.3.3.3.cmml" xref="S2.SS2.SSS0.Px1.p1.7.m7.3.3.3.3"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p1.7.m7.3.3.3.3.1.cmml" xref="S2.SS2.SSS0.Px1.p1.7.m7.3.3.3.3">superscript</csymbol><ci id="S2.SS2.SSS0.Px1.p1.7.m7.3.3.3.3.2.cmml" xref="S2.SS2.SSS0.Px1.p1.7.m7.3.3.3.3.2">ℱ</ci><ci id="S2.SS2.SSS0.Px1.p1.7.m7.3.3.3.3.3.cmml" xref="S2.SS2.SSS0.Px1.p1.7.m7.3.3.3.3.3">𝑡</ci></apply></vector></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p1.7.m7.3c">{({\mathcal{T}}^{t},{\mathcal{Y}}^{t},{\mathcal{F}}^{t})}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px1.p1.7.m7.3d">( caligraphic_T start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT , caligraphic_Y start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT , caligraphic_F start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT )</annotation></semantics></math>。</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS2.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">经验细化</h5>
<div class="ltx_para" id="S2.SS2.SSS0.Px2.p1">
<p class="ltx_p" id="S2.SS2.SSS0.Px2.p1.1">在经验获取后，模型会检查和完善这些经验。这涉及丢弃不正确的数据和增强不完美的数据，从而产生精炼的结果<math alttext="{(\tilde{{\mathcal{T}}}^{t},\tilde{{\mathcal{Y}}}^{t})}" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px2.p1.1.m1.2"><semantics id="S2.SS2.SSS0.Px2.p1.1.m1.2a"><mrow id="S2.SS2.SSS0.Px2.p1.1.m1.2.2.2" xref="S2.SS2.SSS0.Px2.p1.1.m1.2.2.3.cmml"><mo id="S2.SS2.SSS0.Px2.p1.1.m1.2.2.2.3" stretchy="false" xref="S2.SS2.SSS0.Px2.p1.1.m1.2.2.3.cmml">(</mo><msup id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.cmml"><mover accent="true" id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.2" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.2.2" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.2.2.cmml">𝒯</mi><mo id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.2.1" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.2.1.cmml">~</mo></mover><mi id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.3" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.3.cmml">t</mi></msup><mo id="S2.SS2.SSS0.Px2.p1.1.m1.2.2.2.4" xref="S2.SS2.SSS0.Px2.p1.1.m1.2.2.3.cmml">,</mo><msup id="S2.SS2.SSS0.Px2.p1.1.m1.2.2.2.2" xref="S2.SS2.SSS0.Px2.p1.1.m1.2.2.2.2.cmml"><mover accent="true" id="S2.SS2.SSS0.Px2.p1.1.m1.2.2.2.2.2" xref="S2.SS2.SSS0.Px2.p1.1.m1.2.2.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.SSS0.Px2.p1.1.m1.2.2.2.2.2.2" xref="S2.SS2.SSS0.Px2.p1.1.m1.2.2.2.2.2.2.cmml">𝒴</mi><mo id="S2.SS2.SSS0.Px2.p1.1.m1.2.2.2.2.2.1" xref="S2.SS2.SSS0.Px2.p1.1.m1.2.2.2.2.2.1.cmml">~</mo></mover><mi id="S2.SS2.SSS0.Px2.p1.1.m1.2.2.2.2.3" xref="S2.SS2.SSS0.Px2.p1.1.m1.2.2.2.2.3.cmml">t</mi></msup><mo id="S2.SS2.SSS0.Px2.p1.1.m1.2.2.2.5" stretchy="false" xref="S2.SS2.SSS0.Px2.p1.1.m1.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px2.p1.1.m1.2b"><interval closure="open" id="S2.SS2.SSS0.Px2.p1.1.m1.2.2.3.cmml" xref="S2.SS2.SSS0.Px2.p1.1.m1.2.2.2"><apply id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.cmml" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.cmml" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1">superscript</csymbol><apply id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.2.cmml" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.2"><ci id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.2.1.cmml" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.2.1">~</ci><ci id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.2.2.cmml" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.2.2">𝒯</ci></apply><ci id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.3.cmml" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.3">𝑡</ci></apply><apply id="S2.SS2.SSS0.Px2.p1.1.m1.2.2.2.2.cmml" xref="S2.SS2.SSS0.Px2.p1.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px2.p1.1.m1.2.2.2.2.1.cmml" xref="S2.SS2.SSS0.Px2.p1.1.m1.2.2.2.2">superscript</csymbol><apply id="S2.SS2.SSS0.Px2.p1.1.m1.2.2.2.2.2.cmml" xref="S2.SS2.SSS0.Px2.p1.1.m1.2.2.2.2.2"><ci id="S2.SS2.SSS0.Px2.p1.1.m1.2.2.2.2.2.1.cmml" xref="S2.SS2.SSS0.Px2.p1.1.m1.2.2.2.2.2.1">~</ci><ci id="S2.SS2.SSS0.Px2.p1.1.m1.2.2.2.2.2.2.cmml" xref="S2.SS2.SSS0.Px2.p1.1.m1.2.2.2.2.2.2">𝒴</ci></apply><ci id="S2.SS2.SSS0.Px2.p1.1.m1.2.2.2.2.3.cmml" xref="S2.SS2.SSS0.Px2.p1.1.m1.2.2.2.2.3">𝑡</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px2.p1.1.m1.2c">{(\tilde{{\mathcal{T}}}^{t},\tilde{{\mathcal{Y}}}^{t})}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px2.p1.1.m1.2d">( over~ start_ARG caligraphic_T end_ARG start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT , over~ start_ARG caligraphic_Y end_ARG start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT )</annotation></semantics></math>。</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS2.SSS0.Px3">
<h5 class="ltx_title ltx_title_paragraph">更新</h5>
<div class="ltx_para" id="S2.SS2.SSS0.Px3.p1">
<p class="ltx_p" id="S2.SS2.SSS0.Px3.p1.1">利用精细的经验，模型经历了一次更新过程，将<math alttext="{(\tilde{{\mathcal{T}}}^{t},\tilde{{\mathcal{Y}}}^{t})}" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px3.p1.1.m1.2"><semantics id="S2.SS2.SSS0.Px3.p1.1.m1.2a"><mrow id="S2.SS2.SSS0.Px3.p1.1.m1.2.2.2" xref="S2.SS2.SSS0.Px3.p1.1.m1.2.2.3.cmml"><mo id="S2.SS2.SSS0.Px3.p1.1.m1.2.2.2.3" stretchy="false" xref="S2.SS2.SSS0.Px3.p1.1.m1.2.2.3.cmml">(</mo><msup id="S2.SS2.SSS0.Px3.p1.1.m1.1.1.1.1" xref="S2.SS2.SSS0.Px3.p1.1.m1.1.1.1.1.cmml"><mover accent="true" id="S2.SS2.SSS0.Px3.p1.1.m1.1.1.1.1.2" xref="S2.SS2.SSS0.Px3.p1.1.m1.1.1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.SSS0.Px3.p1.1.m1.1.1.1.1.2.2" xref="S2.SS2.SSS0.Px3.p1.1.m1.1.1.1.1.2.2.cmml">𝒯</mi><mo id="S2.SS2.SSS0.Px3.p1.1.m1.1.1.1.1.2.1" xref="S2.SS2.SSS0.Px3.p1.1.m1.1.1.1.1.2.1.cmml">~</mo></mover><mi id="S2.SS2.SSS0.Px3.p1.1.m1.1.1.1.1.3" xref="S2.SS2.SSS0.Px3.p1.1.m1.1.1.1.1.3.cmml">t</mi></msup><mo id="S2.SS2.SSS0.Px3.p1.1.m1.2.2.2.4" xref="S2.SS2.SSS0.Px3.p1.1.m1.2.2.3.cmml">,</mo><msup id="S2.SS2.SSS0.Px3.p1.1.m1.2.2.2.2" xref="S2.SS2.SSS0.Px3.p1.1.m1.2.2.2.2.cmml"><mover accent="true" id="S2.SS2.SSS0.Px3.p1.1.m1.2.2.2.2.2" xref="S2.SS2.SSS0.Px3.p1.1.m1.2.2.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.SSS0.Px3.p1.1.m1.2.2.2.2.2.2" xref="S2.SS2.SSS0.Px3.p1.1.m1.2.2.2.2.2.2.cmml">𝒴</mi><mo id="S2.SS2.SSS0.Px3.p1.1.m1.2.2.2.2.2.1" xref="S2.SS2.SSS0.Px3.p1.1.m1.2.2.2.2.2.1.cmml">~</mo></mover><mi id="S2.SS2.SSS0.Px3.p1.1.m1.2.2.2.2.3" xref="S2.SS2.SSS0.Px3.p1.1.m1.2.2.2.2.3.cmml">t</mi></msup><mo id="S2.SS2.SSS0.Px3.p1.1.m1.2.2.2.5" stretchy="false" xref="S2.SS2.SSS0.Px3.p1.1.m1.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px3.p1.1.m1.2b"><interval closure="open" id="S2.SS2.SSS0.Px3.p1.1.m1.2.2.3.cmml" xref="S2.SS2.SSS0.Px3.p1.1.m1.2.2.2"><apply id="S2.SS2.SSS0.Px3.p1.1.m1.1.1.1.1.cmml" xref="S2.SS2.SSS0.Px3.p1.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px3.p1.1.m1.1.1.1.1.1.cmml" xref="S2.SS2.SSS0.Px3.p1.1.m1.1.1.1.1">superscript</csymbol><apply id="S2.SS2.SSS0.Px3.p1.1.m1.1.1.1.1.2.cmml" xref="S2.SS2.SSS0.Px3.p1.1.m1.1.1.1.1.2"><ci id="S2.SS2.SSS0.Px3.p1.1.m1.1.1.1.1.2.1.cmml" xref="S2.SS2.SSS0.Px3.p1.1.m1.1.1.1.1.2.1">~</ci><ci id="S2.SS2.SSS0.Px3.p1.1.m1.1.1.1.1.2.2.cmml" xref="S2.SS2.SSS0.Px3.p1.1.m1.1.1.1.1.2.2">𝒯</ci></apply><ci id="S2.SS2.SSS0.Px3.p1.1.m1.1.1.1.1.3.cmml" xref="S2.SS2.SSS0.Px3.p1.1.m1.1.1.1.1.3">𝑡</ci></apply><apply id="S2.SS2.SSS0.Px3.p1.1.m1.2.2.2.2.cmml" xref="S2.SS2.SSS0.Px3.p1.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px3.p1.1.m1.2.2.2.2.1.cmml" xref="S2.SS2.SSS0.Px3.p1.1.m1.2.2.2.2">superscript</csymbol><apply id="S2.SS2.SSS0.Px3.p1.1.m1.2.2.2.2.2.cmml" xref="S2.SS2.SSS0.Px3.p1.1.m1.2.2.2.2.2"><ci id="S2.SS2.SSS0.Px3.p1.1.m1.2.2.2.2.2.1.cmml" xref="S2.SS2.SSS0.Px3.p1.1.m1.2.2.2.2.2.1">~</ci><ci id="S2.SS2.SSS0.Px3.p1.1.m1.2.2.2.2.2.2.cmml" xref="S2.SS2.SSS0.Px3.p1.1.m1.2.2.2.2.2.2">𝒴</ci></apply><ci id="S2.SS2.SSS0.Px3.p1.1.m1.2.2.2.2.3.cmml" xref="S2.SS2.SSS0.Px3.p1.1.m1.2.2.2.2.3">𝑡</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px3.p1.1.m1.2c">{(\tilde{{\mathcal{T}}}^{t},\tilde{{\mathcal{Y}}}^{t})}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px3.p1.1.m1.2d">( over~ start_ARG caligraphic_T end_ARG start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT , over~ start_ARG caligraphic_Y end_ARG start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT )</annotation></semantics></math>整合到其框架中。这确保了模型保持当前和优化。</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS2.SSS0.Px4">
<h5 class="ltx_title ltx_title_paragraph">评估</h5>
<div class="ltx_para" id="S2.SS2.SSS0.Px4.p1">
<p class="ltx_p" id="S2.SS2.SSS0.Px4.p1.1">循环在评估阶段结束，模型的性能通过对外部环境的评估来进行评估。这一阶段的结果决定了客观<math alttext="{\mathcal{E}}^{t+1}" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px4.p1.1.m1.1"><semantics id="S2.SS2.SSS0.Px4.p1.1.m1.1a"><msup id="S2.SS2.SSS0.Px4.p1.1.m1.1.1" xref="S2.SS2.SSS0.Px4.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.SSS0.Px4.p1.1.m1.1.1.2" xref="S2.SS2.SSS0.Px4.p1.1.m1.1.1.2.cmml">ℰ</mi><mrow id="S2.SS2.SSS0.Px4.p1.1.m1.1.1.3" xref="S2.SS2.SSS0.Px4.p1.1.m1.1.1.3.cmml"><mi id="S2.SS2.SSS0.Px4.p1.1.m1.1.1.3.2" xref="S2.SS2.SSS0.Px4.p1.1.m1.1.1.3.2.cmml">t</mi><mo id="S2.SS2.SSS0.Px4.p1.1.m1.1.1.3.1" xref="S2.SS2.SSS0.Px4.p1.1.m1.1.1.3.1.cmml">+</mo><mn id="S2.SS2.SSS0.Px4.p1.1.m1.1.1.3.3" xref="S2.SS2.SSS0.Px4.p1.1.m1.1.1.3.3.cmml">1</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px4.p1.1.m1.1b"><apply id="S2.SS2.SSS0.Px4.p1.1.m1.1.1.cmml" xref="S2.SS2.SSS0.Px4.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px4.p1.1.m1.1.1.1.cmml" xref="S2.SS2.SSS0.Px4.p1.1.m1.1.1">superscript</csymbol><ci id="S2.SS2.SSS0.Px4.p1.1.m1.1.1.2.cmml" xref="S2.SS2.SSS0.Px4.p1.1.m1.1.1.2">ℰ</ci><apply id="S2.SS2.SSS0.Px4.p1.1.m1.1.1.3.cmml" xref="S2.SS2.SSS0.Px4.p1.1.m1.1.1.3"><plus id="S2.SS2.SSS0.Px4.p1.1.m1.1.1.3.1.cmml" xref="S2.SS2.SSS0.Px4.p1.1.m1.1.1.3.1"></plus><ci id="S2.SS2.SSS0.Px4.p1.1.m1.1.1.3.2.cmml" xref="S2.SS2.SSS0.Px4.p1.1.m1.1.1.3.2">𝑡</ci><cn id="S2.SS2.SSS0.Px4.p1.1.m1.1.1.3.3.cmml" type="integer" xref="S2.SS2.SSS0.Px4.p1.1.m1.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px4.p1.1.m1.1c">{\mathcal{E}}^{t+1}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px4.p1.1.m1.1d">caligraphic_E start_POSTSUPERSCRIPT italic_t + 1 end_POSTSUPERSCRIPT</annotation></semantics></math>，为随后的自我进化迭代奠定了基础。</p>
</div>
<div class="ltx_para" id="S2.SS2.SSS0.Px4.p2">
<p class="ltx_p" id="S2.SS2.SSS0.Px4.p2.1">概念框架概述了LLMs的自我演进，类似于类人的习得，完善和自主学习过程。我们在图<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#S2.F3" title="Figure 3 ‣ Evaluation ‣ 2.2 Conceptual Framework ‣ 2 Overview ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_tag">3</span></a>中阐明了我们的分类法。</p>
</div>
<figure class="ltx_figure" id="S2.F3"><span class="ltx_ERROR ltx_centering undefined" id="S2.F3.9">{forest}</span>
<p class="ltx_p ltx_align_center" id="S2.F3.8">对于树=
生长=东，
增长父锚点=西，
父锚点=东，
子锚点=西，

[LLMs的自我进化，根，父锚点=南
[评估（§<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#S7" title="7 Evaluation ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_tag">7</span></a>），节点_lv1
[定性，节点_lv2，
[<cite class="ltx_cite ltx_citemacro_citet">Yang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib140" title="">2023b</a>)</cite> ,
LLM解释<cite class="ltx_cite ltx_citemacro_cite">Zheng et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib158" title="">2024a</a>)</cite> ,
ChatEval<cite class="ltx_cite ltx_citemacro_cite">Chan et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib17" title="">2023</a>)</cite>
, 节点_lv3],
]
[定量，节点_lv2,
[
LLM作为评委<cite class="ltx_cite ltx_citemacro_cite">Zheng et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib158" title="">2024a</a>); Dubois et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib34" title="">2024</a>)</cite> ,
奖励分数<cite class="ltx_cite ltx_citemacro_cite">Ouyang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib83" title="">2022</a>)</cite>
, 节点_lv3],
]
]
[更新（§<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#S6" title="6 Updating ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_tag">6</span></a>），节点_lv1，
[在上下文中，节点_lv2
[<span class="ltx_text ltx_font_italic" id="S2.F3.8.1">工作记忆</span>:
反射<cite class="ltx_cite ltx_citemacro_cite">Shinn et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib99" title="">2023</a>)</cite>,
IML<cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib120" title="">2024a</a>)</cite>,
进化代理<cite class="ltx_cite ltx_citemacro_cite">Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib65" title="">2024c</a>)</cite> ,
代理专业<cite class="ltx_cite ltx_citemacro_cite">Zhang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib155" title="">2024d</a>)</cite>,
ProAgent<cite class="ltx_cite ltx_citemacro_cite">Zhang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib152" title="">2024a</a>)</cite>
, 节点_lv3],
[<span class="ltx_text ltx_font_italic" id="S2.F3.8.2">外部记忆</span>:
MoT<cite class="ltx_cite ltx_citemacro_cite">Li and Qiu (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib67" title="">2023</a>)</cite>,
MemoryBank<cite class="ltx_cite ltx_citemacro_cite">Zhong et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib162" title="">2024b</a>)</cite>,
TiM<cite class="ltx_cite ltx_citemacro_cite">Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib72" title="">2023a</a>)</cite>,
IML<cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib120" title="">2024a</a>)</cite>,
TRAN<cite class="ltx_cite ltx_citemacro_cite">Yang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib140" title="">2023b</a>)</cite>,
MemGPT<cite class="ltx_cite ltx_citemacro_cite">Packer et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib84" title="">2023</a>)</cite>
UA<math alttext="{}^{2}" class="ltx_Math" display="inline" id="S2.F3.1.m1.1"><semantics id="S2.F3.1.m1.1a"><msup id="S2.F3.1.m1.1.1" xref="S2.F3.1.m1.1.1.cmml"><mi id="S2.F3.1.m1.1.1a" xref="S2.F3.1.m1.1.1.cmml"></mi><mn id="S2.F3.1.m1.1.1.1" xref="S2.F3.1.m1.1.1.1.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S2.F3.1.m1.1b"><apply id="S2.F3.1.m1.1.1.cmml" xref="S2.F3.1.m1.1.1"><cn id="S2.F3.1.m1.1.1.1.cmml" type="integer" xref="S2.F3.1.m1.1.1.1">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F3.1.m1.1c">{}^{2}</annotation><annotation encoding="application/x-llamapun" id="S2.F3.1.m1.1d">start_FLOATSUPERSCRIPT 2 end_FLOATSUPERSCRIPT</annotation></semantics></math><cite class="ltx_cite ltx_citemacro_cite">Yang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib143" title="">2024d</a>)</cite> ,
ICE<cite class="ltx_cite ltx_citemacro_cite">Qian et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib89" title="">2024</a>)</cite>,
AesopAgent<cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib123" title="">2024d</a>)</cite>
, 节点_lv3],
]
[在权重中，节点_lv2
[<span class="ltx_text ltx_font_italic" id="S2.F3.8.3">架构</span>: LoRA<cite class="ltx_cite ltx_citemacro_cite">Hu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib50" title="">2021</a>)</cite>,
ConPET<cite class="ltx_cite ltx_citemacro_cite">Song et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib104" title="">2023</a>)</cite>,
模型Soups<cite class="ltx_cite ltx_citemacro_cite">Wortsman et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib130" title="">2022</a>)</cite>,
DAIR<cite class="ltx_cite ltx_citemacro_cite">Yu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib146" title="">2023a</a>)</cite>,
UltraFuser<cite class="ltx_cite ltx_citemacro_cite">Ding et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib32" title="">2024</a>)</cite>,
EvoLLM<cite class="ltx_cite ltx_citemacro_cite">Akiba et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib3" title="">2024</a>)</cite>
, 节点_lv3],
[<span class="ltx_text ltx_font_italic" id="S2.F3.8.4">正则化</span>: InstuctGPT<cite class="ltx_cite ltx_citemacro_cite">Ouyang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib83" title="">2022</a>)</cite>,
FuseLLM<cite class="ltx_cite ltx_citemacro_cite">Wan et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib119" title="">2024</a>)</cite> ,
弹性重置<cite class="ltx_cite ltx_citemacro_cite">Noukhovitch et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib82" title="">2024</a>)</cite>,
WARM<cite class="ltx_cite ltx_citemacro_cite">Ramé et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib92" title="">2024</a>)</cite>,
AMA<cite class="ltx_cite ltx_citemacro_cite">Lin et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib69" title="">2024</a>)</cite>
, 节点_lv3],
[<span class="ltx_text ltx_font_italic" id="S2.F3.8.5">重播</span>: RFT<cite class="ltx_cite ltx_citemacro_cite">Yuan et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib149" title="">2023</a>)</cite>,
ReST<cite class="ltx_cite ltx_citemacro_cite">Gulcehre et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib42" title="">2023</a>); Aksitov et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib4" title="">2023</a>)</cite> ,
AMIE<cite class="ltx_cite ltx_citemacro_cite">Tu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib117" title="">2024</a>)</cite>,
SOTOPIA-<math alttext="\pi" class="ltx_Math" display="inline" id="S2.F3.2.m2.1"><semantics id="S2.F3.2.m2.1a"><mi id="S2.F3.2.m2.1.1" xref="S2.F3.2.m2.1.1.cmml">π</mi><annotation-xml encoding="MathML-Content" id="S2.F3.2.m2.1b"><ci id="S2.F3.2.m2.1.1.cmml" xref="S2.F3.2.m2.1.1">𝜋</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.F3.2.m2.1c">\pi</annotation><annotation encoding="application/x-llamapun" id="S2.F3.2.m2.1d">italic_π</annotation></semantics></math><cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib125" title="">2024e</a>)</cite>,
LLM2LLM<cite class="ltx_cite ltx_citemacro_cite">Lee et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib60" title="">2024</a>)</cite>,
LTC<cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib124" title="">2023a</a>)</cite>,
A<math alttext="{}^{3}" class="ltx_Math" display="inline" id="S2.F3.3.m3.1"><semantics id="S2.F3.3.m3.1a"><msup id="S2.F3.3.m3.1.1" xref="S2.F3.3.m3.1.1.cmml"><mi id="S2.F3.3.m3.1.1a" xref="S2.F3.3.m3.1.1.cmml"></mi><mn id="S2.F3.3.m3.1.1.1" xref="S2.F3.3.m3.1.1.1.cmml">3</mn></msup><annotation-xml encoding="MathML-Content" id="S2.F3.3.m3.1b"><apply id="S2.F3.3.m3.1.1.cmml" xref="S2.F3.3.m3.1.1"><cn id="S2.F3.3.m3.1.1.1.cmml" type="integer" xref="S2.F3.3.m3.1.1.1">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F3.3.m3.1c">{}^{3}</annotation><annotation encoding="application/x-llamapun" id="S2.F3.3.m3.1d">start_FLOATSUPERSCRIPT 3 end_FLOATSUPERSCRIPT</annotation></semantics></math>T<cite class="ltx_cite ltx_citemacro_cite">Yang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib142" title="">2024c</a>)</cite>,
SSR<cite class="ltx_cite ltx_citemacro_cite">Huang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib51" title="">2024a</a>)</cite>,
SDFT<cite class="ltx_cite ltx_citemacro_cite">Yang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib141" title="">2024b</a>)</cite>
, 节点_lv3],
]
]
[经验细化（§<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#S5" title="5 Experience Refinement ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_tag">5</span></a>），节点_lv1,
[更正，节点_lv2,
[<span class="ltx_text ltx_font_italic" id="S2.F3.8.6">无批评</span>:
STaR<cite class="ltx_cite ltx_citemacro_cite">Zelikman et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib151" title="">2022</a>)</cite>,
自我调试<cite class="ltx_cite ltx_citemacro_cite">Chen et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib22" title="">2023c</a>)</cite>,
IterRefinement<cite class="ltx_cite ltx_citemacro_cite">Chen et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib20" title="">2023b</a>)</cite>,
临床SV<cite class="ltx_cite ltx_citemacro_cite">Gero et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib40" title="">2023</a>)</cite>
, 节点_lv3],
[<span class="ltx_text ltx_font_italic" id="S2.F3.8.7">基于批评</span>:
Self-Refine<cite class="ltx_cite ltx_citemacro_cite">Madaan et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib80" title="">2023</a>)</cite>,
CAI<cite class="ltx_cite ltx_citemacro_cite">Bai et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib9" title="">2022</a>)</cite>,
RCI<cite class="ltx_cite ltx_citemacro_cite">Kim et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib57" title="">2023</a>)</cite> ,
SELF<cite class="ltx_cite ltx_citemacro_cite">Lu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib76" title="">2023</a>)</cite>,
CRITIC<cite class="ltx_cite ltx_citemacro_cite">Gou et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib41" title="">2023</a>)</cite>,
SelfEvolve<cite class="ltx_cite ltx_citemacro_cite">Jiang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib56" title="">2023</a>)</cite>,
ISR-LLM<cite class="ltx_cite ltx_citemacro_cite">Zhou et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib165" title="">2023b</a>)</cite>,
反思<cite class="ltx_cite ltx_citemacro_cite">Shinn et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib98" title="">2024</a>)</cite>
, 节点_lv3],
]
[过滤，节点_lv2,
[<span class="ltx_text ltx_font_italic" id="S2.F3.8.8">无度量</span>:
自一致性<cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib126" title="">2022</a>)</cite> ,
LMSI<cite class="ltx_cite ltx_citemacro_cite">Huang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib52" title="">2022</a>)</cite>,
自验证<cite class="ltx_cite ltx_citemacro_cite">Weng et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib129" title="">2023</a>)</cite> ,
CodeT<cite class="ltx_cite ltx_citemacro_cite">Chen et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib18" title="">2022</a>)</cite>
, 节点_lv3]
[<span class="ltx_text ltx_font_italic" id="S2.F3.8.9">基于度量</span>:
ReST<math alttext="{}^{EM}" class="ltx_Math" display="inline" id="S2.F3.4.m4.1"><semantics id="S2.F3.4.m4.1a"><msup id="S2.F3.4.m4.1.1" xref="S2.F3.4.m4.1.1.cmml"><mi id="S2.F3.4.m4.1.1a" xref="S2.F3.4.m4.1.1.cmml"></mi><mrow id="S2.F3.4.m4.1.1.1" xref="S2.F3.4.m4.1.1.1.cmml"><mi id="S2.F3.4.m4.1.1.1.2" xref="S2.F3.4.m4.1.1.1.2.cmml">E</mi><mo id="S2.F3.4.m4.1.1.1.1" xref="S2.F3.4.m4.1.1.1.1.cmml">⁢</mo><mi id="S2.F3.4.m4.1.1.1.3" xref="S2.F3.4.m4.1.1.1.3.cmml">M</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S2.F3.4.m4.1b"><apply id="S2.F3.4.m4.1.1.cmml" xref="S2.F3.4.m4.1.1"><apply id="S2.F3.4.m4.1.1.1.cmml" xref="S2.F3.4.m4.1.1.1"><times id="S2.F3.4.m4.1.1.1.1.cmml" xref="S2.F3.4.m4.1.1.1.1"></times><ci id="S2.F3.4.m4.1.1.1.2.cmml" xref="S2.F3.4.m4.1.1.1.2">𝐸</ci><ci id="S2.F3.4.m4.1.1.1.3.cmml" xref="S2.F3.4.m4.1.1.1.3">𝑀</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F3.4.m4.1c">{}^{EM}</annotation><annotation encoding="application/x-llamapun" id="S2.F3.4.m4.1d">start_FLOATSUPERSCRIPT italic_E italic_M end_FLOATSUPERSCRIPT</annotation></semantics></math><cite class="ltx_cite ltx_citemacro_cite">Singh et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib103" title="">2023</a>)</cite>,
AutoAct<cite class="ltx_cite ltx_citemacro_cite">Qiao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib90" title="">2024</a>)</cite>,
自言自语<cite class="ltx_cite ltx_citemacro_cite">Ulmer et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib118" title="">2024</a>)</cite>,
自指导<cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib127" title="">2023b</a>)</cite>
, 节点_lv3],
]
]
[经验获取（§<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#S4" title="4 Experience Acquisition ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_tag">4</span></a>），节点_lv1 ,
[反馈（§<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#S4.SS3" title="4.3 Feedback ‣ 4 Experience Acquisition ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_tag">4.3</span></a>），节点_lv1_5
[环境，节点_lv2,
[
SelfEvolve<cite class="ltx_cite ltx_citemacro_cite">Jiang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib56" title="">2023</a>)</cite>,
自我调试<cite class="ltx_cite ltx_citemacro_cite">Chen et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib22" title="">2023c</a>)</cite>,
反思<cite class="ltx_cite ltx_citemacro_cite">Shinn et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib99" title="">2023</a>)</cite>,
CRITIC<cite class="ltx_cite ltx_citemacro_cite">Gou et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib41" title="">2023</a>)</cite>,
RoboCat<cite class="ltx_cite ltx_citemacro_cite">Bousmalis et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib13" title="">2023</a>)</cite>,
SinViG<cite class="ltx_cite ltx_citemacro_cite">Xu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib135" title="">2024b</a>)</cite>,
SOTOPIA-<math alttext="\pi" class="ltx_Math" display="inline" id="S2.F3.5.m5.1"><semantics id="S2.F3.5.m5.1a"><mi id="S2.F3.5.m5.1.1" xref="S2.F3.5.m5.1.1.cmml">π</mi><annotation-xml encoding="MathML-Content" id="S2.F3.5.m5.1b"><ci id="S2.F3.5.m5.1.1.cmml" xref="S2.F3.5.m5.1.1">𝜋</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.F3.5.m5.1c">\pi</annotation><annotation encoding="application/x-llamapun" id="S2.F3.5.m5.1d">italic_π</annotation></semantics></math><cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib125" title="">2024e</a>)</cite>
, 节点_lv3_5],
]
[模型，节点_lv2,
[
自奖励<cite class="ltx_cite ltx_citemacro_cite">Yuan et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib148" title="">2024</a>)</cite>,
LSX<cite class="ltx_cite ltx_citemacro_cite">Stammer et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib106" title="">2023</a>)</cite>,
DLMA<cite class="ltx_cite ltx_citemacro_cite">Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib70" title="">2024a</a>)</cite>,
SIRLC<cite class="ltx_cite ltx_citemacro_cite">Pang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib85" title="">2023</a>)</cite>,
自对齐<cite class="ltx_cite ltx_citemacro_cite">Zhang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib156" title="">2024e</a>)</cite>,
CAI<cite class="ltx_cite ltx_citemacro_cite">Bai et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib9" title="">2022</a>)</cite>,
自我调整<cite class="ltx_cite ltx_citemacro_cite">Madaan et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib80" title="">2023</a>)</cite>
, 节点_lv3_5],
]
]
[解决方案（§<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#S4.SS2" title="4.2 Solution Evolution ‣ 4 Experience Acquisition ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_tag">4.2</span></a>），节点_lv1_5
[负面，节点_lv2,
[<span class="ltx_text ltx_font_italic" id="S2.F3.8.10">扰动</span>:
RLCD<cite class="ltx_cite ltx_citemacro_cite">Yang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib138" title="">2023a</a>)</cite>,
DLMA<cite class="ltx_cite ltx_citemacro_cite">Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib70" title="">2024a</a>)</cite>,
Ditto<cite class="ltx_cite ltx_citemacro_cite">Lu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib77" title="">2024a</a>)</cite>
, 节点_lv3_5],
[<span class="ltx_text ltx_font_italic" id="S2.F3.8.11">对比</span>:
自奖赏<cite class="ltx_cite ltx_citemacro_cite">Yuan et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib148" title="">2024</a>)</cite>,
SPIN<cite class="ltx_cite ltx_citemacro_cite">Chen et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib24" title="">2024</a>)</cite>,
GRATH<cite class="ltx_cite ltx_citemacro_cite">Chen and Li (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib21" title="">2024</a>)</cite>,
自对比<cite class="ltx_cite ltx_citemacro_cite">Zhang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib154" title="">2024c</a>)</cite>,
ETO<cite class="ltx_cite ltx_citemacro_cite">Song et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib105" title="">2024</a>)</cite>,
A<sup class="ltx_sup" id="S2.F3.8.12">3</sup>T<cite class="ltx_cite ltx_citemacro_cite">Yang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib142" title="">2024c</a>)</cite>,
STE<cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib121" title="">2024b</a>)</cite>,
COTERRORSET<cite class="ltx_cite ltx_citemacro_cite">Tong et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib114" title="">2024</a>)</cite>
, 节点_lv3_5],
]
[积极，节点_lv2,
[<span class="ltx_text ltx_font_italic" id="S2.F3.8.13">有根据的</span>:
自对齐<cite class="ltx_cite ltx_citemacro_cite">Sun et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib108" title="">2024</a>)</cite>,
SALMON<cite class="ltx_cite ltx_citemacro_cite">Sun et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib107" title="">2023</a>)</cite>,
MemoryBank<cite class="ltx_cite ltx_citemacro_cite">Zhong et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib162" title="">2024b</a>)</cite>,
TiM<cite class="ltx_cite ltx_citemacro_cite">Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib72" title="">2023a</a>)</cite>,
MoT<cite class="ltx_cite ltx_citemacro_cite">Li and Qiu (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib67" title="">2023</a>)</cite>,
IML<cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib120" title="">2024a</a>)</cite>,
TRAN<cite class="ltx_cite ltx_citemacro_cite">Yang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib140" title="">2023b</a>)</cite>,
MemGPT<cite class="ltx_cite ltx_citemacro_cite">Packer et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib84" title="">2023</a>)</cite>
, 节点_lv3_5
],
[<span class="ltx_text ltx_font_italic" id="S2.F3.8.14">自我玩耍</span>:
辩论<cite class="ltx_cite ltx_citemacro_cite">Taubenfeld et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib112" title="">2024</a>)</cite>,
自言自语<cite class="ltx_cite ltx_citemacro_cite">Ulmer et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib118" title="">2024</a>)</cite>,
Ditto<cite class="ltx_cite ltx_citemacro_cite">Lu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib77" title="">2024a</a>)</cite>,
SOLID<cite class="ltx_cite ltx_citemacro_cite">Askari et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib6" title="">2024</a>)</cite>,
SOTOPIA-<math alttext="\pi" class="ltx_Math" display="inline" id="S2.F3.6.m6.1"><semantics id="S2.F3.6.m6.1a"><mi id="S2.F3.6.m6.1.1" xref="S2.F3.6.m6.1.1.cmml">π</mi><annotation-xml encoding="MathML-Content" id="S2.F3.6.m6.1b"><ci id="S2.F3.6.m6.1.1.cmml" xref="S2.F3.6.m6.1.1">𝜋</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.F3.6.m6.1c">\pi</annotation><annotation encoding="application/x-llamapun" id="S2.F3.6.m6.1d">italic_π</annotation></semantics></math><cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib125" title="">2024e</a>)</cite>
, 节点_lv3_5],
[<span class="ltx_text ltx_font_italic" id="S2.F3.8.15">交互式</span>:
SelfEvolve<cite class="ltx_cite ltx_citemacro_cite">Jiang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib56" title="">2023</a>)</cite>,
LDB<cite class="ltx_cite ltx_citemacro_cite">Zhong et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib160" title="">2024a</a>)</cite>,
ETO<cite class="ltx_cite ltx_citemacro_cite">Song et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib105" title="">2024</a>)</cite>,
A<math alttext="{}^{3}" class="ltx_Math" display="inline" id="S2.F3.7.m7.1"><semantics id="S2.F3.7.m7.1a"><msup id="S2.F3.7.m7.1.1" xref="S2.F3.7.m7.1.1.cmml"><mi id="S2.F3.7.m7.1.1a" xref="S2.F3.7.m7.1.1.cmml"></mi><mn id="S2.F3.7.m7.1.1.1" xref="S2.F3.7.m7.1.1.1.cmml">3</mn></msup><annotation-xml encoding="MathML-Content" id="S2.F3.7.m7.1b"><apply id="S2.F3.7.m7.1.1.cmml" xref="S2.F3.7.m7.1.1"><cn id="S2.F3.7.m7.1.1.1.cmml" type="integer" xref="S2.F3.7.m7.1.1.1">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F3.7.m7.1c">{}^{3}</annotation><annotation encoding="application/x-llamapun" id="S2.F3.7.m7.1d">start_FLOATSUPERSCRIPT 3 end_FLOATSUPERSCRIPT</annotation></semantics></math>T<cite class="ltx_cite ltx_citemacro_cite">Yang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib142" title="">2024c</a>)</cite>,
AutoAct<cite class="ltx_cite ltx_citemacro_cite">Qiao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib90" title="">2024</a>)</cite>,
KnowAgent<cite class="ltx_cite ltx_citemacro_cite">Zhu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib166" title="">2024</a>)</cite>
, 节点_lv3_5],
[<span class="ltx_text ltx_font_italic" id="S2.F3.8.16">基于原理</span>:
LMSI<cite class="ltx_cite ltx_citemacro_cite">Huang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib52" title="">2022</a>)</cite>,
STaR<cite class="ltx_cite ltx_citemacro_cite">Zelikman et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib151" title="">2022</a>)</cite>,
A<math alttext="{}^{3}" class="ltx_Math" display="inline" id="S2.F3.8.m8.1"><semantics id="S2.F3.8.m8.1a"><msup id="S2.F3.8.m8.1.1" xref="S2.F3.8.m8.1.1.cmml"><mi id="S2.F3.8.m8.1.1a" xref="S2.F3.8.m8.1.1.cmml"></mi><mn id="S2.F3.8.m8.1.1.1" xref="S2.F3.8.m8.1.1.1.cmml">3</mn></msup><annotation-xml encoding="MathML-Content" id="S2.F3.8.m8.1b"><apply id="S2.F3.8.m8.1.1.cmml" xref="S2.F3.8.m8.1.1"><cn id="S2.F3.8.m8.1.1.1.cmml" type="integer" xref="S2.F3.8.m8.1.1.1">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F3.8.m8.1c">{}^{3}</annotation><annotation encoding="application/x-llamapun" id="S2.F3.8.m8.1d">start_FLOATSUPERSCRIPT 3 end_FLOATSUPERSCRIPT</annotation></semantics></math>T<cite class="ltx_cite ltx_citemacro_cite">Yang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib142" title="">2024c</a>)</cite>
, 节点_lv3_5],
]
]
[任务（§<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#S4.SS1" title="4.1 Task Evolution ‣ 4 Experience Acquisition ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_tag">4.1</span></a>），节点_lv1_5
[选择性，节点_lv2,
[
DIVERSE-EVOL<cite class="ltx_cite ltx_citemacro_cite">Wu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib131" title="">2023</a>)</cite>,
SOFT<cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib122" title="">2024c</a>)</cite>,
选择性反思调整<cite class="ltx_cite ltx_citemacro_cite">Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib63" title="">2024b</a>)</cite>
V-STaR<cite class="ltx_cite ltx_citemacro_cite">Hosseini et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib49" title="">2024</a>)</cite>
, 节点_lv3_5],
]
[无知，节点_lv2,
[
自指导<cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib127" title="">2023b</a>); Honovich et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib48" title="">2022</a>); Roziere et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib93" title="">2023</a>)</cite>,
Ada-Instruct<cite class="ltx_cite ltx_citemacro_cite">Cui and Wang (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib27" title="">2023</a>)</cite>,
Evol-Instruct<cite class="ltx_cite ltx_citemacro_cite">Xu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib134" title="">2024a</a>)</cite>,
MetaMath<cite class="ltx_cite ltx_citemacro_cite">Yu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib147" title="">2023b</a>)</cite>,
PromptBreeder<cite class="ltx_cite ltx_citemacro_cite">Fernando et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib36" title="">2023</a>)</cite>,
回译<cite class="ltx_cite ltx_citemacro_cite">Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib66" title="">2023b</a>)</cite>,
Kun<cite class="ltx_cite ltx_citemacro_cite">Zheng et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib159" title="">2024b</a>)</cite>
, 节点_lv3_5],
]
[基于知识，节点_lv2,
[<span class="ltx_text ltx_font_italic" id="S2.F3.8.17">非结构化</span>:
UltraChat<cite class="ltx_cite ltx_citemacro_cite">Ding et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib33" title="">2023</a>)</cite>,
SciGLM<cite class="ltx_cite ltx_citemacro_cite">Zhang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib153" title="">2024b</a>)</cite>,
EvIT<cite class="ltx_cite ltx_citemacro_cite">Tao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib110" title="">2024a</a>)</cite>,
MEEL<cite class="ltx_cite ltx_citemacro_cite">Tao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib111" title="">2024b</a>)</cite>
, 节点_lv3_5],
[<span class="ltx_text ltx_font_italic" id="S2.F3.8.18">结构化</span>:
自对齐<cite class="ltx_cite ltx_citemacro_cite">Sun et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib108" title="">2024</a>)</cite>,
Ditto<cite class="ltx_cite ltx_citemacro_cite">Lu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib77" title="">2024a</a>)</cite>,
SOLID<cite class="ltx_cite ltx_citemacro_cite">Askari et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib6" title="">2024</a>)</cite>
, 节点_lv3_5],
]
]
]
</p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">图3： </span>自进化大型语言模型的分类。</figcaption>
</figure>
</section>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">3 </span>演化目标</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">自我进化的LLM中的进化目标作为预定义的目标，自主地指导它们的发展和完善。就像人类根据需求和欲望设定个人目标一样，这些目标至关重要，因为它们决定了模型如何迭代地自我更新。它们使LLM能够自主地从新数据中学习，优化算法，并适应不断变化的环境，有效地“感知”其需求并根据反馈或自我评估设定自己的目标，以增强功能而无需人类干预。</p>
</div>
<div class="ltx_para" id="S3.p2">
<p class="ltx_p" id="S3.p2.1">我们将演化目标定义为结合了演化能力和演化方向。演化能力代表了一种内在和详细的技能。演化方向是演化目标旨在改进的方面。我们将演化目标表述如下：</p>
</div>
<div class="ltx_para" id="S3.p3">
<table class="ltx_equation ltx_eqn_table" id="S3.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="{\mathcal{E}}^{t}=({\mathcal{A}}^{t},{\mathcal{D}}^{t})," class="ltx_Math" display="block" id="S3.E1.m1.1"><semantics id="S3.E1.m1.1a"><mrow id="S3.E1.m1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml"><mrow id="S3.E1.m1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml"><msup id="S3.E1.m1.1.1.1.1.4" xref="S3.E1.m1.1.1.1.1.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.1.1.1.1.4.2" xref="S3.E1.m1.1.1.1.1.4.2.cmml">ℰ</mi><mi id="S3.E1.m1.1.1.1.1.4.3" xref="S3.E1.m1.1.1.1.1.4.3.cmml">t</mi></msup><mo id="S3.E1.m1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.3.cmml">=</mo><mrow id="S3.E1.m1.1.1.1.1.2.2" xref="S3.E1.m1.1.1.1.1.2.3.cmml"><mo id="S3.E1.m1.1.1.1.1.2.2.3" stretchy="false" xref="S3.E1.m1.1.1.1.1.2.3.cmml">(</mo><msup id="S3.E1.m1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.1.1.2.cmml">𝒜</mi><mi id="S3.E1.m1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.1.3.cmml">t</mi></msup><mo id="S3.E1.m1.1.1.1.1.2.2.4" xref="S3.E1.m1.1.1.1.1.2.3.cmml">,</mo><msup id="S3.E1.m1.1.1.1.1.2.2.2" xref="S3.E1.m1.1.1.1.1.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.1.1.1.1.2.2.2.2" xref="S3.E1.m1.1.1.1.1.2.2.2.2.cmml">𝒟</mi><mi id="S3.E1.m1.1.1.1.1.2.2.2.3" xref="S3.E1.m1.1.1.1.1.2.2.2.3.cmml">t</mi></msup><mo id="S3.E1.m1.1.1.1.1.2.2.5" stretchy="false" xref="S3.E1.m1.1.1.1.1.2.3.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.1b"><apply id="S3.E1.m1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1"><eq id="S3.E1.m1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.3"></eq><apply id="S3.E1.m1.1.1.1.1.4.cmml" xref="S3.E1.m1.1.1.1.1.4"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.4.1.cmml" xref="S3.E1.m1.1.1.1.1.4">superscript</csymbol><ci id="S3.E1.m1.1.1.1.1.4.2.cmml" xref="S3.E1.m1.1.1.1.1.4.2">ℰ</ci><ci id="S3.E1.m1.1.1.1.1.4.3.cmml" xref="S3.E1.m1.1.1.1.1.4.3">𝑡</ci></apply><interval closure="open" id="S3.E1.m1.1.1.1.1.2.3.cmml" xref="S3.E1.m1.1.1.1.1.2.2"><apply id="S3.E1.m1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1">superscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.2">𝒜</ci><ci id="S3.E1.m1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.3">𝑡</ci></apply><apply id="S3.E1.m1.1.1.1.1.2.2.2.cmml" xref="S3.E1.m1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.2.2.2.1.cmml" xref="S3.E1.m1.1.1.1.1.2.2.2">superscript</csymbol><ci id="S3.E1.m1.1.1.1.1.2.2.2.2.cmml" xref="S3.E1.m1.1.1.1.1.2.2.2.2">𝒟</ci><ci id="S3.E1.m1.1.1.1.1.2.2.2.3.cmml" xref="S3.E1.m1.1.1.1.1.2.2.2.3">𝑡</ci></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.1c">{\mathcal{E}}^{t}=({\mathcal{A}}^{t},{\mathcal{D}}^{t}),</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m1.1d">caligraphic_E start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT = ( caligraphic_A start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT , caligraphic_D start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.p3.3">其中<math alttext="{\mathcal{E}}^{t}" class="ltx_Math" display="inline" id="S3.p3.1.m1.1"><semantics id="S3.p3.1.m1.1a"><msup id="S3.p3.1.m1.1.1" xref="S3.p3.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.p3.1.m1.1.1.2" xref="S3.p3.1.m1.1.1.2.cmml">ℰ</mi><mi id="S3.p3.1.m1.1.1.3" xref="S3.p3.1.m1.1.1.3.cmml">t</mi></msup><annotation-xml encoding="MathML-Content" id="S3.p3.1.m1.1b"><apply id="S3.p3.1.m1.1.1.cmml" xref="S3.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.p3.1.m1.1.1.1.cmml" xref="S3.p3.1.m1.1.1">superscript</csymbol><ci id="S3.p3.1.m1.1.1.2.cmml" xref="S3.p3.1.m1.1.1.2">ℰ</ci><ci id="S3.p3.1.m1.1.1.3.cmml" xref="S3.p3.1.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.1.m1.1c">{\mathcal{E}}^{t}</annotation><annotation encoding="application/x-llamapun" id="S3.p3.1.m1.1d">caligraphic_E start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT</annotation></semantics></math>是进化目标，由进化能力<math alttext="{\mathcal{A}}^{t}" class="ltx_Math" display="inline" id="S3.p3.2.m2.1"><semantics id="S3.p3.2.m2.1a"><msup id="S3.p3.2.m2.1.1" xref="S3.p3.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.p3.2.m2.1.1.2" xref="S3.p3.2.m2.1.1.2.cmml">𝒜</mi><mi id="S3.p3.2.m2.1.1.3" xref="S3.p3.2.m2.1.1.3.cmml">t</mi></msup><annotation-xml encoding="MathML-Content" id="S3.p3.2.m2.1b"><apply id="S3.p3.2.m2.1.1.cmml" xref="S3.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.p3.2.m2.1.1.1.cmml" xref="S3.p3.2.m2.1.1">superscript</csymbol><ci id="S3.p3.2.m2.1.1.2.cmml" xref="S3.p3.2.m2.1.1.2">𝒜</ci><ci id="S3.p3.2.m2.1.1.3.cmml" xref="S3.p3.2.m2.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.2.m2.1c">{\mathcal{A}}^{t}</annotation><annotation encoding="application/x-llamapun" id="S3.p3.2.m2.1d">caligraphic_A start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT</annotation></semantics></math>和进化方向<math alttext="{\mathcal{D}}^{t}" class="ltx_Math" display="inline" id="S3.p3.3.m3.1"><semantics id="S3.p3.3.m3.1a"><msup id="S3.p3.3.m3.1.1" xref="S3.p3.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.p3.3.m3.1.1.2" xref="S3.p3.3.m3.1.1.2.cmml">𝒟</mi><mi id="S3.p3.3.m3.1.1.3" xref="S3.p3.3.m3.1.1.3.cmml">t</mi></msup><annotation-xml encoding="MathML-Content" id="S3.p3.3.m3.1b"><apply id="S3.p3.3.m3.1.1.cmml" xref="S3.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.p3.3.m3.1.1.1.cmml" xref="S3.p3.3.m3.1.1">superscript</csymbol><ci id="S3.p3.3.m3.1.1.2.cmml" xref="S3.p3.3.m3.1.1.2">𝒟</ci><ci id="S3.p3.3.m3.1.1.3.cmml" xref="S3.p3.3.m3.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.3.m3.1c">{\mathcal{D}}^{t}</annotation><annotation encoding="application/x-llamapun" id="S3.p3.3.m3.1d">caligraphic_D start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT</annotation></semantics></math>组成。以“推理准确性提高”为例，“推理”是进化能力，“准确性提高”是进化方向。</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">3.1 </span>进化能力</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">在表<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#S3.T1" title="Table 1 ‣ 3.2 Evolution Directions ‣ 3 Evolution Objectives ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_tag">1</span></a>中，我们将当前自我进化研究中的目标进化能力总结和分类为两组：LLMs和LLM代理。</p>
</div>
<section class="ltx_subsubsection" id="S3.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection"><span class="ltx_tag ltx_tag_subsubsection">3.1.1 </span>LLM们</h4>
<div class="ltx_para" id="S3.SS1.SSS1.p1">
<p class="ltx_p" id="S3.SS1.SSS1.p1.1">这些是支撑广泛下游任务的基本能力。</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.SSS1.p2">
<p class="ltx_p" id="S3.SS1.SSS1.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.SSS1.p2.1.1">指示遵循</span>：遵循指示的能力对于有效应用语言模型至关重要。它使这些模型能够在不同任务和领域中满足特定用户需求，并使它们的响应与给定的上下文相一致<cite class="ltx_cite ltx_citemacro_cite">Xu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib133" title="">2023a</a>)</cite>。</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.SSS1.p3">
<p class="ltx_p" id="S3.SS1.SSS1.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.SSS1.p3.1.1">推理</span>：LLMs可以自我演变，识别统计模式，基于信息进行逻辑连接和演绎。它们能够演变以更好地进行涉及系统地按逻辑顺序剖析问题的推理。 <cite class="ltx_cite ltx_citemacro_cite">Cui and Wang (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib27" title="">2023</a>)</cite></p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.SSS1.p4">
<p class="ltx_p" id="S3.SS1.SSS1.p4.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.SSS1.p4.1.1">数学</span>：LLM增强了解决涵盖算术、数学术语、几何和自动定理证明的数学问题的复杂能力<cite class="ltx_cite ltx_citemacro_cite">Ahn et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib2" title="">2024</a>)</cite>，以实现自我进化。</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.SSS1.p5">
<p class="ltx_p" id="S3.SS1.SSS1.p5.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.SSS1.p5.1.1">编码</span>：方法改进了LLM的编码能力，生成更精确和稳健的程序<cite class="ltx_cite ltx_citemacro_cite">Singh et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib103" title="">2023</a>); Zelikman et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib150" title="">2023</a>)</cite>。此外，EvoCodeBench <cite class="ltx_cite ltx_citemacro_cite">Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib62" title="">2024a</a>)</cite> 提供了一个不断更新的演化基准，以防止数据泄漏。</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.SSS1.p6">
<p class="ltx_p" id="S3.SS1.SSS1.p6.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.SSS1.p6.1.1">角色扮演</span>：
它涉及代理理解并在给定环境中扮演特定角色。这在模型必须适应社会结构或遵循与特定身份或功能相关联的行为集的场景中至关重要<cite class="ltx_cite ltx_citemacro_cite">Lu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib77" title="">2024a</a>)</cite>。</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.SSS1.p7">
<p class="ltx_p" id="S3.SS1.SSS1.p7.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.SSS1.p7.1.1">其他</span>：除了上述基本演化目标外，自我演化还可以实现和一系列NLP任务<cite class="ltx_cite ltx_citemacro_cite">Stammer et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib106" title="">2023</a>); Koa et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib59" title="">2024</a>); Gulcehre et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib42" title="">2023</a>); Zhang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib153" title="">2024b</a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib154" title="">c</a>)</cite>。</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection"><span class="ltx_tag ltx_tag_subsubsection">3.1.2 </span>基于LLM的代理</h4>
<div class="ltx_para" id="S3.SS1.SSS2.p1">
<p class="ltx_p" id="S3.SS1.SSS2.p1.1">所讨论的能力是先进的人工智能代理特有的，用于在数字或物理世界中进行任务解决或模拟。这些能力反映了人类认知功能，使这些代理能够执行复杂任务并在动态环境中有效地进行交互。</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.SSS2.p2">
<p class="ltx_p" id="S3.SS1.SSS2.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.SSS2.p2.1.1">规划</span>：
它涉及制定战略和为未来行动或目标做准备的能力。具有这种技能的代理可以分析当前状态，预测潜在行动的结果，并创建一系列步骤来实现特定目标。 <cite class="ltx_cite ltx_citemacro_cite">Qiao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib90" title="">2024</a>)</cite></p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.SSS2.p3">
<p class="ltx_p" id="S3.SS1.SSS2.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.SSS2.p3.1.1">工具使用</span>：
这是利用环境中的物体或工具来执行任务，操纵环境或解决问题的能力<cite class="ltx_cite ltx_citemacro_cite">Zhu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib166" title="">2024</a>)</cite>。</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.SSS2.p4">
<p class="ltx_p" id="S3.SS1.SSS2.p4.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.SSS2.p4.1.1">具身控制</span>：
它指的是一个代理在一个环境中管理和协调其物理形式的能力。这包括运动、灵巧性和物体的操纵。 <cite class="ltx_cite ltx_citemacro_cite">Bousmalis et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib13" title="">2023</a>)</cite>。</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.SSS2.p5">
<p class="ltx_p" id="S3.SS1.SSS2.p5.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.SSS2.p5.1.1">交流</span>：
这是传达信息和理解其他代理或人类消息的能力。具有高级交流能力的代理可以参与对话，与他人合作，并根据接收到的通信调整他们的行为<cite class="ltx_cite ltx_citemacro_cite">Ulmer et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib118" title="">2024</a>)</cite>。</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">3.2 </span>进化方向</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">例子包括但不限于演化方向：</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p2.1.1">提高性能</span>：目标是不断增强模型对各种语言和能力的理解和生成能力。例如，最初用于问答和闲聊的模型可以自主扩展其熟练程度，并发展诊断对话<cite class="ltx_cite ltx_citemacro_cite">Tu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib117" title="">2024</a>)</cite>，社交技能<cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib125" title="">2024e</a>)</cite>和角色扮演<cite class="ltx_cite ltx_citemacro_cite">Lu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib77" title="">2024a</a>)</cite>等能力。</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p3.1.1">适应反馈</span>：这涉及根据反馈改进模型响应，以更好地与偏好相一致或适应环境 <cite class="ltx_cite ltx_citemacro_cite">Yang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib138" title="">2023a</a>); Sun et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib108" title="">2024</a>)</cite>。</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p4">
<p class="ltx_p" id="S3.SS2.p4.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p4.1.1">知识库的扩展</span>：旨在不断更新模型的知识库，以融入最新的信息和趋势。例如，模型可能会自动将新的科学研究整合到其回答中<cite class="ltx_cite ltx_citemacro_cite">Wu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib132" title="">2024</a>)</cite>。</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p5">
<p class="ltx_p" id="S3.SS2.p5.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p5.1.1">安全、伦理和减少偏见</span>：目标是识别和减轻模型的响应中的偏见，确保公平和安全。一个有效的策略是纳入指南，如宪法或具体规则，以识别不当或有偏见的响应，并通过模型更新进行纠正<cite class="ltx_cite ltx_citemacro_cite">Bai et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib9" title="">2022</a>); Lu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib78" title="">2024b</a>)</cite>。</p>
</div>
<figure class="ltx_table" id="S3.T1">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S3.T1.8">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T1.3.3">
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T1.3.3.4" rowspan="2" style="padding-left:3.4pt;padding-right:3.4pt;"><span class="ltx_text ltx_font_smallcaps" id="S3.T1.3.3.4.1">Method</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="S3.T1.3.3.5" style="padding-left:3.4pt;padding-right:3.4pt;">
<span class="ltx_text ltx_font_smallcaps" id="S3.T1.3.3.5.1">Acquisition</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T1.1.1.1" rowspan="2" style="padding-left:3.4pt;padding-right:3.4pt;"><span class="ltx_text" id="S3.T1.1.1.1.1"><span class="ltx_text ltx_font_smallcaps" id="S3.T1.1.1.1.1.1">Refinement</span> <math alttext="f^{{\mathcal{R}}}" class="ltx_Math" display="inline" id="S3.T1.1.1.1.1.m1.1"><semantics id="S3.T1.1.1.1.1.m1.1a"><msup id="S3.T1.1.1.1.1.m1.1.1" xref="S3.T1.1.1.1.1.m1.1.1.cmml"><mi id="S3.T1.1.1.1.1.m1.1.1.2" xref="S3.T1.1.1.1.1.m1.1.1.2.cmml">f</mi><mi class="ltx_font_mathcaligraphic" id="S3.T1.1.1.1.1.m1.1.1.3" xref="S3.T1.1.1.1.1.m1.1.1.3.cmml">ℛ</mi></msup><annotation-xml encoding="MathML-Content" id="S3.T1.1.1.1.1.m1.1b"><apply id="S3.T1.1.1.1.1.m1.1.1.cmml" xref="S3.T1.1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.T1.1.1.1.1.m1.1.1.1.cmml" xref="S3.T1.1.1.1.1.m1.1.1">superscript</csymbol><ci id="S3.T1.1.1.1.1.m1.1.1.2.cmml" xref="S3.T1.1.1.1.1.m1.1.1.2">𝑓</ci><ci id="S3.T1.1.1.1.1.m1.1.1.3.cmml" xref="S3.T1.1.1.1.1.m1.1.1.3">ℛ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.1.1.1.1.m1.1c">f^{{\mathcal{R}}}</annotation><annotation encoding="application/x-llamapun" id="S3.T1.1.1.1.1.m1.1d">italic_f start_POSTSUPERSCRIPT caligraphic_R end_POSTSUPERSCRIPT</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T1.2.2.2" rowspan="2" style="padding-left:3.4pt;padding-right:3.4pt;"><span class="ltx_text" id="S3.T1.2.2.2.1"><span class="ltx_text ltx_font_smallcaps" id="S3.T1.2.2.2.1.1">Updating</span> <math alttext="f^{{\mathcal{U}}}" class="ltx_Math" display="inline" id="S3.T1.2.2.2.1.m1.1"><semantics id="S3.T1.2.2.2.1.m1.1a"><msup id="S3.T1.2.2.2.1.m1.1.1" xref="S3.T1.2.2.2.1.m1.1.1.cmml"><mi id="S3.T1.2.2.2.1.m1.1.1.2" xref="S3.T1.2.2.2.1.m1.1.1.2.cmml">f</mi><mi class="ltx_font_mathcaligraphic" id="S3.T1.2.2.2.1.m1.1.1.3" xref="S3.T1.2.2.2.1.m1.1.1.3.cmml">𝒰</mi></msup><annotation-xml encoding="MathML-Content" id="S3.T1.2.2.2.1.m1.1b"><apply id="S3.T1.2.2.2.1.m1.1.1.cmml" xref="S3.T1.2.2.2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.T1.2.2.2.1.m1.1.1.1.cmml" xref="S3.T1.2.2.2.1.m1.1.1">superscript</csymbol><ci id="S3.T1.2.2.2.1.m1.1.1.2.cmml" xref="S3.T1.2.2.2.1.m1.1.1.2">𝑓</ci><ci id="S3.T1.2.2.2.1.m1.1.1.3.cmml" xref="S3.T1.2.2.2.1.m1.1.1.3">𝒰</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.2.2.2.1.m1.1c">f^{{\mathcal{U}}}</annotation><annotation encoding="application/x-llamapun" id="S3.T1.2.2.2.1.m1.1d">italic_f start_POSTSUPERSCRIPT caligraphic_U end_POSTSUPERSCRIPT</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T1.3.3.3" rowspan="2" style="padding-left:3.4pt;padding-right:3.4pt;"><span class="ltx_text" id="S3.T1.3.3.3.1"><span class="ltx_text ltx_font_smallcaps" id="S3.T1.3.3.3.1.1">Objective</span> <math alttext="{\mathcal{E}}" class="ltx_Math" display="inline" id="S3.T1.3.3.3.1.m1.1"><semantics id="S3.T1.3.3.3.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S3.T1.3.3.3.1.m1.1.1" xref="S3.T1.3.3.3.1.m1.1.1.cmml">ℰ</mi><annotation-xml encoding="MathML-Content" id="S3.T1.3.3.3.1.m1.1b"><ci id="S3.T1.3.3.3.1.m1.1.1.cmml" xref="S3.T1.3.3.3.1.m1.1.1">ℰ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.3.3.3.1.m1.1c">{\mathcal{E}}</annotation><annotation encoding="application/x-llamapun" id="S3.T1.3.3.3.1.m1.1d">caligraphic_E</annotation></semantics></math></span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.6.6">
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.4.4.1" style="padding-left:3.4pt;padding-right:3.4pt;">
<span class="ltx_text ltx_font_smallcaps" id="S3.T1.4.4.1.1">Task</span> <math alttext="f^{{\mathcal{T}}}" class="ltx_Math" display="inline" id="S3.T1.4.4.1.m1.1"><semantics id="S3.T1.4.4.1.m1.1a"><msup id="S3.T1.4.4.1.m1.1.1" xref="S3.T1.4.4.1.m1.1.1.cmml"><mi id="S3.T1.4.4.1.m1.1.1.2" xref="S3.T1.4.4.1.m1.1.1.2.cmml">f</mi><mi class="ltx_font_mathcaligraphic" id="S3.T1.4.4.1.m1.1.1.3" xref="S3.T1.4.4.1.m1.1.1.3.cmml">𝒯</mi></msup><annotation-xml encoding="MathML-Content" id="S3.T1.4.4.1.m1.1b"><apply id="S3.T1.4.4.1.m1.1.1.cmml" xref="S3.T1.4.4.1.m1.1.1"><csymbol cd="ambiguous" id="S3.T1.4.4.1.m1.1.1.1.cmml" xref="S3.T1.4.4.1.m1.1.1">superscript</csymbol><ci id="S3.T1.4.4.1.m1.1.1.2.cmml" xref="S3.T1.4.4.1.m1.1.1.2">𝑓</ci><ci id="S3.T1.4.4.1.m1.1.1.3.cmml" xref="S3.T1.4.4.1.m1.1.1.3">𝒯</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.4.4.1.m1.1c">f^{{\mathcal{T}}}</annotation><annotation encoding="application/x-llamapun" id="S3.T1.4.4.1.m1.1d">italic_f start_POSTSUPERSCRIPT caligraphic_T end_POSTSUPERSCRIPT</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.5.5.2" style="padding-left:3.4pt;padding-right:3.4pt;">
<span class="ltx_text ltx_font_smallcaps" id="S3.T1.5.5.2.1">Solution</span> <math alttext="f^{{\mathcal{Y}}}" class="ltx_Math" display="inline" id="S3.T1.5.5.2.m1.1"><semantics id="S3.T1.5.5.2.m1.1a"><msup id="S3.T1.5.5.2.m1.1.1" xref="S3.T1.5.5.2.m1.1.1.cmml"><mi id="S3.T1.5.5.2.m1.1.1.2" xref="S3.T1.5.5.2.m1.1.1.2.cmml">f</mi><mi class="ltx_font_mathcaligraphic" id="S3.T1.5.5.2.m1.1.1.3" xref="S3.T1.5.5.2.m1.1.1.3.cmml">𝒴</mi></msup><annotation-xml encoding="MathML-Content" id="S3.T1.5.5.2.m1.1b"><apply id="S3.T1.5.5.2.m1.1.1.cmml" xref="S3.T1.5.5.2.m1.1.1"><csymbol cd="ambiguous" id="S3.T1.5.5.2.m1.1.1.1.cmml" xref="S3.T1.5.5.2.m1.1.1">superscript</csymbol><ci id="S3.T1.5.5.2.m1.1.1.2.cmml" xref="S3.T1.5.5.2.m1.1.1.2">𝑓</ci><ci id="S3.T1.5.5.2.m1.1.1.3.cmml" xref="S3.T1.5.5.2.m1.1.1.3">𝒴</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.5.5.2.m1.1c">f^{{\mathcal{Y}}}</annotation><annotation encoding="application/x-llamapun" id="S3.T1.5.5.2.m1.1d">italic_f start_POSTSUPERSCRIPT caligraphic_Y end_POSTSUPERSCRIPT</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.6.6.3" style="padding-left:3.4pt;padding-right:3.4pt;">
<span class="ltx_text ltx_font_smallcaps" id="S3.T1.6.6.3.1">Feedback</span> <math alttext="f^{{\mathcal{F}}}" class="ltx_Math" display="inline" id="S3.T1.6.6.3.m1.1"><semantics id="S3.T1.6.6.3.m1.1a"><msup id="S3.T1.6.6.3.m1.1.1" xref="S3.T1.6.6.3.m1.1.1.cmml"><mi id="S3.T1.6.6.3.m1.1.1.2" xref="S3.T1.6.6.3.m1.1.1.2.cmml">f</mi><mi class="ltx_font_mathcaligraphic" id="S3.T1.6.6.3.m1.1.1.3" xref="S3.T1.6.6.3.m1.1.1.3.cmml">ℱ</mi></msup><annotation-xml encoding="MathML-Content" id="S3.T1.6.6.3.m1.1b"><apply id="S3.T1.6.6.3.m1.1.1.cmml" xref="S3.T1.6.6.3.m1.1.1"><csymbol cd="ambiguous" id="S3.T1.6.6.3.m1.1.1.1.cmml" xref="S3.T1.6.6.3.m1.1.1">superscript</csymbol><ci id="S3.T1.6.6.3.m1.1.1.2.cmml" xref="S3.T1.6.6.3.m1.1.1.2">𝑓</ci><ci id="S3.T1.6.6.3.m1.1.1.3.cmml" xref="S3.T1.6.6.3.m1.1.1.3">ℱ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.6.6.3.m1.1c">f^{{\mathcal{F}}}</annotation><annotation encoding="application/x-llamapun" id="S3.T1.6.6.3.m1.1d">italic_f start_POSTSUPERSCRIPT caligraphic_F end_POSTSUPERSCRIPT</annotation></semantics></math>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.8.9.1">
<td class="ltx_td ltx_align_center ltx_border_t" colspan="7" id="S3.T1.8.9.1.1" style="padding-left:3.4pt;padding-right:3.4pt;"><span class="ltx_text ltx_font_smallcaps" id="S3.T1.8.9.1.1.1">Large Language Models</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.8.10.2">
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.8.10.2.1" style="padding-left:3.4pt;padding-right:3.4pt;">Self-Align <cite class="ltx_cite ltx_citemacro_cite">Sun et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib108" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.8.10.2.2" style="padding-left:3.4pt;padding-right:3.4pt;">Context-Based</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.8.10.2.3" style="padding-left:3.4pt;padding-right:3.4pt;">Pos-G</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.8.10.2.4" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.8.10.2.5" style="padding-left:3.4pt;padding-right:3.4pt;">Filtering</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.8.10.2.6" style="padding-left:3.4pt;padding-right:3.4pt;">In-W</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.8.10.2.7" style="padding-left:3.4pt;padding-right:3.4pt;"><span class="ltx_text" id="S3.T1.8.10.2.7.1" style="color:#000000;">IF</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.8.11.3">
<td class="ltx_td ltx_align_center" id="S3.T1.8.11.3.1" style="padding-left:3.4pt;padding-right:3.4pt;">SciGLM <cite class="ltx_cite ltx_citemacro_cite">Zhang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib153" title="">2024b</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.11.3.2" style="padding-left:3.4pt;padding-right:3.4pt;">Context-Based</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.11.3.3" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.11.3.4" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.11.3.5" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.11.3.6" style="padding-left:3.4pt;padding-right:3.4pt;">In-W</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.11.3.7" style="padding-left:3.4pt;padding-right:3.4pt;"><span class="ltx_text" id="S3.T1.8.11.3.7.1" style="color:#000000;">Other</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.8.12.4">
<td class="ltx_td ltx_align_center" id="S3.T1.8.12.4.1" style="padding-left:3.4pt;padding-right:3.4pt;">EvIT <cite class="ltx_cite ltx_citemacro_cite">Tao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib110" title="">2024a</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.12.4.2" style="padding-left:3.4pt;padding-right:3.4pt;">Context-Based</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.12.4.3" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.12.4.4" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.12.4.5" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.12.4.6" style="padding-left:3.4pt;padding-right:3.4pt;">In-W</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.12.4.7" style="padding-left:3.4pt;padding-right:3.4pt;"><span class="ltx_text" id="S3.T1.8.12.4.7.1" style="color:#000000;">Reasoning</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.8.13.5">
<td class="ltx_td ltx_align_center" id="S3.T1.8.13.5.1" style="padding-left:3.4pt;padding-right:3.4pt;">MEEL <cite class="ltx_cite ltx_citemacro_cite">Tao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib111" title="">2024b</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.13.5.2" style="padding-left:3.4pt;padding-right:3.4pt;">Context-Based</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.13.5.3" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.13.5.4" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.13.5.5" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.13.5.6" style="padding-left:3.4pt;padding-right:3.4pt;">In-W</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.13.5.7" style="padding-left:3.4pt;padding-right:3.4pt;">Reasoning</td>
</tr>
<tr class="ltx_tr" id="S3.T1.8.14.6">
<td class="ltx_td ltx_align_center" id="S3.T1.8.14.6.1" style="padding-left:3.4pt;padding-right:3.4pt;">UltraChat <cite class="ltx_cite ltx_citemacro_cite">Ding et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib33" title="">2023</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.14.6.2" style="padding-left:3.4pt;padding-right:3.4pt;">Context-Based</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.14.6.3" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.14.6.4" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.14.6.5" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.14.6.6" style="padding-left:3.4pt;padding-right:3.4pt;">In-W</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.14.6.7" style="padding-left:3.4pt;padding-right:3.4pt;"><span class="ltx_text" id="S3.T1.8.14.6.7.1" style="color:#000000;">Role-Play</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.8.15.7">
<td class="ltx_td ltx_align_center" id="S3.T1.8.15.7.1" style="padding-left:3.4pt;padding-right:3.4pt;">SOLID <cite class="ltx_cite ltx_citemacro_cite">Askari et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib6" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.15.7.2" style="padding-left:3.4pt;padding-right:3.4pt;">Context-Based</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.15.7.3" style="padding-left:3.4pt;padding-right:3.4pt;">Pos-S</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.15.7.4" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.15.7.5" style="padding-left:3.4pt;padding-right:3.4pt;">Filtering</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.15.7.6" style="padding-left:3.4pt;padding-right:3.4pt;">In-W</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.15.7.7" style="padding-left:3.4pt;padding-right:3.4pt;"><span class="ltx_text" id="S3.T1.8.15.7.7.1" style="color:#000000;">Role-Play</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.8.16.8">
<td class="ltx_td ltx_align_center" id="S3.T1.8.16.8.1" style="padding-left:3.4pt;padding-right:3.4pt;">Ditto <cite class="ltx_cite ltx_citemacro_cite">Lu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib77" title="">2024a</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.16.8.2" style="padding-left:3.4pt;padding-right:3.4pt;">Context-Based</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.16.8.3" style="padding-left:3.4pt;padding-right:3.4pt;">Pos-S, Neg-P</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.16.8.4" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.16.8.5" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.16.8.6" style="padding-left:3.4pt;padding-right:3.4pt;">In-W</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.16.8.7" style="padding-left:3.4pt;padding-right:3.4pt;"><span class="ltx_text" id="S3.T1.8.16.8.7.1" style="color:#000000;">Role-Play</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.8.17.9">
<td class="ltx_td ltx_align_center" id="S3.T1.8.17.9.1" style="padding-left:3.4pt;padding-right:3.4pt;">MetaMath <cite class="ltx_cite ltx_citemacro_cite">Yu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib147" title="">2023b</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.17.9.2" style="padding-left:3.4pt;padding-right:3.4pt;">Context-Free</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.17.9.3" style="padding-left:3.4pt;padding-right:3.4pt;">Pos-R</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.17.9.4" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.17.9.5" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.17.9.6" style="padding-left:3.4pt;padding-right:3.4pt;">In-W</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.17.9.7" style="padding-left:3.4pt;padding-right:3.4pt;">Math</td>
</tr>
<tr class="ltx_tr" id="S3.T1.8.18.10">
<td class="ltx_td ltx_align_center" id="S3.T1.8.18.10.1" style="padding-left:3.4pt;padding-right:3.4pt;">Self-Rewarding <cite class="ltx_cite ltx_citemacro_cite">Yuan et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib148" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.18.10.2" style="padding-left:3.4pt;padding-right:3.4pt;">Context-Free</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.18.10.3" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.18.10.4" style="padding-left:3.4pt;padding-right:3.4pt;">Model</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.18.10.5" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.18.10.6" style="padding-left:3.4pt;padding-right:3.4pt;">In-W</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.18.10.7" style="padding-left:3.4pt;padding-right:3.4pt;"><span class="ltx_text" id="S3.T1.8.18.10.7.1" style="color:#000000;">IF,Reasoning,Role-Play</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.8.19.11">
<td class="ltx_td ltx_align_center" id="S3.T1.8.19.11.1" style="padding-left:3.4pt;padding-right:3.4pt;">Kun <cite class="ltx_cite ltx_citemacro_cite">Zheng et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib159" title="">2024b</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.19.11.2" style="padding-left:3.4pt;padding-right:3.4pt;">Context-Free</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.19.11.3" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.19.11.4" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.19.11.5" style="padding-left:3.4pt;padding-right:3.4pt;">Filtering</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.19.11.6" style="padding-left:3.4pt;padding-right:3.4pt;">In-W</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.19.11.7" style="padding-left:3.4pt;padding-right:3.4pt;"><span class="ltx_text" id="S3.T1.8.19.11.7.1" style="color:#000000;">IF,Reasoning</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.8.20.12">
<td class="ltx_td ltx_align_center" id="S3.T1.8.20.12.1" style="padding-left:3.4pt;padding-right:3.4pt;">PromptBreeder <cite class="ltx_cite ltx_citemacro_cite">Fernando et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib36" title="">2023</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.20.12.2" style="padding-left:3.4pt;padding-right:3.4pt;">Context-Free</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.20.12.3" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.20.12.4" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.20.12.5" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.20.12.6" style="padding-left:3.4pt;padding-right:3.4pt;">In-C</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.20.12.7" style="padding-left:3.4pt;padding-right:3.4pt;">Math, Reasoning</td>
</tr>
<tr class="ltx_tr" id="S3.T1.8.21.13">
<td class="ltx_td ltx_align_center" id="S3.T1.8.21.13.1" style="padding-left:3.4pt;padding-right:3.4pt;">Ada-Instruct <cite class="ltx_cite ltx_citemacro_cite">Cui and Wang (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib27" title="">2023</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.21.13.2" style="padding-left:3.4pt;padding-right:3.4pt;">Context-Free</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.21.13.3" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.21.13.4" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.21.13.5" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.21.13.6" style="padding-left:3.4pt;padding-right:3.4pt;">In-W</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.21.13.7" style="padding-left:3.4pt;padding-right:3.4pt;">Math, Reasoning, Code</td>
</tr>
<tr class="ltx_tr" id="S3.T1.8.22.14">
<td class="ltx_td ltx_align_center" id="S3.T1.8.22.14.1" style="padding-left:3.4pt;padding-right:3.4pt;">Backtranslation <cite class="ltx_cite ltx_citemacro_cite">Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib66" title="">2023b</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.22.14.2" style="padding-left:3.4pt;padding-right:3.4pt;">Context-Free</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.22.14.3" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.22.14.4" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.22.14.5" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.22.14.6" style="padding-left:3.4pt;padding-right:3.4pt;">In-W</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.22.14.7" style="padding-left:3.4pt;padding-right:3.4pt;"><span class="ltx_text" id="S3.T1.8.22.14.7.1" style="color:#000000;">IF</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.8.23.15">
<td class="ltx_td ltx_align_center" id="S3.T1.8.23.15.1" style="padding-left:3.4pt;padding-right:3.4pt;">DiverseEvol <cite class="ltx_cite ltx_citemacro_cite">Wu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib131" title="">2023</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.23.15.2" style="padding-left:3.4pt;padding-right:3.4pt;">Selective</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.23.15.3" style="padding-left:3.4pt;padding-right:3.4pt;">Pos-I</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.23.15.4" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.23.15.5" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.23.15.6" style="padding-left:3.4pt;padding-right:3.4pt;">In-W</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.23.15.7" style="padding-left:3.4pt;padding-right:3.4pt;">Code</td>
</tr>
<tr class="ltx_tr" id="S3.T1.8.24.16">
<td class="ltx_td ltx_align_center" id="S3.T1.8.24.16.1" style="padding-left:3.4pt;padding-right:3.4pt;">Grath <cite class="ltx_cite ltx_citemacro_cite">Chen and Li (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib21" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.24.16.2" style="padding-left:3.4pt;padding-right:3.4pt;">Selective</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.24.16.3" style="padding-left:3.4pt;padding-right:3.4pt;">Neg-C</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.24.16.4" style="padding-left:3.4pt;padding-right:3.4pt;">Model</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.24.16.5" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.24.16.6" style="padding-left:3.4pt;padding-right:3.4pt;">In-W</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.24.16.7" style="padding-left:3.4pt;padding-right:3.4pt;">Reasoning</td>
</tr>
<tr class="ltx_tr" id="S3.T1.7.7">
<td class="ltx_td ltx_align_center" id="S3.T1.7.7.1" style="padding-left:3.4pt;padding-right:3.4pt;">REST<math alttext="{}^{em}" class="ltx_Math" display="inline" id="S3.T1.7.7.1.m1.1"><semantics id="S3.T1.7.7.1.m1.1a"><msup id="S3.T1.7.7.1.m1.1.1" xref="S3.T1.7.7.1.m1.1.1.cmml"><mi id="S3.T1.7.7.1.m1.1.1a" xref="S3.T1.7.7.1.m1.1.1.cmml"></mi><mrow id="S3.T1.7.7.1.m1.1.1.1" xref="S3.T1.7.7.1.m1.1.1.1.cmml"><mi id="S3.T1.7.7.1.m1.1.1.1.2" xref="S3.T1.7.7.1.m1.1.1.1.2.cmml">e</mi><mo id="S3.T1.7.7.1.m1.1.1.1.1" xref="S3.T1.7.7.1.m1.1.1.1.1.cmml">⁢</mo><mi id="S3.T1.7.7.1.m1.1.1.1.3" xref="S3.T1.7.7.1.m1.1.1.1.3.cmml">m</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.T1.7.7.1.m1.1b"><apply id="S3.T1.7.7.1.m1.1.1.cmml" xref="S3.T1.7.7.1.m1.1.1"><apply id="S3.T1.7.7.1.m1.1.1.1.cmml" xref="S3.T1.7.7.1.m1.1.1.1"><times id="S3.T1.7.7.1.m1.1.1.1.1.cmml" xref="S3.T1.7.7.1.m1.1.1.1.1"></times><ci id="S3.T1.7.7.1.m1.1.1.1.2.cmml" xref="S3.T1.7.7.1.m1.1.1.1.2">𝑒</ci><ci id="S3.T1.7.7.1.m1.1.1.1.3.cmml" xref="S3.T1.7.7.1.m1.1.1.1.3">𝑚</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.7.7.1.m1.1c">{}^{em}</annotation><annotation encoding="application/x-llamapun" id="S3.T1.7.7.1.m1.1d">start_FLOATSUPERSCRIPT italic_e italic_m end_FLOATSUPERSCRIPT</annotation></semantics></math> <cite class="ltx_cite ltx_citemacro_cite">Singh et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib103" title="">2023</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.7.7.2" style="padding-left:3.4pt;padding-right:3.4pt;">Selective</td>
<td class="ltx_td ltx_align_center" id="S3.T1.7.7.3" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.7.7.4" style="padding-left:3.4pt;padding-right:3.4pt;">Model</td>
<td class="ltx_td ltx_align_center" id="S3.T1.7.7.5" style="padding-left:3.4pt;padding-right:3.4pt;">Filtering</td>
<td class="ltx_td ltx_align_center" id="S3.T1.7.7.6" style="padding-left:3.4pt;padding-right:3.4pt;">In-W</td>
<td class="ltx_td ltx_align_center" id="S3.T1.7.7.7" style="padding-left:3.4pt;padding-right:3.4pt;">Math, Code</td>
</tr>
<tr class="ltx_tr" id="S3.T1.8.25.17">
<td class="ltx_td ltx_align_center" id="S3.T1.8.25.17.1" style="padding-left:3.4pt;padding-right:3.4pt;">SOFT <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib122" title="">2024c</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.25.17.2" style="padding-left:3.4pt;padding-right:3.4pt;">Selective</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.25.17.3" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.25.17.4" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.25.17.5" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.25.17.6" style="padding-left:3.4pt;padding-right:3.4pt;">In-W</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.25.17.7" style="padding-left:3.4pt;padding-right:3.4pt;"><span class="ltx_text" id="S3.T1.8.25.17.7.1" style="color:#000000;">IF</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.8.26.18">
<td class="ltx_td ltx_align_center" id="S3.T1.8.26.18.1" style="padding-left:3.4pt;padding-right:3.4pt;">LSX <cite class="ltx_cite ltx_citemacro_cite">Stammer et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib106" title="">2023</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.26.18.2" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.26.18.3" style="padding-left:3.4pt;padding-right:3.4pt;">Pos-R</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.26.18.4" style="padding-left:3.4pt;padding-right:3.4pt;">Model</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.26.18.5" style="padding-left:3.4pt;padding-right:3.4pt;">Correcting</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.26.18.6" style="padding-left:3.4pt;padding-right:3.4pt;">In-W</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.26.18.7" style="padding-left:3.4pt;padding-right:3.4pt;">Other</td>
</tr>
<tr class="ltx_tr" id="S3.T1.8.27.19">
<td class="ltx_td ltx_align_center" id="S3.T1.8.27.19.1" style="padding-left:3.4pt;padding-right:3.4pt;">LMSI <cite class="ltx_cite ltx_citemacro_cite">Huang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib52" title="">2022</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.27.19.2" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.27.19.3" style="padding-left:3.4pt;padding-right:3.4pt;">Pos-R</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.27.19.4" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.27.19.5" style="padding-left:3.4pt;padding-right:3.4pt;">Filtering</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.27.19.6" style="padding-left:3.4pt;padding-right:3.4pt;">In-W</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.27.19.7" style="padding-left:3.4pt;padding-right:3.4pt;">Math</td>
</tr>
<tr class="ltx_tr" id="S3.T1.8.28.20">
<td class="ltx_td ltx_align_center" id="S3.T1.8.28.20.1" style="padding-left:3.4pt;padding-right:3.4pt;">TRAN <cite class="ltx_cite ltx_citemacro_cite">Yang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib140" title="">2023b</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.28.20.2" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.28.20.3" style="padding-left:3.4pt;padding-right:3.4pt;">Pos-G</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.28.20.4" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.28.20.5" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.28.20.6" style="padding-left:3.4pt;padding-right:3.4pt;">In-C</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.28.20.7" style="padding-left:3.4pt;padding-right:3.4pt;">Reasoning</td>
</tr>
<tr class="ltx_tr" id="S3.T1.8.29.21">
<td class="ltx_td ltx_align_center" id="S3.T1.8.29.21.1" style="padding-left:3.4pt;padding-right:3.4pt;">MOT <cite class="ltx_cite ltx_citemacro_cite">Li and Qiu (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib67" title="">2023</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.29.21.2" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.29.21.3" style="padding-left:3.4pt;padding-right:3.4pt;">Pos-R, Pos-G</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.29.21.4" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.29.21.5" style="padding-left:3.4pt;padding-right:3.4pt;">Filtering</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.29.21.6" style="padding-left:3.4pt;padding-right:3.4pt;">In-C</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.29.21.7" style="padding-left:3.4pt;padding-right:3.4pt;">Math, Reasoning</td>
</tr>
<tr class="ltx_tr" id="S3.T1.8.30.22">
<td class="ltx_td ltx_align_center" id="S3.T1.8.30.22.1" style="padding-left:3.4pt;padding-right:3.4pt;">STaR <cite class="ltx_cite ltx_citemacro_cite">Zelikman et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib151" title="">2022</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.30.22.2" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.30.22.3" style="padding-left:3.4pt;padding-right:3.4pt;">Pos-R, Neg-C</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.30.22.4" style="padding-left:3.4pt;padding-right:3.4pt;">Model</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.30.22.5" style="padding-left:3.4pt;padding-right:3.4pt;">Correct</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.30.22.6" style="padding-left:3.4pt;padding-right:3.4pt;">In-W</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.30.22.7" style="padding-left:3.4pt;padding-right:3.4pt;">Reasoning</td>
</tr>
<tr class="ltx_tr" id="S3.T1.8.31.23">
<td class="ltx_td ltx_align_center" id="S3.T1.8.31.23.1" style="padding-left:3.4pt;padding-right:3.4pt;">COTERRORSET <cite class="ltx_cite ltx_citemacro_cite">Tong et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib114" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.31.23.2" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.31.23.3" style="padding-left:3.4pt;padding-right:3.4pt;">Pos-R, Neg-C</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.31.23.4" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.31.23.5" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.31.23.6" style="padding-left:3.4pt;padding-right:3.4pt;">In-W</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.31.23.7" style="padding-left:3.4pt;padding-right:3.4pt;">Math, Reasoning</td>
</tr>
<tr class="ltx_tr" id="S3.T1.8.32.24">
<td class="ltx_td ltx_align_center" id="S3.T1.8.32.24.1" style="padding-left:3.4pt;padding-right:3.4pt;">Self-Debugging <cite class="ltx_cite ltx_citemacro_cite">Chen et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib22" title="">2023c</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.32.24.2" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.32.24.3" style="padding-left:3.4pt;padding-right:3.4pt;">Pos-I</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.32.24.4" style="padding-left:3.4pt;padding-right:3.4pt;">Env</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.32.24.5" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.32.24.6" style="padding-left:3.4pt;padding-right:3.4pt;">In-C</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.32.24.7" style="padding-left:3.4pt;padding-right:3.4pt;">Code</td>
</tr>
<tr class="ltx_tr" id="S3.T1.8.33.25">
<td class="ltx_td ltx_align_center" id="S3.T1.8.33.25.1" style="padding-left:3.4pt;padding-right:3.4pt;">SelfEvolve <cite class="ltx_cite ltx_citemacro_cite">Jiang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib56" title="">2023</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.33.25.2" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.33.25.3" style="padding-left:3.4pt;padding-right:3.4pt;">Pos-I</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.33.25.4" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.33.25.5" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.33.25.6" style="padding-left:3.4pt;padding-right:3.4pt;">In-C</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.33.25.7" style="padding-left:3.4pt;padding-right:3.4pt;">Code</td>
</tr>
<tr class="ltx_tr" id="S3.T1.8.34.26">
<td class="ltx_td ltx_align_center" id="S3.T1.8.34.26.1" style="padding-left:3.4pt;padding-right:3.4pt;">Reflexion <cite class="ltx_cite ltx_citemacro_cite">Shinn et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib98" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.34.26.2" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.34.26.3" style="padding-left:3.4pt;padding-right:3.4pt;">Pos-I, Pos-G</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.34.26.4" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.34.26.5" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.34.26.6" style="padding-left:3.4pt;padding-right:3.4pt;">In-C</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.34.26.7" style="padding-left:3.4pt;padding-right:3.4pt;">Code, Reasoning</td>
</tr>
<tr class="ltx_tr" id="S3.T1.8.35.27">
<td class="ltx_td ltx_align_center" id="S3.T1.8.35.27.1" style="padding-left:3.4pt;padding-right:3.4pt;">V-STaR <cite class="ltx_cite ltx_citemacro_cite">Hosseini et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib49" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.35.27.2" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.35.27.3" style="padding-left:3.4pt;padding-right:3.4pt;">Neg-C</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.35.27.4" style="padding-left:3.4pt;padding-right:3.4pt;">Model</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.35.27.5" style="padding-left:3.4pt;padding-right:3.4pt;">Filter</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.35.27.6" style="padding-left:3.4pt;padding-right:3.4pt;">In-W</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.35.27.7" style="padding-left:3.4pt;padding-right:3.4pt;">Math, Code</td>
</tr>
<tr class="ltx_tr" id="S3.T1.8.36.28">
<td class="ltx_td ltx_align_center" id="S3.T1.8.36.28.1" style="padding-left:3.4pt;padding-right:3.4pt;">Self-Contrast <cite class="ltx_cite ltx_citemacro_cite">Zhang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib156" title="">2024e</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.36.28.2" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.36.28.3" style="padding-left:3.4pt;padding-right:3.4pt;">Neg-C</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.36.28.4" style="padding-left:3.4pt;padding-right:3.4pt;">Model</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.36.28.5" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.36.28.6" style="padding-left:3.4pt;padding-right:3.4pt;">In-W</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.36.28.7" style="padding-left:3.4pt;padding-right:3.4pt;">Reasoning</td>
</tr>
<tr class="ltx_tr" id="S3.T1.8.37.29">
<td class="ltx_td ltx_align_center" id="S3.T1.8.37.29.1" style="padding-left:3.4pt;padding-right:3.4pt;">SALMON <cite class="ltx_cite ltx_citemacro_cite">Sun et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib107" title="">2023</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.37.29.2" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.37.29.3" style="padding-left:3.4pt;padding-right:3.4pt;">Neg-C</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.37.29.4" style="padding-left:3.4pt;padding-right:3.4pt;">Model</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.37.29.5" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.37.29.6" style="padding-left:3.4pt;padding-right:3.4pt;">In-W</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.37.29.7" style="padding-left:3.4pt;padding-right:3.4pt;"><span class="ltx_text" id="S3.T1.8.37.29.7.1" style="color:#000000;">IF,Reasoning,Role-Play</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.8.38.30">
<td class="ltx_td ltx_align_center" id="S3.T1.8.38.30.1" style="padding-left:3.4pt;padding-right:3.4pt;">SPIN <cite class="ltx_cite ltx_citemacro_cite">Chen et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib24" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.38.30.2" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.38.30.3" style="padding-left:3.4pt;padding-right:3.4pt;">Neg-C</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.38.30.4" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.38.30.5" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.38.30.6" style="padding-left:3.4pt;padding-right:3.4pt;">In-W</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.38.30.7" style="padding-left:3.4pt;padding-right:3.4pt;"><span class="ltx_text" id="S3.T1.8.38.30.7.1" style="color:#000000;">IF,Reasoning,Role-Play</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.8.39.31">
<td class="ltx_td ltx_align_center" id="S3.T1.8.39.31.1" style="padding-left:3.4pt;padding-right:3.4pt;">RLCD <cite class="ltx_cite ltx_citemacro_cite">Yang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib138" title="">2023a</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.39.31.2" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.39.31.3" style="padding-left:3.4pt;padding-right:3.4pt;">Neg-P</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.39.31.4" style="padding-left:3.4pt;padding-right:3.4pt;">Model</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.39.31.5" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.39.31.6" style="padding-left:3.4pt;padding-right:3.4pt;">In-W</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.39.31.7" style="padding-left:3.4pt;padding-right:3.4pt;"><span class="ltx_text" id="S3.T1.8.39.31.7.1" style="color:#000000;">IF</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.8.40.32">
<td class="ltx_td ltx_align_center" id="S3.T1.8.40.32.1" style="padding-left:3.4pt;padding-right:3.4pt;">DLMA <cite class="ltx_cite ltx_citemacro_cite">Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib70" title="">2024a</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.40.32.2" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.40.32.3" style="padding-left:3.4pt;padding-right:3.4pt;">Neg-P</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.40.32.4" style="padding-left:3.4pt;padding-right:3.4pt;">Model</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.40.32.5" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.40.32.6" style="padding-left:3.4pt;padding-right:3.4pt;">In-W</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.40.32.7" style="padding-left:3.4pt;padding-right:3.4pt;"><span class="ltx_text" id="S3.T1.8.40.32.7.1" style="color:#000000;">IF</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.8.41.33">
<td class="ltx_td ltx_align_center" id="S3.T1.8.41.33.1" style="padding-left:3.4pt;padding-right:3.4pt;">SELF <cite class="ltx_cite ltx_citemacro_cite">Lu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib76" title="">2023</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.41.33.2" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.41.33.3" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.41.33.4" style="padding-left:3.4pt;padding-right:3.4pt;">Model</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.41.33.5" style="padding-left:3.4pt;padding-right:3.4pt;">Correct</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.41.33.6" style="padding-left:3.4pt;padding-right:3.4pt;">In-W</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.41.33.7" style="padding-left:3.4pt;padding-right:3.4pt;"><span class="ltx_text" id="S3.T1.8.41.33.7.1" style="color:#000000;">IF, Math</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.8.42.34">
<td class="ltx_td ltx_align_center ltx_border_t" colspan="7" id="S3.T1.8.42.34.1" style="padding-left:3.4pt;padding-right:3.4pt;">
<span class="ltx_text ltx_font_smallcaps" id="S3.T1.8.42.34.1.1">LLM Agents</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.8.43.35">
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.8.43.35.1" style="padding-left:3.4pt;padding-right:3.4pt;">AutoAct <cite class="ltx_cite ltx_citemacro_cite">Qiao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib90" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.8.43.35.2" style="padding-left:3.4pt;padding-right:3.4pt;">Context-Based</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.8.43.35.3" style="padding-left:3.4pt;padding-right:3.4pt;">Pos-I</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.8.43.35.4" style="padding-left:3.4pt;padding-right:3.4pt;">Env</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.8.43.35.5" style="padding-left:3.4pt;padding-right:3.4pt;">Filtering</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.8.43.35.6" style="padding-left:3.4pt;padding-right:3.4pt;">In-W</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.8.43.35.7" style="padding-left:3.4pt;padding-right:3.4pt;">Planning, Tool</td>
</tr>
<tr class="ltx_tr" id="S3.T1.8.44.36">
<td class="ltx_td ltx_align_center" id="S3.T1.8.44.36.1" style="padding-left:3.4pt;padding-right:3.4pt;">KnowAgent <cite class="ltx_cite ltx_citemacro_cite">Zhu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib166" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.44.36.2" style="padding-left:3.4pt;padding-right:3.4pt;">Context-Based</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.44.36.3" style="padding-left:3.4pt;padding-right:3.4pt;">Pos-I, Pos-G</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.44.36.4" style="padding-left:3.4pt;padding-right:3.4pt;">Env</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.44.36.5" style="padding-left:3.4pt;padding-right:3.4pt;">Filtering</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.44.36.6" style="padding-left:3.4pt;padding-right:3.4pt;">In-W</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.44.36.7" style="padding-left:3.4pt;padding-right:3.4pt;">Embodied, Planning, Tool</td>
</tr>
<tr class="ltx_tr" id="S3.T1.8.45.37">
<td class="ltx_td ltx_align_center" id="S3.T1.8.45.37.1" style="padding-left:3.4pt;padding-right:3.4pt;">RoboCat <cite class="ltx_cite ltx_citemacro_cite">Bousmalis et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib13" title="">2023</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.45.37.2" style="padding-left:3.4pt;padding-right:3.4pt;">Context-Free</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.45.37.3" style="padding-left:3.4pt;padding-right:3.4pt;">Pos-I</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.45.37.4" style="padding-left:3.4pt;padding-right:3.4pt;">Env</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.45.37.5" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.45.37.6" style="padding-left:3.4pt;padding-right:3.4pt;">In-W</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.45.37.7" style="padding-left:3.4pt;padding-right:3.4pt;">Embodied</td>
</tr>
<tr class="ltx_tr" id="S3.T1.8.46.38">
<td class="ltx_td ltx_align_center" id="S3.T1.8.46.38.1" style="padding-left:3.4pt;padding-right:3.4pt;">STE <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib121" title="">2024b</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.46.38.2" style="padding-left:3.4pt;padding-right:3.4pt;">Context-Free</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.46.38.3" style="padding-left:3.4pt;padding-right:3.4pt;">Pos-I, Neg-C</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.46.38.4" style="padding-left:3.4pt;padding-right:3.4pt;">Env</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.46.38.5" style="padding-left:3.4pt;padding-right:3.4pt;">Correct</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.46.38.6" style="padding-left:3.4pt;padding-right:3.4pt;">In-W</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.46.38.7" style="padding-left:3.4pt;padding-right:3.4pt;">Tool</td>
</tr>
<tr class="ltx_tr" id="S3.T1.8.47.39">
<td class="ltx_td ltx_align_center" id="S3.T1.8.47.39.1" style="padding-left:3.4pt;padding-right:3.4pt;">IML <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib120" title="">2024a</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.47.39.2" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.47.39.3" style="padding-left:3.4pt;padding-right:3.4pt;">Pos-R, Pos-G</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.47.39.4" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.47.39.5" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.47.39.6" style="padding-left:3.4pt;padding-right:3.4pt;">In-C</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.47.39.7" style="padding-left:3.4pt;padding-right:3.4pt;">Reasoning</td>
</tr>
<tr class="ltx_tr" id="S3.T1.8.48.40">
<td class="ltx_td ltx_align_center" id="S3.T1.8.48.40.1" style="padding-left:3.4pt;padding-right:3.4pt;">SinViG <cite class="ltx_cite ltx_citemacro_citet">Xu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib135" title="">2024b</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.48.40.2" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.48.40.3" style="padding-left:3.4pt;padding-right:3.4pt;">Pos-I</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.48.40.4" style="padding-left:3.4pt;padding-right:3.4pt;">Env</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.48.40.5" style="padding-left:3.4pt;padding-right:3.4pt;">Filtering</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.48.40.6" style="padding-left:3.4pt;padding-right:3.4pt;">In-W</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.48.40.7" style="padding-left:3.4pt;padding-right:3.4pt;">Embodied</td>
</tr>
<tr class="ltx_tr" id="S3.T1.8.49.41">
<td class="ltx_td ltx_align_center" id="S3.T1.8.49.41.1" style="padding-left:3.4pt;padding-right:3.4pt;">ETO <cite class="ltx_cite ltx_citemacro_cite">Song et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib105" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.49.41.2" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.49.41.3" style="padding-left:3.4pt;padding-right:3.4pt;">Pos-I, Neg-C</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.49.41.4" style="padding-left:3.4pt;padding-right:3.4pt;">Env</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.49.41.5" style="padding-left:3.4pt;padding-right:3.4pt;">Correct</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.49.41.6" style="padding-left:3.4pt;padding-right:3.4pt;">In-W</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.49.41.7" style="padding-left:3.4pt;padding-right:3.4pt;">Tool</td>
</tr>
<tr class="ltx_tr" id="S3.T1.8.50.42">
<td class="ltx_td ltx_align_center" id="S3.T1.8.50.42.1" style="padding-left:3.4pt;padding-right:3.4pt;">A<sup class="ltx_sup" id="S3.T1.8.50.42.1.1">3</sup>T <cite class="ltx_cite ltx_citemacro_cite">Yang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib142" title="">2024c</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.50.42.2" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.50.42.3" style="padding-left:3.4pt;padding-right:3.4pt;">Pos-I, Neg-C</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.50.42.4" style="padding-left:3.4pt;padding-right:3.4pt;">Env</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.50.42.5" style="padding-left:3.4pt;padding-right:3.4pt;">Correct</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.50.42.6" style="padding-left:3.4pt;padding-right:3.4pt;">In-W</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.50.42.7" style="padding-left:3.4pt;padding-right:3.4pt;">Tool</td>
</tr>
<tr class="ltx_tr" id="S3.T1.8.51.43">
<td class="ltx_td ltx_align_center" id="S3.T1.8.51.43.1" style="padding-left:3.4pt;padding-right:3.4pt;">Debates <cite class="ltx_cite ltx_citemacro_cite">Taubenfeld et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib112" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.51.43.2" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.51.43.3" style="padding-left:3.4pt;padding-right:3.4pt;">Pos-S</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.51.43.4" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.51.43.5" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.51.43.6" style="padding-left:3.4pt;padding-right:3.4pt;">In-W</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.51.43.7" style="padding-left:3.4pt;padding-right:3.4pt;">Communication</td>
</tr>
<tr class="ltx_tr" id="S3.T1.8.8">
<td class="ltx_td ltx_align_center" id="S3.T1.8.8.1" style="padding-left:3.4pt;padding-right:3.4pt;">SOTOPIA-<math alttext="\pi" class="ltx_Math" display="inline" id="S3.T1.8.8.1.m1.1"><semantics id="S3.T1.8.8.1.m1.1a"><mi id="S3.T1.8.8.1.m1.1.1" xref="S3.T1.8.8.1.m1.1.1.cmml">π</mi><annotation-xml encoding="MathML-Content" id="S3.T1.8.8.1.m1.1b"><ci id="S3.T1.8.8.1.m1.1.1.cmml" xref="S3.T1.8.8.1.m1.1.1">𝜋</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.8.8.1.m1.1c">\pi</annotation><annotation encoding="application/x-llamapun" id="S3.T1.8.8.1.m1.1d">italic_π</annotation></semantics></math> <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib125" title="">2024e</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.8.2" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.8.3" style="padding-left:3.4pt;padding-right:3.4pt;">Pos-S,Pos-G</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.8.4" style="padding-left:3.4pt;padding-right:3.4pt;">Env</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.8.5" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.8.6" style="padding-left:3.4pt;padding-right:3.4pt;">In-W</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.8.7" style="padding-left:3.4pt;padding-right:3.4pt;">Communication</td>
</tr>
<tr class="ltx_tr" id="S3.T1.8.52.44">
<td class="ltx_td ltx_align_center" id="S3.T1.8.52.44.1" style="padding-left:3.4pt;padding-right:3.4pt;">Self-Talk <cite class="ltx_cite ltx_citemacro_cite">Ulmer et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib118" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.52.44.2" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.52.44.3" style="padding-left:3.4pt;padding-right:3.4pt;">Pos-S, Pos-G</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.52.44.4" style="padding-left:3.4pt;padding-right:3.4pt;">Model</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.52.44.5" style="padding-left:3.4pt;padding-right:3.4pt;">Filtering</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.52.44.6" style="padding-left:3.4pt;padding-right:3.4pt;">In-W</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.52.44.7" style="padding-left:3.4pt;padding-right:3.4pt;">Communication</td>
</tr>
<tr class="ltx_tr" id="S3.T1.8.53.45">
<td class="ltx_td ltx_align_center" id="S3.T1.8.53.45.1" style="padding-left:3.4pt;padding-right:3.4pt;">MemGPT <cite class="ltx_cite ltx_citemacro_cite">Packer et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib84" title="">2023</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.53.45.2" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.53.45.3" style="padding-left:3.4pt;padding-right:3.4pt;">Pos-G</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.53.45.4" style="padding-left:3.4pt;padding-right:3.4pt;">Env</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.53.45.5" style="padding-left:3.4pt;padding-right:3.4pt;">Filtering</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.53.45.6" style="padding-left:3.4pt;padding-right:3.4pt;">In-C</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.53.45.7" style="padding-left:3.4pt;padding-right:3.4pt;">Communication</td>
</tr>
<tr class="ltx_tr" id="S3.T1.8.54.46">
<td class="ltx_td ltx_align_center" id="S3.T1.8.54.46.1" style="padding-left:3.4pt;padding-right:3.4pt;">MemoryBank <cite class="ltx_cite ltx_citemacro_cite">Zhong et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib162" title="">2024b</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.54.46.2" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.54.46.3" style="padding-left:3.4pt;padding-right:3.4pt;">Pos-G</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.54.46.4" style="padding-left:3.4pt;padding-right:3.4pt;">Env</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.54.46.5" style="padding-left:3.4pt;padding-right:3.4pt;">Filtering</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.54.46.6" style="padding-left:3.4pt;padding-right:3.4pt;">In-C</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.54.46.7" style="padding-left:3.4pt;padding-right:3.4pt;">Communication</td>
</tr>
<tr class="ltx_tr" id="S3.T1.8.55.47">
<td class="ltx_td ltx_align_center" id="S3.T1.8.55.47.1" style="padding-left:3.4pt;padding-right:3.4pt;">ProAgent <cite class="ltx_cite ltx_citemacro_cite">Zhang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib152" title="">2024a</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.55.47.2" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.55.47.3" style="padding-left:3.4pt;padding-right:3.4pt;">Pos-G</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.55.47.4" style="padding-left:3.4pt;padding-right:3.4pt;">Env</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.55.47.5" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.55.47.6" style="padding-left:3.4pt;padding-right:3.4pt;">In-C</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.55.47.7" style="padding-left:3.4pt;padding-right:3.4pt;">Embodied</td>
</tr>
<tr class="ltx_tr" id="S3.T1.8.56.48">
<td class="ltx_td ltx_align_center" id="S3.T1.8.56.48.1" style="padding-left:3.4pt;padding-right:3.4pt;">Agent-Pro <cite class="ltx_cite ltx_citemacro_cite">Zhang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib155" title="">2024d</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.56.48.2" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.56.48.3" style="padding-left:3.4pt;padding-right:3.4pt;">Pos-G</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.56.48.4" style="padding-left:3.4pt;padding-right:3.4pt;">Env</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.56.48.5" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.56.48.6" style="padding-left:3.4pt;padding-right:3.4pt;">In-C</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.56.48.7" style="padding-left:3.4pt;padding-right:3.4pt;">Planning</td>
</tr>
<tr class="ltx_tr" id="S3.T1.8.57.49">
<td class="ltx_td ltx_align_center" id="S3.T1.8.57.49.1" style="padding-left:3.4pt;padding-right:3.4pt;">AesopAgent <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib123" title="">2024d</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.57.49.2" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.57.49.3" style="padding-left:3.4pt;padding-right:3.4pt;">Pos-G</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.57.49.4" style="padding-left:3.4pt;padding-right:3.4pt;">Env</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.57.49.5" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.57.49.6" style="padding-left:3.4pt;padding-right:3.4pt;">In-C</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.57.49.7" style="padding-left:3.4pt;padding-right:3.4pt;">Planning</td>
</tr>
<tr class="ltx_tr" id="S3.T1.8.58.50">
<td class="ltx_td ltx_align_center" id="S3.T1.8.58.50.1" style="padding-left:3.4pt;padding-right:3.4pt;">ICE <cite class="ltx_cite ltx_citemacro_cite">Qian et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib89" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.58.50.2" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.58.50.3" style="padding-left:3.4pt;padding-right:3.4pt;">Pos-G</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.58.50.4" style="padding-left:3.4pt;padding-right:3.4pt;">Env</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.58.50.5" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.58.50.6" style="padding-left:3.4pt;padding-right:3.4pt;">In-C</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.58.50.7" style="padding-left:3.4pt;padding-right:3.4pt;">Planning</td>
</tr>
<tr class="ltx_tr" id="S3.T1.8.59.51">
<td class="ltx_td ltx_align_center" id="S3.T1.8.59.51.1" style="padding-left:3.4pt;padding-right:3.4pt;">TiM <cite class="ltx_cite ltx_citemacro_cite">Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib72" title="">2023a</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.59.51.2" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.59.51.3" style="padding-left:3.4pt;padding-right:3.4pt;">Pos-G</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.59.51.4" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.59.51.5" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.59.51.6" style="padding-left:3.4pt;padding-right:3.4pt;">In-C</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.59.51.7" style="padding-left:3.4pt;padding-right:3.4pt;">Communication</td>
</tr>
<tr class="ltx_tr" id="S3.T1.8.60.52">
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.8.60.52.1" style="padding-left:3.4pt;padding-right:3.4pt;">Werewolf <cite class="ltx_cite ltx_citemacro_cite">Xu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib136" title="">2023b</a>)</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.8.60.52.2" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.8.60.52.3" style="padding-left:3.4pt;padding-right:3.4pt;">Pos-G</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.8.60.52.4" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.8.60.52.5" style="padding-left:3.4pt;padding-right:3.4pt;">-</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.8.60.52.6" style="padding-left:3.4pt;padding-right:3.4pt;">In-C</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.8.60.52.7" style="padding-left:3.4pt;padding-right:3.4pt;">Planning</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">表1： </span>自我进化方法概述，详细介绍了进化阶段的方法。 关键词：Pos（积极），Neg（消极），R（基于原理），I（互动），S（自我对弈），G（基于实地的），C（对比），P（扰动性），Env（环境），In-W（权重内），In-C（上下文内），IF（遵循指示）。对于进化目标，<span class="ltx_text" id="S3.T1.12.1" style="color:#000000;">反馈适应</span>为绿色，<span class="ltx_text" id="S3.T1.13.2" style="color:#000000;">知识库扩展</span>为蓝色，<span class="ltx_text" id="S3.T1.14.3" style="color:#000000;">安全、道德和减少偏见</span>为棕色。提高性能为默认颜色，黑色。</figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">4 </span>经验获取</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">探索和利用<cite class="ltx_cite ltx_citemacro_cite">Gupta et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib44" title="">2006</a>)</cite>是人类和LLM学习的基本策略。其中，探索涉及寻求新的体验以实现目标，类似于LLM自身进化的初始阶段，即经验获取。这一过程对自我进化至关重要，使模型能够自主应对核心挑战，如适应新任务、克服知识限制和增强解决方案的有效性。此外，经验是一个全面的构建，不仅包括遇到的任务<cite class="ltx_cite ltx_citemacro_cite">Dewey (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib31" title="">1938</a>)</cite>，还包括为解决这些任务开发的解决方案<cite class="ltx_cite ltx_citemacro_cite">Schön (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib96" title="">2017</a>)</cite>，以及作为任务表现结果而收到的反馈<cite class="ltx_cite ltx_citemacro_cite">Boud et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib12" title="">2013</a>)</cite>。</p>
</div>
<div class="ltx_para" id="S4.p2">
<p class="ltx_p" id="S4.p2.1">受此启发，我们将经验获取分为三个部分：任务演化、解决方案演化和获取反馈。在任务演化中，LLMs策划并演化与演化目标一致的新任务。对于解决方案演化，LLMs制定并实施策略来完成这些任务。最后，LLMs可以选择性地从与环境互动中收集反馈以进行进一步改进。</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">4.1 </span>任务演变</h3>
<figure class="ltx_figure" id="S4.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_portrait" height="1095" id="S4.F4.g1" src="resource/x3.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">图4： </span>任务演化。 <math alttext="{\mathcal{E}}^{t}" class="ltx_Math" display="inline" id="S4.F4.5.m1.1"><semantics id="S4.F4.5.m1.1b"><msup id="S4.F4.5.m1.1.1" xref="S4.F4.5.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.F4.5.m1.1.1.2" xref="S4.F4.5.m1.1.1.2.cmml">ℰ</mi><mi id="S4.F4.5.m1.1.1.3" xref="S4.F4.5.m1.1.1.3.cmml">t</mi></msup><annotation-xml encoding="MathML-Content" id="S4.F4.5.m1.1c"><apply id="S4.F4.5.m1.1.1.cmml" xref="S4.F4.5.m1.1.1"><csymbol cd="ambiguous" id="S4.F4.5.m1.1.1.1.cmml" xref="S4.F4.5.m1.1.1">superscript</csymbol><ci id="S4.F4.5.m1.1.1.2.cmml" xref="S4.F4.5.m1.1.1.2">ℰ</ci><ci id="S4.F4.5.m1.1.1.3.cmml" xref="S4.F4.5.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.5.m1.1d">{\mathcal{E}}^{t}</annotation><annotation encoding="application/x-llamapun" id="S4.F4.5.m1.1e">caligraphic_E start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT</annotation></semantics></math>和<math alttext="{\mathcal{T}}^{t}" class="ltx_Math" display="inline" id="S4.F4.6.m2.1"><semantics id="S4.F4.6.m2.1b"><msup id="S4.F4.6.m2.1.1" xref="S4.F4.6.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.F4.6.m2.1.1.2" xref="S4.F4.6.m2.1.1.2.cmml">𝒯</mi><mi id="S4.F4.6.m2.1.1.3" xref="S4.F4.6.m2.1.1.3.cmml">t</mi></msup><annotation-xml encoding="MathML-Content" id="S4.F4.6.m2.1c"><apply id="S4.F4.6.m2.1.1.cmml" xref="S4.F4.6.m2.1.1"><csymbol cd="ambiguous" id="S4.F4.6.m2.1.1.1.cmml" xref="S4.F4.6.m2.1.1">superscript</csymbol><ci id="S4.F4.6.m2.1.1.2.cmml" xref="S4.F4.6.m2.1.1.2">𝒯</ci><ci id="S4.F4.6.m2.1.1.3.cmml" xref="S4.F4.6.m2.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.6.m2.1d">{\mathcal{T}}^{t}</annotation><annotation encoding="application/x-llamapun" id="S4.F4.6.m2.1e">caligraphic_T start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT</annotation></semantics></math>是演化目标和<math alttext="t^{th}" class="ltx_Math" display="inline" id="S4.F4.7.m3.1"><semantics id="S4.F4.7.m3.1b"><msup id="S4.F4.7.m3.1.1" xref="S4.F4.7.m3.1.1.cmml"><mi id="S4.F4.7.m3.1.1.2" xref="S4.F4.7.m3.1.1.2.cmml">t</mi><mrow id="S4.F4.7.m3.1.1.3" xref="S4.F4.7.m3.1.1.3.cmml"><mi id="S4.F4.7.m3.1.1.3.2" xref="S4.F4.7.m3.1.1.3.2.cmml">t</mi><mo id="S4.F4.7.m3.1.1.3.1" xref="S4.F4.7.m3.1.1.3.1.cmml">⁢</mo><mi id="S4.F4.7.m3.1.1.3.3" xref="S4.F4.7.m3.1.1.3.3.cmml">h</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S4.F4.7.m3.1c"><apply id="S4.F4.7.m3.1.1.cmml" xref="S4.F4.7.m3.1.1"><csymbol cd="ambiguous" id="S4.F4.7.m3.1.1.1.cmml" xref="S4.F4.7.m3.1.1">superscript</csymbol><ci id="S4.F4.7.m3.1.1.2.cmml" xref="S4.F4.7.m3.1.1.2">𝑡</ci><apply id="S4.F4.7.m3.1.1.3.cmml" xref="S4.F4.7.m3.1.1.3"><times id="S4.F4.7.m3.1.1.3.1.cmml" xref="S4.F4.7.m3.1.1.3.1"></times><ci id="S4.F4.7.m3.1.1.3.2.cmml" xref="S4.F4.7.m3.1.1.3.2">𝑡</ci><ci id="S4.F4.7.m3.1.1.3.3.cmml" xref="S4.F4.7.m3.1.1.3.3">ℎ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.7.m3.1d">t^{th}</annotation><annotation encoding="application/x-llamapun" id="S4.F4.7.m3.1e">italic_t start_POSTSUPERSCRIPT italic_t italic_h end_POSTSUPERSCRIPT</annotation></semantics></math>迭代的任务。 <math alttext="{\mathbb{T}}" class="ltx_Math" display="inline" id="S4.F4.8.m4.1"><semantics id="S4.F4.8.m4.1b"><mi id="S4.F4.8.m4.1.1" xref="S4.F4.8.m4.1.1.cmml">𝕋</mi><annotation-xml encoding="MathML-Content" id="S4.F4.8.m4.1c"><ci id="S4.F4.8.m4.1.1.cmml" xref="S4.F4.8.m4.1.1">𝕋</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.8.m4.1d">{\mathbb{T}}</annotation><annotation encoding="application/x-llamapun" id="S4.F4.8.m4.1e">blackboard_T</annotation></semantics></math>是要选择的所有任务的集合。 前两个是生成方法，根据它们各自对知识的使用方式而有所不同。 相比之下，第三种方法采用了判别式方法来选择要学习的内容。</figcaption>
</figure>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">为了获得新的经验，模型首先根据当前迭代中的演化目标<math alttext="{\mathcal{E}}^{t}" class="ltx_Math" display="inline" id="S4.SS1.p1.1.m1.1"><semantics id="S4.SS1.p1.1.m1.1a"><msup id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.p1.1.m1.1.1.2" xref="S4.SS1.p1.1.m1.1.1.2.cmml">ℰ</mi><mi id="S4.SS1.p1.1.m1.1.1.3" xref="S4.SS1.p1.1.m1.1.1.3.cmml">t</mi></msup><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><apply id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.1.m1.1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1">superscript</csymbol><ci id="S4.SS1.p1.1.m1.1.1.2.cmml" xref="S4.SS1.p1.1.m1.1.1.2">ℰ</ci><ci id="S4.SS1.p1.1.m1.1.1.3.cmml" xref="S4.SS1.p1.1.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">{\mathcal{E}}^{t}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.1.m1.1d">caligraphic_E start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT</annotation></semantics></math>来演化新任务。任务演化是引擎中启动整个演化过程的关键步骤。形式上，我们将任务演化表示为：</p>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<table class="ltx_equation ltx_eqn_table" id="S4.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="{\mathcal{T}}^{t}=f^{{\mathcal{T}}}({\mathcal{E}}^{t},\mathrm{M}^{t})," class="ltx_Math" display="block" id="S4.E2.m1.1"><semantics id="S4.E2.m1.1a"><mrow id="S4.E2.m1.1.1.1" xref="S4.E2.m1.1.1.1.1.cmml"><mrow id="S4.E2.m1.1.1.1.1" xref="S4.E2.m1.1.1.1.1.cmml"><msup id="S4.E2.m1.1.1.1.1.4" xref="S4.E2.m1.1.1.1.1.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E2.m1.1.1.1.1.4.2" xref="S4.E2.m1.1.1.1.1.4.2.cmml">𝒯</mi><mi id="S4.E2.m1.1.1.1.1.4.3" xref="S4.E2.m1.1.1.1.1.4.3.cmml">t</mi></msup><mo id="S4.E2.m1.1.1.1.1.3" xref="S4.E2.m1.1.1.1.1.3.cmml">=</mo><mrow id="S4.E2.m1.1.1.1.1.2" xref="S4.E2.m1.1.1.1.1.2.cmml"><msup id="S4.E2.m1.1.1.1.1.2.4" xref="S4.E2.m1.1.1.1.1.2.4.cmml"><mi id="S4.E2.m1.1.1.1.1.2.4.2" xref="S4.E2.m1.1.1.1.1.2.4.2.cmml">f</mi><mi class="ltx_font_mathcaligraphic" id="S4.E2.m1.1.1.1.1.2.4.3" xref="S4.E2.m1.1.1.1.1.2.4.3.cmml">𝒯</mi></msup><mo id="S4.E2.m1.1.1.1.1.2.3" xref="S4.E2.m1.1.1.1.1.2.3.cmml">⁢</mo><mrow id="S4.E2.m1.1.1.1.1.2.2.2" xref="S4.E2.m1.1.1.1.1.2.2.3.cmml"><mo id="S4.E2.m1.1.1.1.1.2.2.2.3" stretchy="false" xref="S4.E2.m1.1.1.1.1.2.2.3.cmml">(</mo><msup id="S4.E2.m1.1.1.1.1.1.1.1.1" xref="S4.E2.m1.1.1.1.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E2.m1.1.1.1.1.1.1.1.1.2" xref="S4.E2.m1.1.1.1.1.1.1.1.1.2.cmml">ℰ</mi><mi id="S4.E2.m1.1.1.1.1.1.1.1.1.3" xref="S4.E2.m1.1.1.1.1.1.1.1.1.3.cmml">t</mi></msup><mo id="S4.E2.m1.1.1.1.1.2.2.2.4" xref="S4.E2.m1.1.1.1.1.2.2.3.cmml">,</mo><msup id="S4.E2.m1.1.1.1.1.2.2.2.2" xref="S4.E2.m1.1.1.1.1.2.2.2.2.cmml"><mi id="S4.E2.m1.1.1.1.1.2.2.2.2.2" mathvariant="normal" xref="S4.E2.m1.1.1.1.1.2.2.2.2.2.cmml">M</mi><mi id="S4.E2.m1.1.1.1.1.2.2.2.2.3" xref="S4.E2.m1.1.1.1.1.2.2.2.2.3.cmml">t</mi></msup><mo id="S4.E2.m1.1.1.1.1.2.2.2.5" stretchy="false" xref="S4.E2.m1.1.1.1.1.2.2.3.cmml">)</mo></mrow></mrow></mrow><mo id="S4.E2.m1.1.1.1.2" xref="S4.E2.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E2.m1.1b"><apply id="S4.E2.m1.1.1.1.1.cmml" xref="S4.E2.m1.1.1.1"><eq id="S4.E2.m1.1.1.1.1.3.cmml" xref="S4.E2.m1.1.1.1.1.3"></eq><apply id="S4.E2.m1.1.1.1.1.4.cmml" xref="S4.E2.m1.1.1.1.1.4"><csymbol cd="ambiguous" id="S4.E2.m1.1.1.1.1.4.1.cmml" xref="S4.E2.m1.1.1.1.1.4">superscript</csymbol><ci id="S4.E2.m1.1.1.1.1.4.2.cmml" xref="S4.E2.m1.1.1.1.1.4.2">𝒯</ci><ci id="S4.E2.m1.1.1.1.1.4.3.cmml" xref="S4.E2.m1.1.1.1.1.4.3">𝑡</ci></apply><apply id="S4.E2.m1.1.1.1.1.2.cmml" xref="S4.E2.m1.1.1.1.1.2"><times id="S4.E2.m1.1.1.1.1.2.3.cmml" xref="S4.E2.m1.1.1.1.1.2.3"></times><apply id="S4.E2.m1.1.1.1.1.2.4.cmml" xref="S4.E2.m1.1.1.1.1.2.4"><csymbol cd="ambiguous" id="S4.E2.m1.1.1.1.1.2.4.1.cmml" xref="S4.E2.m1.1.1.1.1.2.4">superscript</csymbol><ci id="S4.E2.m1.1.1.1.1.2.4.2.cmml" xref="S4.E2.m1.1.1.1.1.2.4.2">𝑓</ci><ci id="S4.E2.m1.1.1.1.1.2.4.3.cmml" xref="S4.E2.m1.1.1.1.1.2.4.3">𝒯</ci></apply><interval closure="open" id="S4.E2.m1.1.1.1.1.2.2.3.cmml" xref="S4.E2.m1.1.1.1.1.2.2.2"><apply id="S4.E2.m1.1.1.1.1.1.1.1.1.cmml" xref="S4.E2.m1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E2.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E2.m1.1.1.1.1.1.1.1.1">superscript</csymbol><ci id="S4.E2.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E2.m1.1.1.1.1.1.1.1.1.2">ℰ</ci><ci id="S4.E2.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S4.E2.m1.1.1.1.1.1.1.1.1.3">𝑡</ci></apply><apply id="S4.E2.m1.1.1.1.1.2.2.2.2.cmml" xref="S4.E2.m1.1.1.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S4.E2.m1.1.1.1.1.2.2.2.2.1.cmml" xref="S4.E2.m1.1.1.1.1.2.2.2.2">superscript</csymbol><ci id="S4.E2.m1.1.1.1.1.2.2.2.2.2.cmml" xref="S4.E2.m1.1.1.1.1.2.2.2.2.2">M</ci><ci id="S4.E2.m1.1.1.1.1.2.2.2.2.3.cmml" xref="S4.E2.m1.1.1.1.1.2.2.2.2.3">𝑡</ci></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E2.m1.1c">{\mathcal{T}}^{t}=f^{{\mathcal{T}}}({\mathcal{E}}^{t},\mathrm{M}^{t}),</annotation><annotation encoding="application/x-llamapun" id="S4.E2.m1.1d">caligraphic_T start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT = italic_f start_POSTSUPERSCRIPT caligraphic_T end_POSTSUPERSCRIPT ( caligraphic_E start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT , roman_M start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S4.SS1.p2.6">其中<math alttext="f^{{\mathcal{T}}}" class="ltx_Math" display="inline" id="S4.SS1.p2.1.m1.1"><semantics id="S4.SS1.p2.1.m1.1a"><msup id="S4.SS1.p2.1.m1.1.1" xref="S4.SS1.p2.1.m1.1.1.cmml"><mi id="S4.SS1.p2.1.m1.1.1.2" xref="S4.SS1.p2.1.m1.1.1.2.cmml">f</mi><mi class="ltx_font_mathcaligraphic" id="S4.SS1.p2.1.m1.1.1.3" xref="S4.SS1.p2.1.m1.1.1.3.cmml">𝒯</mi></msup><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.1b"><apply id="S4.SS1.p2.1.m1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.1.m1.1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1">superscript</csymbol><ci id="S4.SS1.p2.1.m1.1.1.2.cmml" xref="S4.SS1.p2.1.m1.1.1.2">𝑓</ci><ci id="S4.SS1.p2.1.m1.1.1.3.cmml" xref="S4.SS1.p2.1.m1.1.1.3">𝒯</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.1c">f^{{\mathcal{T}}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.1.m1.1d">italic_f start_POSTSUPERSCRIPT caligraphic_T end_POSTSUPERSCRIPT</annotation></semantics></math>是任务演化函数。<math alttext="{\mathcal{E}}^{t}" class="ltx_Math" display="inline" id="S4.SS1.p2.2.m2.1"><semantics id="S4.SS1.p2.2.m2.1a"><msup id="S4.SS1.p2.2.m2.1.1" xref="S4.SS1.p2.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.p2.2.m2.1.1.2" xref="S4.SS1.p2.2.m2.1.1.2.cmml">ℰ</mi><mi id="S4.SS1.p2.2.m2.1.1.3" xref="S4.SS1.p2.2.m2.1.1.3.cmml">t</mi></msup><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.2.m2.1b"><apply id="S4.SS1.p2.2.m2.1.1.cmml" xref="S4.SS1.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.2.m2.1.1.1.cmml" xref="S4.SS1.p2.2.m2.1.1">superscript</csymbol><ci id="S4.SS1.p2.2.m2.1.1.2.cmml" xref="S4.SS1.p2.2.m2.1.1.2">ℰ</ci><ci id="S4.SS1.p2.2.m2.1.1.3.cmml" xref="S4.SS1.p2.2.m2.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.2.m2.1c">{\mathcal{E}}^{t}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.2.m2.1d">caligraphic_E start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT</annotation></semantics></math>、<math alttext="M^{t}" class="ltx_Math" display="inline" id="S4.SS1.p2.3.m3.1"><semantics id="S4.SS1.p2.3.m3.1a"><msup id="S4.SS1.p2.3.m3.1.1" xref="S4.SS1.p2.3.m3.1.1.cmml"><mi id="S4.SS1.p2.3.m3.1.1.2" xref="S4.SS1.p2.3.m3.1.1.2.cmml">M</mi><mi id="S4.SS1.p2.3.m3.1.1.3" xref="S4.SS1.p2.3.m3.1.1.3.cmml">t</mi></msup><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.3.m3.1b"><apply id="S4.SS1.p2.3.m3.1.1.cmml" xref="S4.SS1.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.3.m3.1.1.1.cmml" xref="S4.SS1.p2.3.m3.1.1">superscript</csymbol><ci id="S4.SS1.p2.3.m3.1.1.2.cmml" xref="S4.SS1.p2.3.m3.1.1.2">𝑀</ci><ci id="S4.SS1.p2.3.m3.1.1.3.cmml" xref="S4.SS1.p2.3.m3.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.3.m3.1c">M^{t}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.3.m3.1d">italic_M start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT</annotation></semantics></math>和<math alttext="{\mathcal{T}}^{t}" class="ltx_Math" display="inline" id="S4.SS1.p2.4.m4.1"><semantics id="S4.SS1.p2.4.m4.1a"><msup id="S4.SS1.p2.4.m4.1.1" xref="S4.SS1.p2.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.p2.4.m4.1.1.2" xref="S4.SS1.p2.4.m4.1.1.2.cmml">𝒯</mi><mi id="S4.SS1.p2.4.m4.1.1.3" xref="S4.SS1.p2.4.m4.1.1.3.cmml">t</mi></msup><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.4.m4.1b"><apply id="S4.SS1.p2.4.m4.1.1.cmml" xref="S4.SS1.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.4.m4.1.1.1.cmml" xref="S4.SS1.p2.4.m4.1.1">superscript</csymbol><ci id="S4.SS1.p2.4.m4.1.1.2.cmml" xref="S4.SS1.p2.4.m4.1.1.2">𝒯</ci><ci id="S4.SS1.p2.4.m4.1.1.3.cmml" xref="S4.SS1.p2.4.m4.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.4.m4.1c">{\mathcal{T}}^{t}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.4.m4.1d">caligraphic_T start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT</annotation></semantics></math>分别表示演化目标、模型和迭代<math alttext="t" class="ltx_Math" display="inline" id="S4.SS1.p2.5.m5.1"><semantics id="S4.SS1.p2.5.m5.1a"><mi id="S4.SS1.p2.5.m5.1.1" xref="S4.SS1.p2.5.m5.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.5.m5.1b"><ci id="S4.SS1.p2.5.m5.1.1.cmml" xref="S4.SS1.p2.5.m5.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.5.m5.1c">t</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.5.m5.1d">italic_t</annotation></semantics></math>时演化的任务。我们将现有的关于任务演化方法<math alttext="f^{{\mathcal{T}}}" class="ltx_Math" display="inline" id="S4.SS1.p2.6.m6.1"><semantics id="S4.SS1.p2.6.m6.1a"><msup id="S4.SS1.p2.6.m6.1.1" xref="S4.SS1.p2.6.m6.1.1.cmml"><mi id="S4.SS1.p2.6.m6.1.1.2" xref="S4.SS1.p2.6.m6.1.1.2.cmml">f</mi><mi class="ltx_font_mathcaligraphic" id="S4.SS1.p2.6.m6.1.1.3" xref="S4.SS1.p2.6.m6.1.1.3.cmml">𝒯</mi></msup><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.6.m6.1b"><apply id="S4.SS1.p2.6.m6.1.1.cmml" xref="S4.SS1.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.6.m6.1.1.1.cmml" xref="S4.SS1.p2.6.m6.1.1">superscript</csymbol><ci id="S4.SS1.p2.6.m6.1.1.2.cmml" xref="S4.SS1.p2.6.m6.1.1.2">𝑓</ci><ci id="S4.SS1.p2.6.m6.1.1.3.cmml" xref="S4.SS1.p2.6.m6.1.1.3">𝒯</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.6.m6.1c">f^{{\mathcal{T}}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.6.m6.1d">italic_f start_POSTSUPERSCRIPT caligraphic_T end_POSTSUPERSCRIPT</annotation></semantics></math>的研究总结和归类为三组：<span class="ltx_text ltx_font_italic" id="S4.SS1.p2.6.1">基于知识</span>、<span class="ltx_text ltx_font_italic" id="S4.SS1.p2.6.2">无知识</span>和<span class="ltx_text ltx_font_italic" id="S4.SS1.p2.6.3">选择性</span>。我们将在以下部分详细介绍每种类型，并在图<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#S4.F4" title="Figure 4 ‣ 4.1 Task Evolution ‣ 4 Experience Acquisition ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_tag">4</span></a>中展示概念。</p>
</div>
<section class="ltx_paragraph ltx_pruned_first" id="S4.SS1.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">基于知识</h5>
<div class="ltx_para" id="S4.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px1.p1.1">目标<math alttext="{\mathcal{E}}^{t}" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px1.p1.1.m1.1"><semantics id="S4.SS1.SSS0.Px1.p1.1.m1.1a"><msup id="S4.SS1.SSS0.Px1.p1.1.m1.1.1" xref="S4.SS1.SSS0.Px1.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.SSS0.Px1.p1.1.m1.1.1.2" xref="S4.SS1.SSS0.Px1.p1.1.m1.1.1.2.cmml">ℰ</mi><mi id="S4.SS1.SSS0.Px1.p1.1.m1.1.1.3" xref="S4.SS1.SSS0.Px1.p1.1.m1.1.1.3.cmml">t</mi></msup><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px1.p1.1.m1.1b"><apply id="S4.SS1.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S4.SS1.SSS0.Px1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS0.Px1.p1.1.m1.1.1.1.cmml" xref="S4.SS1.SSS0.Px1.p1.1.m1.1.1">superscript</csymbol><ci id="S4.SS1.SSS0.Px1.p1.1.m1.1.1.2.cmml" xref="S4.SS1.SSS0.Px1.p1.1.m1.1.1.2">ℰ</ci><ci id="S4.SS1.SSS0.Px1.p1.1.m1.1.1.3.cmml" xref="S4.SS1.SSS0.Px1.p1.1.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px1.p1.1.m1.1c">{\mathcal{E}}^{t}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS0.Px1.p1.1.m1.1d">caligraphic_E start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT</annotation></semantics></math>可能与外部知识相关联，以便在当前LLMs中并非固有的知识中发展。
明确地从知识中汲取丰富了任务和演化目标之间的相关性。
它还确保了任务中相关事实的有效性。
我们深入研究基于知识的方法，试图在外部信息的帮助下发展新的任务。</p>
</div>
<div class="ltx_para" id="S4.SS1.SSS0.Px1.p2">
<p class="ltx_p" id="S4.SS1.SSS0.Px1.p2.1">第一种知识是结构化的。结构化知识信息密集且组织良好。
Self-Align <cite class="ltx_cite ltx_citemacro_cite">Sun et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib108" title="">2024</a>)</cite> 策划了涵盖20个科学主题的主题引导任务，例如科学和法律专业知识。
除了主题知识外，DITTO <cite class="ltx_cite ltx_citemacro_cite">Lu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib77" title="">2024a</a>)</cite> 还包括来自Wikidata和Wikipedia的角色知识。该知识包括属性、概况和简洁的角色细节，用于角色扮演对话。
SOLID <cite class="ltx_cite ltx_citemacro_cite">Askari et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib6" title="">2024</a>)</cite> 生成结构化的实体知识作为对话的开端。</p>
</div>
<div class="ltx_para" id="S4.SS1.SSS0.Px1.p3">
<p class="ltx_p" id="S4.SS1.SSS0.Px1.p3.1">第二组任务包括从非结构化上下文中发展而来的任务。非结构化上下文易于获取，但知识稀疏。
UltraChat <cite class="ltx_cite ltx_citemacro_cite">Ding et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib33" title="">2023</a>)</cite> 收集了基于30个元概念的20种文本材料的非结构化知识，以构建对话任务。
SciGLM <cite class="ltx_cite ltx_citemacro_cite">Zhang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib153" title="">2024b</a>)</cite> 从多样化科学学科的文本中提出问题，涵盖丰富的科学知识。
EvIT <cite class="ltx_cite ltx_citemacro_cite">Tao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib110" title="">2024a</a>)</cite> 基于从无监督语料库中挖掘的大规模非结构化事件推理任务。
同样，MEEL <cite class="ltx_cite ltx_citemacro_cite">Tao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib111" title="">2024b</a>)</cite> 在图像和文本中发展多模态事件，以构建MM事件推理任务。</p>
</div>
</section>
<section class="ltx_paragraph ltx_pruned_first" id="S4.SS1.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">Knowledge-Free
知识无关</h5>
<div class="ltx_para" id="S4.SS1.SSS0.Px2.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px2.p1.1">与先前需要大量人力劳动收集外部知识的方法不同，无知识方法独立运行，使用不断发展的对象<math alttext="{\mathcal{E}}^{t}" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px2.p1.1.m1.1"><semantics id="S4.SS1.SSS0.Px2.p1.1.m1.1a"><msup id="S4.SS1.SSS0.Px2.p1.1.m1.1.1" xref="S4.SS1.SSS0.Px2.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.SSS0.Px2.p1.1.m1.1.1.2" xref="S4.SS1.SSS0.Px2.p1.1.m1.1.1.2.cmml">ℰ</mi><mi id="S4.SS1.SSS0.Px2.p1.1.m1.1.1.3" xref="S4.SS1.SSS0.Px2.p1.1.m1.1.1.3.cmml">t</mi></msup><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px2.p1.1.m1.1b"><apply id="S4.SS1.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S4.SS1.SSS0.Px2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="S4.SS1.SSS0.Px2.p1.1.m1.1.1">superscript</csymbol><ci id="S4.SS1.SSS0.Px2.p1.1.m1.1.1.2.cmml" xref="S4.SS1.SSS0.Px2.p1.1.m1.1.1.2">ℰ</ci><ci id="S4.SS1.SSS0.Px2.p1.1.m1.1.1.3.cmml" xref="S4.SS1.SSS0.Px2.p1.1.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px2.p1.1.m1.1c">{\mathcal{E}}^{t}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS0.Px2.p1.1.m1.1d">caligraphic_E start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT</annotation></semantics></math>和模型本身。这些高效方法可以生成更多样化的任务，而无需额外的知识限制。</p>
</div>
<div class="ltx_para" id="S4.SS1.SSS0.Px2.p2">
<p class="ltx_p" id="S4.SS1.SSS0.Px2.p2.1">首先，LLMs可以根据<math alttext="{\mathcal{E}}^{t}" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px2.p2.1.m1.1"><semantics id="S4.SS1.SSS0.Px2.p2.1.m1.1a"><msup id="S4.SS1.SSS0.Px2.p2.1.m1.1.1" xref="S4.SS1.SSS0.Px2.p2.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.SSS0.Px2.p2.1.m1.1.1.2" xref="S4.SS1.SSS0.Px2.p2.1.m1.1.1.2.cmml">ℰ</mi><mi id="S4.SS1.SSS0.Px2.p2.1.m1.1.1.3" xref="S4.SS1.SSS0.Px2.p2.1.m1.1.1.3.cmml">t</mi></msup><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px2.p2.1.m1.1b"><apply id="S4.SS1.SSS0.Px2.p2.1.m1.1.1.cmml" xref="S4.SS1.SSS0.Px2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS0.Px2.p2.1.m1.1.1.1.cmml" xref="S4.SS1.SSS0.Px2.p2.1.m1.1.1">superscript</csymbol><ci id="S4.SS1.SSS0.Px2.p2.1.m1.1.1.2.cmml" xref="S4.SS1.SSS0.Px2.p2.1.m1.1.1.2">ℰ</ci><ci id="S4.SS1.SSS0.Px2.p2.1.m1.1.1.3.cmml" xref="S4.SS1.SSS0.Px2.p2.1.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px2.p2.1.m1.1c">{\mathcal{E}}^{t}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS0.Px2.p2.1.m1.1d">caligraphic_E start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT</annotation></semantics></math>自行提示自己生成新任务。
Self-Instruct <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib127" title="">2023b</a>); Honovich et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib48" title="">2022</a>); Roziere et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib93" title="">2023</a>)</cite>是一种典型的无知识任务演化方法。 这些方法基于演化目标自动生成各种新任务指令。
Ada-Instruct <cite class="ltx_cite ltx_citemacro_cite">Cui and Wang (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib27" title="">2023</a>)</cite>进一步提出了一种自适应任务指令生成策略，对开源LLMs进行微调，以生成用于代码完成和数学推理的冗长而复杂的任务指令。</p>
</div>
<div class="ltx_para" id="S4.SS1.SSS0.Px2.p3">
<p class="ltx_p" id="S4.SS1.SSS0.Px2.p3.1">其次，扩展和增强原始任务可以提高指示的质量。
WizardLM <cite class="ltx_cite ltx_citemacro_cite">Xu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib133" title="">2023a</a>)</cite>提出了Evol-Instruct，它通过深度和广度的演变进化指示跟随的任务，并在代码生成中进一步扩展。
MetaMath <cite class="ltx_cite ltx_citemacro_cite">Yu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib147" title="">2023b</a>)</cite>以多种方式重写问题，包括改述、自我验证和FOBAR。它演变出一个新的MetaMathQA数据集，用于微调LLMs以改进数学任务解决。
Promptbreeder <cite class="ltx_cite ltx_citemacro_cite">Fernando et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib36" title="">2023</a>)</cite>通过突变提示演变种子任务。它通过超级变异提示进一步演变变异提示，以增加任务多样性。</p>
</div>
<div class="ltx_para" id="S4.SS1.SSS0.Px2.p4">
<p class="ltx_p" id="S4.SS1.SSS0.Px2.p4.1">第三，从纯文本中提取任务是另一种方式。
反向翻译<cite class="ltx_cite ltx_citemacro_cite">Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib66" title="">2023b</a>)</cite>从未标记的数据中提取自包含的部分，并将其视为任务的答案。
同样，Kun<cite class="ltx_cite ltx_citemacro_cite">Zheng et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib159" title="">2024b</a>)</cite>提出了一种利用来自未标记数据的指示进行反向翻译的任务自进化算法。</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px3">
<h5 class="ltx_title ltx_title_paragraph">选择性</h5>
<div class="ltx_para" id="S4.SS1.SSS0.Px3.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px3.p1.1">与任务生成相反，我们可以从大规模现有任务开始。在每次迭代中，LLMs可以选择展现出与当前不断发展的目标<math alttext="\mathcal{E}^{t}" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px3.p1.1.m1.1"><semantics id="S4.SS1.SSS0.Px3.p1.1.m1.1a"><msup id="S4.SS1.SSS0.Px3.p1.1.m1.1.1" xref="S4.SS1.SSS0.Px3.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.SSS0.Px3.p1.1.m1.1.1.2" xref="S4.SS1.SSS0.Px3.p1.1.m1.1.1.2.cmml">ℰ</mi><mi id="S4.SS1.SSS0.Px3.p1.1.m1.1.1.3" xref="S4.SS1.SSS0.Px3.p1.1.m1.1.1.3.cmml">t</mi></msup><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px3.p1.1.m1.1b"><apply id="S4.SS1.SSS0.Px3.p1.1.m1.1.1.cmml" xref="S4.SS1.SSS0.Px3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS0.Px3.p1.1.m1.1.1.1.cmml" xref="S4.SS1.SSS0.Px3.p1.1.m1.1.1">superscript</csymbol><ci id="S4.SS1.SSS0.Px3.p1.1.m1.1.1.2.cmml" xref="S4.SS1.SSS0.Px3.p1.1.m1.1.1.2">ℰ</ci><ci id="S4.SS1.SSS0.Px3.p1.1.m1.1.1.3.cmml" xref="S4.SS1.SSS0.Px3.p1.1.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px3.p1.1.m1.1c">\mathcal{E}^{t}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS0.Px3.p1.1.m1.1d">caligraphic_E start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT</annotation></semantics></math>最高相关性的任务，而无需额外生成。这种方法避免了对新任务的复杂策划，简化了进化过程<cite class="ltx_cite ltx_citemacro_cite">Zhou et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib163" title="">2024</a>); Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib64" title="">2023a</a>); Chen et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib19" title="">2023a</a>)</cite>。</p>
</div>
<div class="ltx_para" id="S4.SS1.SSS0.Px3.p2">
<p class="ltx_p" id="S4.SS1.SSS0.Px3.p2.1">一个简单的任务选择方法是从任务池中随机抽样任务，如REST <cite class="ltx_cite ltx_citemacro_cite">Gulcehre et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib42" title="">2023</a>)</cite>，REST<math alttext="{}^{em}" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px3.p2.1.m1.1"><semantics id="S4.SS1.SSS0.Px3.p2.1.m1.1a"><msup id="S4.SS1.SSS0.Px3.p2.1.m1.1.1" xref="S4.SS1.SSS0.Px3.p2.1.m1.1.1.cmml"><mi id="S4.SS1.SSS0.Px3.p2.1.m1.1.1a" xref="S4.SS1.SSS0.Px3.p2.1.m1.1.1.cmml"></mi><mrow id="S4.SS1.SSS0.Px3.p2.1.m1.1.1.1" xref="S4.SS1.SSS0.Px3.p2.1.m1.1.1.1.cmml"><mi id="S4.SS1.SSS0.Px3.p2.1.m1.1.1.1.2" xref="S4.SS1.SSS0.Px3.p2.1.m1.1.1.1.2.cmml">e</mi><mo id="S4.SS1.SSS0.Px3.p2.1.m1.1.1.1.1" xref="S4.SS1.SSS0.Px3.p2.1.m1.1.1.1.1.cmml">⁢</mo><mi id="S4.SS1.SSS0.Px3.p2.1.m1.1.1.1.3" xref="S4.SS1.SSS0.Px3.p2.1.m1.1.1.1.3.cmml">m</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px3.p2.1.m1.1b"><apply id="S4.SS1.SSS0.Px3.p2.1.m1.1.1.cmml" xref="S4.SS1.SSS0.Px3.p2.1.m1.1.1"><apply id="S4.SS1.SSS0.Px3.p2.1.m1.1.1.1.cmml" xref="S4.SS1.SSS0.Px3.p2.1.m1.1.1.1"><times id="S4.SS1.SSS0.Px3.p2.1.m1.1.1.1.1.cmml" xref="S4.SS1.SSS0.Px3.p2.1.m1.1.1.1.1"></times><ci id="S4.SS1.SSS0.Px3.p2.1.m1.1.1.1.2.cmml" xref="S4.SS1.SSS0.Px3.p2.1.m1.1.1.1.2">𝑒</ci><ci id="S4.SS1.SSS0.Px3.p2.1.m1.1.1.1.3.cmml" xref="S4.SS1.SSS0.Px3.p2.1.m1.1.1.1.3">𝑚</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px3.p2.1.m1.1c">{}^{em}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS0.Px3.p2.1.m1.1d">start_FLOATSUPERSCRIPT italic_e italic_m end_FLOATSUPERSCRIPT</annotation></semantics></math> <cite class="ltx_cite ltx_citemacro_cite">Singh et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib103" title="">2023</a>)</cite>和GRATH <cite class="ltx_cite ltx_citemacro_cite">Chen and Li (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib21" title="">2024</a>)</cite>。与随机选择不同，DIVERSE-EVOL <cite class="ltx_cite ltx_citemacro_cite">Wu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib131" title="">2023</a>)</cite>引入了一种数据抽样技术，模型基于嵌入空间中的独特性选择新数据点，确保所选子集的多样性增强。然后，SOFT <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib122" title="">2024c</a>)</cite>分割初始训练集。每次迭代选择分割集的一个块作为演化任务。</p>
</div>
<div class="ltx_para" id="S4.SS1.SSS0.Px3.p3">
<p class="ltx_p" id="S4.SS1.SSS0.Px3.p3.1"><cite class="ltx_cite ltx_citemacro_citet">Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib63" title="">2024b</a>)</cite>提出了选择性反射调整，并通过计算新颖的度量来选择任务子集，以确定答案与问题的相关程度。
V-STaR <cite class="ltx_cite ltx_citemacro_cite">Hosseini et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib49" title="">2024</a>)</cite>选择上一轮的正确解决方案，并将它们的任务指令添加到下一轮的任务集中。</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">4.2 </span>解决方案演变</h3>
<figure class="ltx_figure" id="S4.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="653" id="S4.F5.g1" src="resource/x4.png" width="1660"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">图5：</span>解决方案演变。 <math alttext="{\mathcal{E}}^{t}" class="ltx_Math" display="inline" id="S4.F5.6.m1.1"><semantics id="S4.F5.6.m1.1b"><msup id="S4.F5.6.m1.1.1" xref="S4.F5.6.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.F5.6.m1.1.1.2" xref="S4.F5.6.m1.1.1.2.cmml">ℰ</mi><mi id="S4.F5.6.m1.1.1.3" xref="S4.F5.6.m1.1.1.3.cmml">t</mi></msup><annotation-xml encoding="MathML-Content" id="S4.F5.6.m1.1c"><apply id="S4.F5.6.m1.1.1.cmml" xref="S4.F5.6.m1.1.1"><csymbol cd="ambiguous" id="S4.F5.6.m1.1.1.1.cmml" xref="S4.F5.6.m1.1.1">superscript</csymbol><ci id="S4.F5.6.m1.1.1.2.cmml" xref="S4.F5.6.m1.1.1.2">ℰ</ci><ci id="S4.F5.6.m1.1.1.3.cmml" xref="S4.F5.6.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F5.6.m1.1d">{\mathcal{E}}^{t}</annotation><annotation encoding="application/x-llamapun" id="S4.F5.6.m1.1e">caligraphic_E start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT</annotation></semantics></math>，<math alttext="{\mathcal{T}}^{t}" class="ltx_Math" display="inline" id="S4.F5.7.m2.1"><semantics id="S4.F5.7.m2.1b"><msup id="S4.F5.7.m2.1.1" xref="S4.F5.7.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.F5.7.m2.1.1.2" xref="S4.F5.7.m2.1.1.2.cmml">𝒯</mi><mi id="S4.F5.7.m2.1.1.3" xref="S4.F5.7.m2.1.1.3.cmml">t</mi></msup><annotation-xml encoding="MathML-Content" id="S4.F5.7.m2.1c"><apply id="S4.F5.7.m2.1.1.cmml" xref="S4.F5.7.m2.1.1"><csymbol cd="ambiguous" id="S4.F5.7.m2.1.1.1.cmml" xref="S4.F5.7.m2.1.1">superscript</csymbol><ci id="S4.F5.7.m2.1.1.2.cmml" xref="S4.F5.7.m2.1.1.2">𝒯</ci><ci id="S4.F5.7.m2.1.1.3.cmml" xref="S4.F5.7.m2.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F5.7.m2.1d">{\mathcal{T}}^{t}</annotation><annotation encoding="application/x-llamapun" id="S4.F5.7.m2.1e">caligraphic_T start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT</annotation></semantics></math>和<math alttext="{\mathcal{Y}}^{t}" class="ltx_Math" display="inline" id="S4.F5.8.m3.1"><semantics id="S4.F5.8.m3.1b"><msup id="S4.F5.8.m3.1.1" xref="S4.F5.8.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.F5.8.m3.1.1.2" xref="S4.F5.8.m3.1.1.2.cmml">𝒴</mi><mi id="S4.F5.8.m3.1.1.3" xref="S4.F5.8.m3.1.1.3.cmml">t</mi></msup><annotation-xml encoding="MathML-Content" id="S4.F5.8.m3.1c"><apply id="S4.F5.8.m3.1.1.cmml" xref="S4.F5.8.m3.1.1"><csymbol cd="ambiguous" id="S4.F5.8.m3.1.1.1.cmml" xref="S4.F5.8.m3.1.1">superscript</csymbol><ci id="S4.F5.8.m3.1.1.2.cmml" xref="S4.F5.8.m3.1.1.2">𝒴</ci><ci id="S4.F5.8.m3.1.1.3.cmml" xref="S4.F5.8.m3.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F5.8.m3.1d">{\mathcal{Y}}^{t}</annotation><annotation encoding="application/x-llamapun" id="S4.F5.8.m3.1e">caligraphic_Y start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT</annotation></semantics></math>是<math alttext="t^{th}" class="ltx_Math" display="inline" id="S4.F5.9.m4.1"><semantics id="S4.F5.9.m4.1b"><msup id="S4.F5.9.m4.1.1" xref="S4.F5.9.m4.1.1.cmml"><mi id="S4.F5.9.m4.1.1.2" xref="S4.F5.9.m4.1.1.2.cmml">t</mi><mrow id="S4.F5.9.m4.1.1.3" xref="S4.F5.9.m4.1.1.3.cmml"><mi id="S4.F5.9.m4.1.1.3.2" xref="S4.F5.9.m4.1.1.3.2.cmml">t</mi><mo id="S4.F5.9.m4.1.1.3.1" xref="S4.F5.9.m4.1.1.3.1.cmml">⁢</mo><mi id="S4.F5.9.m4.1.1.3.3" xref="S4.F5.9.m4.1.1.3.3.cmml">h</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S4.F5.9.m4.1c"><apply id="S4.F5.9.m4.1.1.cmml" xref="S4.F5.9.m4.1.1"><csymbol cd="ambiguous" id="S4.F5.9.m4.1.1.1.cmml" xref="S4.F5.9.m4.1.1">superscript</csymbol><ci id="S4.F5.9.m4.1.1.2.cmml" xref="S4.F5.9.m4.1.1.2">𝑡</ci><apply id="S4.F5.9.m4.1.1.3.cmml" xref="S4.F5.9.m4.1.1.3"><times id="S4.F5.9.m4.1.1.3.1.cmml" xref="S4.F5.9.m4.1.1.3.1"></times><ci id="S4.F5.9.m4.1.1.3.2.cmml" xref="S4.F5.9.m4.1.1.3.2">𝑡</ci><ci id="S4.F5.9.m4.1.1.3.3.cmml" xref="S4.F5.9.m4.1.1.3.3">ℎ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F5.9.m4.1d">t^{th}</annotation><annotation encoding="application/x-llamapun" id="S4.F5.9.m4.1e">italic_t start_POSTSUPERSCRIPT italic_t italic_h end_POSTSUPERSCRIPT</annotation></semantics></math>迭代的不断发展的目标、任务和解决方案。 <math alttext="{\mathcal{R}}" class="ltx_Math" display="inline" id="S4.F5.10.m5.1"><semantics id="S4.F5.10.m5.1b"><mi class="ltx_font_mathcaligraphic" id="S4.F5.10.m5.1.1" xref="S4.F5.10.m5.1.1.cmml">ℛ</mi><annotation-xml encoding="MathML-Content" id="S4.F5.10.m5.1c"><ci id="S4.F5.10.m5.1.1.cmml" xref="S4.F5.10.m5.1.1">ℛ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F5.10.m5.1d">{\mathcal{R}}</annotation><annotation encoding="application/x-llamapun" id="S4.F5.10.m5.1e">caligraphic_R</annotation></semantics></math>是理性思考。</figcaption>
</figure>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">在获得进化任务后，LLMs解决任务以获取相应的解决方案。
最常见的策略是根据任务表述直接生成解决方案 <cite class="ltx_cite ltx_citemacro_cite">Zelikman et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib151" title="">2022</a>); Gulcehre et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib42" title="">2023</a>); Singh et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib103" title="">2023</a>); Zheng et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib159" title="">2024b</a>); Yuan et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib148" title="">2024</a>)</cite>。
然而，这种直接的方法可能会得到与进化目标无关的解决方案，导致次优的进化 <cite class="ltx_cite ltx_citemacro_cite">Hare (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib45" title="">2019</a>)</cite>。
因此，解决方案的演化使用不同的策略来解决任务，并通过确保解决方案不仅仅是生成的，而且也是相关和信息丰富的来增强LLM的能力。
在本节中，我们全面调查这些策略，并在图 <a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#S4.F5" title="Figure 5 ‣ 4.2 Solution Evolution ‣ 4 Experience Acquisition ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_tag">5</span></a>中加以说明。
我们首先将解决方案演化如下进行阐述：</p>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<table class="ltx_equation ltx_eqn_table" id="S4.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="{\mathcal{Y}}^{t}=f^{{\mathcal{Y}}}({\mathcal{T}}^{t},{\mathcal{E}}^{t},%
\mathrm{M}^{t})," class="ltx_Math" display="block" id="S4.E3.m1.1"><semantics id="S4.E3.m1.1a"><mrow id="S4.E3.m1.1.1.1" xref="S4.E3.m1.1.1.1.1.cmml"><mrow id="S4.E3.m1.1.1.1.1" xref="S4.E3.m1.1.1.1.1.cmml"><msup id="S4.E3.m1.1.1.1.1.5" xref="S4.E3.m1.1.1.1.1.5.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E3.m1.1.1.1.1.5.2" xref="S4.E3.m1.1.1.1.1.5.2.cmml">𝒴</mi><mi id="S4.E3.m1.1.1.1.1.5.3" xref="S4.E3.m1.1.1.1.1.5.3.cmml">t</mi></msup><mo id="S4.E3.m1.1.1.1.1.4" xref="S4.E3.m1.1.1.1.1.4.cmml">=</mo><mrow id="S4.E3.m1.1.1.1.1.3" xref="S4.E3.m1.1.1.1.1.3.cmml"><msup id="S4.E3.m1.1.1.1.1.3.5" xref="S4.E3.m1.1.1.1.1.3.5.cmml"><mi id="S4.E3.m1.1.1.1.1.3.5.2" xref="S4.E3.m1.1.1.1.1.3.5.2.cmml">f</mi><mi class="ltx_font_mathcaligraphic" id="S4.E3.m1.1.1.1.1.3.5.3" xref="S4.E3.m1.1.1.1.1.3.5.3.cmml">𝒴</mi></msup><mo id="S4.E3.m1.1.1.1.1.3.4" xref="S4.E3.m1.1.1.1.1.3.4.cmml">⁢</mo><mrow id="S4.E3.m1.1.1.1.1.3.3.3" xref="S4.E3.m1.1.1.1.1.3.3.4.cmml"><mo id="S4.E3.m1.1.1.1.1.3.3.3.4" stretchy="false" xref="S4.E3.m1.1.1.1.1.3.3.4.cmml">(</mo><msup id="S4.E3.m1.1.1.1.1.1.1.1.1" xref="S4.E3.m1.1.1.1.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E3.m1.1.1.1.1.1.1.1.1.2" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2.cmml">𝒯</mi><mi id="S4.E3.m1.1.1.1.1.1.1.1.1.3" xref="S4.E3.m1.1.1.1.1.1.1.1.1.3.cmml">t</mi></msup><mo id="S4.E3.m1.1.1.1.1.3.3.3.5" xref="S4.E3.m1.1.1.1.1.3.3.4.cmml">,</mo><msup id="S4.E3.m1.1.1.1.1.2.2.2.2" xref="S4.E3.m1.1.1.1.1.2.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E3.m1.1.1.1.1.2.2.2.2.2" xref="S4.E3.m1.1.1.1.1.2.2.2.2.2.cmml">ℰ</mi><mi id="S4.E3.m1.1.1.1.1.2.2.2.2.3" xref="S4.E3.m1.1.1.1.1.2.2.2.2.3.cmml">t</mi></msup><mo id="S4.E3.m1.1.1.1.1.3.3.3.6" xref="S4.E3.m1.1.1.1.1.3.3.4.cmml">,</mo><msup id="S4.E3.m1.1.1.1.1.3.3.3.3" xref="S4.E3.m1.1.1.1.1.3.3.3.3.cmml"><mi id="S4.E3.m1.1.1.1.1.3.3.3.3.2" mathvariant="normal" xref="S4.E3.m1.1.1.1.1.3.3.3.3.2.cmml">M</mi><mi id="S4.E3.m1.1.1.1.1.3.3.3.3.3" xref="S4.E3.m1.1.1.1.1.3.3.3.3.3.cmml">t</mi></msup><mo id="S4.E3.m1.1.1.1.1.3.3.3.7" stretchy="false" xref="S4.E3.m1.1.1.1.1.3.3.4.cmml">)</mo></mrow></mrow></mrow><mo id="S4.E3.m1.1.1.1.2" xref="S4.E3.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E3.m1.1b"><apply id="S4.E3.m1.1.1.1.1.cmml" xref="S4.E3.m1.1.1.1"><eq id="S4.E3.m1.1.1.1.1.4.cmml" xref="S4.E3.m1.1.1.1.1.4"></eq><apply id="S4.E3.m1.1.1.1.1.5.cmml" xref="S4.E3.m1.1.1.1.1.5"><csymbol cd="ambiguous" id="S4.E3.m1.1.1.1.1.5.1.cmml" xref="S4.E3.m1.1.1.1.1.5">superscript</csymbol><ci id="S4.E3.m1.1.1.1.1.5.2.cmml" xref="S4.E3.m1.1.1.1.1.5.2">𝒴</ci><ci id="S4.E3.m1.1.1.1.1.5.3.cmml" xref="S4.E3.m1.1.1.1.1.5.3">𝑡</ci></apply><apply id="S4.E3.m1.1.1.1.1.3.cmml" xref="S4.E3.m1.1.1.1.1.3"><times id="S4.E3.m1.1.1.1.1.3.4.cmml" xref="S4.E3.m1.1.1.1.1.3.4"></times><apply id="S4.E3.m1.1.1.1.1.3.5.cmml" xref="S4.E3.m1.1.1.1.1.3.5"><csymbol cd="ambiguous" id="S4.E3.m1.1.1.1.1.3.5.1.cmml" xref="S4.E3.m1.1.1.1.1.3.5">superscript</csymbol><ci id="S4.E3.m1.1.1.1.1.3.5.2.cmml" xref="S4.E3.m1.1.1.1.1.3.5.2">𝑓</ci><ci id="S4.E3.m1.1.1.1.1.3.5.3.cmml" xref="S4.E3.m1.1.1.1.1.3.5.3">𝒴</ci></apply><vector id="S4.E3.m1.1.1.1.1.3.3.4.cmml" xref="S4.E3.m1.1.1.1.1.3.3.3"><apply id="S4.E3.m1.1.1.1.1.1.1.1.1.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E3.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1">superscript</csymbol><ci id="S4.E3.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.2">𝒯</ci><ci id="S4.E3.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S4.E3.m1.1.1.1.1.1.1.1.1.3">𝑡</ci></apply><apply id="S4.E3.m1.1.1.1.1.2.2.2.2.cmml" xref="S4.E3.m1.1.1.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S4.E3.m1.1.1.1.1.2.2.2.2.1.cmml" xref="S4.E3.m1.1.1.1.1.2.2.2.2">superscript</csymbol><ci id="S4.E3.m1.1.1.1.1.2.2.2.2.2.cmml" xref="S4.E3.m1.1.1.1.1.2.2.2.2.2">ℰ</ci><ci id="S4.E3.m1.1.1.1.1.2.2.2.2.3.cmml" xref="S4.E3.m1.1.1.1.1.2.2.2.2.3">𝑡</ci></apply><apply id="S4.E3.m1.1.1.1.1.3.3.3.3.cmml" xref="S4.E3.m1.1.1.1.1.3.3.3.3"><csymbol cd="ambiguous" id="S4.E3.m1.1.1.1.1.3.3.3.3.1.cmml" xref="S4.E3.m1.1.1.1.1.3.3.3.3">superscript</csymbol><ci id="S4.E3.m1.1.1.1.1.3.3.3.3.2.cmml" xref="S4.E3.m1.1.1.1.1.3.3.3.3.2">M</ci><ci id="S4.E3.m1.1.1.1.1.3.3.3.3.3.cmml" xref="S4.E3.m1.1.1.1.1.3.3.3.3.3">𝑡</ci></apply></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E3.m1.1c">{\mathcal{Y}}^{t}=f^{{\mathcal{Y}}}({\mathcal{T}}^{t},{\mathcal{E}}^{t},%
\mathrm{M}^{t}),</annotation><annotation encoding="application/x-llamapun" id="S4.E3.m1.1d">caligraphic_Y start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT = italic_f start_POSTSUPERSCRIPT caligraphic_Y end_POSTSUPERSCRIPT ( caligraphic_T start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT , caligraphic_E start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT , roman_M start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S4.SS2.p2.1">其中<math alttext="f^{{\mathcal{Y}}}" class="ltx_Math" display="inline" id="S4.SS2.p2.1.m1.1"><semantics id="S4.SS2.p2.1.m1.1a"><msup id="S4.SS2.p2.1.m1.1.1" xref="S4.SS2.p2.1.m1.1.1.cmml"><mi id="S4.SS2.p2.1.m1.1.1.2" xref="S4.SS2.p2.1.m1.1.1.2.cmml">f</mi><mi class="ltx_font_mathcaligraphic" id="S4.SS2.p2.1.m1.1.1.3" xref="S4.SS2.p2.1.m1.1.1.3.cmml">𝒴</mi></msup><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.m1.1b"><apply id="S4.SS2.p2.1.m1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p2.1.m1.1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1">superscript</csymbol><ci id="S4.SS2.p2.1.m1.1.1.2.cmml" xref="S4.SS2.p2.1.m1.1.1.2">𝑓</ci><ci id="S4.SS2.p2.1.m1.1.1.3.cmml" xref="S4.SS2.p2.1.m1.1.1.3">𝒴</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.m1.1c">f^{{\mathcal{Y}}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p2.1.m1.1d">italic_f start_POSTSUPERSCRIPT caligraphic_Y end_POSTSUPERSCRIPT</annotation></semantics></math>是模型接近演化目标的策略。</p>
</div>
<div class="ltx_para" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.1">我们然后根据解决方案的正确性将这些方法分为积极和消极两种。
积极方法介绍了获取正确和理想解决方案的各种方法。
相反，消极方法引出并收集不受欢迎的解决方案，包括不忠实或错误对齐的模型行为，然后用于偏好对齐。
我们将在接下来的章节中详细阐述每种类型的细节。</p>
</div>
<section class="ltx_subsubsection" id="S4.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection"><span class="ltx_tag ltx_tag_subsubsection">4.2.1 </span>积极</h4>
<div class="ltx_para" id="S4.SS2.SSS1.p1">
<p class="ltx_p" id="S4.SS2.SSS1.p1.1">当前的研究探索了超越基本推理的多种方法，以获得与进化目标一致的正确解决方案。
我们将任务解决过程划分为四种类型：基于原理、交互式、自我对弈和基于基础的。</p>
</div>
<section class="ltx_paragraph" id="S4.SS2.SSS1.Px1">
<h5 class="ltx_title ltx_title_paragraph">基于原因</h5>
<div class="ltx_para" id="S4.SS2.SSS1.Px1.p1">
<p class="ltx_p" id="S4.SS2.SSS1.Px1.p1.1">该模型在解决任务时融入了对逐步发展目标的合理解释，并能够通过利用这些合理解释进行自我演变。这些方法使模型能够明确承认发展目标，并朝着这个方向完成任务。 <cite class="ltx_cite ltx_citemacro_cite">Wei et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib128" title="">2022</a>); Yao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib144" title="">2024</a>); Besta et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib10" title="">2024</a>); Yao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib145" title="">2022</a>)</cite>。</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS1.Px1.p2">
<p class="ltx_p" id="S4.SS2.SSS1.Px1.p2.1"><cite class="ltx_cite ltx_citemacro_citet">Huang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib52" title="">2022</a>)</cite>提出了一种方法，其中LLM使用为未标记的问题生成的“高置信度”理性增强答案进行自我演变。
同样，STaR <cite class="ltx_cite ltx_citemacro_cite">Zelikman et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib151" title="">2022</a>)</cite>在解决任务时生成理性。如果答案错误，它进一步纠正理性和答案。然后，它将答案和理性作为经验来微调模型。
类似地，LSX <cite class="ltx_cite ltx_citemacro_cite">Stammer et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib106" title="">2023</a>)</cite>提出了生成答案解释的新范式，将学习模块执行基本任务和评估学习者提供的解释质量的批评模块之间进行迭代循环。
<cite class="ltx_cite ltx_citemacro_citet">Song et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib105" title="">2024</a>); Yang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib142" title="">2024c</a>)</cite>在解决任务时以ReAct <cite class="ltx_cite ltx_citemacro_cite">Yao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib145" title="">2022</a>)</cite>的风格获得了理性。这些理性在接下来的步骤中进一步用于训练代理。</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS2.SSS1.Px2">
<h5 class="ltx_title ltx_title_paragraph">交互式</h5>
<div class="ltx_para" id="S4.SS2.SSS1.Px2.p1">
<p class="ltx_p" id="S4.SS2.SSS1.Px2.p1.1">模型可以与环境互动，以增强进化过程。这些方法可以获取有价值的环境反馈，以指导自我进化方向。</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS1.Px2.p2">
<p class="ltx_p" id="S4.SS2.SSS1.Px2.p2.1">SelfEvolve和LDB <cite class="ltx_cite ltx_citemacro_cite">Jiang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib56" title="">2023</a>); Zhong et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib160" title="">2024a</a>)</cite> 通过自我进化提高了代码生成能力。它们允许模型生成代码并通过在解释器上运行代码获得反馈。
作为另一个环境，<cite class="ltx_cite ltx_citemacro_citet">Song et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib105" title="">2024</a>); Yang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib142" title="">2024c</a>)</cite> 在具体场景中相互作用并获得反馈。它们学会根据当前状态采取适当的行动。
对于代理能力，AutoAct <cite class="ltx_cite ltx_citemacro_cite">Qiao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib90" title="">2024</a>)</cite> 从零开始引入了自我规划，专注于内在的自学习过程。在这个过程中，代理通过与环境反馈的递归规划迭代来增强他们的能力。
在AutoAct之后，<cite class="ltx_cite ltx_citemacro_cite">Zhu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib166" title="">2024</a>)</cite> 通过整合自我进化和外部行动知识库进一步增强了代理训练。这种方法通过环境驱动的纠正反馈循环引导行动生成并增强规划能力。</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS2.SSS1.Px3">
<h5 class="ltx_title ltx_title_paragraph">自我对弈</h5>
<div class="ltx_para" id="S4.SS2.SSS1.Px3.p1">
<p class="ltx_p" id="S4.SS2.SSS1.Px3.p1.1">这是一个模型通过与自身的副本对战来学习进化的情况。
自我对弈是一种强大的进化方法，因为它使系统能够在闭环中与自身进行交流以获得反馈。在模型可以模拟各种角色的环境中，比如多人游戏，这种方法特别有效。与交互式方法相比，自我对弈是一种有效的策略，可以在没有环境的情况下获得反馈。</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS1.Px3.p2">
<p class="ltx_p" id="S4.SS2.SSS1.Px3.p2.1"><cite class="ltx_cite ltx_citemacro_citet">Taubenfeld et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib112" title="">2024</a>)</cite>调查LLMs模拟辩论中的系统偏见。
与辩论相反，<cite class="ltx_cite ltx_citemacro_citet">Ulmer et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib118" title="">2024</a>)</cite>让LLMs遵循生成的原则进行对话。
另一种通过角色扮演进行对话。 <cite class="ltx_cite ltx_citemacro_citet">Lu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib77" title="">2024a</a>)</cite>提出自我模拟角色扮演对话。该过程涉及指导LLM以角色简介，并调整其回答以保持与角色知识和风格的一致性。
同样，<cite class="ltx_cite ltx_citemacro_citet">Askari et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib6" title="">2024</a>)</cite>提出SOLID来生成大规模意图感知的角色扮演对话。这种自我玩耍的方式利用了LLMs的广泛知识，构建了信息丰富的交流，简化了对话生成过程。
<cite class="ltx_cite ltx_citemacro_citet">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib125" title="">2024e</a>)</cite>引入了一种新颖的方法，每个LLM都遵循一个角色，并与其他人沟通以实现他们的目标。</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS2.SSS1.Px4">
<h5 class="ltx_title ltx_title_paragraph">基础的</h5>
<div class="ltx_para" id="S4.SS2.SSS1.Px4.p1">
<p class="ltx_p" id="S4.SS2.SSS1.Px4.p1.1">为了达到不断发展的目标并减少探索空间，模型可以建立在现有规则<cite class="ltx_cite ltx_citemacro_cite">Sun et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib108" title="">2024</a>)</cite>和以往经验的基础上，以在解决任务时提供进一步明确的指导。</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS1.Px4.p2">
<p class="ltx_p" id="S4.SS2.SSS1.Px4.p2.1">LLM可以通过基于预定义规则和原则进行有效地生成理想解决方案。
例如，Self-Align <cite class="ltx_cite ltx_citemacro_cite">Sun et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib108" title="">2024</a>)</cite> 通过具有原则驱动的约束条件生成自我进化的问题，以指导任务解决过程。
SALMON <cite class="ltx_cite ltx_citemacro_cite">Sun et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib107" title="">2023</a>)</cite> 设计了一组结合原则，要求模型在解决任务时遵循这些原则。
Self-Talk <cite class="ltx_cite ltx_citemacro_cite">Ulmer et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib118" title="">2024</a>)</cite> 确保LLM根据预设的代理人角色生成与工作流程对齐的对话。他们根据GPT-4事先生成工作流程。</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS1.Px4.p3">
<p class="ltx_p" id="S4.SS2.SSS1.Px4.p3.1">除了预定义的规则，基于先前经验可以改进解决方案。
MemoryBank <cite class="ltx_cite ltx_citemacro_cite">Zhong et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib162" title="">2024b</a>)</cite> 和 TiM <cite class="ltx_cite ltx_citemacro_cite">Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib72" title="">2023a</a>)</cite> 通过整合先前的问题-答案记录来回答当前问题。
与以往的解决方案历史不同，MoT <cite class="ltx_cite ltx_citemacro_cite">Li and Qiu (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib67" title="">2023</a>)</cite>、IML <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib120" title="">2024a</a>)</cite> 和 TRAN <cite class="ltx_cite ltx_citemacro_cite">Yang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib140" title="">2023b</a>)</cite> 结合了从历史中诱导出的规则来回答新问题。
MemGPT <cite class="ltx_cite ltx_citemacro_cite">Packer et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib84" title="">2023</a>)</cite> 结合了这些优点，检索先前的问题、解决方案、诱发事件和用户画像知识。</p>
</div>
</section>
</section>
<section class="ltx_subsubsection" id="S4.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection"><span class="ltx_tag ltx_tag_subsubsection">4.2.2 </span>负面</h4>
<div class="ltx_para" id="S4.SS2.SSS2.p1">
<p class="ltx_p" id="S4.SS2.SSS2.p1.1">除了获取积极解决方案外，最近的研究表明LLMs也可以从负面解决方案中获益，以实现自我改进<cite class="ltx_cite ltx_citemacro_cite">Yang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib140" title="">2023b</a>)</cite>。这种策略类似于人类学习技能时的反复试验。本节总结了获取负面解决方案的典型方法，以帮助自我进化。</p>
</div>
<section class="ltx_paragraph ltx_pruned_first" id="S4.SS2.SSS2.Px1">
<h5 class="ltx_title ltx_title_paragraph">对比性</h5>
<div class="ltx_para" id="S4.SS2.SSS2.Px1.p1">
<p class="ltx_p" id="S4.SS2.SSS2.Px1.p1.1">一个广泛使用的方法组是收集一个任务的多个解决方案，然后对比正面和负面的解决方案以获得改进。</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS2.Px1.p2">
<p class="ltx_p" id="S4.SS2.SSS2.Px1.p2.1">自我奖励，SPIN <cite class="ltx_cite ltx_citemacro_cite">Yuan et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib148" title="">2024</a>); Chen et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib24" title="">2024</a>)</cite> 通过比较高分和低分的答案来更新模型。
类似地，GRATH <cite class="ltx_cite ltx_citemacro_cite">Chen and Li (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib21" title="">2024</a>)</cite> 生成正确和不正确的答案。然后通过比较这两个答案来训练模型。
自我对比 <cite class="ltx_cite ltx_citemacro_cite">Zhang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib154" title="">2024c</a>)</cite> 对比差异，并将这些差异总结成一个清单，可以用来重新检查和消除差异。
在ETO <cite class="ltx_cite ltx_citemacro_cite">Song et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib105" title="">2024</a>)</cite> 中，模型与体验环境互动来完成任务，并从失败的解决方案中进行优化。
A<sup class="ltx_sup" id="S4.SS2.SSS2.Px1.p2.1.1">3</sup>T <cite class="ltx_cite ltx_citemacro_cite">Yang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib142" title="">2024c</a>)</cite> 通过在每个行动后添加理由来改进ETO以解决任务。
STE <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib121" title="">2024b</a>)</cite> 实施试错法，模型使用不熟悉的工具解决任务。它通过分析失败的尝试来学习，以改善未来任务中的问题解决策略。
最近，COTERRORSET <cite class="ltx_cite ltx_citemacro_cite">Tong et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib114" title="">2024</a>)</cite> 获得了PALM-2生成的不正确解决方案，并提出了错误调整，这需要模型避免犯错。</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS2.SSS2.Px2">
<h5 class="ltx_title ltx_title_paragraph">Perturbative</h5>
<div class="ltx_para" id="S4.SS2.SSS2.Px2.p1">
<p class="ltx_p" id="S4.SS2.SSS2.Px2.p1.1">与<span class="ltx_text ltx_font_italic" id="S4.SS2.SSS2.Px2.p1.1.1">对比</span>相比，<span class="ltx_text ltx_font_italic" id="S4.SS2.SSS2.Px2.p1.1.2">扰动</span>方法试图故意添加扰动以获得负解。
模型可以后来学会避免生成这些负答案。
添加扰动以获得负解比对比方法更可控。</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS2.Px2.p2">
<p class="ltx_p" id="S4.SS2.SSS2.Px2.p2.1">一些方法增加扰动以生成有害解决方案<cite class="ltx_cite ltx_citemacro_cite">Yang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib138" title="">2023a</a>); Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib70" title="">2024a</a>)</cite>。
给定一个任务，RLCD<cite class="ltx_cite ltx_citemacro_cite">Yang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib138" title="">2023a</a>)</cite>会策划正面和负面指示，并生成正面和负面解决方案。
DLMA<cite class="ltx_cite ltx_citemacro_cite">Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib70" title="">2024a</a>)</cite>收集正面和负面指导提示，随后产生相应的正面和负面解决方案。</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS2.Px2.p3">
<p class="ltx_p" id="S4.SS2.SSS2.Px2.p3.1">与有害扰动不同，引入负面情境是另一种方式。Ditto <cite class="ltx_cite ltx_citemacro_cite">Lu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib77" title="">2024a</a>)</cite>添加负面人物角色以生成不正确的对话。然后模型从负面对话中学习，以进化人物对话能力。</p>
</div>
</section>
</section>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">4.3 </span>反馈</h3>
<figure class="ltx_figure" id="S4.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="629" id="S4.F6.g1" src="resource/x5.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">图6： </span>反馈类型。 <math alttext="{\mathcal{E}}^{t}" class="ltx_Math" display="inline" id="S4.F6.4.m1.1"><semantics id="S4.F6.4.m1.1b"><msup id="S4.F6.4.m1.1.1" xref="S4.F6.4.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.F6.4.m1.1.1.2" xref="S4.F6.4.m1.1.1.2.cmml">ℰ</mi><mi id="S4.F6.4.m1.1.1.3" xref="S4.F6.4.m1.1.1.3.cmml">t</mi></msup><annotation-xml encoding="MathML-Content" id="S4.F6.4.m1.1c"><apply id="S4.F6.4.m1.1.1.cmml" xref="S4.F6.4.m1.1.1"><csymbol cd="ambiguous" id="S4.F6.4.m1.1.1.1.cmml" xref="S4.F6.4.m1.1.1">superscript</csymbol><ci id="S4.F6.4.m1.1.1.2.cmml" xref="S4.F6.4.m1.1.1.2">ℰ</ci><ci id="S4.F6.4.m1.1.1.3.cmml" xref="S4.F6.4.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F6.4.m1.1d">{\mathcal{E}}^{t}</annotation><annotation encoding="application/x-llamapun" id="S4.F6.4.m1.1e">caligraphic_E start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT</annotation></semantics></math> 和 <math alttext="{\mathcal{Y}}^{t}" class="ltx_Math" display="inline" id="S4.F6.5.m2.1"><semantics id="S4.F6.5.m2.1b"><msup id="S4.F6.5.m2.1.1" xref="S4.F6.5.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.F6.5.m2.1.1.2" xref="S4.F6.5.m2.1.1.2.cmml">𝒴</mi><mi id="S4.F6.5.m2.1.1.3" xref="S4.F6.5.m2.1.1.3.cmml">t</mi></msup><annotation-xml encoding="MathML-Content" id="S4.F6.5.m2.1c"><apply id="S4.F6.5.m2.1.1.cmml" xref="S4.F6.5.m2.1.1"><csymbol cd="ambiguous" id="S4.F6.5.m2.1.1.1.cmml" xref="S4.F6.5.m2.1.1">superscript</csymbol><ci id="S4.F6.5.m2.1.1.2.cmml" xref="S4.F6.5.m2.1.1.2">𝒴</ci><ci id="S4.F6.5.m2.1.1.3.cmml" xref="S4.F6.5.m2.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F6.5.m2.1d">{\mathcal{Y}}^{t}</annotation><annotation encoding="application/x-llamapun" id="S4.F6.5.m2.1e">caligraphic_Y start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT</annotation></semantics></math> 是第<math alttext="t^{th}" class="ltx_Math" display="inline" id="S4.F6.6.m3.1"><semantics id="S4.F6.6.m3.1b"><msup id="S4.F6.6.m3.1.1" xref="S4.F6.6.m3.1.1.cmml"><mi id="S4.F6.6.m3.1.1.2" xref="S4.F6.6.m3.1.1.2.cmml">t</mi><mrow id="S4.F6.6.m3.1.1.3" xref="S4.F6.6.m3.1.1.3.cmml"><mi id="S4.F6.6.m3.1.1.3.2" xref="S4.F6.6.m3.1.1.3.2.cmml">t</mi><mo id="S4.F6.6.m3.1.1.3.1" xref="S4.F6.6.m3.1.1.3.1.cmml">⁢</mo><mi id="S4.F6.6.m3.1.1.3.3" xref="S4.F6.6.m3.1.1.3.3.cmml">h</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S4.F6.6.m3.1c"><apply id="S4.F6.6.m3.1.1.cmml" xref="S4.F6.6.m3.1.1"><csymbol cd="ambiguous" id="S4.F6.6.m3.1.1.1.cmml" xref="S4.F6.6.m3.1.1">superscript</csymbol><ci id="S4.F6.6.m3.1.1.2.cmml" xref="S4.F6.6.m3.1.1.2">𝑡</ci><apply id="S4.F6.6.m3.1.1.3.cmml" xref="S4.F6.6.m3.1.1.3"><times id="S4.F6.6.m3.1.1.3.1.cmml" xref="S4.F6.6.m3.1.1.3.1"></times><ci id="S4.F6.6.m3.1.1.3.2.cmml" xref="S4.F6.6.m3.1.1.3.2">𝑡</ci><ci id="S4.F6.6.m3.1.1.3.3.cmml" xref="S4.F6.6.m3.1.1.3.3">ℎ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F6.6.m3.1d">t^{th}</annotation><annotation encoding="application/x-llamapun" id="S4.F6.6.m3.1e">italic_t start_POSTSUPERSCRIPT italic_t italic_h end_POSTSUPERSCRIPT</annotation></semantics></math>次迭代的演变目标和任务解决方案。</figcaption>
</figure>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.2">人类学习技能时，反馈在展示解决方案的正确性方面起着至关重要的作用。这些关键信息使人类能够反思，然后更新他们的技能。
与这个过程类似，LLMs应在自我演变周期中在任务解决过程中或之后获得反馈。我们将这个过程正式化如下：</p>
<table class="ltx_equation ltx_eqn_table" id="S4.E4">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="{\mathcal{F}}^{t}=f^{{\mathcal{F}}}({\mathcal{T}}^{t},{\mathcal{Y}}^{t},{%
\mathcal{E}}^{t},\mathrm{M}^{t},\mathrm{ENV})," class="ltx_Math" display="block" id="S4.E4.m1.2"><semantics id="S4.E4.m1.2a"><mrow id="S4.E4.m1.2.2.1" xref="S4.E4.m1.2.2.1.1.cmml"><mrow id="S4.E4.m1.2.2.1.1" xref="S4.E4.m1.2.2.1.1.cmml"><msup id="S4.E4.m1.2.2.1.1.6" xref="S4.E4.m1.2.2.1.1.6.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E4.m1.2.2.1.1.6.2" xref="S4.E4.m1.2.2.1.1.6.2.cmml">ℱ</mi><mi id="S4.E4.m1.2.2.1.1.6.3" xref="S4.E4.m1.2.2.1.1.6.3.cmml">t</mi></msup><mo id="S4.E4.m1.2.2.1.1.5" xref="S4.E4.m1.2.2.1.1.5.cmml">=</mo><mrow id="S4.E4.m1.2.2.1.1.4" xref="S4.E4.m1.2.2.1.1.4.cmml"><msup id="S4.E4.m1.2.2.1.1.4.6" xref="S4.E4.m1.2.2.1.1.4.6.cmml"><mi id="S4.E4.m1.2.2.1.1.4.6.2" xref="S4.E4.m1.2.2.1.1.4.6.2.cmml">f</mi><mi class="ltx_font_mathcaligraphic" id="S4.E4.m1.2.2.1.1.4.6.3" xref="S4.E4.m1.2.2.1.1.4.6.3.cmml">ℱ</mi></msup><mo id="S4.E4.m1.2.2.1.1.4.5" xref="S4.E4.m1.2.2.1.1.4.5.cmml">⁢</mo><mrow id="S4.E4.m1.2.2.1.1.4.4.4" xref="S4.E4.m1.2.2.1.1.4.4.5.cmml"><mo id="S4.E4.m1.2.2.1.1.4.4.4.5" stretchy="false" xref="S4.E4.m1.2.2.1.1.4.4.5.cmml">(</mo><msup id="S4.E4.m1.2.2.1.1.1.1.1.1" xref="S4.E4.m1.2.2.1.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E4.m1.2.2.1.1.1.1.1.1.2" xref="S4.E4.m1.2.2.1.1.1.1.1.1.2.cmml">𝒯</mi><mi id="S4.E4.m1.2.2.1.1.1.1.1.1.3" xref="S4.E4.m1.2.2.1.1.1.1.1.1.3.cmml">t</mi></msup><mo id="S4.E4.m1.2.2.1.1.4.4.4.6" xref="S4.E4.m1.2.2.1.1.4.4.5.cmml">,</mo><msup id="S4.E4.m1.2.2.1.1.2.2.2.2" xref="S4.E4.m1.2.2.1.1.2.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E4.m1.2.2.1.1.2.2.2.2.2" xref="S4.E4.m1.2.2.1.1.2.2.2.2.2.cmml">𝒴</mi><mi id="S4.E4.m1.2.2.1.1.2.2.2.2.3" xref="S4.E4.m1.2.2.1.1.2.2.2.2.3.cmml">t</mi></msup><mo id="S4.E4.m1.2.2.1.1.4.4.4.7" xref="S4.E4.m1.2.2.1.1.4.4.5.cmml">,</mo><msup id="S4.E4.m1.2.2.1.1.3.3.3.3" xref="S4.E4.m1.2.2.1.1.3.3.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E4.m1.2.2.1.1.3.3.3.3.2" xref="S4.E4.m1.2.2.1.1.3.3.3.3.2.cmml">ℰ</mi><mi id="S4.E4.m1.2.2.1.1.3.3.3.3.3" xref="S4.E4.m1.2.2.1.1.3.3.3.3.3.cmml">t</mi></msup><mo id="S4.E4.m1.2.2.1.1.4.4.4.8" xref="S4.E4.m1.2.2.1.1.4.4.5.cmml">,</mo><msup id="S4.E4.m1.2.2.1.1.4.4.4.4" xref="S4.E4.m1.2.2.1.1.4.4.4.4.cmml"><mi id="S4.E4.m1.2.2.1.1.4.4.4.4.2" mathvariant="normal" xref="S4.E4.m1.2.2.1.1.4.4.4.4.2.cmml">M</mi><mi id="S4.E4.m1.2.2.1.1.4.4.4.4.3" xref="S4.E4.m1.2.2.1.1.4.4.4.4.3.cmml">t</mi></msup><mo id="S4.E4.m1.2.2.1.1.4.4.4.9" xref="S4.E4.m1.2.2.1.1.4.4.5.cmml">,</mo><mi id="S4.E4.m1.1.1" xref="S4.E4.m1.1.1.cmml">ENV</mi><mo id="S4.E4.m1.2.2.1.1.4.4.4.10" stretchy="false" xref="S4.E4.m1.2.2.1.1.4.4.5.cmml">)</mo></mrow></mrow></mrow><mo id="S4.E4.m1.2.2.1.2" xref="S4.E4.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E4.m1.2b"><apply id="S4.E4.m1.2.2.1.1.cmml" xref="S4.E4.m1.2.2.1"><eq id="S4.E4.m1.2.2.1.1.5.cmml" xref="S4.E4.m1.2.2.1.1.5"></eq><apply id="S4.E4.m1.2.2.1.1.6.cmml" xref="S4.E4.m1.2.2.1.1.6"><csymbol cd="ambiguous" id="S4.E4.m1.2.2.1.1.6.1.cmml" xref="S4.E4.m1.2.2.1.1.6">superscript</csymbol><ci id="S4.E4.m1.2.2.1.1.6.2.cmml" xref="S4.E4.m1.2.2.1.1.6.2">ℱ</ci><ci id="S4.E4.m1.2.2.1.1.6.3.cmml" xref="S4.E4.m1.2.2.1.1.6.3">𝑡</ci></apply><apply id="S4.E4.m1.2.2.1.1.4.cmml" xref="S4.E4.m1.2.2.1.1.4"><times id="S4.E4.m1.2.2.1.1.4.5.cmml" xref="S4.E4.m1.2.2.1.1.4.5"></times><apply id="S4.E4.m1.2.2.1.1.4.6.cmml" xref="S4.E4.m1.2.2.1.1.4.6"><csymbol cd="ambiguous" id="S4.E4.m1.2.2.1.1.4.6.1.cmml" xref="S4.E4.m1.2.2.1.1.4.6">superscript</csymbol><ci id="S4.E4.m1.2.2.1.1.4.6.2.cmml" xref="S4.E4.m1.2.2.1.1.4.6.2">𝑓</ci><ci id="S4.E4.m1.2.2.1.1.4.6.3.cmml" xref="S4.E4.m1.2.2.1.1.4.6.3">ℱ</ci></apply><vector id="S4.E4.m1.2.2.1.1.4.4.5.cmml" xref="S4.E4.m1.2.2.1.1.4.4.4"><apply id="S4.E4.m1.2.2.1.1.1.1.1.1.cmml" xref="S4.E4.m1.2.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E4.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S4.E4.m1.2.2.1.1.1.1.1.1">superscript</csymbol><ci id="S4.E4.m1.2.2.1.1.1.1.1.1.2.cmml" xref="S4.E4.m1.2.2.1.1.1.1.1.1.2">𝒯</ci><ci id="S4.E4.m1.2.2.1.1.1.1.1.1.3.cmml" xref="S4.E4.m1.2.2.1.1.1.1.1.1.3">𝑡</ci></apply><apply id="S4.E4.m1.2.2.1.1.2.2.2.2.cmml" xref="S4.E4.m1.2.2.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S4.E4.m1.2.2.1.1.2.2.2.2.1.cmml" xref="S4.E4.m1.2.2.1.1.2.2.2.2">superscript</csymbol><ci id="S4.E4.m1.2.2.1.1.2.2.2.2.2.cmml" xref="S4.E4.m1.2.2.1.1.2.2.2.2.2">𝒴</ci><ci id="S4.E4.m1.2.2.1.1.2.2.2.2.3.cmml" xref="S4.E4.m1.2.2.1.1.2.2.2.2.3">𝑡</ci></apply><apply id="S4.E4.m1.2.2.1.1.3.3.3.3.cmml" xref="S4.E4.m1.2.2.1.1.3.3.3.3"><csymbol cd="ambiguous" id="S4.E4.m1.2.2.1.1.3.3.3.3.1.cmml" xref="S4.E4.m1.2.2.1.1.3.3.3.3">superscript</csymbol><ci id="S4.E4.m1.2.2.1.1.3.3.3.3.2.cmml" xref="S4.E4.m1.2.2.1.1.3.3.3.3.2">ℰ</ci><ci id="S4.E4.m1.2.2.1.1.3.3.3.3.3.cmml" xref="S4.E4.m1.2.2.1.1.3.3.3.3.3">𝑡</ci></apply><apply id="S4.E4.m1.2.2.1.1.4.4.4.4.cmml" xref="S4.E4.m1.2.2.1.1.4.4.4.4"><csymbol cd="ambiguous" id="S4.E4.m1.2.2.1.1.4.4.4.4.1.cmml" xref="S4.E4.m1.2.2.1.1.4.4.4.4">superscript</csymbol><ci id="S4.E4.m1.2.2.1.1.4.4.4.4.2.cmml" xref="S4.E4.m1.2.2.1.1.4.4.4.4.2">M</ci><ci id="S4.E4.m1.2.2.1.1.4.4.4.4.3.cmml" xref="S4.E4.m1.2.2.1.1.4.4.4.4.3">𝑡</ci></apply><ci id="S4.E4.m1.1.1.cmml" xref="S4.E4.m1.1.1">ENV</ci></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E4.m1.2c">{\mathcal{F}}^{t}=f^{{\mathcal{F}}}({\mathcal{T}}^{t},{\mathcal{Y}}^{t},{%
\mathcal{E}}^{t},\mathrm{M}^{t},\mathrm{ENV}),</annotation><annotation encoding="application/x-llamapun" id="S4.E4.m1.2d">caligraphic_F start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT = italic_f start_POSTSUPERSCRIPT caligraphic_F end_POSTSUPERSCRIPT ( caligraphic_T start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT , caligraphic_Y start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT , caligraphic_E start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT , roman_M start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT , roman_ENV ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S4.SS3.p1.1">其中<math alttext="f^{{\mathcal{F}}}" class="ltx_Math" display="inline" id="S4.SS3.p1.1.m1.1"><semantics id="S4.SS3.p1.1.m1.1a"><msup id="S4.SS3.p1.1.m1.1.1" xref="S4.SS3.p1.1.m1.1.1.cmml"><mi id="S4.SS3.p1.1.m1.1.1.2" xref="S4.SS3.p1.1.m1.1.1.2.cmml">f</mi><mi class="ltx_font_mathcaligraphic" id="S4.SS3.p1.1.m1.1.1.3" xref="S4.SS3.p1.1.m1.1.1.3.cmml">ℱ</mi></msup><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.1.m1.1b"><apply id="S4.SS3.p1.1.m1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS3.p1.1.m1.1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1">superscript</csymbol><ci id="S4.SS3.p1.1.m1.1.1.2.cmml" xref="S4.SS3.p1.1.m1.1.1.2">𝑓</ci><ci id="S4.SS3.p1.1.m1.1.1.3.cmml" xref="S4.SS3.p1.1.m1.1.1.3">ℱ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.1.m1.1c">f^{{\mathcal{F}}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.1.m1.1d">italic_f start_POSTSUPERSCRIPT caligraphic_F end_POSTSUPERSCRIPT</annotation></semantics></math>是获取反馈的方法。</p>
</div>
<div class="ltx_para" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.1">在这部分中，我们总结了两种类型的反馈。模型反馈是指收集LLM自身所评价的评论或分数。此外，环境表示直接来自外部环境的反馈。我们在图<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#S4.F6" title="Figure 6 ‣ 4.3 Feedback ‣ 4 Experience Acquisition ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_tag">6</span></a>中说明了这些概念。</p>
</div>
<section class="ltx_subsubsection" id="S4.SS3.SSS1">
<h4 class="ltx_title ltx_title_subsubsection"><span class="ltx_tag ltx_tag_subsubsection">4.3.1 </span>模型</h4>
<div class="ltx_para" id="S4.SS3.SSS1.p1">
<p class="ltx_p" id="S4.SS3.SSS1.p1.1">当前研究表明LLMs可以很好地扮演评论家<cite class="ltx_cite ltx_citemacro_cite">Zheng et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib158" title="">2024a</a>)</cite>。在自我演变的循环中，模型对自身进行评判，以获得解决方案的反馈。</p>
</div>
<div class="ltx_para" id="S4.SS3.SSS1.p2">
<p class="ltx_p" id="S4.SS3.SSS1.p2.1">一种反馈类型是指示正确性的分数。
Self-Reward <cite class="ltx_cite ltx_citemacro_cite">Yuan et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib148" title="">2024</a>)</cite>，LSX <cite class="ltx_cite ltx_citemacro_citet">Stammer et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib106" title="">2023</a>)</cite>和DLMA <cite class="ltx_cite ltx_citemacro_cite">Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib70" title="">2024a</a>)</cite>通过LLM作为评判者输出自己的解决方案的评分。
与此类似，SIRLC <cite class="ltx_cite ltx_citemacro_cite">Pang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib85" title="">2023</a>)</cite>利用LLM的自我评估结果作为进一步强化学习的奖励。
Self-Alignment <cite class="ltx_cite ltx_citemacro_cite">Zhang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib156" title="">2024e</a>)</cite>利用LLM的自我评估能力生成其输出的事实准确性的置信度分数。</p>
</div>
<div class="ltx_para" id="S4.SS3.SSS1.p3">
<p class="ltx_p" id="S4.SS3.SSS1.p3.1">另一种类型提供了文本描述，提供多维信息。为了通过监督学习改变响应的分布，CAI <cite class="ltx_cite ltx_citemacro_cite">Bai et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib9" title="">2022</a>)</cite> 要求模型根据宪法中的原则对其响应进行批判。与监督学习和强化学习方法相比，Self-Refine <cite class="ltx_cite ltx_citemacro_cite">Madaan et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib80" title="">2023</a>)</cite>允许模型以少量方式自动生成自然语言反馈。</p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS3.SSS2">
<h4 class="ltx_title ltx_title_subsubsection"><span class="ltx_tag ltx_tag_subsubsection">4.3.2 </span>环境</h4>
<div class="ltx_para" id="S4.SS3.SSS2.p1">
<p class="ltx_p" id="S4.SS3.SSS2.p1.1">另一种形式的反馈来自环境，在解决方案可以直接评估的任务中很常见。这种反馈是精确和详细的，可以为模型更新提供足够的信息。它们可能来自代码解释器<cite class="ltx_cite ltx_citemacro_cite">Jiang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib56" title="">2023</a>); Chen et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib22" title="">2023c</a>); Shinn et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib98" title="">2024</a>)</cite>、工具执行<cite class="ltx_cite ltx_citemacro_cite">Qiao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib90" title="">2024</a>); Gou et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib41" title="">2023</a>)</cite>、具体环境<cite class="ltx_cite ltx_citemacro_cite">Bousmalis et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib13" title="">2023</a>); Xu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib135" title="">2024b</a>); Zhou et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib165" title="">2023b</a>)</cite>和其他LLM或代理<cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib125" title="">2024e</a>); Taubenfeld et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib112" title="">2024</a>); Ulmer et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib118" title="">2024</a>)</cite>。</p>
</div>
<div class="ltx_para" id="S4.SS3.SSS2.p2">
<p class="ltx_p" id="S4.SS3.SSS2.p2.1">对于代码生成，Self-Debugging <cite class="ltx_cite ltx_citemacro_citet">Chen et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib22" title="">2023c</a>)</cite> 利用测试用例的执行结果作为反馈的一部分，而SelfEvolve <cite class="ltx_cite ltx_citemacro_cite">Jiang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib56" title="">2023</a>)</cite> 则从解释器接收错误消息。
类似地，Reflexion <cite class="ltx_cite ltx_citemacro_cite">Shinn et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib99" title="">2023</a>)</cite> 也从代码解释器获得运行时反馈。然后进一步反映以生成想法。
这个运行时反馈包含了可以指出改进代码生成的关键信息的追溯信息。</p>
</div>
<div class="ltx_para" id="S4.SS3.SSS2.p3">
<p class="ltx_p" id="S4.SS3.SSS2.p3.1">最近，方法赋予LLM和代理工具使用能力。执行工具导致反馈<cite class="ltx_cite ltx_citemacro_cite">Gou et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib41" title="">2023</a>); Qiao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib90" title="">2024</a>); Song et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib105" title="">2024</a>); Yang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib142" title="">2024c</a>); Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib121" title="">2024b</a>)</cite>。</p>
</div>
<div class="ltx_para" id="S4.SS3.SSS2.p4">
<p class="ltx_p" id="S4.SS3.SSS2.p4.1">RoboCat <cite class="ltx_cite ltx_citemacro_cite">Bousmalis et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib13" title="">2023</a>)</cite> 和 SinViG <cite class="ltx_cite ltx_citemacro_cite">Xu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib135" title="">2024b</a>)</cite> 在机器人实体环境中行动。这种类型的反馈精确而有力，可以指导自我进化。</p>
</div>
<div class="ltx_para" id="S4.SS3.SSS2.p5">
<p class="ltx_p" id="S4.SS3.SSS2.p5.1">通信反馈在基于LLM的多智能体系统中是常见且有效的。智能体可以相互纠正和支持，实现共同进化<cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib125" title="">2024e</a>); Taubenfeld et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib112" title="">2024</a>); Ulmer et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib118" title="">2024</a>)</cite>。</p>
</div>
<figure class="ltx_figure" id="S4.F7"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="605" id="S4.F7.g1" src="resource/x6.png" width="1660"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">图7：</span>经验细化。</figcaption>
</figure>
</section>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">5 </span>经验细化</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.3">在经验获取和自我演化更新之前，LLM可能通过经验的精炼提高其输出的质量和可靠性。它帮助LLM适应新的信息和环境，而不依赖外部资源，在动态环境中提供更可靠和有效的帮助。这一过程可以表述如下：</p>
<table class="ltx_equation ltx_eqn_table" id="S5.E5">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\tilde{{\mathcal{T}}}^{t},\tilde{{\mathcal{Y}}}^{t}=f^{{\mathcal{R}}}({%
\mathcal{T}}^{t},{\mathcal{Y}}^{t},{\mathcal{F}}^{t},{\mathcal{E}}^{t},\mathrm%
{M}^{t})," class="ltx_Math" display="block" id="S5.E5.m1.1"><semantics id="S5.E5.m1.1a"><mrow id="S5.E5.m1.1.1.1" xref="S5.E5.m1.1.1.1.1.cmml"><mrow id="S5.E5.m1.1.1.1.1" xref="S5.E5.m1.1.1.1.1.cmml"><mrow id="S5.E5.m1.1.1.1.1.2.2" xref="S5.E5.m1.1.1.1.1.2.3.cmml"><msup id="S5.E5.m1.1.1.1.1.1.1.1" xref="S5.E5.m1.1.1.1.1.1.1.1.cmml"><mover accent="true" id="S5.E5.m1.1.1.1.1.1.1.1.2" xref="S5.E5.m1.1.1.1.1.1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.E5.m1.1.1.1.1.1.1.1.2.2" xref="S5.E5.m1.1.1.1.1.1.1.1.2.2.cmml">𝒯</mi><mo id="S5.E5.m1.1.1.1.1.1.1.1.2.1" xref="S5.E5.m1.1.1.1.1.1.1.1.2.1.cmml">~</mo></mover><mi id="S5.E5.m1.1.1.1.1.1.1.1.3" xref="S5.E5.m1.1.1.1.1.1.1.1.3.cmml">t</mi></msup><mo id="S5.E5.m1.1.1.1.1.2.2.3" xref="S5.E5.m1.1.1.1.1.2.3.cmml">,</mo><msup id="S5.E5.m1.1.1.1.1.2.2.2" xref="S5.E5.m1.1.1.1.1.2.2.2.cmml"><mover accent="true" id="S5.E5.m1.1.1.1.1.2.2.2.2" xref="S5.E5.m1.1.1.1.1.2.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.E5.m1.1.1.1.1.2.2.2.2.2" xref="S5.E5.m1.1.1.1.1.2.2.2.2.2.cmml">𝒴</mi><mo id="S5.E5.m1.1.1.1.1.2.2.2.2.1" xref="S5.E5.m1.1.1.1.1.2.2.2.2.1.cmml">~</mo></mover><mi id="S5.E5.m1.1.1.1.1.2.2.2.3" xref="S5.E5.m1.1.1.1.1.2.2.2.3.cmml">t</mi></msup></mrow><mo id="S5.E5.m1.1.1.1.1.8" xref="S5.E5.m1.1.1.1.1.8.cmml">=</mo><mrow id="S5.E5.m1.1.1.1.1.7" xref="S5.E5.m1.1.1.1.1.7.cmml"><msup id="S5.E5.m1.1.1.1.1.7.7" xref="S5.E5.m1.1.1.1.1.7.7.cmml"><mi id="S5.E5.m1.1.1.1.1.7.7.2" xref="S5.E5.m1.1.1.1.1.7.7.2.cmml">f</mi><mi class="ltx_font_mathcaligraphic" id="S5.E5.m1.1.1.1.1.7.7.3" xref="S5.E5.m1.1.1.1.1.7.7.3.cmml">ℛ</mi></msup><mo id="S5.E5.m1.1.1.1.1.7.6" xref="S5.E5.m1.1.1.1.1.7.6.cmml">⁢</mo><mrow id="S5.E5.m1.1.1.1.1.7.5.5" xref="S5.E5.m1.1.1.1.1.7.5.6.cmml"><mo id="S5.E5.m1.1.1.1.1.7.5.5.6" stretchy="false" xref="S5.E5.m1.1.1.1.1.7.5.6.cmml">(</mo><msup id="S5.E5.m1.1.1.1.1.3.1.1.1" xref="S5.E5.m1.1.1.1.1.3.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.E5.m1.1.1.1.1.3.1.1.1.2" xref="S5.E5.m1.1.1.1.1.3.1.1.1.2.cmml">𝒯</mi><mi id="S5.E5.m1.1.1.1.1.3.1.1.1.3" xref="S5.E5.m1.1.1.1.1.3.1.1.1.3.cmml">t</mi></msup><mo id="S5.E5.m1.1.1.1.1.7.5.5.7" xref="S5.E5.m1.1.1.1.1.7.5.6.cmml">,</mo><msup id="S5.E5.m1.1.1.1.1.4.2.2.2" xref="S5.E5.m1.1.1.1.1.4.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.E5.m1.1.1.1.1.4.2.2.2.2" xref="S5.E5.m1.1.1.1.1.4.2.2.2.2.cmml">𝒴</mi><mi id="S5.E5.m1.1.1.1.1.4.2.2.2.3" xref="S5.E5.m1.1.1.1.1.4.2.2.2.3.cmml">t</mi></msup><mo id="S5.E5.m1.1.1.1.1.7.5.5.8" xref="S5.E5.m1.1.1.1.1.7.5.6.cmml">,</mo><msup id="S5.E5.m1.1.1.1.1.5.3.3.3" xref="S5.E5.m1.1.1.1.1.5.3.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.E5.m1.1.1.1.1.5.3.3.3.2" xref="S5.E5.m1.1.1.1.1.5.3.3.3.2.cmml">ℱ</mi><mi id="S5.E5.m1.1.1.1.1.5.3.3.3.3" xref="S5.E5.m1.1.1.1.1.5.3.3.3.3.cmml">t</mi></msup><mo id="S5.E5.m1.1.1.1.1.7.5.5.9" xref="S5.E5.m1.1.1.1.1.7.5.6.cmml">,</mo><msup id="S5.E5.m1.1.1.1.1.6.4.4.4" xref="S5.E5.m1.1.1.1.1.6.4.4.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.E5.m1.1.1.1.1.6.4.4.4.2" xref="S5.E5.m1.1.1.1.1.6.4.4.4.2.cmml">ℰ</mi><mi id="S5.E5.m1.1.1.1.1.6.4.4.4.3" xref="S5.E5.m1.1.1.1.1.6.4.4.4.3.cmml">t</mi></msup><mo id="S5.E5.m1.1.1.1.1.7.5.5.10" xref="S5.E5.m1.1.1.1.1.7.5.6.cmml">,</mo><msup id="S5.E5.m1.1.1.1.1.7.5.5.5" xref="S5.E5.m1.1.1.1.1.7.5.5.5.cmml"><mi id="S5.E5.m1.1.1.1.1.7.5.5.5.2" mathvariant="normal" xref="S5.E5.m1.1.1.1.1.7.5.5.5.2.cmml">M</mi><mi id="S5.E5.m1.1.1.1.1.7.5.5.5.3" xref="S5.E5.m1.1.1.1.1.7.5.5.5.3.cmml">t</mi></msup><mo id="S5.E5.m1.1.1.1.1.7.5.5.11" stretchy="false" xref="S5.E5.m1.1.1.1.1.7.5.6.cmml">)</mo></mrow></mrow></mrow><mo id="S5.E5.m1.1.1.1.2" xref="S5.E5.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.E5.m1.1b"><apply id="S5.E5.m1.1.1.1.1.cmml" xref="S5.E5.m1.1.1.1"><eq id="S5.E5.m1.1.1.1.1.8.cmml" xref="S5.E5.m1.1.1.1.1.8"></eq><list id="S5.E5.m1.1.1.1.1.2.3.cmml" xref="S5.E5.m1.1.1.1.1.2.2"><apply id="S5.E5.m1.1.1.1.1.1.1.1.cmml" xref="S5.E5.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S5.E5.m1.1.1.1.1.1.1.1.1.cmml" xref="S5.E5.m1.1.1.1.1.1.1.1">superscript</csymbol><apply id="S5.E5.m1.1.1.1.1.1.1.1.2.cmml" xref="S5.E5.m1.1.1.1.1.1.1.1.2"><ci id="S5.E5.m1.1.1.1.1.1.1.1.2.1.cmml" xref="S5.E5.m1.1.1.1.1.1.1.1.2.1">~</ci><ci id="S5.E5.m1.1.1.1.1.1.1.1.2.2.cmml" xref="S5.E5.m1.1.1.1.1.1.1.1.2.2">𝒯</ci></apply><ci id="S5.E5.m1.1.1.1.1.1.1.1.3.cmml" xref="S5.E5.m1.1.1.1.1.1.1.1.3">𝑡</ci></apply><apply id="S5.E5.m1.1.1.1.1.2.2.2.cmml" xref="S5.E5.m1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S5.E5.m1.1.1.1.1.2.2.2.1.cmml" xref="S5.E5.m1.1.1.1.1.2.2.2">superscript</csymbol><apply id="S5.E5.m1.1.1.1.1.2.2.2.2.cmml" xref="S5.E5.m1.1.1.1.1.2.2.2.2"><ci id="S5.E5.m1.1.1.1.1.2.2.2.2.1.cmml" xref="S5.E5.m1.1.1.1.1.2.2.2.2.1">~</ci><ci id="S5.E5.m1.1.1.1.1.2.2.2.2.2.cmml" xref="S5.E5.m1.1.1.1.1.2.2.2.2.2">𝒴</ci></apply><ci id="S5.E5.m1.1.1.1.1.2.2.2.3.cmml" xref="S5.E5.m1.1.1.1.1.2.2.2.3">𝑡</ci></apply></list><apply id="S5.E5.m1.1.1.1.1.7.cmml" xref="S5.E5.m1.1.1.1.1.7"><times id="S5.E5.m1.1.1.1.1.7.6.cmml" xref="S5.E5.m1.1.1.1.1.7.6"></times><apply id="S5.E5.m1.1.1.1.1.7.7.cmml" xref="S5.E5.m1.1.1.1.1.7.7"><csymbol cd="ambiguous" id="S5.E5.m1.1.1.1.1.7.7.1.cmml" xref="S5.E5.m1.1.1.1.1.7.7">superscript</csymbol><ci id="S5.E5.m1.1.1.1.1.7.7.2.cmml" xref="S5.E5.m1.1.1.1.1.7.7.2">𝑓</ci><ci id="S5.E5.m1.1.1.1.1.7.7.3.cmml" xref="S5.E5.m1.1.1.1.1.7.7.3">ℛ</ci></apply><vector id="S5.E5.m1.1.1.1.1.7.5.6.cmml" xref="S5.E5.m1.1.1.1.1.7.5.5"><apply id="S5.E5.m1.1.1.1.1.3.1.1.1.cmml" xref="S5.E5.m1.1.1.1.1.3.1.1.1"><csymbol cd="ambiguous" id="S5.E5.m1.1.1.1.1.3.1.1.1.1.cmml" xref="S5.E5.m1.1.1.1.1.3.1.1.1">superscript</csymbol><ci id="S5.E5.m1.1.1.1.1.3.1.1.1.2.cmml" xref="S5.E5.m1.1.1.1.1.3.1.1.1.2">𝒯</ci><ci id="S5.E5.m1.1.1.1.1.3.1.1.1.3.cmml" xref="S5.E5.m1.1.1.1.1.3.1.1.1.3">𝑡</ci></apply><apply id="S5.E5.m1.1.1.1.1.4.2.2.2.cmml" xref="S5.E5.m1.1.1.1.1.4.2.2.2"><csymbol cd="ambiguous" id="S5.E5.m1.1.1.1.1.4.2.2.2.1.cmml" xref="S5.E5.m1.1.1.1.1.4.2.2.2">superscript</csymbol><ci id="S5.E5.m1.1.1.1.1.4.2.2.2.2.cmml" xref="S5.E5.m1.1.1.1.1.4.2.2.2.2">𝒴</ci><ci id="S5.E5.m1.1.1.1.1.4.2.2.2.3.cmml" xref="S5.E5.m1.1.1.1.1.4.2.2.2.3">𝑡</ci></apply><apply id="S5.E5.m1.1.1.1.1.5.3.3.3.cmml" xref="S5.E5.m1.1.1.1.1.5.3.3.3"><csymbol cd="ambiguous" id="S5.E5.m1.1.1.1.1.5.3.3.3.1.cmml" xref="S5.E5.m1.1.1.1.1.5.3.3.3">superscript</csymbol><ci id="S5.E5.m1.1.1.1.1.5.3.3.3.2.cmml" xref="S5.E5.m1.1.1.1.1.5.3.3.3.2">ℱ</ci><ci id="S5.E5.m1.1.1.1.1.5.3.3.3.3.cmml" xref="S5.E5.m1.1.1.1.1.5.3.3.3.3">𝑡</ci></apply><apply id="S5.E5.m1.1.1.1.1.6.4.4.4.cmml" xref="S5.E5.m1.1.1.1.1.6.4.4.4"><csymbol cd="ambiguous" id="S5.E5.m1.1.1.1.1.6.4.4.4.1.cmml" xref="S5.E5.m1.1.1.1.1.6.4.4.4">superscript</csymbol><ci id="S5.E5.m1.1.1.1.1.6.4.4.4.2.cmml" xref="S5.E5.m1.1.1.1.1.6.4.4.4.2">ℰ</ci><ci id="S5.E5.m1.1.1.1.1.6.4.4.4.3.cmml" xref="S5.E5.m1.1.1.1.1.6.4.4.4.3">𝑡</ci></apply><apply id="S5.E5.m1.1.1.1.1.7.5.5.5.cmml" xref="S5.E5.m1.1.1.1.1.7.5.5.5"><csymbol cd="ambiguous" id="S5.E5.m1.1.1.1.1.7.5.5.5.1.cmml" xref="S5.E5.m1.1.1.1.1.7.5.5.5">superscript</csymbol><ci id="S5.E5.m1.1.1.1.1.7.5.5.5.2.cmml" xref="S5.E5.m1.1.1.1.1.7.5.5.5.2">M</ci><ci id="S5.E5.m1.1.1.1.1.7.5.5.5.3.cmml" xref="S5.E5.m1.1.1.1.1.7.5.5.5.3">𝑡</ci></apply></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E5.m1.1c">\tilde{{\mathcal{T}}}^{t},\tilde{{\mathcal{Y}}}^{t}=f^{{\mathcal{R}}}({%
\mathcal{T}}^{t},{\mathcal{Y}}^{t},{\mathcal{F}}^{t},{\mathcal{E}}^{t},\mathrm%
{M}^{t}),</annotation><annotation encoding="application/x-llamapun" id="S5.E5.m1.1d">over~ start_ARG caligraphic_T end_ARG start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT , over~ start_ARG caligraphic_Y end_ARG start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT = italic_f start_POSTSUPERSCRIPT caligraphic_R end_POSTSUPERSCRIPT ( caligraphic_T start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT , caligraphic_Y start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT , caligraphic_F start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT , caligraphic_E start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT , roman_M start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S5.p1.2">其中<math alttext="f^{{\mathcal{R}}}" class="ltx_Math" display="inline" id="S5.p1.1.m1.1"><semantics id="S5.p1.1.m1.1a"><msup id="S5.p1.1.m1.1.1" xref="S5.p1.1.m1.1.1.cmml"><mi id="S5.p1.1.m1.1.1.2" xref="S5.p1.1.m1.1.1.2.cmml">f</mi><mi class="ltx_font_mathcaligraphic" id="S5.p1.1.m1.1.1.3" xref="S5.p1.1.m1.1.1.3.cmml">ℛ</mi></msup><annotation-xml encoding="MathML-Content" id="S5.p1.1.m1.1b"><apply id="S5.p1.1.m1.1.1.cmml" xref="S5.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.p1.1.m1.1.1.1.cmml" xref="S5.p1.1.m1.1.1">superscript</csymbol><ci id="S5.p1.1.m1.1.1.2.cmml" xref="S5.p1.1.m1.1.1.2">𝑓</ci><ci id="S5.p1.1.m1.1.1.3.cmml" xref="S5.p1.1.m1.1.1.3">ℛ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.1.m1.1c">f^{{\mathcal{R}}}</annotation><annotation encoding="application/x-llamapun" id="S5.p1.1.m1.1d">italic_f start_POSTSUPERSCRIPT caligraphic_R end_POSTSUPERSCRIPT</annotation></semantics></math>是经验改进的方法，<math alttext="\tilde{{\mathcal{T}}}^{t},\tilde{{\mathcal{Y}}}^{t}" class="ltx_Math" display="inline" id="S5.p1.2.m2.2"><semantics id="S5.p1.2.m2.2a"><mrow id="S5.p1.2.m2.2.2.2" xref="S5.p1.2.m2.2.2.3.cmml"><msup id="S5.p1.2.m2.1.1.1.1" xref="S5.p1.2.m2.1.1.1.1.cmml"><mover accent="true" id="S5.p1.2.m2.1.1.1.1.2" xref="S5.p1.2.m2.1.1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.p1.2.m2.1.1.1.1.2.2" xref="S5.p1.2.m2.1.1.1.1.2.2.cmml">𝒯</mi><mo id="S5.p1.2.m2.1.1.1.1.2.1" xref="S5.p1.2.m2.1.1.1.1.2.1.cmml">~</mo></mover><mi id="S5.p1.2.m2.1.1.1.1.3" xref="S5.p1.2.m2.1.1.1.1.3.cmml">t</mi></msup><mo id="S5.p1.2.m2.2.2.2.3" xref="S5.p1.2.m2.2.2.3.cmml">,</mo><msup id="S5.p1.2.m2.2.2.2.2" xref="S5.p1.2.m2.2.2.2.2.cmml"><mover accent="true" id="S5.p1.2.m2.2.2.2.2.2" xref="S5.p1.2.m2.2.2.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.p1.2.m2.2.2.2.2.2.2" xref="S5.p1.2.m2.2.2.2.2.2.2.cmml">𝒴</mi><mo id="S5.p1.2.m2.2.2.2.2.2.1" xref="S5.p1.2.m2.2.2.2.2.2.1.cmml">~</mo></mover><mi id="S5.p1.2.m2.2.2.2.2.3" xref="S5.p1.2.m2.2.2.2.2.3.cmml">t</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S5.p1.2.m2.2b"><list id="S5.p1.2.m2.2.2.3.cmml" xref="S5.p1.2.m2.2.2.2"><apply id="S5.p1.2.m2.1.1.1.1.cmml" xref="S5.p1.2.m2.1.1.1.1"><csymbol cd="ambiguous" id="S5.p1.2.m2.1.1.1.1.1.cmml" xref="S5.p1.2.m2.1.1.1.1">superscript</csymbol><apply id="S5.p1.2.m2.1.1.1.1.2.cmml" xref="S5.p1.2.m2.1.1.1.1.2"><ci id="S5.p1.2.m2.1.1.1.1.2.1.cmml" xref="S5.p1.2.m2.1.1.1.1.2.1">~</ci><ci id="S5.p1.2.m2.1.1.1.1.2.2.cmml" xref="S5.p1.2.m2.1.1.1.1.2.2">𝒯</ci></apply><ci id="S5.p1.2.m2.1.1.1.1.3.cmml" xref="S5.p1.2.m2.1.1.1.1.3">𝑡</ci></apply><apply id="S5.p1.2.m2.2.2.2.2.cmml" xref="S5.p1.2.m2.2.2.2.2"><csymbol cd="ambiguous" id="S5.p1.2.m2.2.2.2.2.1.cmml" xref="S5.p1.2.m2.2.2.2.2">superscript</csymbol><apply id="S5.p1.2.m2.2.2.2.2.2.cmml" xref="S5.p1.2.m2.2.2.2.2.2"><ci id="S5.p1.2.m2.2.2.2.2.2.1.cmml" xref="S5.p1.2.m2.2.2.2.2.2.1">~</ci><ci id="S5.p1.2.m2.2.2.2.2.2.2.cmml" xref="S5.p1.2.m2.2.2.2.2.2.2">𝒴</ci></apply><ci id="S5.p1.2.m2.2.2.2.2.3.cmml" xref="S5.p1.2.m2.2.2.2.2.3">𝑡</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.2.m2.2c">\tilde{{\mathcal{T}}}^{t},\tilde{{\mathcal{Y}}}^{t}</annotation><annotation encoding="application/x-llamapun" id="S5.p1.2.m2.2d">over~ start_ARG caligraphic_T end_ARG start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT , over~ start_ARG caligraphic_Y end_ARG start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT</annotation></semantics></math>是改进的任务和解决方案。我们将这些方法分类为两类：过滤和纠正。</p>
</div>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">5.1 </span>过滤</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">自我进化中的改进涉及两种主要的过滤策略：<span class="ltx_text ltx_font_italic" id="S5.SS1.p1.1.1">基于度量</span>和<span class="ltx_text ltx_font_italic" id="S5.SS1.p1.1.2">无度量</span>。前者使用外部度量来评估和过滤输出，而后者不依赖于这些度量。这确保只有最可靠和高质量的数据被用于进一步更新。</p>
</div>
<section class="ltx_subsubsection" id="S5.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection"><span class="ltx_tag ltx_tag_subsubsection">5.1.1 </span>基于度量的</h4>
<div class="ltx_para" id="S5.SS1.SSS1.p1">
<p class="ltx_p" id="S5.SS1.SSS1.p1.1">通过依赖反馈和预定义的标准，基于度量的过滤提高了输出的质量<cite class="ltx_cite ltx_citemacro_cite">Singh et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib103" title="">2023</a>); Qiao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib90" title="">2024</a>); Ulmer et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib118" title="">2024</a>); Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib127" title="">2023b</a>)</cite>，确保通过每一次精炼迭代逐步增强LLM的能力。</p>
</div>
<div class="ltx_para" id="S5.SS1.SSS1.p2">
<p class="ltx_p" id="S5.SS1.SSS1.p2.1">例如，ReST<math alttext="{}^{EM}" class="ltx_Math" display="inline" id="S5.SS1.SSS1.p2.1.m1.1"><semantics id="S5.SS1.SSS1.p2.1.m1.1a"><msup id="S5.SS1.SSS1.p2.1.m1.1.1" xref="S5.SS1.SSS1.p2.1.m1.1.1.cmml"><mi id="S5.SS1.SSS1.p2.1.m1.1.1a" xref="S5.SS1.SSS1.p2.1.m1.1.1.cmml"></mi><mrow id="S5.SS1.SSS1.p2.1.m1.1.1.1" xref="S5.SS1.SSS1.p2.1.m1.1.1.1.cmml"><mi id="S5.SS1.SSS1.p2.1.m1.1.1.1.2" xref="S5.SS1.SSS1.p2.1.m1.1.1.1.2.cmml">E</mi><mo id="S5.SS1.SSS1.p2.1.m1.1.1.1.1" xref="S5.SS1.SSS1.p2.1.m1.1.1.1.1.cmml">⁢</mo><mi id="S5.SS1.SSS1.p2.1.m1.1.1.1.3" xref="S5.SS1.SSS1.p2.1.m1.1.1.1.3.cmml">M</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS1.p2.1.m1.1b"><apply id="S5.SS1.SSS1.p2.1.m1.1.1.cmml" xref="S5.SS1.SSS1.p2.1.m1.1.1"><apply id="S5.SS1.SSS1.p2.1.m1.1.1.1.cmml" xref="S5.SS1.SSS1.p2.1.m1.1.1.1"><times id="S5.SS1.SSS1.p2.1.m1.1.1.1.1.cmml" xref="S5.SS1.SSS1.p2.1.m1.1.1.1.1"></times><ci id="S5.SS1.SSS1.p2.1.m1.1.1.1.2.cmml" xref="S5.SS1.SSS1.p2.1.m1.1.1.1.2">𝐸</ci><ci id="S5.SS1.SSS1.p2.1.m1.1.1.1.3.cmml" xref="S5.SS1.SSS1.p2.1.m1.1.1.1.3">𝑀</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS1.p2.1.m1.1c">{}^{EM}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS1.p2.1.m1.1d">start_FLOATSUPERSCRIPT italic_E italic_M end_FLOATSUPERSCRIPT</annotation></semantics></math> <cite class="ltx_cite ltx_citemacro_cite">Singh et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib103" title="">2023</a>)</cite> 将奖励函数纳入当前策略采样的数据集中，该函数基于生成样本的正确性提供二元奖励，而不是在ReST<cite class="ltx_cite ltx_citemacro_cite">Gulcehre et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib42" title="">2023</a>)</cite>中基于人类偏好训练的学习奖励模型。AutoAct<cite class="ltx_cite ltx_citemacro_cite">Qiao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib90" title="">2024</a>)</cite> 利用F1分数和准确度作为合成轨迹的奖励，并收集具有完全正确答案的轨迹用于进一步训练。Self-Talk<cite class="ltx_cite ltx_citemacro_cite">Ulmer et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib118" title="">2024</a>)</cite> 测量完成子目标的数量来过滤生成的对话，确保只有高质量的数据用于训练。为了鼓励源指令的多样性，Self-Instruct<cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib127" title="">2023b</a>)</cite> 在将其添加到任务池之前，使用ROUGE-L相似度和启发式自动过滤低质量或重复的指令。</p>
</div>
<div class="ltx_para" id="S5.SS1.SSS1.p3">
<p class="ltx_p" id="S5.SS1.SSS1.p3.1">过滤标准或度量标准对于维护生成输出的质量和可靠性至关重要，从而确保模型能力的持续改进。</p>
</div>
</section>
<section class="ltx_subsubsection" id="S5.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection"><span class="ltx_tag ltx_tag_subsubsection">5.1.2 </span>无度量</h4>
<div class="ltx_para" id="S5.SS1.SSS2.p1">
<p class="ltx_p" id="S5.SS1.SSS2.p1.1">一些方法寻求超出外部指标的过滤策略，使过程更加灵活和适应性强。 <span class="ltx_text ltx_font_italic" id="S5.SS1.SSS2.p1.1.1">无度量</span> 过滤通常涉及对输出进行采样，并根据内部一致性度量或其他模型固有标准进行评估 <cite class="ltx_cite ltx_citemacro_cite">Huang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib52" title="">2022</a>); Weng et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib129" title="">2023</a>); Chen et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib18" title="">2022</a>)</cite>。自一致性过滤 <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib126" title="">2022</a>)</cite> 基于在多个生成的推理路径上的最终答案的一致性，更高的一致性表示更高的可靠性。 LMSI <cite class="ltx_cite ltx_citemacro_cite">Huang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib52" title="">2022</a>)</cite> 利用CoT提示加自一致性来生成高可信度的自训练数据。</p>
</div>
<div class="ltx_para" id="S5.SS1.SSS2.p2">
<p class="ltx_p" id="S5.SS1.SSS2.p2.1">设计准确反映输出质量的内部一致性度量可能具有挑战性。 自我验证<cite class="ltx_cite ltx_citemacro_cite">Weng et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib129" title="">2023</a>)</cite>允许模型选择具有最高可解释验证分数的候选答案，该分数通过评估预测值和原始条件值之间的一致性来计算。 对于代码生成任务，CodeT<cite class="ltx_cite ltx_citemacro_cite">Chen et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib18" title="">2022</a>)</cite>考虑到输出与生成的测试用例的一致性以及输出与其他代码样本的一致性。</p>
</div>
<div class="ltx_para" id="S5.SS1.SSS2.p3">
<p class="ltx_p" id="S5.SS1.SSS2.p3.1">这些方法强调语言模型根据内部一致性评估和过滤其输出的能力，展示了在没有外部指标直接干预的情况下自我进化的重要一步。</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">5.2 </span>纠正</h3>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">最近自我演进的进展突显了迭代自我校正的重要性，这使得模型能够改进它们的经验。本节将使用的方法分为两类：<span class="ltx_text ltx_font_italic" id="S5.SS2.p1.1.1">基于批评</span> 和 <span class="ltx_text ltx_font_italic" id="S5.SS2.p1.1.2">无批评</span> 校正。批评通常作为强烈的提示，包括感知错误或次优输出背后的原理，引导模型朝着改进的迭代方向发展。</p>
</div>
<section class="ltx_subsubsection" id="S5.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection"><span class="ltx_tag ltx_tag_subsubsection">5.2.1 </span>基于批评的</h4>
<div class="ltx_para" id="S5.SS2.SSS1.p1">
<p class="ltx_p" id="S5.SS2.SSS1.p1.1">这些方法依赖于额外的评判过程来得出对经验的批评。然后，根据批评对经验进行改进。通过利用自动生成的<cite class="ltx_cite ltx_citemacro_cite">Madaan et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib80" title="">2023</a>); Bai et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib9" title="">2022</a>); Shinn et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib99" title="">2023</a>); Lu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib76" title="">2023</a>)</cite>或环境交互生成的批评<cite class="ltx_cite ltx_citemacro_cite">Gou et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib41" title="">2023</a>); Jiang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib56" title="">2023</a>); Zhou et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib165" title="">2023b</a>)</cite>，模型受益于细致纠正的详细反馈。</p>
</div>
<div class="ltx_para" id="S5.SS2.SSS1.p2">
<p class="ltx_p" id="S5.SS2.SSS1.p2.1">LLM已经证明了他们在输出中识别错误的能力。 Self-Refine <cite class="ltx_cite ltx_citemacro_cite">Madaan et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib80" title="">2023</a>)</cite>引入了一个迭代过程，在这个过程中，模型在没有额外训练的情况下根据可行的自我反馈完善其初始输出。为了从纠正中发展，CAI <cite class="ltx_cite ltx_citemacro_cite">Bai et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib9" title="">2022</a>)</cite>在监督学习阶段生成对其输出的批评和修订，从而显著改善了初始模型。应用于自动化计算机任务的代理，RCI <cite class="ltx_cite ltx_citemacro_cite">Kim et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib57" title="">2023</a>)</cite>根据发现输出中的错误改进其先前的输出。</p>
</div>
<div class="ltx_para" id="S5.SS2.SSS1.p3">
<p class="ltx_p" id="S5.SS2.SSS1.p3.1">由于较弱的模型可能会在自我批评过程中遇到困难，因此有几种方法可以使模型使用外部工具提供的批评来纠正输出。CRITIC <cite class="ltx_cite ltx_citemacro_cite">Gou et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib41" title="">2023</a>)</cite> 允许LLMs根据与一般领域工具互动期间获得的批评来修订输出。SelfEvolve <cite class="ltx_cite ltx_citemacro_cite">Jiang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib56" title="">2023</a>)</cite> 促使LLM根据解释器抛出的错误信息来完善答案代码。ISR-LLM <cite class="ltx_cite ltx_citemacro_cite">Zhou et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib165" title="">2023b</a>)</cite> 在迭代自我完善过程中帮助LLM规划者找到修订后的行动计划。</p>
</div>
<div class="ltx_para" id="S5.SS2.SSS1.p4">
<p class="ltx_p" id="S5.SS2.SSS1.p4.1">该方法的主要优势在于其处理和对详细反馈做出反应的能力，可能导致更有针对性和微妙的修正。</p>
</div>
</section>
<section class="ltx_subsubsection" id="S5.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection"><span class="ltx_tag ltx_tag_subsubsection">5.2.2 </span>无批评</h4>
<div class="ltx_para" id="S5.SS2.SSS2.p1">
<p class="ltx_p" id="S5.SS2.SSS2.p1.1">与基于批评的方法相反，无批评的方法直接校正经验，利用客观信息<cite class="ltx_cite ltx_citemacro_cite">Zelikman et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib151" title="">2022</a>); Chen et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib22" title="">2023c</a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib20" title="">b</a>); Gero et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib40" title="">2023</a>)</cite>。这些方法的优势在于独立于批评提供的微妙反馈，允许严格遵守事实准确性或特定指导方针的校正，而不会受到批评可能引入的偏见的影响。</p>
</div>
<div class="ltx_para" id="S5.SS2.SSS2.p2">
<p class="ltx_p" id="S5.SS2.SSS2.p2.1">一组无批评的方法修改了关于任务是否被正确解决的信号的经验。自学习推理器（STaR）<cite class="ltx_cite ltx_citemacro_cite">Zelikman et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib151" title="">2022</a>)</cite>提出了一种迭代生成理由来回答问题的技术。如果答案不正确，模型将再次提示正确答案，以生成更明智的理由。自我调试<cite class="ltx_cite ltx_citemacro_cite">Chen et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib22" title="">2023c</a>)</cite>使模型能够通过调查单元测试的执行结果并自行解释代码来执行调试步骤。</p>
</div>
<div class="ltx_para" id="S5.SS2.SSS2.p3">
<p class="ltx_p" id="S5.SS2.SSS2.p3.1">不同于依赖于任务解决信号，解决过程中产生的其他信息可以被利用。IterRefinement <cite class="ltx_cite ltx_citemacro_cite">Chen et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib20" title="">2023b</a>)</cite> 依赖一系列精炼的提示，鼓励模型重新考虑和改进其先前的输出，而不受任何直接批评的影响。对于信息提取任务，Clinical SV <cite class="ltx_cite ltx_citemacro_cite">Gero et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib40" title="">2023</a>)</cite> 将每个元素都基于输入中的证据，并使用提供的证据修剪不准确的元素。</p>
</div>
<div class="ltx_para" id="S5.SS2.SSS2.p4">
<p class="ltx_p" id="S5.SS2.SSS2.p4.1">这些无批评的方法简化了纠正机制，使得实施更容易，调整更快。</p>
</div>
<figure class="ltx_figure" id="S5.F8"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="698" id="S5.F8.g1" src="resource/x7.png" width="1660"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">图8： </span>包括加权和上下文更新的<span class="ltx_text ltx_font_italic" id="S5.F8.8.1">更新</span>方法的说明。术语<math alttext="\tilde{{\mathcal{T}}}^{t}" class="ltx_Math" display="inline" id="S5.F8.4.m1.1"><semantics id="S5.F8.4.m1.1b"><msup id="S5.F8.4.m1.1.1" xref="S5.F8.4.m1.1.1.cmml"><mover accent="true" id="S5.F8.4.m1.1.1.2" xref="S5.F8.4.m1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.F8.4.m1.1.1.2.2" xref="S5.F8.4.m1.1.1.2.2.cmml">𝒯</mi><mo id="S5.F8.4.m1.1.1.2.1" xref="S5.F8.4.m1.1.1.2.1.cmml">~</mo></mover><mi id="S5.F8.4.m1.1.1.3" xref="S5.F8.4.m1.1.1.3.cmml">t</mi></msup><annotation-xml encoding="MathML-Content" id="S5.F8.4.m1.1c"><apply id="S5.F8.4.m1.1.1.cmml" xref="S5.F8.4.m1.1.1"><csymbol cd="ambiguous" id="S5.F8.4.m1.1.1.1.cmml" xref="S5.F8.4.m1.1.1">superscript</csymbol><apply id="S5.F8.4.m1.1.1.2.cmml" xref="S5.F8.4.m1.1.1.2"><ci id="S5.F8.4.m1.1.1.2.1.cmml" xref="S5.F8.4.m1.1.1.2.1">~</ci><ci id="S5.F8.4.m1.1.1.2.2.cmml" xref="S5.F8.4.m1.1.1.2.2">𝒯</ci></apply><ci id="S5.F8.4.m1.1.1.3.cmml" xref="S5.F8.4.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F8.4.m1.1d">\tilde{{\mathcal{T}}}^{t}</annotation><annotation encoding="application/x-llamapun" id="S5.F8.4.m1.1e">over~ start_ARG caligraphic_T end_ARG start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT</annotation></semantics></math>和<math alttext="\tilde{{\mathcal{Y}}}^{t}" class="ltx_Math" display="inline" id="S5.F8.5.m2.1"><semantics id="S5.F8.5.m2.1b"><msup id="S5.F8.5.m2.1.1" xref="S5.F8.5.m2.1.1.cmml"><mover accent="true" id="S5.F8.5.m2.1.1.2" xref="S5.F8.5.m2.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.F8.5.m2.1.1.2.2" xref="S5.F8.5.m2.1.1.2.2.cmml">𝒴</mi><mo id="S5.F8.5.m2.1.1.2.1" xref="S5.F8.5.m2.1.1.2.1.cmml">~</mo></mover><mi id="S5.F8.5.m2.1.1.3" xref="S5.F8.5.m2.1.1.3.cmml">t</mi></msup><annotation-xml encoding="MathML-Content" id="S5.F8.5.m2.1c"><apply id="S5.F8.5.m2.1.1.cmml" xref="S5.F8.5.m2.1.1"><csymbol cd="ambiguous" id="S5.F8.5.m2.1.1.1.cmml" xref="S5.F8.5.m2.1.1">superscript</csymbol><apply id="S5.F8.5.m2.1.1.2.cmml" xref="S5.F8.5.m2.1.1.2"><ci id="S5.F8.5.m2.1.1.2.1.cmml" xref="S5.F8.5.m2.1.1.2.1">~</ci><ci id="S5.F8.5.m2.1.1.2.2.cmml" xref="S5.F8.5.m2.1.1.2.2">𝒴</ci></apply><ci id="S5.F8.5.m2.1.1.3.cmml" xref="S5.F8.5.m2.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F8.5.m2.1d">\tilde{{\mathcal{Y}}}^{t}</annotation><annotation encoding="application/x-llamapun" id="S5.F8.5.m2.1e">over~ start_ARG caligraphic_Y end_ARG start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT</annotation></semantics></math>分别代表精炼的经验，每个经验包含任务和相应的解决方案。<math alttext="\mathrm{M}^{t}" class="ltx_Math" display="inline" id="S5.F8.6.m3.1"><semantics id="S5.F8.6.m3.1b"><msup id="S5.F8.6.m3.1.1" xref="S5.F8.6.m3.1.1.cmml"><mi id="S5.F8.6.m3.1.1.2" mathvariant="normal" xref="S5.F8.6.m3.1.1.2.cmml">M</mi><mi id="S5.F8.6.m3.1.1.3" xref="S5.F8.6.m3.1.1.3.cmml">t</mi></msup><annotation-xml encoding="MathML-Content" id="S5.F8.6.m3.1c"><apply id="S5.F8.6.m3.1.1.cmml" xref="S5.F8.6.m3.1.1"><csymbol cd="ambiguous" id="S5.F8.6.m3.1.1.1.cmml" xref="S5.F8.6.m3.1.1">superscript</csymbol><ci id="S5.F8.6.m3.1.1.2.cmml" xref="S5.F8.6.m3.1.1.2">M</ci><ci id="S5.F8.6.m3.1.1.3.cmml" xref="S5.F8.6.m3.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F8.6.m3.1d">\mathrm{M}^{t}</annotation><annotation encoding="application/x-llamapun" id="S5.F8.6.m3.1e">roman_M start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT</annotation></semantics></math>表示更新后的模型。</figcaption>
</figure>
</section>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">6 </span>更新</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.2">在经验的完善之后，我们进入了利用完善的经验来提高模型性能的关键更新阶段。我们将更新形式化如下：</p>
<table class="ltx_equation ltx_eqn_table" id="S6.E6">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathrm{M}^{t+1}=f^{{\mathcal{U}}}(\tilde{{\mathcal{T}}}^{t},\tilde{{\mathcal{%
Y}}}^{t},{\mathcal{E}}^{t},\mathrm{M}^{t})," class="ltx_Math" display="block" id="S6.E6.m1.1"><semantics id="S6.E6.m1.1a"><mrow id="S6.E6.m1.1.1.1" xref="S6.E6.m1.1.1.1.1.cmml"><mrow id="S6.E6.m1.1.1.1.1" xref="S6.E6.m1.1.1.1.1.cmml"><msup id="S6.E6.m1.1.1.1.1.6" xref="S6.E6.m1.1.1.1.1.6.cmml"><mi id="S6.E6.m1.1.1.1.1.6.2" mathvariant="normal" xref="S6.E6.m1.1.1.1.1.6.2.cmml">M</mi><mrow id="S6.E6.m1.1.1.1.1.6.3" xref="S6.E6.m1.1.1.1.1.6.3.cmml"><mi id="S6.E6.m1.1.1.1.1.6.3.2" xref="S6.E6.m1.1.1.1.1.6.3.2.cmml">t</mi><mo id="S6.E6.m1.1.1.1.1.6.3.1" xref="S6.E6.m1.1.1.1.1.6.3.1.cmml">+</mo><mn id="S6.E6.m1.1.1.1.1.6.3.3" xref="S6.E6.m1.1.1.1.1.6.3.3.cmml">1</mn></mrow></msup><mo id="S6.E6.m1.1.1.1.1.5" xref="S6.E6.m1.1.1.1.1.5.cmml">=</mo><mrow id="S6.E6.m1.1.1.1.1.4" xref="S6.E6.m1.1.1.1.1.4.cmml"><msup id="S6.E6.m1.1.1.1.1.4.6" xref="S6.E6.m1.1.1.1.1.4.6.cmml"><mi id="S6.E6.m1.1.1.1.1.4.6.2" xref="S6.E6.m1.1.1.1.1.4.6.2.cmml">f</mi><mi class="ltx_font_mathcaligraphic" id="S6.E6.m1.1.1.1.1.4.6.3" xref="S6.E6.m1.1.1.1.1.4.6.3.cmml">𝒰</mi></msup><mo id="S6.E6.m1.1.1.1.1.4.5" xref="S6.E6.m1.1.1.1.1.4.5.cmml">⁢</mo><mrow id="S6.E6.m1.1.1.1.1.4.4.4" xref="S6.E6.m1.1.1.1.1.4.4.5.cmml"><mo id="S6.E6.m1.1.1.1.1.4.4.4.5" stretchy="false" xref="S6.E6.m1.1.1.1.1.4.4.5.cmml">(</mo><msup id="S6.E6.m1.1.1.1.1.1.1.1.1" xref="S6.E6.m1.1.1.1.1.1.1.1.1.cmml"><mover accent="true" id="S6.E6.m1.1.1.1.1.1.1.1.1.2" xref="S6.E6.m1.1.1.1.1.1.1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S6.E6.m1.1.1.1.1.1.1.1.1.2.2" xref="S6.E6.m1.1.1.1.1.1.1.1.1.2.2.cmml">𝒯</mi><mo id="S6.E6.m1.1.1.1.1.1.1.1.1.2.1" xref="S6.E6.m1.1.1.1.1.1.1.1.1.2.1.cmml">~</mo></mover><mi id="S6.E6.m1.1.1.1.1.1.1.1.1.3" xref="S6.E6.m1.1.1.1.1.1.1.1.1.3.cmml">t</mi></msup><mo id="S6.E6.m1.1.1.1.1.4.4.4.6" xref="S6.E6.m1.1.1.1.1.4.4.5.cmml">,</mo><msup id="S6.E6.m1.1.1.1.1.2.2.2.2" xref="S6.E6.m1.1.1.1.1.2.2.2.2.cmml"><mover accent="true" id="S6.E6.m1.1.1.1.1.2.2.2.2.2" xref="S6.E6.m1.1.1.1.1.2.2.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S6.E6.m1.1.1.1.1.2.2.2.2.2.2" xref="S6.E6.m1.1.1.1.1.2.2.2.2.2.2.cmml">𝒴</mi><mo id="S6.E6.m1.1.1.1.1.2.2.2.2.2.1" xref="S6.E6.m1.1.1.1.1.2.2.2.2.2.1.cmml">~</mo></mover><mi id="S6.E6.m1.1.1.1.1.2.2.2.2.3" xref="S6.E6.m1.1.1.1.1.2.2.2.2.3.cmml">t</mi></msup><mo id="S6.E6.m1.1.1.1.1.4.4.4.7" xref="S6.E6.m1.1.1.1.1.4.4.5.cmml">,</mo><msup id="S6.E6.m1.1.1.1.1.3.3.3.3" xref="S6.E6.m1.1.1.1.1.3.3.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S6.E6.m1.1.1.1.1.3.3.3.3.2" xref="S6.E6.m1.1.1.1.1.3.3.3.3.2.cmml">ℰ</mi><mi id="S6.E6.m1.1.1.1.1.3.3.3.3.3" xref="S6.E6.m1.1.1.1.1.3.3.3.3.3.cmml">t</mi></msup><mo id="S6.E6.m1.1.1.1.1.4.4.4.8" xref="S6.E6.m1.1.1.1.1.4.4.5.cmml">,</mo><msup id="S6.E6.m1.1.1.1.1.4.4.4.4" xref="S6.E6.m1.1.1.1.1.4.4.4.4.cmml"><mi id="S6.E6.m1.1.1.1.1.4.4.4.4.2" mathvariant="normal" xref="S6.E6.m1.1.1.1.1.4.4.4.4.2.cmml">M</mi><mi id="S6.E6.m1.1.1.1.1.4.4.4.4.3" xref="S6.E6.m1.1.1.1.1.4.4.4.4.3.cmml">t</mi></msup><mo id="S6.E6.m1.1.1.1.1.4.4.4.9" stretchy="false" xref="S6.E6.m1.1.1.1.1.4.4.5.cmml">)</mo></mrow></mrow></mrow><mo id="S6.E6.m1.1.1.1.2" xref="S6.E6.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.E6.m1.1b"><apply id="S6.E6.m1.1.1.1.1.cmml" xref="S6.E6.m1.1.1.1"><eq id="S6.E6.m1.1.1.1.1.5.cmml" xref="S6.E6.m1.1.1.1.1.5"></eq><apply id="S6.E6.m1.1.1.1.1.6.cmml" xref="S6.E6.m1.1.1.1.1.6"><csymbol cd="ambiguous" id="S6.E6.m1.1.1.1.1.6.1.cmml" xref="S6.E6.m1.1.1.1.1.6">superscript</csymbol><ci id="S6.E6.m1.1.1.1.1.6.2.cmml" xref="S6.E6.m1.1.1.1.1.6.2">M</ci><apply id="S6.E6.m1.1.1.1.1.6.3.cmml" xref="S6.E6.m1.1.1.1.1.6.3"><plus id="S6.E6.m1.1.1.1.1.6.3.1.cmml" xref="S6.E6.m1.1.1.1.1.6.3.1"></plus><ci id="S6.E6.m1.1.1.1.1.6.3.2.cmml" xref="S6.E6.m1.1.1.1.1.6.3.2">𝑡</ci><cn id="S6.E6.m1.1.1.1.1.6.3.3.cmml" type="integer" xref="S6.E6.m1.1.1.1.1.6.3.3">1</cn></apply></apply><apply id="S6.E6.m1.1.1.1.1.4.cmml" xref="S6.E6.m1.1.1.1.1.4"><times id="S6.E6.m1.1.1.1.1.4.5.cmml" xref="S6.E6.m1.1.1.1.1.4.5"></times><apply id="S6.E6.m1.1.1.1.1.4.6.cmml" xref="S6.E6.m1.1.1.1.1.4.6"><csymbol cd="ambiguous" id="S6.E6.m1.1.1.1.1.4.6.1.cmml" xref="S6.E6.m1.1.1.1.1.4.6">superscript</csymbol><ci id="S6.E6.m1.1.1.1.1.4.6.2.cmml" xref="S6.E6.m1.1.1.1.1.4.6.2">𝑓</ci><ci id="S6.E6.m1.1.1.1.1.4.6.3.cmml" xref="S6.E6.m1.1.1.1.1.4.6.3">𝒰</ci></apply><vector id="S6.E6.m1.1.1.1.1.4.4.5.cmml" xref="S6.E6.m1.1.1.1.1.4.4.4"><apply id="S6.E6.m1.1.1.1.1.1.1.1.1.cmml" xref="S6.E6.m1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S6.E6.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S6.E6.m1.1.1.1.1.1.1.1.1">superscript</csymbol><apply id="S6.E6.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S6.E6.m1.1.1.1.1.1.1.1.1.2"><ci id="S6.E6.m1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S6.E6.m1.1.1.1.1.1.1.1.1.2.1">~</ci><ci id="S6.E6.m1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S6.E6.m1.1.1.1.1.1.1.1.1.2.2">𝒯</ci></apply><ci id="S6.E6.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S6.E6.m1.1.1.1.1.1.1.1.1.3">𝑡</ci></apply><apply id="S6.E6.m1.1.1.1.1.2.2.2.2.cmml" xref="S6.E6.m1.1.1.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S6.E6.m1.1.1.1.1.2.2.2.2.1.cmml" xref="S6.E6.m1.1.1.1.1.2.2.2.2">superscript</csymbol><apply id="S6.E6.m1.1.1.1.1.2.2.2.2.2.cmml" xref="S6.E6.m1.1.1.1.1.2.2.2.2.2"><ci id="S6.E6.m1.1.1.1.1.2.2.2.2.2.1.cmml" xref="S6.E6.m1.1.1.1.1.2.2.2.2.2.1">~</ci><ci id="S6.E6.m1.1.1.1.1.2.2.2.2.2.2.cmml" xref="S6.E6.m1.1.1.1.1.2.2.2.2.2.2">𝒴</ci></apply><ci id="S6.E6.m1.1.1.1.1.2.2.2.2.3.cmml" xref="S6.E6.m1.1.1.1.1.2.2.2.2.3">𝑡</ci></apply><apply id="S6.E6.m1.1.1.1.1.3.3.3.3.cmml" xref="S6.E6.m1.1.1.1.1.3.3.3.3"><csymbol cd="ambiguous" id="S6.E6.m1.1.1.1.1.3.3.3.3.1.cmml" xref="S6.E6.m1.1.1.1.1.3.3.3.3">superscript</csymbol><ci id="S6.E6.m1.1.1.1.1.3.3.3.3.2.cmml" xref="S6.E6.m1.1.1.1.1.3.3.3.3.2">ℰ</ci><ci id="S6.E6.m1.1.1.1.1.3.3.3.3.3.cmml" xref="S6.E6.m1.1.1.1.1.3.3.3.3.3">𝑡</ci></apply><apply id="S6.E6.m1.1.1.1.1.4.4.4.4.cmml" xref="S6.E6.m1.1.1.1.1.4.4.4.4"><csymbol cd="ambiguous" id="S6.E6.m1.1.1.1.1.4.4.4.4.1.cmml" xref="S6.E6.m1.1.1.1.1.4.4.4.4">superscript</csymbol><ci id="S6.E6.m1.1.1.1.1.4.4.4.4.2.cmml" xref="S6.E6.m1.1.1.1.1.4.4.4.4.2">M</ci><ci id="S6.E6.m1.1.1.1.1.4.4.4.4.3.cmml" xref="S6.E6.m1.1.1.1.1.4.4.4.4.3">𝑡</ci></apply></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.E6.m1.1c">\mathrm{M}^{t+1}=f^{{\mathcal{U}}}(\tilde{{\mathcal{T}}}^{t},\tilde{{\mathcal{%
Y}}}^{t},{\mathcal{E}}^{t},\mathrm{M}^{t}),</annotation><annotation encoding="application/x-llamapun" id="S6.E6.m1.1d">roman_M start_POSTSUPERSCRIPT italic_t + 1 end_POSTSUPERSCRIPT = italic_f start_POSTSUPERSCRIPT caligraphic_U end_POSTSUPERSCRIPT ( over~ start_ARG caligraphic_T end_ARG start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT , over~ start_ARG caligraphic_Y end_ARG start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT , caligraphic_E start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT , roman_M start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S6.p1.1">其中<math alttext="f^{{\mathcal{U}}}" class="ltx_Math" display="inline" id="S6.p1.1.m1.1"><semantics id="S6.p1.1.m1.1a"><msup id="S6.p1.1.m1.1.1" xref="S6.p1.1.m1.1.1.cmml"><mi id="S6.p1.1.m1.1.1.2" xref="S6.p1.1.m1.1.1.2.cmml">f</mi><mi class="ltx_font_mathcaligraphic" id="S6.p1.1.m1.1.1.3" xref="S6.p1.1.m1.1.1.3.cmml">𝒰</mi></msup><annotation-xml encoding="MathML-Content" id="S6.p1.1.m1.1b"><apply id="S6.p1.1.m1.1.1.cmml" xref="S6.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S6.p1.1.m1.1.1.1.cmml" xref="S6.p1.1.m1.1.1">superscript</csymbol><ci id="S6.p1.1.m1.1.1.2.cmml" xref="S6.p1.1.m1.1.1.2">𝑓</ci><ci id="S6.p1.1.m1.1.1.3.cmml" xref="S6.p1.1.m1.1.1.3">𝒰</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.1.m1.1c">f^{{\mathcal{U}}}</annotation><annotation encoding="application/x-llamapun" id="S6.p1.1.m1.1d">italic_f start_POSTSUPERSCRIPT caligraphic_U end_POSTSUPERSCRIPT</annotation></semantics></math>是更新函数。这些更新方法通过适应新经验并在变化的环境中持续改进性能，保持模型的有效性并在迭代训练过程中提高性能。</p>
</div>
<div class="ltx_para" id="S6.p2">
<p class="ltx_p" id="S6.p2.1">我们将这些方法分为重量内学习，涉及模型权重的更新，和上下文内学习，涉及外部或工作内存的更新。</p>
</div>
<section class="ltx_subsection" id="S6.SS1">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">6.1 </span>内部权重</h3>
<div class="ltx_para" id="S6.SS1.p1">
<p class="ltx_p" id="S6.SS1.p1.1">经典的训练范式在更新LLM的重量方面包括连续预训练<cite class="ltx_cite ltx_citemacro_cite">Brown et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib14" title="">2020</a>); Roziere et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib93" title="">2023</a>)</cite>，监督微调<cite class="ltx_cite ltx_citemacro_cite">Longpre et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib75" title="">2023</a>)</cite>和偏好对齐<cite class="ltx_cite ltx_citemacro_cite">Ouyang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib83" title="">2022</a>); Touvron et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib115" title="">2023a</a>)</cite>。然而，在自我演变的迭代训练过程中，核心挑战在于<span class="ltx_text ltx_font_bold" id="S6.SS1.p1.1.1">实现整体改进</span>和<span class="ltx_text ltx_font_bold" id="S6.SS1.p1.1.2">防止灾难性遗忘</span>，这需要在保留原始技能的同时，细化或获取新的能力。对这一挑战的解决方案可以分为三种主要策略：基于重放的、基于正则化的和基于合并的方法。</p>
</div>
<section class="ltx_subsubsection" id="S6.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection"><span class="ltx_tag ltx_tag_subsubsection">6.1.1 </span>基于重播的</h4>
<div class="ltx_para" id="S6.SS1.SSS1.p1">
<p class="ltx_p" id="S6.SS1.SSS1.p1.1">重新播放的方法重新引入以保留旧知识。 其中一种是经验重放，它混合原始和新的训练数据以更新LLMs <cite class="ltx_cite ltx_citemacro_cite">Roziere et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib93" title="">2023</a>); Yang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib142" title="">2024c</a>); Zheng et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib157" title="">2023</a>); Lee et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib60" title="">2024</a>); Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib124" title="">2023a</a>)</cite>。 例如，拒绝抽样微调（RFT）<cite class="ltx_cite ltx_citemacro_cite">Yuan et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib149" title="">2023</a>)</cite>和强化自我训练（ReST）<cite class="ltx_cite ltx_citemacro_cite">Gulcehre et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib42" title="">2023</a>); Aksitov et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib4" title="">2023</a>)</cite>方法通过将种子训练数据与模型自身生成的过滤新输出混合来迭代地更新大型语言模型。 AMIE <cite class="ltx_cite ltx_citemacro_cite">Tu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib117" title="">2024</a>)</cite> 利用自我对弈模拟学习环境进行迭代改进，并通过内外自我对弈循环将生成的对话与监督微调数据混合。 SOTOPIA-<math alttext="\pi" class="ltx_Math" display="inline" id="S6.SS1.SSS1.p1.1.m1.1"><semantics id="S6.SS1.SSS1.p1.1.m1.1a"><mi id="S6.SS1.SSS1.p1.1.m1.1.1" xref="S6.SS1.SSS1.p1.1.m1.1.1.cmml">π</mi><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS1.p1.1.m1.1b"><ci id="S6.SS1.SSS1.p1.1.m1.1.1.cmml" xref="S6.SS1.SSS1.p1.1.m1.1.1">𝜋</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS1.p1.1.m1.1c">\pi</annotation><annotation encoding="application/x-llamapun" id="S6.SS1.SSS1.p1.1.m1.1d">italic_π</annotation></semantics></math> <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib125" title="">2024e</a>)</cite> 利用来自专家模型的行为克隆和自动生成的社交互动轨迹来加强积极行为。</p>
</div>
<div class="ltx_para" id="S6.SS1.SSS1.p2">
<p class="ltx_p" id="S6.SS1.SSS1.p2.1">另一个是生成式重放，它采用自生成的合成数据作为知识，以减轻灾难性遗忘。例如，自生成排练（SSR）<cite class="ltx_cite ltx_citemacro_cite">Huang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib51" title="">2024a</a>)</cite> 生成用于排练的合成训练实例，使模型能够保持其能力，而不依赖于先前训练阶段的真实数据。自蒸馏微调（SDFT）<cite class="ltx_cite ltx_citemacro_cite">Yang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib141" title="">2024b</a>)</cite> 从模型本身生成蒸馏数据集，以弥合任务数据集与LLM原始分布之间的分布差距，以减轻灾难性遗忘。</p>
</div>
</section>
<section class="ltx_subsubsection" id="S6.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection"><span class="ltx_tag ltx_tag_subsubsection">6.1.2 </span>基于正则化</h4>
<div class="ltx_para" id="S6.SS1.SSS2.p1">
<p class="ltx_p" id="S6.SS1.SSS2.p1.2">基于正则化的方法限制模型的更新，以防止与原始行为有显著偏差，例如基于函数和权重的正则化。基于函数的正则化专注于修改模型在训练期间优化的损失函数。例如，InstuctGPT使用从初始策略模型的输出概率到更新后的策略模型的每个标记的KL散度惩罚。FuseLLM采用类似知识蒸馏的技术，利用从源LLM生成的概率分布，将集体知识传递到目标LLM。</p>
</div>
<div class="ltx_para" id="S6.SS1.SSS2.p2">
<p class="ltx_p" id="S6.SS1.SSS2.p2.1">基于权重的正则化<cite class="ltx_cite ltx_citemacro_cite">Kirkpatrick et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib58" title="">2017</a>)</cite>在训练过程中直接针对模型的权重。诸如Elastic Reset<cite class="ltx_cite ltx_citemacro_cite">Noukhovitch et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib82" title="">2024</a>)</cite>之类的技术通过定期将在线模型重置为先前状态的指数移动平均值来抵消RLHF中的对齐漂移。此外，<cite class="ltx_cite ltx_citemacro_citet">Ramé et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib92" title="">2024</a>)</cite>引入了WARM，通过权重平均化结合多个奖励模型来解决奖励欺骗和不对齐问题。此外，AMA<cite class="ltx_cite ltx_citemacro_cite">Lin et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib69" title="">2024</a>)</cite>自适应地平均模型权重，以优化奖励最大化和遗忘缓解之间的权衡。</p>
</div>
</section>
<section class="ltx_subsubsection" id="S6.SS1.SSS3">
<h4 class="ltx_title ltx_title_subsubsection"><span class="ltx_tag ltx_tag_subsubsection">6.1.3 </span>基于架构</h4>
<div class="ltx_para" id="S6.SS1.SSS3.p1">
<p class="ltx_p" id="S6.SS1.SSS3.p1.1">基于架构的方法明确利用额外的参数或模型进行更新，包括基于分解和合并的方法。基于分解的方法将大型神经网络参数分离成通用和任务特定的组件，并仅更新任务特定的参数以减少遗忘。LoRA <cite class="ltx_cite ltx_citemacro_cite">Hu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib50" title="">2021</a>); Dettmers et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib29" title="">2024</a>)</cite> 注入可训练的低秩矩阵，显著减少可训练参数的数量，同时在各种任务中保持或提高模型性能。后来，这一范式被GPT4tools <cite class="ltx_cite ltx_citemacro_cite">Yang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib139" title="">2024a</a>)</cite>、OpenAGI <cite class="ltx_cite ltx_citemacro_cite">Ge et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib39" title="">2024</a>)</cite>和Dromedary <cite class="ltx_cite ltx_citemacro_cite">Sun et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib108" title="">2024</a>)</cite>采用。动态ConPET <cite class="ltx_cite ltx_citemacro_cite">Song et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib104" title="">2023</a>)</cite>将预选和预测与任务特定的LoRA模块结合起来，以防止遗忘，确保LLMs对新任务的可伸缩和有效适应。</p>
</div>
<div class="ltx_para" id="S6.SS1.SSS3.p2">
<p class="ltx_p" id="S6.SS1.SSS3.p2.1">合并型方法，另一方面，涉及将多个模型或层合并以实现一般改进，包括但不限于将多个通用和专门模型权重合并为单个模型<cite class="ltx_cite ltx_citemacro_cite">Wortsman et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib130" title="">2022</a>); Ilharco et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib55" title="">2022</a>); Yu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib146" title="">2023a</a>); Yadav et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib137" title="">2024</a>)</cite>，通过专家混合方法<cite class="ltx_cite ltx_citemacro_cite">Ding et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib32" title="">2024</a>)</cite>甚至层次合并和缩放，如EvoLLM<cite class="ltx_cite ltx_citemacro_cite">Akiba et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib3" title="">2024</a>)</cite>。</p>
</div>
</section>
</section>
<section class="ltx_subsection ltx_pruned_first" id="S6.SS2">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">6.2 </span>上下文内</h3>
<div class="ltx_para" id="S6.SS2.p1">
<p class="ltx_p" id="S6.SS2.p1.1">除了直接更新模型参数外，另一种方法是利用LLM的上下文能力来从经验中学习，从而实现快速自适应更新而无需昂贵的训练成本。这些方法可以分为更新外部和工作内存。</p>
</div>
<figure class="ltx_table" id="S6.T2">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S6.T2.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S6.T2.1.1.1">
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T2.1.1.1.1" style="padding-left:8.5pt;padding-right:8.5pt;"><span class="ltx_text ltx_font_smallcaps" id="S6.T2.1.1.1.1.1">Method</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T2.1.1.1.2" style="padding-left:8.5pt;padding-right:8.5pt;"><span class="ltx_text ltx_font_smallcaps" id="S6.T2.1.1.1.2.1">Content</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T2.1.1.1.3" style="padding-left:8.5pt;padding-right:8.5pt;"><span class="ltx_text ltx_font_smallcaps" id="S6.T2.1.1.1.3.1">Operation</span></td>
</tr>
<tr class="ltx_tr" id="S6.T2.1.2.2">
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T2.1.2.2.1" style="padding-left:8.5pt;padding-right:8.5pt;">MoT <cite class="ltx_cite ltx_citemacro_cite">Li and Qiu (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib67" title="">2023</a>)</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T2.1.2.2.2" style="padding-left:8.5pt;padding-right:8.5pt;"><span class="ltx_text ltx_font_typewriter" id="S6.T2.1.2.2.2.1">Experience</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T2.1.2.2.3" style="padding-left:8.5pt;padding-right:8.5pt;"><span class="ltx_text ltx_font_typewriter" id="S6.T2.1.2.2.3.1">Insert</span></td>
</tr>
<tr class="ltx_tr" id="S6.T2.1.3.3">
<td class="ltx_td ltx_align_center" id="S6.T2.1.3.3.1" style="padding-left:8.5pt;padding-right:8.5pt;">TRAN <cite class="ltx_cite ltx_citemacro_cite">Yang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib140" title="">2023b</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S6.T2.1.3.3.2" style="padding-left:8.5pt;padding-right:8.5pt;"><span class="ltx_text ltx_font_typewriter" id="S6.T2.1.3.3.2.1">Rationale</span></td>
<td class="ltx_td ltx_align_center" id="S6.T2.1.3.3.3" style="padding-left:8.5pt;padding-right:8.5pt;">
<span class="ltx_text ltx_font_typewriter" id="S6.T2.1.3.3.3.1">Insert</span>, <span class="ltx_text ltx_font_typewriter" id="S6.T2.1.3.3.3.2">Reflect</span>
</td>
</tr>
<tr class="ltx_tr" id="S6.T2.1.4.4">
<td class="ltx_td ltx_align_center" id="S6.T2.1.4.4.1" style="padding-left:8.5pt;padding-right:8.5pt;">MemoryBank <cite class="ltx_cite ltx_citemacro_cite">Zhong et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib162" title="">2024b</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S6.T2.1.4.4.2" style="padding-left:8.5pt;padding-right:8.5pt;">
<span class="ltx_text ltx_font_typewriter" id="S6.T2.1.4.4.2.1">Experience</span>, <span class="ltx_text ltx_font_typewriter" id="S6.T2.1.4.4.2.2">Rationale</span>
</td>
<td class="ltx_td ltx_align_center" id="S6.T2.1.4.4.3" style="padding-left:8.5pt;padding-right:8.5pt;">
<span class="ltx_text ltx_font_typewriter" id="S6.T2.1.4.4.3.1">Insert</span>, <span class="ltx_text ltx_font_typewriter" id="S6.T2.1.4.4.3.2">Reflect</span>, <span class="ltx_text ltx_font_typewriter" id="S6.T2.1.4.4.3.3">Forget</span>
</td>
</tr>
<tr class="ltx_tr" id="S6.T2.1.5.5">
<td class="ltx_td ltx_align_center" id="S6.T2.1.5.5.1" style="padding-left:8.5pt;padding-right:8.5pt;">MemGPT <cite class="ltx_cite ltx_citemacro_cite">Packer et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib84" title="">2023</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S6.T2.1.5.5.2" style="padding-left:8.5pt;padding-right:8.5pt;"><span class="ltx_text ltx_font_typewriter" id="S6.T2.1.5.5.2.1">Experience</span></td>
<td class="ltx_td ltx_align_center" id="S6.T2.1.5.5.3" style="padding-left:8.5pt;padding-right:8.5pt;">
<span class="ltx_text ltx_font_typewriter" id="S6.T2.1.5.5.3.1">Insert</span>, <span class="ltx_text ltx_font_typewriter" id="S6.T2.1.5.5.3.2">Forget</span>
</td>
</tr>
<tr class="ltx_tr" id="S6.T2.1.6.6">
<td class="ltx_td ltx_align_center" id="S6.T2.1.6.6.1" style="padding-left:8.5pt;padding-right:8.5pt;">TiM <cite class="ltx_cite ltx_citemacro_cite">Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib72" title="">2023a</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S6.T2.1.6.6.2" style="padding-left:8.5pt;padding-right:8.5pt;"><span class="ltx_text ltx_font_typewriter" id="S6.T2.1.6.6.2.1">Rationale</span></td>
<td class="ltx_td ltx_align_center" id="S6.T2.1.6.6.3" style="padding-left:8.5pt;padding-right:8.5pt;"><span class="ltx_text ltx_font_typewriter" id="S6.T2.1.6.6.3.1">Insert</span></td>
</tr>
<tr class="ltx_tr" id="S6.T2.1.7.7">
<td class="ltx_td ltx_align_center" id="S6.T2.1.7.7.1" style="padding-left:8.5pt;padding-right:8.5pt;">IML <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib120" title="">2024a</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S6.T2.1.7.7.2" style="padding-left:8.5pt;padding-right:8.5pt;"><span class="ltx_text ltx_font_typewriter" id="S6.T2.1.7.7.2.1">Rationale</span></td>
<td class="ltx_td ltx_align_center" id="S6.T2.1.7.7.3" style="padding-left:8.5pt;padding-right:8.5pt;">Insert, <span class="ltx_text ltx_font_typewriter" id="S6.T2.1.7.7.3.1">Reflect</span>
</td>
</tr>
<tr class="ltx_tr" id="S6.T2.1.8.8">
<td class="ltx_td ltx_align_center" id="S6.T2.1.8.8.1" style="padding-left:8.5pt;padding-right:8.5pt;">ICE <cite class="ltx_cite ltx_citemacro_cite">Qian et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib89" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S6.T2.1.8.8.2" style="padding-left:8.5pt;padding-right:8.5pt;"><span class="ltx_text ltx_font_typewriter" id="S6.T2.1.8.8.2.1">Rationale</span></td>
<td class="ltx_td ltx_align_center" id="S6.T2.1.8.8.3" style="padding-left:8.5pt;padding-right:8.5pt;">
<span class="ltx_text ltx_font_typewriter" id="S6.T2.1.8.8.3.1">Insert</span>, <span class="ltx_text ltx_font_typewriter" id="S6.T2.1.8.8.3.2">Reflect</span>
</td>
</tr>
<tr class="ltx_tr" id="S6.T2.1.9.9">
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T2.1.9.9.1" style="padding-left:8.5pt;padding-right:8.5pt;">AesopAgent <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib123" title="">2024d</a>)</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T2.1.9.9.2" style="padding-left:8.5pt;padding-right:8.5pt;">
<span class="ltx_text ltx_font_typewriter" id="S6.T2.1.9.9.2.1">Experience</span>, <span class="ltx_text ltx_font_typewriter" id="S6.T2.1.9.9.2.2">Rationale</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T2.1.9.9.3" style="padding-left:8.5pt;padding-right:8.5pt;">
<span class="ltx_text ltx_font_typewriter" id="S6.T2.1.9.9.3.1">Insert</span>, <span class="ltx_text ltx_font_typewriter" id="S6.T2.1.9.9.3.2">Reflect</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">表2： </span>更新外部存储器的内容和操作。</figcaption>
</figure>
<section class="ltx_paragraph ltx_pruned_first" id="S6.SS2.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">外部内存</h5>
<div class="ltx_para" id="S6.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="S6.SS2.SSS0.Px1.p1.1">该方法利用外部模块来收集、更新和检索过去的经验和知识，使模型能够访问丰富的见解，并在不更新模型参数的情况下取得更好的结果。外部存储器机制在AI Agent系统中很常见<cite class="ltx_cite ltx_citemacro_cite">Xu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib136" title="">2023b</a>); Qian et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib89" title="">2024</a>); Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib123" title="">2024d</a>)</cite>。
本节详细介绍了更新外部存储器的最新方法，重点介绍了记忆<span class="ltx_text ltx_font_italic" id="S6.SS2.SSS0.Px1.p1.1.1">内容</span>和<span class="ltx_text ltx_font_italic" id="S6.SS2.SSS0.Px1.p1.1.2">更新操作</span>的方面，并总结在表<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#S6.T2" title="Table 2 ‣ 6.2 In-Context ‣ 6 Updating ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_tag">2</span></a>中。</p>
</div>
<div class="ltx_para" id="S6.SS2.SSS0.Px1.p2">
<p class="ltx_p" id="S6.SS2.SSS0.Px1.p2.1"><span class="ltx_text ltx_font_italic" id="S6.SS2.SSS0.Px1.p2.1.1">内容：</span>外部记忆主要存储两种类型的内容：过去的经验和反思的理性，每种都有不同的目的。例如，过去的经验提供了宝贵的历史背景，成为实现改善结果的引导力。
MoT <cite class="ltx_cite ltx_citemacro_cite">Li and Qiu (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib67" title="">2023</a>)</cite> 存档筛选后的问题-答案对，以构建有益的记忆库。
此外，MemGPT <cite class="ltx_cite ltx_citemacro_cite">Packer et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib84" title="">2023</a>)</cite> 中的FIFO队列机制维护了一系列消息的滚动历史，封装了代理和用户之间的交互，系统通知，以及函数调用的输入和输出。</p>
</div>
<div class="ltx_para" id="S6.SS2.SSS0.Px1.p3">
<p class="ltx_p" id="S6.SS2.SSS0.Px1.p3.1">另一方面，反思性的原理提供了简明的解释，比如支持决策的规则，以及从经验中推断出的规则和有关错误的信息，以减少未来的错误。
相应地，TiM<cite class="ltx_cite ltx_citemacro_cite">Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib72" title="">2023a</a>)</cite>保留了归纳推理，即阐明实体之间关系的文本。
此外，IML<cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib120" title="">2024a</a>)</cite>和ICE<cite class="ltx_cite ltx_citemacro_cite">Qian et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib89" title="">2024</a>)</cite>存储了一系列轨迹推导出的全面注释和规则，展示了记忆系统可以容纳的广泛内容类型。</p>
</div>
<div class="ltx_para" id="S6.SS2.SSS0.Px1.p4">
<p class="ltx_p" id="S6.SS2.SSS0.Px1.p4.1">MemoryBank <cite class="ltx_cite ltx_citemacro_cite">Zhong et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib162" title="">2024b</a>)</cite>和AesopAgent <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib123" title="">2024d</a>)</cite>建立了经验和反思知识存储，这是两种记忆的整合。</p>
</div>
<div class="ltx_para" id="S6.SS2.SSS0.Px1.p5">
<p class="ltx_p" id="S6.SS2.SSS0.Px1.p5.1"><span class="ltx_text ltx_font_italic" id="S6.SS2.SSS0.Px1.p5.1.1">更新操作：</span>我们将操作分类为插入、反思和遗忘。最常见的操作是插入，方法是将文本内容插入内存进行存储<cite class="ltx_cite ltx_citemacro_cite">Li and Qiu (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib67" title="">2023</a>); Yang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib140" title="">2023b</a>); Zhong et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib162" title="">2024b</a>); Packer et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib84" title="">2023</a>); Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib72" title="">2023a</a>); Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib120" title="">2024a</a>)</cite>。
另一个操作是反思，这是为了思考和总结以前的经验，将规则和知识概念化以供将来使用<cite class="ltx_cite ltx_citemacro_cite">Yang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib140" title="">2023b</a>); Zhong et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib162" title="">2024b</a>); Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib120" title="">2024a</a>); Qian et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib89" title="">2024</a>)</cite>。
最后，由于内存存储空间有限，遗忘内容对于保持内存高效和内容有效性至关重要。
MemGPT<cite class="ltx_cite ltx_citemacro_cite">Packer et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib84" title="">2023</a>)</cite>采用FIFO队列来遗忘内容。
MemoryBank<cite class="ltx_cite ltx_citemacro_cite">Zhong et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib162" title="">2024b</a>)</cite>在每个项目的插入时间上建立了遗忘曲线。</p>
</div>
</section>
<section class="ltx_paragraph" id="S6.SS2.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">工作记忆</h5>
<div class="ltx_para" id="S6.SS2.SSS0.Px2.p1">
<p class="ltx_p" id="S6.SS2.SSS0.Px2.p1.1">这些方法利用过去的经验通过更新内部记忆流、状态或信念（称为工作记忆），通常以口头提示的形式，来发展代理的能力。 Reflexion <cite class="ltx_cite ltx_citemacro_cite">Shinn et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib99" title="">2023</a>)</cite> 引入了口头强化学习，用于决策改进，而无需传统的模型更新。同样，IML <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib120" title="">2024a</a>)</cite> 使基于LLM的代理能够自主学习和适应其环境，通过直接在工作记忆中总结、完善和更新基于过去经验的知识。</p>
</div>
<div class="ltx_para" id="S6.SS2.SSS0.Px2.p2">
<p class="ltx_p" id="S6.SS2.SSS0.Px2.p2.1">EvolutionaryAgent <cite class="ltx_cite ltx_citemacro_cite">Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib65" title="">2024c</a>)</cite> 通过进化和选择原则使代理与动态变化的社会规范保持一致，利用环境反馈进行自我进化。Agent-Pro <cite class="ltx_cite ltx_citemacro_cite">Zhang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib155" title="">2024d</a>)</cite> 采用政策级别的反思和优化，允许代理根据过去的结果在互动场景中调整其行为和信念。最后，ProAgent <cite class="ltx_cite ltx_citemacro_cite">Zhang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib152" title="">2024a</a>)</cite> 通过动态解释队友的意图并调整行为来增强多代理系统中的合作。</p>
</div>
<div class="ltx_para" id="S6.SS2.SSS0.Px2.p3">
<p class="ltx_p" id="S6.SS2.SSS0.Px2.p3.1">这些集体作品表明，将过去的经验和知识整合到代理的记忆流中，以改进其状态或信念，从而提高其在各种任务和环境中的性能和适应性的重要性。</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">7 </span>评估</h2>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">就像人类学习过程一样，通过评估来确定当前能力水平是否足够并满足应用要求是至关重要的。此外，正是通过这些评估，我们可以确定未来学习的方向。然而，如何准确评估进化模型的性能并为未来改进提供方向是一个至关重要但尚未充分探讨的研究领域。对于给定的进化模型<math alttext="M^{t}" class="ltx_Math" display="inline" id="S7.p1.1.m1.1"><semantics id="S7.p1.1.m1.1a"><msup id="S7.p1.1.m1.1.1" xref="S7.p1.1.m1.1.1.cmml"><mi id="S7.p1.1.m1.1.1.2" xref="S7.p1.1.m1.1.1.2.cmml">M</mi><mi id="S7.p1.1.m1.1.1.3" xref="S7.p1.1.m1.1.1.3.cmml">t</mi></msup><annotation-xml encoding="MathML-Content" id="S7.p1.1.m1.1b"><apply id="S7.p1.1.m1.1.1.cmml" xref="S7.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S7.p1.1.m1.1.1.1.cmml" xref="S7.p1.1.m1.1.1">superscript</csymbol><ci id="S7.p1.1.m1.1.1.2.cmml" xref="S7.p1.1.m1.1.1.2">𝑀</ci><ci id="S7.p1.1.m1.1.1.3.cmml" xref="S7.p1.1.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.p1.1.m1.1c">M^{t}</annotation><annotation encoding="application/x-llamapun" id="S7.p1.1.m1.1d">italic_M start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT</annotation></semantics></math>，我们构想评估过程如下：</p>
<table class="ltx_equation ltx_eqn_table" id="S7.E7">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="{\mathcal{E}}^{t+1},{\mathcal{S}}^{t+1}=f^{{\mathcal{E}}}(M^{t},{\mathcal{E}}^%
{t},\mathrm{ENV})," class="ltx_Math" display="block" id="S7.E7.m1.2"><semantics id="S7.E7.m1.2a"><mrow id="S7.E7.m1.2.2.1" xref="S7.E7.m1.2.2.1.1.cmml"><mrow id="S7.E7.m1.2.2.1.1" xref="S7.E7.m1.2.2.1.1.cmml"><mrow id="S7.E7.m1.2.2.1.1.2.2" xref="S7.E7.m1.2.2.1.1.2.3.cmml"><msup id="S7.E7.m1.2.2.1.1.1.1.1" xref="S7.E7.m1.2.2.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S7.E7.m1.2.2.1.1.1.1.1.2" xref="S7.E7.m1.2.2.1.1.1.1.1.2.cmml">ℰ</mi><mrow id="S7.E7.m1.2.2.1.1.1.1.1.3" xref="S7.E7.m1.2.2.1.1.1.1.1.3.cmml"><mi id="S7.E7.m1.2.2.1.1.1.1.1.3.2" xref="S7.E7.m1.2.2.1.1.1.1.1.3.2.cmml">t</mi><mo id="S7.E7.m1.2.2.1.1.1.1.1.3.1" xref="S7.E7.m1.2.2.1.1.1.1.1.3.1.cmml">+</mo><mn id="S7.E7.m1.2.2.1.1.1.1.1.3.3" xref="S7.E7.m1.2.2.1.1.1.1.1.3.3.cmml">1</mn></mrow></msup><mo id="S7.E7.m1.2.2.1.1.2.2.3" xref="S7.E7.m1.2.2.1.1.2.3.cmml">,</mo><msup id="S7.E7.m1.2.2.1.1.2.2.2" xref="S7.E7.m1.2.2.1.1.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S7.E7.m1.2.2.1.1.2.2.2.2" xref="S7.E7.m1.2.2.1.1.2.2.2.2.cmml">𝒮</mi><mrow id="S7.E7.m1.2.2.1.1.2.2.2.3" xref="S7.E7.m1.2.2.1.1.2.2.2.3.cmml"><mi id="S7.E7.m1.2.2.1.1.2.2.2.3.2" xref="S7.E7.m1.2.2.1.1.2.2.2.3.2.cmml">t</mi><mo id="S7.E7.m1.2.2.1.1.2.2.2.3.1" xref="S7.E7.m1.2.2.1.1.2.2.2.3.1.cmml">+</mo><mn id="S7.E7.m1.2.2.1.1.2.2.2.3.3" xref="S7.E7.m1.2.2.1.1.2.2.2.3.3.cmml">1</mn></mrow></msup></mrow><mo id="S7.E7.m1.2.2.1.1.5" xref="S7.E7.m1.2.2.1.1.5.cmml">=</mo><mrow id="S7.E7.m1.2.2.1.1.4" xref="S7.E7.m1.2.2.1.1.4.cmml"><msup id="S7.E7.m1.2.2.1.1.4.4" xref="S7.E7.m1.2.2.1.1.4.4.cmml"><mi id="S7.E7.m1.2.2.1.1.4.4.2" xref="S7.E7.m1.2.2.1.1.4.4.2.cmml">f</mi><mi class="ltx_font_mathcaligraphic" id="S7.E7.m1.2.2.1.1.4.4.3" xref="S7.E7.m1.2.2.1.1.4.4.3.cmml">ℰ</mi></msup><mo id="S7.E7.m1.2.2.1.1.4.3" xref="S7.E7.m1.2.2.1.1.4.3.cmml">⁢</mo><mrow id="S7.E7.m1.2.2.1.1.4.2.2" xref="S7.E7.m1.2.2.1.1.4.2.3.cmml"><mo id="S7.E7.m1.2.2.1.1.4.2.2.3" stretchy="false" xref="S7.E7.m1.2.2.1.1.4.2.3.cmml">(</mo><msup id="S7.E7.m1.2.2.1.1.3.1.1.1" xref="S7.E7.m1.2.2.1.1.3.1.1.1.cmml"><mi id="S7.E7.m1.2.2.1.1.3.1.1.1.2" xref="S7.E7.m1.2.2.1.1.3.1.1.1.2.cmml">M</mi><mi id="S7.E7.m1.2.2.1.1.3.1.1.1.3" xref="S7.E7.m1.2.2.1.1.3.1.1.1.3.cmml">t</mi></msup><mo id="S7.E7.m1.2.2.1.1.4.2.2.4" xref="S7.E7.m1.2.2.1.1.4.2.3.cmml">,</mo><msup id="S7.E7.m1.2.2.1.1.4.2.2.2" xref="S7.E7.m1.2.2.1.1.4.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S7.E7.m1.2.2.1.1.4.2.2.2.2" xref="S7.E7.m1.2.2.1.1.4.2.2.2.2.cmml">ℰ</mi><mi id="S7.E7.m1.2.2.1.1.4.2.2.2.3" xref="S7.E7.m1.2.2.1.1.4.2.2.2.3.cmml">t</mi></msup><mo id="S7.E7.m1.2.2.1.1.4.2.2.5" xref="S7.E7.m1.2.2.1.1.4.2.3.cmml">,</mo><mi id="S7.E7.m1.1.1" xref="S7.E7.m1.1.1.cmml">ENV</mi><mo id="S7.E7.m1.2.2.1.1.4.2.2.6" stretchy="false" xref="S7.E7.m1.2.2.1.1.4.2.3.cmml">)</mo></mrow></mrow></mrow><mo id="S7.E7.m1.2.2.1.2" xref="S7.E7.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S7.E7.m1.2b"><apply id="S7.E7.m1.2.2.1.1.cmml" xref="S7.E7.m1.2.2.1"><eq id="S7.E7.m1.2.2.1.1.5.cmml" xref="S7.E7.m1.2.2.1.1.5"></eq><list id="S7.E7.m1.2.2.1.1.2.3.cmml" xref="S7.E7.m1.2.2.1.1.2.2"><apply id="S7.E7.m1.2.2.1.1.1.1.1.cmml" xref="S7.E7.m1.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S7.E7.m1.2.2.1.1.1.1.1.1.cmml" xref="S7.E7.m1.2.2.1.1.1.1.1">superscript</csymbol><ci id="S7.E7.m1.2.2.1.1.1.1.1.2.cmml" xref="S7.E7.m1.2.2.1.1.1.1.1.2">ℰ</ci><apply id="S7.E7.m1.2.2.1.1.1.1.1.3.cmml" xref="S7.E7.m1.2.2.1.1.1.1.1.3"><plus id="S7.E7.m1.2.2.1.1.1.1.1.3.1.cmml" xref="S7.E7.m1.2.2.1.1.1.1.1.3.1"></plus><ci id="S7.E7.m1.2.2.1.1.1.1.1.3.2.cmml" xref="S7.E7.m1.2.2.1.1.1.1.1.3.2">𝑡</ci><cn id="S7.E7.m1.2.2.1.1.1.1.1.3.3.cmml" type="integer" xref="S7.E7.m1.2.2.1.1.1.1.1.3.3">1</cn></apply></apply><apply id="S7.E7.m1.2.2.1.1.2.2.2.cmml" xref="S7.E7.m1.2.2.1.1.2.2.2"><csymbol cd="ambiguous" id="S7.E7.m1.2.2.1.1.2.2.2.1.cmml" xref="S7.E7.m1.2.2.1.1.2.2.2">superscript</csymbol><ci id="S7.E7.m1.2.2.1.1.2.2.2.2.cmml" xref="S7.E7.m1.2.2.1.1.2.2.2.2">𝒮</ci><apply id="S7.E7.m1.2.2.1.1.2.2.2.3.cmml" xref="S7.E7.m1.2.2.1.1.2.2.2.3"><plus id="S7.E7.m1.2.2.1.1.2.2.2.3.1.cmml" xref="S7.E7.m1.2.2.1.1.2.2.2.3.1"></plus><ci id="S7.E7.m1.2.2.1.1.2.2.2.3.2.cmml" xref="S7.E7.m1.2.2.1.1.2.2.2.3.2">𝑡</ci><cn id="S7.E7.m1.2.2.1.1.2.2.2.3.3.cmml" type="integer" xref="S7.E7.m1.2.2.1.1.2.2.2.3.3">1</cn></apply></apply></list><apply id="S7.E7.m1.2.2.1.1.4.cmml" xref="S7.E7.m1.2.2.1.1.4"><times id="S7.E7.m1.2.2.1.1.4.3.cmml" xref="S7.E7.m1.2.2.1.1.4.3"></times><apply id="S7.E7.m1.2.2.1.1.4.4.cmml" xref="S7.E7.m1.2.2.1.1.4.4"><csymbol cd="ambiguous" id="S7.E7.m1.2.2.1.1.4.4.1.cmml" xref="S7.E7.m1.2.2.1.1.4.4">superscript</csymbol><ci id="S7.E7.m1.2.2.1.1.4.4.2.cmml" xref="S7.E7.m1.2.2.1.1.4.4.2">𝑓</ci><ci id="S7.E7.m1.2.2.1.1.4.4.3.cmml" xref="S7.E7.m1.2.2.1.1.4.4.3">ℰ</ci></apply><vector id="S7.E7.m1.2.2.1.1.4.2.3.cmml" xref="S7.E7.m1.2.2.1.1.4.2.2"><apply id="S7.E7.m1.2.2.1.1.3.1.1.1.cmml" xref="S7.E7.m1.2.2.1.1.3.1.1.1"><csymbol cd="ambiguous" id="S7.E7.m1.2.2.1.1.3.1.1.1.1.cmml" xref="S7.E7.m1.2.2.1.1.3.1.1.1">superscript</csymbol><ci id="S7.E7.m1.2.2.1.1.3.1.1.1.2.cmml" xref="S7.E7.m1.2.2.1.1.3.1.1.1.2">𝑀</ci><ci id="S7.E7.m1.2.2.1.1.3.1.1.1.3.cmml" xref="S7.E7.m1.2.2.1.1.3.1.1.1.3">𝑡</ci></apply><apply id="S7.E7.m1.2.2.1.1.4.2.2.2.cmml" xref="S7.E7.m1.2.2.1.1.4.2.2.2"><csymbol cd="ambiguous" id="S7.E7.m1.2.2.1.1.4.2.2.2.1.cmml" xref="S7.E7.m1.2.2.1.1.4.2.2.2">superscript</csymbol><ci id="S7.E7.m1.2.2.1.1.4.2.2.2.2.cmml" xref="S7.E7.m1.2.2.1.1.4.2.2.2.2">ℰ</ci><ci id="S7.E7.m1.2.2.1.1.4.2.2.2.3.cmml" xref="S7.E7.m1.2.2.1.1.4.2.2.2.3">𝑡</ci></apply><ci id="S7.E7.m1.1.1.cmml" xref="S7.E7.m1.1.1">ENV</ci></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.E7.m1.2c">{\mathcal{E}}^{t+1},{\mathcal{S}}^{t+1}=f^{{\mathcal{E}}}(M^{t},{\mathcal{E}}^%
{t},\mathrm{ENV}),</annotation><annotation encoding="application/x-llamapun" id="S7.E7.m1.2d">caligraphic_E start_POSTSUPERSCRIPT italic_t + 1 end_POSTSUPERSCRIPT , caligraphic_S start_POSTSUPERSCRIPT italic_t + 1 end_POSTSUPERSCRIPT = italic_f start_POSTSUPERSCRIPT caligraphic_E end_POSTSUPERSCRIPT ( italic_M start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT , caligraphic_E start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT , roman_ENV ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(7)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S7.p1.5">其中<math alttext="f^{E}" class="ltx_Math" display="inline" id="S7.p1.2.m1.1"><semantics id="S7.p1.2.m1.1a"><msup id="S7.p1.2.m1.1.1" xref="S7.p1.2.m1.1.1.cmml"><mi id="S7.p1.2.m1.1.1.2" xref="S7.p1.2.m1.1.1.2.cmml">f</mi><mi id="S7.p1.2.m1.1.1.3" xref="S7.p1.2.m1.1.1.3.cmml">E</mi></msup><annotation-xml encoding="MathML-Content" id="S7.p1.2.m1.1b"><apply id="S7.p1.2.m1.1.1.cmml" xref="S7.p1.2.m1.1.1"><csymbol cd="ambiguous" id="S7.p1.2.m1.1.1.1.cmml" xref="S7.p1.2.m1.1.1">superscript</csymbol><ci id="S7.p1.2.m1.1.1.2.cmml" xref="S7.p1.2.m1.1.1.2">𝑓</ci><ci id="S7.p1.2.m1.1.1.3.cmml" xref="S7.p1.2.m1.1.1.3">𝐸</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.p1.2.m1.1c">f^{E}</annotation><annotation encoding="application/x-llamapun" id="S7.p1.2.m1.1d">italic_f start_POSTSUPERSCRIPT italic_E end_POSTSUPERSCRIPT</annotation></semantics></math>表示评估函数，用于衡量当前模型的性能得分（<math alttext="{\mathcal{S}}^{t+1}" class="ltx_Math" display="inline" id="S7.p1.3.m2.1"><semantics id="S7.p1.3.m2.1a"><msup id="S7.p1.3.m2.1.1" xref="S7.p1.3.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S7.p1.3.m2.1.1.2" xref="S7.p1.3.m2.1.1.2.cmml">𝒮</mi><mrow id="S7.p1.3.m2.1.1.3" xref="S7.p1.3.m2.1.1.3.cmml"><mi id="S7.p1.3.m2.1.1.3.2" xref="S7.p1.3.m2.1.1.3.2.cmml">t</mi><mo id="S7.p1.3.m2.1.1.3.1" xref="S7.p1.3.m2.1.1.3.1.cmml">+</mo><mn id="S7.p1.3.m2.1.1.3.3" xref="S7.p1.3.m2.1.1.3.3.cmml">1</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S7.p1.3.m2.1b"><apply id="S7.p1.3.m2.1.1.cmml" xref="S7.p1.3.m2.1.1"><csymbol cd="ambiguous" id="S7.p1.3.m2.1.1.1.cmml" xref="S7.p1.3.m2.1.1">superscript</csymbol><ci id="S7.p1.3.m2.1.1.2.cmml" xref="S7.p1.3.m2.1.1.2">𝒮</ci><apply id="S7.p1.3.m2.1.1.3.cmml" xref="S7.p1.3.m2.1.1.3"><plus id="S7.p1.3.m2.1.1.3.1.cmml" xref="S7.p1.3.m2.1.1.3.1"></plus><ci id="S7.p1.3.m2.1.1.3.2.cmml" xref="S7.p1.3.m2.1.1.3.2">𝑡</ci><cn id="S7.p1.3.m2.1.1.3.3.cmml" type="integer" xref="S7.p1.3.m2.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.p1.3.m2.1c">{\mathcal{S}}^{t+1}</annotation><annotation encoding="application/x-llamapun" id="S7.p1.3.m2.1d">caligraphic_S start_POSTSUPERSCRIPT italic_t + 1 end_POSTSUPERSCRIPT</annotation></semantics></math>）并提供下一次迭代的发展目标（<math alttext="{\mathcal{E}}^{t+1}" class="ltx_Math" display="inline" id="S7.p1.4.m3.1"><semantics id="S7.p1.4.m3.1a"><msup id="S7.p1.4.m3.1.1" xref="S7.p1.4.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S7.p1.4.m3.1.1.2" xref="S7.p1.4.m3.1.1.2.cmml">ℰ</mi><mrow id="S7.p1.4.m3.1.1.3" xref="S7.p1.4.m3.1.1.3.cmml"><mi id="S7.p1.4.m3.1.1.3.2" xref="S7.p1.4.m3.1.1.3.2.cmml">t</mi><mo id="S7.p1.4.m3.1.1.3.1" xref="S7.p1.4.m3.1.1.3.1.cmml">+</mo><mn id="S7.p1.4.m3.1.1.3.3" xref="S7.p1.4.m3.1.1.3.3.cmml">1</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S7.p1.4.m3.1b"><apply id="S7.p1.4.m3.1.1.cmml" xref="S7.p1.4.m3.1.1"><csymbol cd="ambiguous" id="S7.p1.4.m3.1.1.1.cmml" xref="S7.p1.4.m3.1.1">superscript</csymbol><ci id="S7.p1.4.m3.1.1.2.cmml" xref="S7.p1.4.m3.1.1.2">ℰ</ci><apply id="S7.p1.4.m3.1.1.3.cmml" xref="S7.p1.4.m3.1.1.3"><plus id="S7.p1.4.m3.1.1.3.1.cmml" xref="S7.p1.4.m3.1.1.3.1"></plus><ci id="S7.p1.4.m3.1.1.3.2.cmml" xref="S7.p1.4.m3.1.1.3.2">𝑡</ci><cn id="S7.p1.4.m3.1.1.3.3.cmml" type="integer" xref="S7.p1.4.m3.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.p1.4.m3.1c">{\mathcal{E}}^{t+1}</annotation><annotation encoding="application/x-llamapun" id="S7.p1.4.m3.1d">caligraphic_E start_POSTSUPERSCRIPT italic_t + 1 end_POSTSUPERSCRIPT</annotation></semantics></math>）。评估函数<math alttext="f^{\mathcal{E}}" class="ltx_Math" display="inline" id="S7.p1.5.m4.1"><semantics id="S7.p1.5.m4.1a"><msup id="S7.p1.5.m4.1.1" xref="S7.p1.5.m4.1.1.cmml"><mi id="S7.p1.5.m4.1.1.2" xref="S7.p1.5.m4.1.1.2.cmml">f</mi><mi class="ltx_font_mathcaligraphic" id="S7.p1.5.m4.1.1.3" xref="S7.p1.5.m4.1.1.3.cmml">ℰ</mi></msup><annotation-xml encoding="MathML-Content" id="S7.p1.5.m4.1b"><apply id="S7.p1.5.m4.1.1.cmml" xref="S7.p1.5.m4.1.1"><csymbol cd="ambiguous" id="S7.p1.5.m4.1.1.1.cmml" xref="S7.p1.5.m4.1.1">superscript</csymbol><ci id="S7.p1.5.m4.1.1.2.cmml" xref="S7.p1.5.m4.1.1.2">𝑓</ci><ci id="S7.p1.5.m4.1.1.3.cmml" xref="S7.p1.5.m4.1.1.3">ℰ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.p1.5.m4.1c">f^{\mathcal{E}}</annotation><annotation encoding="application/x-llamapun" id="S7.p1.5.m4.1d">italic_f start_POSTSUPERSCRIPT caligraphic_E end_POSTSUPERSCRIPT</annotation></semantics></math>可以分为定量和定性方法，各自提供有价值的模型性能洞察和改进领域。</p>
</div>
<section class="ltx_subsection" id="S7.SS1">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">7.1 </span>定量评估</h3>
<div class="ltx_para" id="S7.SS1.p1">
<p class="ltx_p" id="S7.SS1.p1.1">这种方法专注于提供可衡量的指标来可靠地评估LLM的性能，比如自动<cite class="ltx_cite ltx_citemacro_cite">Papineni et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib86" title="">2002</a>); Lin (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib68" title="">2004</a>)</cite>和人工评估。然而，传统的自动指标难以准确评估日益复杂的任务，而人工评估并非自主自进化的理想选择。最近的趋势使用LLMs作为自动评估者的人类代理，为评估提供了经济高效和可扩展的解决方案。</p>
</div>
<div class="ltx_para" id="S7.SS1.p2">
<p class="ltx_p" id="S7.SS1.p2.1">例如，奖励模型分数被广泛用于衡量模型或任务的性能<cite class="ltx_cite ltx_citemacro_cite">Shinn et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib98" title="">2024</a>)</cite>并选择最佳检查点<cite class="ltx_cite ltx_citemacro_cite">Ouyang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib83" title="">2022</a>)</cite>。LLM作为评判者<cite class="ltx_cite ltx_citemacro_cite">Zheng et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib158" title="">2024a</a>)</cite>使用LLMs来评估LLMs，采用成对比较、单一答案评分和参考指导评分等方法。这表明LLMs可以与人类判断密切匹配，从而实现高效的大规模评估。</p>
</div>
</section>
<section class="ltx_subsection" id="S7.SS2">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">7.2 </span>定性评估</h3>
<div class="ltx_para" id="S7.SS2.p1">
<p class="ltx_p" id="S7.SS2.p1.1">定性评估涉及案例研究和分析，以得出见解，为后续迭代提供不断发展的指导。像LLM作为法官<cite class="ltx_cite ltx_citemacro_cite">Zheng et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib158" title="">2024a</a>)</cite>这样的倡议提供了其评估背后的推理；ChatEval<cite class="ltx_cite ltx_citemacro_cite">Chan et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib17" title="">2023</a>)</cite>通过辩论机制探讨模型输出的优势和劣势。此外，TRAN<cite class="ltx_cite ltx_citemacro_cite">Yang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib140" title="">2023b</a>)</cite>利用过去的错误制定规则，以增强未来LLM的性能。然而，与实例级别的批评或反思相比，任务或模型级别的定性评估仍需要全面调查。</p>
</div>
</section>
</section>
<section class="ltx_section" id="S8">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">8 </span>未解决的问题</h2>
<section class="ltx_subsection" id="S8.SS1">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">8.1 </span>目标：多样性和层次结构</h3>
<div class="ltx_para" id="S8.SS1.p1">
<p class="ltx_p" id="S8.SS1.p1.1">Section <a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#S3" title="3 Evolution Objectives ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_tag">3</span></a> 总结了现有的进化目标及其覆盖范围。然而，这些突出的目标只能满足广泛人类需求的一小部分。
在各种任务和行业中广泛应用LLM突显了建立自我进化框架以全面解决更广泛的现实任务领域中未解决的挑战。 <cite class="ltx_cite ltx_citemacro_cite">Eloundou et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib35" title="">2023</a>)</cite></p>
</div>
<div class="ltx_para" id="S8.SS1.p2">
<p class="ltx_p" id="S8.SS1.p2.1">此外，不断发展的目标概念涉及潜在的分层结构；例如，UltraTool <cite class="ltx_cite ltx_citemacro_cite">Huang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib54" title="">2024b</a>)</cite> 和T-Eval <cite class="ltx_cite ltx_citemacro_cite">Chen et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib23" title="">2023d</a>)</cite> 将工具使用能力分类为各种子维度。将进化目标探索为可管理的子目标，并单独追求它们，成为一种可行的策略。</p>
</div>
<div class="ltx_para" id="S8.SS1.p3">
<p class="ltx_p" id="S8.SS1.p3.1">总的来说，存在开发有效解决多样化和层次化目标的自我演变框架的明显和紧迫的需求。</p>
</div>
</section>
<section class="ltx_subsection" id="S8.SS2">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">8.2 </span>自主级别：从低到高</h3>
<div class="ltx_para" id="S8.SS2.p1">
<p class="ltx_p" id="S8.SS2.p1.1">大型模型中的自我进化正在兴起，但其自主级别缺乏明确的定义。我们将自我进化分为三个层次：低、中、高级自主权。</p>
</div>
<section class="ltx_paragraph" id="S8.SS2.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">低级</h5>
<div class="ltx_para" id="S8.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="S8.SS2.SSS0.Px1.p1.2">在这个级别中，用户预定义了进化对象<math alttext="{\mathcal{E}}" class="ltx_Math" display="inline" id="S8.SS2.SSS0.Px1.p1.1.m1.1"><semantics id="S8.SS2.SSS0.Px1.p1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S8.SS2.SSS0.Px1.p1.1.m1.1.1" xref="S8.SS2.SSS0.Px1.p1.1.m1.1.1.cmml">ℰ</mi><annotation-xml encoding="MathML-Content" id="S8.SS2.SSS0.Px1.p1.1.m1.1b"><ci id="S8.SS2.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S8.SS2.SSS0.Px1.p1.1.m1.1.1">ℰ</ci></annotation-xml><annotation encoding="application/x-tex" id="S8.SS2.SSS0.Px1.p1.1.m1.1c">{\mathcal{E}}</annotation><annotation encoding="application/x-llamapun" id="S8.SS2.SSS0.Px1.p1.1.m1.1d">caligraphic_E</annotation></semantics></math>并且保持不变。用户需要自己设计进化管道，即所有模块<math alttext="f^{\bullet}" class="ltx_Math" display="inline" id="S8.SS2.SSS0.Px1.p1.2.m2.1"><semantics id="S8.SS2.SSS0.Px1.p1.2.m2.1a"><msup id="S8.SS2.SSS0.Px1.p1.2.m2.1.1" xref="S8.SS2.SSS0.Px1.p1.2.m2.1.1.cmml"><mi id="S8.SS2.SSS0.Px1.p1.2.m2.1.1.2" xref="S8.SS2.SSS0.Px1.p1.2.m2.1.1.2.cmml">f</mi><mo id="S8.SS2.SSS0.Px1.p1.2.m2.1.1.3" xref="S8.SS2.SSS0.Px1.p1.2.m2.1.1.3.cmml">∙</mo></msup><annotation-xml encoding="MathML-Content" id="S8.SS2.SSS0.Px1.p1.2.m2.1b"><apply id="S8.SS2.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S8.SS2.SSS0.Px1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S8.SS2.SSS0.Px1.p1.2.m2.1.1.1.cmml" xref="S8.SS2.SSS0.Px1.p1.2.m2.1.1">superscript</csymbol><ci id="S8.SS2.SSS0.Px1.p1.2.m2.1.1.2.cmml" xref="S8.SS2.SSS0.Px1.p1.2.m2.1.1.2">𝑓</ci><ci id="S8.SS2.SSS0.Px1.p1.2.m2.1.1.3.cmml" xref="S8.SS2.SSS0.Px1.p1.2.m2.1.1.3">∙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S8.SS2.SSS0.Px1.p1.2.m2.1c">f^{\bullet}</annotation><annotation encoding="application/x-llamapun" id="S8.SS2.SSS0.Px1.p1.2.m2.1d">italic_f start_POSTSUPERSCRIPT ∙ end_POSTSUPERSCRIPT</annotation></semantics></math>。然后，模型根据设计的框架完成自我进化过程。我们用以下公式表示这个自我进化级别：</p>
<table class="ltx_equation ltx_eqn_table" id="S8.E8">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathrm{\tilde{M}}=\mathrm{Evol^{L}}(\mathrm{M},{\mathcal{E}},f^{\bullet},%
\mathrm{ENV})," class="ltx_Math" display="block" id="S8.E8.m1.4"><semantics id="S8.E8.m1.4a"><mrow id="S8.E8.m1.4.4.1" xref="S8.E8.m1.4.4.1.1.cmml"><mrow id="S8.E8.m1.4.4.1.1" xref="S8.E8.m1.4.4.1.1.cmml"><mover accent="true" id="S8.E8.m1.4.4.1.1.3" xref="S8.E8.m1.4.4.1.1.3.cmml"><mi id="S8.E8.m1.4.4.1.1.3.2" mathvariant="normal" xref="S8.E8.m1.4.4.1.1.3.2.cmml">M</mi><mo id="S8.E8.m1.4.4.1.1.3.1" xref="S8.E8.m1.4.4.1.1.3.1.cmml">~</mo></mover><mo id="S8.E8.m1.4.4.1.1.2" xref="S8.E8.m1.4.4.1.1.2.cmml">=</mo><mrow id="S8.E8.m1.4.4.1.1.1" xref="S8.E8.m1.4.4.1.1.1.cmml"><msup id="S8.E8.m1.4.4.1.1.1.3" xref="S8.E8.m1.4.4.1.1.1.3.cmml"><mi id="S8.E8.m1.4.4.1.1.1.3.2" xref="S8.E8.m1.4.4.1.1.1.3.2.cmml">Evol</mi><mi id="S8.E8.m1.4.4.1.1.1.3.3" mathvariant="normal" xref="S8.E8.m1.4.4.1.1.1.3.3.cmml">L</mi></msup><mo id="S8.E8.m1.4.4.1.1.1.2" xref="S8.E8.m1.4.4.1.1.1.2.cmml">⁢</mo><mrow id="S8.E8.m1.4.4.1.1.1.1.1" xref="S8.E8.m1.4.4.1.1.1.1.2.cmml"><mo id="S8.E8.m1.4.4.1.1.1.1.1.2" stretchy="false" xref="S8.E8.m1.4.4.1.1.1.1.2.cmml">(</mo><mi id="S8.E8.m1.1.1" mathvariant="normal" xref="S8.E8.m1.1.1.cmml">M</mi><mo id="S8.E8.m1.4.4.1.1.1.1.1.3" xref="S8.E8.m1.4.4.1.1.1.1.2.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S8.E8.m1.2.2" xref="S8.E8.m1.2.2.cmml">ℰ</mi><mo id="S8.E8.m1.4.4.1.1.1.1.1.4" xref="S8.E8.m1.4.4.1.1.1.1.2.cmml">,</mo><msup id="S8.E8.m1.4.4.1.1.1.1.1.1" xref="S8.E8.m1.4.4.1.1.1.1.1.1.cmml"><mi id="S8.E8.m1.4.4.1.1.1.1.1.1.2" xref="S8.E8.m1.4.4.1.1.1.1.1.1.2.cmml">f</mi><mo id="S8.E8.m1.4.4.1.1.1.1.1.1.3" xref="S8.E8.m1.4.4.1.1.1.1.1.1.3.cmml">∙</mo></msup><mo id="S8.E8.m1.4.4.1.1.1.1.1.5" xref="S8.E8.m1.4.4.1.1.1.1.2.cmml">,</mo><mi id="S8.E8.m1.3.3" xref="S8.E8.m1.3.3.cmml">ENV</mi><mo id="S8.E8.m1.4.4.1.1.1.1.1.6" stretchy="false" xref="S8.E8.m1.4.4.1.1.1.1.2.cmml">)</mo></mrow></mrow></mrow><mo id="S8.E8.m1.4.4.1.2" xref="S8.E8.m1.4.4.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S8.E8.m1.4b"><apply id="S8.E8.m1.4.4.1.1.cmml" xref="S8.E8.m1.4.4.1"><eq id="S8.E8.m1.4.4.1.1.2.cmml" xref="S8.E8.m1.4.4.1.1.2"></eq><apply id="S8.E8.m1.4.4.1.1.3.cmml" xref="S8.E8.m1.4.4.1.1.3"><ci id="S8.E8.m1.4.4.1.1.3.1.cmml" xref="S8.E8.m1.4.4.1.1.3.1">~</ci><ci id="S8.E8.m1.4.4.1.1.3.2.cmml" xref="S8.E8.m1.4.4.1.1.3.2">M</ci></apply><apply id="S8.E8.m1.4.4.1.1.1.cmml" xref="S8.E8.m1.4.4.1.1.1"><times id="S8.E8.m1.4.4.1.1.1.2.cmml" xref="S8.E8.m1.4.4.1.1.1.2"></times><apply id="S8.E8.m1.4.4.1.1.1.3.cmml" xref="S8.E8.m1.4.4.1.1.1.3"><csymbol cd="ambiguous" id="S8.E8.m1.4.4.1.1.1.3.1.cmml" xref="S8.E8.m1.4.4.1.1.1.3">superscript</csymbol><ci id="S8.E8.m1.4.4.1.1.1.3.2.cmml" xref="S8.E8.m1.4.4.1.1.1.3.2">Evol</ci><ci id="S8.E8.m1.4.4.1.1.1.3.3.cmml" xref="S8.E8.m1.4.4.1.1.1.3.3">L</ci></apply><vector id="S8.E8.m1.4.4.1.1.1.1.2.cmml" xref="S8.E8.m1.4.4.1.1.1.1.1"><ci id="S8.E8.m1.1.1.cmml" xref="S8.E8.m1.1.1">M</ci><ci id="S8.E8.m1.2.2.cmml" xref="S8.E8.m1.2.2">ℰ</ci><apply id="S8.E8.m1.4.4.1.1.1.1.1.1.cmml" xref="S8.E8.m1.4.4.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S8.E8.m1.4.4.1.1.1.1.1.1.1.cmml" xref="S8.E8.m1.4.4.1.1.1.1.1.1">superscript</csymbol><ci id="S8.E8.m1.4.4.1.1.1.1.1.1.2.cmml" xref="S8.E8.m1.4.4.1.1.1.1.1.1.2">𝑓</ci><ci id="S8.E8.m1.4.4.1.1.1.1.1.1.3.cmml" xref="S8.E8.m1.4.4.1.1.1.1.1.1.3">∙</ci></apply><ci id="S8.E8.m1.3.3.cmml" xref="S8.E8.m1.3.3">ENV</ci></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S8.E8.m1.4c">\mathrm{\tilde{M}}=\mathrm{Evol^{L}}(\mathrm{M},{\mathcal{E}},f^{\bullet},%
\mathrm{ENV}),</annotation><annotation encoding="application/x-llamapun" id="S8.E8.m1.4d">over~ start_ARG roman_M end_ARG = roman_Evol start_POSTSUPERSCRIPT roman_L end_POSTSUPERSCRIPT ( roman_M , caligraphic_E , italic_f start_POSTSUPERSCRIPT ∙ end_POSTSUPERSCRIPT , roman_ENV ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(8)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S8.SS2.SSS0.Px1.p1.5">其中，<math alttext="\mathrm{M}" class="ltx_Math" display="inline" id="S8.SS2.SSS0.Px1.p1.3.m1.1"><semantics id="S8.SS2.SSS0.Px1.p1.3.m1.1a"><mi id="S8.SS2.SSS0.Px1.p1.3.m1.1.1" mathvariant="normal" xref="S8.SS2.SSS0.Px1.p1.3.m1.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S8.SS2.SSS0.Px1.p1.3.m1.1b"><ci id="S8.SS2.SSS0.Px1.p1.3.m1.1.1.cmml" xref="S8.SS2.SSS0.Px1.p1.3.m1.1.1">M</ci></annotation-xml><annotation encoding="application/x-tex" id="S8.SS2.SSS0.Px1.p1.3.m1.1c">\mathrm{M}</annotation><annotation encoding="application/x-llamapun" id="S8.SS2.SSS0.Px1.p1.3.m1.1d">roman_M</annotation></semantics></math>表示要进化的模型。 <math alttext="\mathrm{\tilde{M}}" class="ltx_Math" display="inline" id="S8.SS2.SSS0.Px1.p1.4.m2.1"><semantics id="S8.SS2.SSS0.Px1.p1.4.m2.1a"><mover accent="true" id="S8.SS2.SSS0.Px1.p1.4.m2.1.1" xref="S8.SS2.SSS0.Px1.p1.4.m2.1.1.cmml"><mi id="S8.SS2.SSS0.Px1.p1.4.m2.1.1.2" mathvariant="normal" xref="S8.SS2.SSS0.Px1.p1.4.m2.1.1.2.cmml">M</mi><mo id="S8.SS2.SSS0.Px1.p1.4.m2.1.1.1" xref="S8.SS2.SSS0.Px1.p1.4.m2.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S8.SS2.SSS0.Px1.p1.4.m2.1b"><apply id="S8.SS2.SSS0.Px1.p1.4.m2.1.1.cmml" xref="S8.SS2.SSS0.Px1.p1.4.m2.1.1"><ci id="S8.SS2.SSS0.Px1.p1.4.m2.1.1.1.cmml" xref="S8.SS2.SSS0.Px1.p1.4.m2.1.1.1">~</ci><ci id="S8.SS2.SSS0.Px1.p1.4.m2.1.1.2.cmml" xref="S8.SS2.SSS0.Px1.p1.4.m2.1.1.2">M</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S8.SS2.SSS0.Px1.p1.4.m2.1c">\mathrm{\tilde{M}}</annotation><annotation encoding="application/x-llamapun" id="S8.SS2.SSS0.Px1.p1.4.m2.1d">over~ start_ARG roman_M end_ARG</annotation></semantics></math>是进化的输出。 <math alttext="\mathrm{ENV}" class="ltx_Math" display="inline" id="S8.SS2.SSS0.Px1.p1.5.m3.1"><semantics id="S8.SS2.SSS0.Px1.p1.5.m3.1a"><mi id="S8.SS2.SSS0.Px1.p1.5.m3.1.1" xref="S8.SS2.SSS0.Px1.p1.5.m3.1.1.cmml">ENV</mi><annotation-xml encoding="MathML-Content" id="S8.SS2.SSS0.Px1.p1.5.m3.1b"><ci id="S8.SS2.SSS0.Px1.p1.5.m3.1.1.cmml" xref="S8.SS2.SSS0.Px1.p1.5.m3.1.1">ENV</ci></annotation-xml><annotation encoding="application/x-tex" id="S8.SS2.SSS0.Px1.p1.5.m3.1c">\mathrm{ENV}</annotation><annotation encoding="application/x-llamapun" id="S8.SS2.SSS0.Px1.p1.5.m3.1d">roman_ENV</annotation></semantics></math>是环境。大部分当前的工作都在这个层面上。</p>
</div>
</section>
<section class="ltx_paragraph" id="S8.SS2.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">中级水平</h5>
<div class="ltx_para" id="S8.SS2.SSS0.Px2.p1">
<p class="ltx_p" id="S8.SS2.SSS0.Px2.p1.3">在这个级别中，用户只设置演化对象<math alttext="{\mathcal{E}}" class="ltx_Math" display="inline" id="S8.SS2.SSS0.Px2.p1.1.m1.1"><semantics id="S8.SS2.SSS0.Px2.p1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S8.SS2.SSS0.Px2.p1.1.m1.1.1" xref="S8.SS2.SSS0.Px2.p1.1.m1.1.1.cmml">ℰ</mi><annotation-xml encoding="MathML-Content" id="S8.SS2.SSS0.Px2.p1.1.m1.1b"><ci id="S8.SS2.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S8.SS2.SSS0.Px2.p1.1.m1.1.1">ℰ</ci></annotation-xml><annotation encoding="application/x-tex" id="S8.SS2.SSS0.Px2.p1.1.m1.1c">{\mathcal{E}}</annotation><annotation encoding="application/x-llamapun" id="S8.SS2.SSS0.Px2.p1.1.m1.1d">caligraphic_E</annotation></semantics></math>并保持其不变。用户不需要在框架中设计特定模块<math alttext="f^{\bullet}" class="ltx_Math" display="inline" id="S8.SS2.SSS0.Px2.p1.2.m2.1"><semantics id="S8.SS2.SSS0.Px2.p1.2.m2.1a"><msup id="S8.SS2.SSS0.Px2.p1.2.m2.1.1" xref="S8.SS2.SSS0.Px2.p1.2.m2.1.1.cmml"><mi id="S8.SS2.SSS0.Px2.p1.2.m2.1.1.2" xref="S8.SS2.SSS0.Px2.p1.2.m2.1.1.2.cmml">f</mi><mo id="S8.SS2.SSS0.Px2.p1.2.m2.1.1.3" xref="S8.SS2.SSS0.Px2.p1.2.m2.1.1.3.cmml">∙</mo></msup><annotation-xml encoding="MathML-Content" id="S8.SS2.SSS0.Px2.p1.2.m2.1b"><apply id="S8.SS2.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S8.SS2.SSS0.Px2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S8.SS2.SSS0.Px2.p1.2.m2.1.1.1.cmml" xref="S8.SS2.SSS0.Px2.p1.2.m2.1.1">superscript</csymbol><ci id="S8.SS2.SSS0.Px2.p1.2.m2.1.1.2.cmml" xref="S8.SS2.SSS0.Px2.p1.2.m2.1.1.2">𝑓</ci><ci id="S8.SS2.SSS0.Px2.p1.2.m2.1.1.3.cmml" xref="S8.SS2.SSS0.Px2.p1.2.m2.1.1.3">∙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S8.SS2.SSS0.Px2.p1.2.m2.1c">f^{\bullet}</annotation><annotation encoding="application/x-llamapun" id="S8.SS2.SSS0.Px2.p1.2.m2.1d">italic_f start_POSTSUPERSCRIPT ∙ end_POSTSUPERSCRIPT</annotation></semantics></math>。模型可以独立为自我演变构建每个模块<math alttext="f^{\bullet}" class="ltx_Math" display="inline" id="S8.SS2.SSS0.Px2.p1.3.m3.1"><semantics id="S8.SS2.SSS0.Px2.p1.3.m3.1a"><msup id="S8.SS2.SSS0.Px2.p1.3.m3.1.1" xref="S8.SS2.SSS0.Px2.p1.3.m3.1.1.cmml"><mi id="S8.SS2.SSS0.Px2.p1.3.m3.1.1.2" xref="S8.SS2.SSS0.Px2.p1.3.m3.1.1.2.cmml">f</mi><mo id="S8.SS2.SSS0.Px2.p1.3.m3.1.1.3" xref="S8.SS2.SSS0.Px2.p1.3.m3.1.1.3.cmml">∙</mo></msup><annotation-xml encoding="MathML-Content" id="S8.SS2.SSS0.Px2.p1.3.m3.1b"><apply id="S8.SS2.SSS0.Px2.p1.3.m3.1.1.cmml" xref="S8.SS2.SSS0.Px2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S8.SS2.SSS0.Px2.p1.3.m3.1.1.1.cmml" xref="S8.SS2.SSS0.Px2.p1.3.m3.1.1">superscript</csymbol><ci id="S8.SS2.SSS0.Px2.p1.3.m3.1.1.2.cmml" xref="S8.SS2.SSS0.Px2.p1.3.m3.1.1.2">𝑓</ci><ci id="S8.SS2.SSS0.Px2.p1.3.m3.1.1.3.cmml" xref="S8.SS2.SSS0.Px2.p1.3.m3.1.1.3">∙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S8.SS2.SSS0.Px2.p1.3.m3.1c">f^{\bullet}</annotation><annotation encoding="application/x-llamapun" id="S8.SS2.SSS0.Px2.p1.3.m3.1d">italic_f start_POSTSUPERSCRIPT ∙ end_POSTSUPERSCRIPT</annotation></semantics></math>。这个级别表示如下：</p>
<table class="ltx_equation ltx_eqn_table" id="S8.E9">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathrm{\tilde{M}}=\mathrm{Evol^{M}}(\mathrm{M},{\mathcal{E}},\mathrm{ENV})," class="ltx_Math" display="block" id="S8.E9.m1.4"><semantics id="S8.E9.m1.4a"><mrow id="S8.E9.m1.4.4.1" xref="S8.E9.m1.4.4.1.1.cmml"><mrow id="S8.E9.m1.4.4.1.1" xref="S8.E9.m1.4.4.1.1.cmml"><mover accent="true" id="S8.E9.m1.4.4.1.1.2" xref="S8.E9.m1.4.4.1.1.2.cmml"><mi id="S8.E9.m1.4.4.1.1.2.2" mathvariant="normal" xref="S8.E9.m1.4.4.1.1.2.2.cmml">M</mi><mo id="S8.E9.m1.4.4.1.1.2.1" xref="S8.E9.m1.4.4.1.1.2.1.cmml">~</mo></mover><mo id="S8.E9.m1.4.4.1.1.1" xref="S8.E9.m1.4.4.1.1.1.cmml">=</mo><mrow id="S8.E9.m1.4.4.1.1.3" xref="S8.E9.m1.4.4.1.1.3.cmml"><msup id="S8.E9.m1.4.4.1.1.3.2" xref="S8.E9.m1.4.4.1.1.3.2.cmml"><mi id="S8.E9.m1.4.4.1.1.3.2.2" xref="S8.E9.m1.4.4.1.1.3.2.2.cmml">Evol</mi><mi id="S8.E9.m1.4.4.1.1.3.2.3" mathvariant="normal" xref="S8.E9.m1.4.4.1.1.3.2.3.cmml">M</mi></msup><mo id="S8.E9.m1.4.4.1.1.3.1" xref="S8.E9.m1.4.4.1.1.3.1.cmml">⁢</mo><mrow id="S8.E9.m1.4.4.1.1.3.3.2" xref="S8.E9.m1.4.4.1.1.3.3.1.cmml"><mo id="S8.E9.m1.4.4.1.1.3.3.2.1" stretchy="false" xref="S8.E9.m1.4.4.1.1.3.3.1.cmml">(</mo><mi id="S8.E9.m1.1.1" mathvariant="normal" xref="S8.E9.m1.1.1.cmml">M</mi><mo id="S8.E9.m1.4.4.1.1.3.3.2.2" xref="S8.E9.m1.4.4.1.1.3.3.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S8.E9.m1.2.2" xref="S8.E9.m1.2.2.cmml">ℰ</mi><mo id="S8.E9.m1.4.4.1.1.3.3.2.3" xref="S8.E9.m1.4.4.1.1.3.3.1.cmml">,</mo><mi id="S8.E9.m1.3.3" xref="S8.E9.m1.3.3.cmml">ENV</mi><mo id="S8.E9.m1.4.4.1.1.3.3.2.4" stretchy="false" xref="S8.E9.m1.4.4.1.1.3.3.1.cmml">)</mo></mrow></mrow></mrow><mo id="S8.E9.m1.4.4.1.2" xref="S8.E9.m1.4.4.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S8.E9.m1.4b"><apply id="S8.E9.m1.4.4.1.1.cmml" xref="S8.E9.m1.4.4.1"><eq id="S8.E9.m1.4.4.1.1.1.cmml" xref="S8.E9.m1.4.4.1.1.1"></eq><apply id="S8.E9.m1.4.4.1.1.2.cmml" xref="S8.E9.m1.4.4.1.1.2"><ci id="S8.E9.m1.4.4.1.1.2.1.cmml" xref="S8.E9.m1.4.4.1.1.2.1">~</ci><ci id="S8.E9.m1.4.4.1.1.2.2.cmml" xref="S8.E9.m1.4.4.1.1.2.2">M</ci></apply><apply id="S8.E9.m1.4.4.1.1.3.cmml" xref="S8.E9.m1.4.4.1.1.3"><times id="S8.E9.m1.4.4.1.1.3.1.cmml" xref="S8.E9.m1.4.4.1.1.3.1"></times><apply id="S8.E9.m1.4.4.1.1.3.2.cmml" xref="S8.E9.m1.4.4.1.1.3.2"><csymbol cd="ambiguous" id="S8.E9.m1.4.4.1.1.3.2.1.cmml" xref="S8.E9.m1.4.4.1.1.3.2">superscript</csymbol><ci id="S8.E9.m1.4.4.1.1.3.2.2.cmml" xref="S8.E9.m1.4.4.1.1.3.2.2">Evol</ci><ci id="S8.E9.m1.4.4.1.1.3.2.3.cmml" xref="S8.E9.m1.4.4.1.1.3.2.3">M</ci></apply><vector id="S8.E9.m1.4.4.1.1.3.3.1.cmml" xref="S8.E9.m1.4.4.1.1.3.3.2"><ci id="S8.E9.m1.1.1.cmml" xref="S8.E9.m1.1.1">M</ci><ci id="S8.E9.m1.2.2.cmml" xref="S8.E9.m1.2.2">ℰ</ci><ci id="S8.E9.m1.3.3.cmml" xref="S8.E9.m1.3.3">ENV</ci></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S8.E9.m1.4c">\mathrm{\tilde{M}}=\mathrm{Evol^{M}}(\mathrm{M},{\mathcal{E}},\mathrm{ENV}),</annotation><annotation encoding="application/x-llamapun" id="S8.E9.m1.4d">over~ start_ARG roman_M end_ARG = roman_Evol start_POSTSUPERSCRIPT roman_M end_POSTSUPERSCRIPT ( roman_M , caligraphic_E , roman_ENV ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(9)</span></td>
</tr></tbody>
</table>
</div>
</section>
<section class="ltx_paragraph" id="S8.SS2.SSS0.Px3">
<h5 class="ltx_title ltx_title_paragraph">高水平</h5>
<div class="ltx_para" id="S8.SS2.SSS0.Px3.p1">
<p class="ltx_p" id="S8.SS2.SSS0.Px3.p1.3">在最终级别，模型诊断其缺陷并构建自我进化方法以改进自身。这是自我进化的最终目的。用户模型根据评估<math alttext="f^{E}" class="ltx_Math" display="inline" id="S8.SS2.SSS0.Px3.p1.2.m2.1"><semantics id="S8.SS2.SSS0.Px3.p1.2.m2.1a"><msup id="S8.SS2.SSS0.Px3.p1.2.m2.1.1" xref="S8.SS2.SSS0.Px3.p1.2.m2.1.1.cmml"><mi id="S8.SS2.SSS0.Px3.p1.2.m2.1.1.2" xref="S8.SS2.SSS0.Px3.p1.2.m2.1.1.2.cmml">f</mi><mi id="S8.SS2.SSS0.Px3.p1.2.m2.1.1.3" xref="S8.SS2.SSS0.Px3.p1.2.m2.1.1.3.cmml">E</mi></msup><annotation-xml encoding="MathML-Content" id="S8.SS2.SSS0.Px3.p1.2.m2.1b"><apply id="S8.SS2.SSS0.Px3.p1.2.m2.1.1.cmml" xref="S8.SS2.SSS0.Px3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S8.SS2.SSS0.Px3.p1.2.m2.1.1.1.cmml" xref="S8.SS2.SSS0.Px3.p1.2.m2.1.1">superscript</csymbol><ci id="S8.SS2.SSS0.Px3.p1.2.m2.1.1.2.cmml" xref="S8.SS2.SSS0.Px3.p1.2.m2.1.1.2">𝑓</ci><ci id="S8.SS2.SSS0.Px3.p1.2.m2.1.1.3.cmml" xref="S8.SS2.SSS0.Px3.p1.2.m2.1.1.3">𝐸</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S8.SS2.SSS0.Px3.p1.2.m2.1c">f^{E}</annotation><annotation encoding="application/x-llamapun" id="S8.SS2.SSS0.Px3.p1.2.m2.1d">italic_f start_POSTSUPERSCRIPT italic_E end_POSTSUPERSCRIPT</annotation></semantics></math>输出设置自己的进化对象<math alttext="{\mathcal{E}}" class="ltx_Math" display="inline" id="S8.SS2.SSS0.Px3.p1.1.m1.1"><semantics id="S8.SS2.SSS0.Px3.p1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S8.SS2.SSS0.Px3.p1.1.m1.1.1" xref="S8.SS2.SSS0.Px3.p1.1.m1.1.1.cmml">ℰ</mi><annotation-xml encoding="MathML-Content" id="S8.SS2.SSS0.Px3.p1.1.m1.1b"><ci id="S8.SS2.SSS0.Px3.p1.1.m1.1.1.cmml" xref="S8.SS2.SSS0.Px3.p1.1.m1.1.1">ℰ</ci></annotation-xml><annotation encoding="application/x-tex" id="S8.SS2.SSS0.Px3.p1.1.m1.1c">{\mathcal{E}}</annotation><annotation encoding="application/x-llamapun" id="S8.SS2.SSS0.Px3.p1.1.m1.1d">caligraphic_E</annotation></semantics></math>。进化目标会在迭代过程中发生变化。
此外，模型在框架中设计了具体的模块<math alttext="f^{\bullet}" class="ltx_Math" display="inline" id="S8.SS2.SSS0.Px3.p1.3.m3.1"><semantics id="S8.SS2.SSS0.Px3.p1.3.m3.1a"><msup id="S8.SS2.SSS0.Px3.p1.3.m3.1.1" xref="S8.SS2.SSS0.Px3.p1.3.m3.1.1.cmml"><mi id="S8.SS2.SSS0.Px3.p1.3.m3.1.1.2" xref="S8.SS2.SSS0.Px3.p1.3.m3.1.1.2.cmml">f</mi><mo id="S8.SS2.SSS0.Px3.p1.3.m3.1.1.3" xref="S8.SS2.SSS0.Px3.p1.3.m3.1.1.3.cmml">∙</mo></msup><annotation-xml encoding="MathML-Content" id="S8.SS2.SSS0.Px3.p1.3.m3.1b"><apply id="S8.SS2.SSS0.Px3.p1.3.m3.1.1.cmml" xref="S8.SS2.SSS0.Px3.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S8.SS2.SSS0.Px3.p1.3.m3.1.1.1.cmml" xref="S8.SS2.SSS0.Px3.p1.3.m3.1.1">superscript</csymbol><ci id="S8.SS2.SSS0.Px3.p1.3.m3.1.1.2.cmml" xref="S8.SS2.SSS0.Px3.p1.3.m3.1.1.2">𝑓</ci><ci id="S8.SS2.SSS0.Px3.p1.3.m3.1.1.3.cmml" xref="S8.SS2.SSS0.Px3.p1.3.m3.1.1.3">∙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S8.SS2.SSS0.Px3.p1.3.m3.1c">f^{\bullet}</annotation><annotation encoding="application/x-llamapun" id="S8.SS2.SSS0.Px3.p1.3.m3.1d">italic_f start_POSTSUPERSCRIPT ∙ end_POSTSUPERSCRIPT</annotation></semantics></math>。
我们将这个级别表示为：</p>
<table class="ltx_equation ltx_eqn_table" id="S8.E10">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathrm{\tilde{M}}=\mathrm{Evol^{H}}(\mathrm{M},\mathrm{ENV})," class="ltx_Math" display="block" id="S8.E10.m1.3"><semantics id="S8.E10.m1.3a"><mrow id="S8.E10.m1.3.3.1" xref="S8.E10.m1.3.3.1.1.cmml"><mrow id="S8.E10.m1.3.3.1.1" xref="S8.E10.m1.3.3.1.1.cmml"><mover accent="true" id="S8.E10.m1.3.3.1.1.2" xref="S8.E10.m1.3.3.1.1.2.cmml"><mi id="S8.E10.m1.3.3.1.1.2.2" mathvariant="normal" xref="S8.E10.m1.3.3.1.1.2.2.cmml">M</mi><mo id="S8.E10.m1.3.3.1.1.2.1" xref="S8.E10.m1.3.3.1.1.2.1.cmml">~</mo></mover><mo id="S8.E10.m1.3.3.1.1.1" xref="S8.E10.m1.3.3.1.1.1.cmml">=</mo><mrow id="S8.E10.m1.3.3.1.1.3" xref="S8.E10.m1.3.3.1.1.3.cmml"><msup id="S8.E10.m1.3.3.1.1.3.2" xref="S8.E10.m1.3.3.1.1.3.2.cmml"><mi id="S8.E10.m1.3.3.1.1.3.2.2" xref="S8.E10.m1.3.3.1.1.3.2.2.cmml">Evol</mi><mi id="S8.E10.m1.3.3.1.1.3.2.3" mathvariant="normal" xref="S8.E10.m1.3.3.1.1.3.2.3.cmml">H</mi></msup><mo id="S8.E10.m1.3.3.1.1.3.1" xref="S8.E10.m1.3.3.1.1.3.1.cmml">⁢</mo><mrow id="S8.E10.m1.3.3.1.1.3.3.2" xref="S8.E10.m1.3.3.1.1.3.3.1.cmml"><mo id="S8.E10.m1.3.3.1.1.3.3.2.1" stretchy="false" xref="S8.E10.m1.3.3.1.1.3.3.1.cmml">(</mo><mi id="S8.E10.m1.1.1" mathvariant="normal" xref="S8.E10.m1.1.1.cmml">M</mi><mo id="S8.E10.m1.3.3.1.1.3.3.2.2" xref="S8.E10.m1.3.3.1.1.3.3.1.cmml">,</mo><mi id="S8.E10.m1.2.2" xref="S8.E10.m1.2.2.cmml">ENV</mi><mo id="S8.E10.m1.3.3.1.1.3.3.2.3" stretchy="false" xref="S8.E10.m1.3.3.1.1.3.3.1.cmml">)</mo></mrow></mrow></mrow><mo id="S8.E10.m1.3.3.1.2" xref="S8.E10.m1.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S8.E10.m1.3b"><apply id="S8.E10.m1.3.3.1.1.cmml" xref="S8.E10.m1.3.3.1"><eq id="S8.E10.m1.3.3.1.1.1.cmml" xref="S8.E10.m1.3.3.1.1.1"></eq><apply id="S8.E10.m1.3.3.1.1.2.cmml" xref="S8.E10.m1.3.3.1.1.2"><ci id="S8.E10.m1.3.3.1.1.2.1.cmml" xref="S8.E10.m1.3.3.1.1.2.1">~</ci><ci id="S8.E10.m1.3.3.1.1.2.2.cmml" xref="S8.E10.m1.3.3.1.1.2.2">M</ci></apply><apply id="S8.E10.m1.3.3.1.1.3.cmml" xref="S8.E10.m1.3.3.1.1.3"><times id="S8.E10.m1.3.3.1.1.3.1.cmml" xref="S8.E10.m1.3.3.1.1.3.1"></times><apply id="S8.E10.m1.3.3.1.1.3.2.cmml" xref="S8.E10.m1.3.3.1.1.3.2"><csymbol cd="ambiguous" id="S8.E10.m1.3.3.1.1.3.2.1.cmml" xref="S8.E10.m1.3.3.1.1.3.2">superscript</csymbol><ci id="S8.E10.m1.3.3.1.1.3.2.2.cmml" xref="S8.E10.m1.3.3.1.1.3.2.2">Evol</ci><ci id="S8.E10.m1.3.3.1.1.3.2.3.cmml" xref="S8.E10.m1.3.3.1.1.3.2.3">H</ci></apply><interval closure="open" id="S8.E10.m1.3.3.1.1.3.3.1.cmml" xref="S8.E10.m1.3.3.1.1.3.3.2"><ci id="S8.E10.m1.1.1.cmml" xref="S8.E10.m1.1.1">M</ci><ci id="S8.E10.m1.2.2.cmml" xref="S8.E10.m1.2.2">ENV</ci></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S8.E10.m1.3c">\mathrm{\tilde{M}}=\mathrm{Evol^{H}}(\mathrm{M},\mathrm{ENV}),</annotation><annotation encoding="application/x-llamapun" id="S8.E10.m1.3d">over~ start_ARG roman_M end_ARG = roman_Evol start_POSTSUPERSCRIPT roman_H end_POSTSUPERSCRIPT ( roman_M , roman_ENV ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(10)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S8.SS2.SSS0.Px3.p2">
<p class="ltx_p" id="S8.SS2.SSS0.Px3.p2.1">如前所述在先前的开放问题中（§ <a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#S8.SS1" title="8.1 Objectives: Diversity and Hierarchy ‣ 8 Open Problems ‣ A Survey on Self-Evolution of Large Language Models"><span class="ltx_text ltx_ref_tag">8.1</span></a>），存在大量未实现的目标。然而，大多数现有的自我演化框架都属于低级别，需要专门设计的模块 <cite class="ltx_cite ltx_citemacro_cite">Yuan et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib148" title="">2024</a>); Lu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib77" title="">2024a</a>); Qiao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib90" title="">2024</a>)</cite>。这些框架依赖于特定的目标，并依赖于大量的人力努力来开发。耗尽所有的目标并不高效，这就迫切需要开发中高级别的自我演化框架。在中级别，不需要专家努力来设计特定的模块。LLMs可以根据目标自我演化。然后在高级别，LLMs可以调查他们当前的不足并有针对性地演化。总之，开发高度自主的自我演化框架仍然是一个悬而未决的问题。</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S8.SS3">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">8.3 </span>经验获取与完善：从经验到理论</h3>
<div class="ltx_para" id="S8.SS3.p1">
<p class="ltx_p" id="S8.SS3.p1.1">假设我们已经解决了之前的两个挑战，即我们开发了有前途的自我演化框架，但自我演化LLM的探索缺乏坚实的理论基础。这个想法认为LLM可以自我改进或纠正其输出，无论是否有来自环境的反馈。然而，其背后的机制仍然不清楚。研究显示出了不同的结果：<cite class="ltx_cite ltx_citemacro_citet">Huang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib53" title="">2023</a>)</cite>观察到拥有超过220亿个参数的模型具有自我纠正行为，而<cite class="ltx_cite ltx_citemacro_citet">Ganguli et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib38" title="">2023</a>)</cite>发现LLM在没有外部反馈的情况下难以自我纠正推理错误。</p>
</div>
<div class="ltx_para" id="S8.SS3.p2">
<p class="ltx_p" id="S8.SS3.p2.1">一个相关的挑战是使用自生成的数据进行学习。批评者认为这种方法可能会减少语言多样性<cite class="ltx_cite ltx_citemacro_cite">Guo et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib43" title="">2023</a>)</cite>，并导致“模型崩溃”，即模型无法捕捉复杂的、长尾的数据分布<cite class="ltx_cite ltx_citemacro_cite">Shumailov et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib100" title="">2023</a>)</cite>。此外，<cite class="ltx_cite ltx_citemacro_citet">Alemohammad et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib5" title="">2023</a>)</cite>发现，训练在他们的合成输出上的生成模型逐渐失去输出质量和多样性。<cite class="ltx_cite ltx_citemacro_citet">Fu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib37" title="">2024</a>)</cite>通过理论分析自我消耗的训练循环对模型性能的影响，强调了平衡合成和真实数据以减轻错误积累的重要性。</p>
</div>
<div class="ltx_para" id="S8.SS3.p3">
<p class="ltx_p" id="S8.SS3.p3.1">最近的研究<cite class="ltx_cite ltx_citemacro_cite">Yang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib142" title="">2024c</a>); Singh et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib103" title="">2023</a>)</cite>也表明，目前的方法在进行三轮以上的自我演化后很难有所改善。一个假设的原因是LLM的自我批评没有与不断演化的目标共同演化，但仍然需要更多的实验和理论支持。这些发现凸显了对自我演化LLM进行更多理论探索的迫切需求。解决这些问题对于推动该领域的发展，并确保模型能够在不断改善中有效学习是至关重要的。</p>
</div>
</section>
<section class="ltx_subsection" id="S8.SS4">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">8.4 </span>更新：稳定性-可塑性困境</h3>
<div class="ltx_para" id="S8.SS4.p1">
<p class="ltx_p" id="S8.SS4.p1.1">稳定性-可塑性困境代表了一个关键但尚未解决的挑战，这对于迭代自我演变至关重要。这一困境反映了在适应新数据或任务（可塑性）的同时保留先前学到信息的需求（稳定性）的难度。现有的LLMs要么忽视了这个问题，要么采用了可能无效的传统方法。虽然从头开始训练模型可以缓解灾难性遗忘的问题，但这是非常低效的，特别是当模型参数呈指数增长并且自主学习能力不断提高时。在获得新技能和保留现有知识之间找到平衡对于实现有效和高效的自我演变至关重要，从而实现整体改善。</p>
</div>
</section>
<section class="ltx_subsection" id="S8.SS5">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">8.5 </span>评估：系统性和演变</h3>
<div class="ltx_para" id="S8.SS5.p1">
<p class="ltx_p" id="S8.SS5.p1.1">为了有效评估LLMs，动态、综合的基准至关重要。随着我们向人工通用智能（AGI）的进展，这变得更加关键。传统的静态基准由于LLMs的不断发展性质和通过与环境（如搜索引擎）进行交互而可能获取测试数据的潜力，因而面临过时的风险，从而破坏了它们的可靠性。像Sotopia <cite class="ltx_cite ltx_citemacro_cite">Zhou et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib164" title="">2023a</a>)</cite>这样的动态基准提出了一个解决方案，通过创建一个基于LLM的环境来评估LLMs的社会智能，从而避免了静态基准所提出的限制。</p>
</div>
</section>
<section class="ltx_subsection" id="S8.SS6">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">8.6 </span>安全性和超对齐</h3>
<div class="ltx_para" id="S8.SS6.p1">
<p class="ltx_p" id="S8.SS6.p1.1">LLM的进步为AI系统实现甚至超越专家级能力的支持性和自主决策打开了可能性。为了安全起见，确保这些LLM与人类的价值观和偏好保持一致至关重要，特别是为了减轻可能影响政治辩论等领域的固有偏见，正如<cite class="ltx_cite ltx_citemacro_citet">Taubenfeld et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib112" title="">2024</a>)</cite>所强调的那样。OpenAI的倡议，Superalignment <cite class="ltx_cite ltx_citemacro_cite">Leike and Sutskever (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib61" title="">2023</a>)</cite>，旨在通过开发可扩展的训练方法、验证对齐模型、通过可扩展的监督<cite class="ltx_cite ltx_citemacro_cite">Saunders et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib94" title="">2022</a>)</cite>、鲁棒性<cite class="ltx_cite ltx_citemacro_cite">Perez et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib88" title="">2022</a>)</cite>、自动可解释性<cite class="ltx_cite ltx_citemacro_cite">Bills et al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.14387v1#bib.bib11" title="">2023</a>)</cite>和对抗测试来应力测试对齐过程来对齐超级智能。尽管还存在挑战，但Superalignment标志着开发一种以可扩展方式与人类道德和价值观密切保持一致的自我进化的LLM的初步尝试。</p>
</div>
</section>
</section>
<section class="ltx_section" id="S9">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">9 </span>结论</h2>
<div class="ltx_para" id="S9.p1">
<p class="ltx_p" id="S9.p1.1">LLM向自我进化范式的演变代表了人工智能领域类似于人类学习过程的转变。这有望克服当前模型严重依赖人类标注和教师模型的局限性。
本调查提出了一个全面的框架，用于理解和开发自进化的LLMs，围绕着经验获取、改进、更新和评估的迭代循环进行构建。通过详细描述进展并将进化目标分类在该框架内，我们提供了对当前方法的全面概述，并突出了LLMs自适应、学习和自我改进的潜力。
我们还确定了现有的挑战，并提出了未来研究的方向，旨在加速迈向更加动态、智能和高效的模型的进展。这项工作加深了对自进化的LLMs的理解。它为人工智能领域的重大进展铺平了道路，标志着迈向能够在复杂的现实世界任务中超越人类表现的超智能系统的一步。</p>
</div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">致谢</h2>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">这项工作得到了阿里巴巴集团通过阿里巴巴研究实习计划的支持。</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">参考文献</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Achiam et al. (2023)</span>
<span class="ltx_bibblock">
Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. 2023.

</span>
<span class="ltx_bibblock">Gpt-4 technical report.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">arXiv preprint arXiv:2303.08774</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ahn et al. (2024)</span>
<span class="ltx_bibblock">
Janice Ahn, Rishu Verma, Renze Lou, Di Liu, Rui Zhang, and Wenpeng Yin. 2024.

</span>
<span class="ltx_bibblock">Large language models for mathematical reasoning: Progresses and challenges.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">arXiv preprint arXiv:2402.00157</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Akiba et al. (2024)</span>
<span class="ltx_bibblock">
Takuya Akiba, Makoto Shing, Yujin Tang, Qi Sun, and David Ha. 2024.

</span>
<span class="ltx_bibblock">Evolutionary optimization of model merging recipes.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">arXiv preprint arXiv:2403.13187</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Aksitov et al. (2023)</span>
<span class="ltx_bibblock">
Renat Aksitov, Sobhan Miryoosefi, Zonglin Li, Daliang Li, Sheila Babayan, Kavya Kopparapu, Zachary Fisher, Ruiqi Guo, Sushant Prakash, Pranesh Srinivasan, et al. 2023.

</span>
<span class="ltx_bibblock">Rest meets react: Self-improvement for multi-step reasoning llm agent.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">arXiv preprint arXiv:2312.10003</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Alemohammad et al. (2023)</span>
<span class="ltx_bibblock">
Sina Alemohammad, Josue Casco-Rodriguez, Lorenzo Luzi, Ahmed Imtiaz Humayun, Hossein Babaei, Daniel LeJeune, Ali Siahkoohi, and Richard Baraniuk. 2023.

</span>
<span class="ltx_bibblock">Self-consuming generative models go mad.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">The Twelfth International Conference on Learning Representations</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Askari et al. (2024)</span>
<span class="ltx_bibblock">
Arian Askari, Roxana Petcu, Chuan Meng, Mohammad Aliannejadi, Amin Abolghasemi, Evangelos Kanoulas, and Suzan Verberne. 2024.

</span>
<span class="ltx_bibblock">Self-seeding and multi-intent self-instructing llms for generating intent-aware information-seeking dialogs.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">arXiv preprint arXiv:2402.11633</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bäck and Schwefel (1993)</span>
<span class="ltx_bibblock">
Thomas Bäck and Hans-Paul Schwefel. 1993.

</span>
<span class="ltx_bibblock">An overview of evolutionary algorithms for parameter optimization.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">Evolutionary computation</em>, 1(1):1–23.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bai et al. (2023)</span>
<span class="ltx_bibblock">
Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng, Yang Fan, Wenbin Ge, Yu Han, Fei Huang, et al. 2023.

</span>
<span class="ltx_bibblock">Qwen technical report.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">arXiv preprint arXiv:2309.16609</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bai et al. (2022)</span>
<span class="ltx_bibblock">
Yuntao Bai, Saurav Kadavath, Sandipan Kundu, Amanda Askell, Jackson Kernion, Andy Jones, Anna Chen, Anna Goldie, Azalia Mirhoseini, Cameron McKinnon, et al. 2022.

</span>
<span class="ltx_bibblock">Constitutional ai: Harmlessness from ai feedback.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">arXiv preprint arXiv:2212.08073</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Besta et al. (2024)</span>
<span class="ltx_bibblock">
Maciej Besta, Nils Blach, Ales Kubicek, Robert Gerstenberger, Michal Podstawski, Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, Hubert Niewiadomski, Piotr Nyczyk, et al. 2024.

</span>
<span class="ltx_bibblock">Graph of thoughts: Solving elaborate problems with large language models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">Proceedings of the AAAI Conference on Artificial Intelligence</em>, volume 38, pages 17682–17690.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bills et al. (2023)</span>
<span class="ltx_bibblock">
Steven Bills, Nick Cammarata, Dan Mossing, Henk Tillman, Leo Gao, Gabriel Goh, Ilya Sutskever, Jan Leike, Jeff Wu, and William Saunders. 2023.

</span>
<span class="ltx_bibblock">Language models can explain neurons in language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">URL https://openaipublic. blob. core. windows. net/neuron-explainer/paper/index. html.(Date accessed: 14.05. 2023)</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Boud et al. (2013)</span>
<span class="ltx_bibblock">
David Boud, Rosemary Keogh, and David Walker. 2013.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">Reflection: Turning experience into learning</em>.

</span>
<span class="ltx_bibblock">Routledge.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bousmalis et al. (2023)</span>
<span class="ltx_bibblock">
Konstantinos Bousmalis, Giulia Vezzani, Dushyant Rao, Coline Manon Devin, Alex X Lee, Maria Bauza Villalonga, Todor Davchev, Yuxiang Zhou, Agrim Gupta, Akhil Raju, et al. 2023.

</span>
<span class="ltx_bibblock">Robocat: A self-improving generalist agent for robotic manipulation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">Transactions on Machine Learning Research</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et al. (2020)</span>
<span class="ltx_bibblock">
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020.

</span>
<span class="ltx_bibblock">Language models are few-shot learners.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">Advances in neural information processing systems</em>, 33:1877–1901.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Burns et al. (2023)</span>
<span class="ltx_bibblock">
Collin Burns, Pavel Izmailov, Jan Hendrik Kirchner, Bowen Baker, Leo Gao, Leopold Aschenbrenner, Yining Chen, Adrien Ecoffet, Manas Joglekar, Jan Leike, et al. 2023.

</span>
<span class="ltx_bibblock">Weak-to-strong generalization: Eliciting strong capabilities with weak supervision.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">arXiv preprint arXiv:2312.09390</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chalmers (1997)</span>
<span class="ltx_bibblock">
David J Chalmers. 1997.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">The conscious mind: In search of a fundamental theory</em>.

</span>
<span class="ltx_bibblock">Oxford Paperbacks.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chan et al. (2023)</span>
<span class="ltx_bibblock">
Chi-Min Chan, Weize Chen, Yusheng Su, Jianxuan Yu, Wei Xue, Shanghang Zhang, Jie Fu, and Zhiyuan Liu. 2023.

</span>
<span class="ltx_bibblock">Chateval: Towards better llm-based evaluators through multi-agent debate.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">The Twelfth International Conference on Learning Representations</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2022)</span>
<span class="ltx_bibblock">
Bei Chen, Fengji Zhang, Anh Nguyen, Daoguang Zan, Zeqi Lin, Jian-Guang Lou, and Weizhu Chen. 2022.

</span>
<span class="ltx_bibblock">Codet: Code generation with generated tests.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">arXiv preprint arXiv:2207.10397</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2023a)</span>
<span class="ltx_bibblock">
Lichang Chen, Shiyang Li, Jun Yan, Hai Wang, Kalpa Gunaratna, Vikas Yadav, Zheng Tang, Vijay Srinivasan, Tianyi Zhou, Heng Huang, et al. 2023a.

</span>
<span class="ltx_bibblock">Alpagasus: Training a better alpaca with fewer data.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">arXiv preprint arXiv:2307.08701</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2023b)</span>
<span class="ltx_bibblock">
Pinzhen Chen, Zhicheng Guo, Barry Haddow, and Kenneth Heafield. 2023b.

</span>
<span class="ltx_bibblock">Iterative translation refinement with large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">arXiv preprint arXiv:2306.03856</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen and Li (2024)</span>
<span class="ltx_bibblock">
Weixin Chen and Bo Li. 2024.

</span>
<span class="ltx_bibblock">Grath: Gradual self-truthifying for large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">arXiv preprint arXiv:2401.12292</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2023c)</span>
<span class="ltx_bibblock">
Xinyun Chen, Maxwell Lin, Nathanael Schaerli, and Denny Zhou. 2023c.

</span>
<span class="ltx_bibblock">Teaching large language models to self-debug.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">The 61st Annual Meeting Of The Association For Computational Linguistics</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2023d)</span>
<span class="ltx_bibblock">
Zehui Chen, Weihua Du, Wenwei Zhang, Kuikun Liu, Jiangning Liu, Miao Zheng, Jingming Zhuo, Songyang Zhang, Dahua Lin, Kai Chen, et al. 2023d.

</span>
<span class="ltx_bibblock">T-eval: Evaluating the tool utilization capability step by step.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">arXiv preprint arXiv:2312.14033</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2024)</span>
<span class="ltx_bibblock">
Zixiang Chen, Yihe Deng, Huizhuo Yuan, Kaixuan Ji, and Quanquan Gu. 2024.

</span>
<span class="ltx_bibblock">Self-play fine-tuning converts weak language models to strong language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">arXiv preprint arXiv:2401.01335</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chung et al. (2022)</span>
<span class="ltx_bibblock">
Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Yunxuan Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et al. 2022.

</span>
<span class="ltx_bibblock">Scaling instruction-finetuned language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">arXiv preprint arXiv:2210.11416</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Collins et al. (2023)</span>
<span class="ltx_bibblock">
Katherine M Collins, Albert Q Jiang, Simon Frieder, Lionel Wong, Miri Zilka, Umang Bhatt, Thomas Lukasiewicz, Yuhuai Wu, Joshua B Tenenbaum, William Hart, et al. 2023.

</span>
<span class="ltx_bibblock">Evaluating language models for mathematics through interactions.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">arXiv preprint arXiv:2306.01694</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cui and Wang (2023)</span>
<span class="ltx_bibblock">
Wanyun Cui and Qianle Wang. 2023.

</span>
<span class="ltx_bibblock">Ada-instruct: Adapting instruction generators for complex reasoning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">arXiv preprint arXiv:2310.04484</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dennett (1993)</span>
<span class="ltx_bibblock">
Daniel C Dennett. 1993.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">Consciousness explained</em>.

</span>
<span class="ltx_bibblock">Penguin uk.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dettmers et al. (2024)</span>
<span class="ltx_bibblock">
Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, and Luke Zettlemoyer. 2024.

</span>
<span class="ltx_bibblock">Qlora: Efficient finetuning of quantized llms.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">Advances in Neural Information Processing Systems</em>, 36.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Devlin et al. (2018)</span>
<span class="ltx_bibblock">
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018.

</span>
<span class="ltx_bibblock">Bert: Pre-training of deep bidirectional transformers for language understanding.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">arXiv preprint arXiv:1810.04805</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dewey (1938)</span>
<span class="ltx_bibblock">
John Dewey. 1938.

</span>
<span class="ltx_bibblock">Experience and education: Kappa delta pi.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">International Honor Society in Education</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ding et al. (2024)</span>
<span class="ltx_bibblock">
Ning Ding, Yulin Chen, Ganqu Cui, Xingtai Lv, Ruobing Xie, Bowen Zhou, Zhiyuan Liu, and Maosong Sun. 2024.

</span>
<span class="ltx_bibblock">Mastering text, code and math simultaneously via fusing highly specialized language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">arXiv preprint arXiv:2403.08281</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ding et al. (2023)</span>
<span class="ltx_bibblock">
Ning Ding, Yulin Chen, Bokai Xu, Yujia Qin, Zhi Zheng, Shengding Hu, Zhiyuan Liu, Maosong Sun, and Bowen Zhou. 2023.

</span>
<span class="ltx_bibblock">Enhancing chat language models by scaling high-quality instructional conversations.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">arXiv preprint arXiv:2305.14233</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dubois et al. (2024)</span>
<span class="ltx_bibblock">
Yann Dubois, Chen Xuechen Li, Rohan Taori, Tianyi Zhang, Ishaan Gulrajani, Jimmy Ba, Carlos Guestrin, Percy S Liang, and Tatsunori B Hashimoto. 2024.

</span>
<span class="ltx_bibblock">Alpacafarm: A simulation framework for methods that learn from human feedback.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">Advances in Neural Information Processing Systems</em>, 36.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Eloundou et al. (2023)</span>
<span class="ltx_bibblock">
Tyna Eloundou, Sam Manning, Pamela Mishkin, and Daniel Rock. 2023.

</span>
<span class="ltx_bibblock">Gpts are gpts: An early look at the labor market impact potential of large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">arXiv preprint arXiv:2303.10130</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fernando et al. (2023)</span>
<span class="ltx_bibblock">
Chrisantha Fernando, Dylan Banarse, Henryk Michalewski, Simon Osindero, and Tim Rocktäschel. 2023.

</span>
<span class="ltx_bibblock">Promptbreeder: Self-referential self-improvement via prompt evolution.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">arXiv preprint arXiv:2309.16797</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fu et al. (2024)</span>
<span class="ltx_bibblock">
Shi Fu, Sen Zhang, Yingjie Wang, Xinmei Tian, and Dacheng Tao. 2024.

</span>
<span class="ltx_bibblock">Towards theoretical understandings of self-consuming generative models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">arXiv preprint arXiv:2402.11778</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ganguli et al. (2023)</span>
<span class="ltx_bibblock">
Deep Ganguli, Amanda Askell, Nicholas Schiefer, Thomas I Liao, Kamilė Lukošiūtė, Anna Chen, Anna Goldie, Azalia Mirhoseini, Catherine Olsson, Danny Hernandez, et al. 2023.

</span>
<span class="ltx_bibblock">The capacity for moral self-correction in large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">arXiv preprint arXiv:2302.07459</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ge et al. (2024)</span>
<span class="ltx_bibblock">
Yingqiang Ge, Wenyue Hua, Kai Mei, Juntao Tan, Shuyuan Xu, Zelong Li, Yongfeng Zhang, et al. 2024.

</span>
<span class="ltx_bibblock">Openagi: When llm meets domain experts.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">Advances in Neural Information Processing Systems</em>, 36.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gero et al. (2023)</span>
<span class="ltx_bibblock">
Zelalem Gero, Chandan Singh, Hao Cheng, Tristan Naumann, Michel Galley, Jianfeng Gao, and Hoifung Poon. 2023.

</span>
<span class="ltx_bibblock">Self-verification improves few-shot clinical information extraction.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">arXiv preprint arXiv:2306.00024</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gou et al. (2023)</span>
<span class="ltx_bibblock">
Zhibin Gou, Zhihong Shao, Yeyun Gong, Yelong Shen, Yujiu Yang, Nan Duan, and Weizhu Chen. 2023.

</span>
<span class="ltx_bibblock">Critic: Large language models can self-correct with tool-interactive critiquing.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">arXiv preprint arXiv:2305.11738</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gulcehre et al. (2023)</span>
<span class="ltx_bibblock">
Caglar Gulcehre, Tom Le Paine, Srivatsan Srinivasan, Ksenia Konyushkova, Lotte Weerts, Abhishek Sharma, Aditya Siddhant, Alex Ahern, Miaosen Wang, Chenjie Gu, et al. 2023.

</span>
<span class="ltx_bibblock">Reinforced self-training (rest) for language modeling.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">arXiv preprint arXiv:2308.08998</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guo et al. (2023)</span>
<span class="ltx_bibblock">
Yanzhu Guo, Guokan Shang, Michalis Vazirgiannis, and Chloé Clavel. 2023.

</span>
<span class="ltx_bibblock">The curious decline of linguistic diversity: Training language models on synthetic text.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">arXiv preprint arXiv:2311.09807</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gupta et al. (2006)</span>
<span class="ltx_bibblock">
Anil K Gupta, Ken G Smith, and Christina E Shalley. 2006.

</span>
<span class="ltx_bibblock">The interplay between exploration and exploitation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">Academy of management journal</em>, 49(4):693–706.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hare (2019)</span>
<span class="ltx_bibblock">
Joshua Hare. 2019.

</span>
<span class="ltx_bibblock">Dealing with sparse rewards in reinforcement learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib45.1.1">arXiv preprint arXiv:1910.09281</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hinton et al. (2015)</span>
<span class="ltx_bibblock">
Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. 2015.

</span>
<span class="ltx_bibblock">Distilling the knowledge in a neural network.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib46.1.1">arXiv preprint arXiv:1503.02531</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Holland (1992)</span>
<span class="ltx_bibblock">
John H Holland. 1992.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib47.1.1">Adaptation in natural and artificial systems: an introductory analysis with applications to biology, control, and artificial intelligence</em>.

</span>
<span class="ltx_bibblock">MIT press.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Honovich et al. (2022)</span>
<span class="ltx_bibblock">
Or Honovich, Thomas Scialom, Omer Levy, and Timo Schick. 2022.

</span>
<span class="ltx_bibblock">Unnatural instructions: Tuning language models with (almost) no human labor.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib48.1.1">arXiv preprint arXiv:2212.09689</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hosseini et al. (2024)</span>
<span class="ltx_bibblock">
Arian Hosseini, Xingdi Yuan, Nikolay Malkin, Aaron Courville, Alessandro Sordoni, and Rishabh Agarwal. 2024.

</span>
<span class="ltx_bibblock">V-star: Training verifiers for self-taught reasoners.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib49.1.1">arXiv preprint arXiv:2402.06457</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et al. (2021)</span>
<span class="ltx_bibblock">
Edward J Hu, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, Weizhu Chen, et al. 2021.

</span>
<span class="ltx_bibblock">Lora: Low-rank adaptation of large language models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib50.1.1">International Conference on Learning Representations</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et al. (2024a)</span>
<span class="ltx_bibblock">
Jianheng Huang, Leyang Cui, Ante Wang, Chengyi Yang, Xinting Liao, Linfeng Song, Junfeng Yao, and Jinsong Su. 2024a.

</span>
<span class="ltx_bibblock">Mitigating catastrophic forgetting in large language models with self-synthesized rehearsal.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib51.1.1">arXiv preprint arXiv:2403.01244</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et al. (2022)</span>
<span class="ltx_bibblock">
Jiaxin Huang, Shixiang Shane Gu, Le Hou, Yuexin Wu, Xuezhi Wang, Hongkun Yu, and Jiawei Han. 2022.

</span>
<span class="ltx_bibblock">Large language models can self-improve.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib52.1.1">arXiv preprint arXiv:2210.11610</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et al. (2023)</span>
<span class="ltx_bibblock">
Jie Huang, Xinyun Chen, Swaroop Mishra, Huaixiu Steven Zheng, Adams Wei Yu, Xinying Song, and Denny Zhou. 2023.

</span>
<span class="ltx_bibblock">Large language models cannot self-correct reasoning yet.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib53.1.1">The Twelfth International Conference on Learning Representations</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et al. (2024b)</span>
<span class="ltx_bibblock">
Shijue Huang, Wanjun Zhong, Jianqiao Lu, Qi Zhu, Jiahui Gao, Weiwen Liu, Yutai Hou, Xingshan Zeng, Yasheng Wang, Lifeng Shang, et al. 2024b.

</span>
<span class="ltx_bibblock">Planning, creation, usage: Benchmarking llms for comprehensive tool utilization in real-world complex scenarios.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib54.1.1">arXiv preprint arXiv:2401.17167</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ilharco et al. (2022)</span>
<span class="ltx_bibblock">
Gabriel Ilharco, Marco Tulio Ribeiro, Mitchell Wortsman, Ludwig Schmidt, Hannaneh Hajishirzi, and Ali Farhadi. 2022.

</span>
<span class="ltx_bibblock">Editing models with task arithmetic.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib55.1.1">The Eleventh International Conference on Learning Representations</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et al. (2023)</span>
<span class="ltx_bibblock">
Shuyang Jiang, Yuhao Wang, and Yu Wang. 2023.

</span>
<span class="ltx_bibblock">Selfevolve: A code evolution framework via large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib56.1.1">arXiv preprint arXiv:2306.02907</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim et al. (2023)</span>
<span class="ltx_bibblock">
Geunwoo Kim, Pierre Baldi, and Stephen McAleer. 2023.

</span>
<span class="ltx_bibblock">Language models can solve computer tasks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib57.1.1">arXiv preprint arXiv:2303.17491</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kirkpatrick et al. (2017)</span>
<span class="ltx_bibblock">
James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei A Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka Grabska-Barwinska, et al. 2017.

</span>
<span class="ltx_bibblock">Overcoming catastrophic forgetting in neural networks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib58.1.1">Proceedings of the national academy of sciences</em>, 114(13):3521–3526.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Koa et al. (2024)</span>
<span class="ltx_bibblock">
Kelvin JL Koa, Yunshan Ma, Ritchie Ng, and Tat-Seng Chua. 2024.

</span>
<span class="ltx_bibblock">Learning to generate explainable stock predictions using self-reflective large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib59.1.1">arXiv preprint arXiv:2402.03659</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee et al. (2024)</span>
<span class="ltx_bibblock">
Nicholas Lee, Thanakul Wattanawong, Sehoon Kim, Karttikeya Mangalam, Sheng Shen, Gopala Anumanchipali, Michael W Mahoney, Kurt Keutzer, and Amir Gholami. 2024.

</span>
<span class="ltx_bibblock">Llm2llm: Boosting llms with novel iterative data enhancement.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib60.1.1">arXiv preprint arXiv:2403.15042</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib61">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Leike and Sutskever (2023)</span>
<span class="ltx_bibblock">
Jan Leike and Ilya Sutskever. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://openai.com/blog/introducing-superalignment" title="">Introducing superalignment</a>.

</span>
<span class="ltx_bibblock">Accessed: 2024-04-01.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib62">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2024a)</span>
<span class="ltx_bibblock">
Jia Li, Ge Li, Xuanming Zhang, Yihong Dong, and Zhi Jin. 2024a.

</span>
<span class="ltx_bibblock">Evocodebench: An evolving code generation benchmark aligned with real-world code repositories.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib62.1.1">arXiv preprint arXiv:2404.00599</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib63">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2024b)</span>
<span class="ltx_bibblock">
Ming Li, Lichang Chen, Jiuhai Chen, Shwai He, Jiuxiang Gu, and Tianyi Zhou. 2024b.

</span>
<span class="ltx_bibblock">Selective reflection-tuning: Student-selected data recycling for llm instruction-tuning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib63.1.1">arXiv preprint arXiv:2402.10110</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib64">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2023a)</span>
<span class="ltx_bibblock">
Ming Li, Yong Zhang, Zhitao Li, Jiuhai Chen, Lichang Chen, Ning Cheng, Jianzong Wang, Tianyi Zhou, and Jing Xiao. 2023a.

</span>
<span class="ltx_bibblock">From quantity to quality: Boosting llm performance with self-guided data selection for instruction tuning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib64.1.1">arXiv preprint arXiv:2308.12032</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib65">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2024c)</span>
<span class="ltx_bibblock">
Shimin Li, Tianxiang Sun, and Xipeng Qiu. 2024c.

</span>
<span class="ltx_bibblock">Agent alignment in evolving social norms.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib65.1.1">arXiv preprint arXiv:2401.04620</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib66">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2023b)</span>
<span class="ltx_bibblock">
Xian Li, Ping Yu, Chunting Zhou, Timo Schick, Luke Zettlemoyer, Omer Levy, Jason Weston, and Mike Lewis. 2023b.

</span>
<span class="ltx_bibblock">Self-alignment with instruction backtranslation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib66.1.1">arXiv preprint arXiv:2308.06259</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib67">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li and Qiu (2023)</span>
<span class="ltx_bibblock">
Xiaonan Li and Xipeng Qiu. 2023.

</span>
<span class="ltx_bibblock">Mot: Memory-of-thought enables chatgpt to self-improve.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib67.1.1">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em>, pages 6354–6374.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib68">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin (2004)</span>
<span class="ltx_bibblock">
Chin-Yew Lin. 2004.

</span>
<span class="ltx_bibblock">Rouge: A package for automatic evaluation of summaries.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib68.1.1">Text summarization branches out</em>, pages 74–81.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib69">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et al. (2024)</span>
<span class="ltx_bibblock">
Yong Lin, Hangyu Lin, Wei Xiong, Shizhe Diao, Jianmeng Liu, Jipeng Zhang, Rui Pan, Haoxiang Wang, Wenbin Hu, Hanning Zhang, Hanze Dong, Renjie Pi, Han Zhao, Nan Jiang, Heng Ji, Yuan Yao, and Tong Zhang. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2309.06256" title="">Mitigating the alignment tax of rlhf</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib69.1.1">arXiv</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib70">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2024a)</span>
<span class="ltx_bibblock">
Aiwei Liu, Haoping Bai, Zhiyun Lu, Xiang Kong, Simon Wang, Jiulong Shan, Meng Cao, and Lijie Wen. 2024a.

</span>
<span class="ltx_bibblock">Direct large language model alignment through self-rewarding contrastive prompt distillation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib70.1.1">arXiv preprint arXiv:2402.11907</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib71">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2024b)</span>
<span class="ltx_bibblock">
Jiawei Liu, Chunqiu Steven Xia, Yuyao Wang, and Lingming Zhang. 2024b.

</span>
<span class="ltx_bibblock">Is your code generated by chatgpt really correct? rigorous evaluation of large language models for code generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib71.1.1">Advances in Neural Information Processing Systems</em>, 36.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib72">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2023a)</span>
<span class="ltx_bibblock">
Lei Liu, Xiaoyan Yang, Yue Shen, Binbin Hu, Zhiqiang Zhang, Jinjie Gu, and Guannan Zhang. 2023a.

</span>
<span class="ltx_bibblock">Think-in-memory: Recalling and post-thinking enable llms with long-term memory.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib72.1.1">arXiv preprint arXiv:2311.08719</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib73">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2023b)</span>
<span class="ltx_bibblock">
Xiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu Lai, Yu Gu, Hangliang Ding, Kaiwen Men, Kejuan Yang, et al. 2023b.

</span>
<span class="ltx_bibblock">Agentbench: Evaluating llms as agents.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib73.1.1">arXiv preprint arXiv:2308.03688</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib74">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2021)</span>
<span class="ltx_bibblock">
Yuqiao Liu, Yanan Sun, Bing Xue, Mengjie Zhang, Gary G Yen, and Kay Chen Tan. 2021.

</span>
<span class="ltx_bibblock">A survey on evolutionary neural architecture search.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib74.1.1">IEEE transactions on neural networks and learning systems</em>, 34(2):550–570.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib75">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Longpre et al. (2023)</span>
<span class="ltx_bibblock">
Shayne Longpre, Le Hou, Tu Vu, Albert Webson, Hyung Won Chung, Yi Tay, Denny Zhou, Quoc V Le, Barret Zoph, Jason Wei, et al. 2023.

</span>
<span class="ltx_bibblock">The flan collection: Designing data and methods for effective instruction tuning.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib75.1.1">International Conference on Machine Learning</em>, pages 22631–22648. PMLR.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib76">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lu et al. (2023)</span>
<span class="ltx_bibblock">
Jianqiao Lu, Wanjun Zhong, Wenyong Huang, Yufei Wang, Fei Mi, Baojun Wang, Weichao Wang, Lifeng Shang, and Qun Liu. 2023.

</span>
<span class="ltx_bibblock">Self: Language-driven self-evolution for large language model.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib76.1.1">arXiv preprint arXiv:2310.00533</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib77">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lu et al. (2024a)</span>
<span class="ltx_bibblock">
Keming Lu, Bowen Yu, Chang Zhou, and Jingren Zhou. 2024a.

</span>
<span class="ltx_bibblock">Large language models are superpositions of all characters: Attaining arbitrary role-play via self-alignment.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib77.1.1">arXiv preprint arXiv:2401.12474</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib78">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lu et al. (2024b)</span>
<span class="ltx_bibblock">
Xinyu Lu, Bowen Yu, Yaojie Lu, Hongyu Lin, Haiyang Yu, Le Sun, Xianpei Han, and Yongbin Li. 2024b.

</span>
<span class="ltx_bibblock">Sofa: Shielded on-the-fly alignment via priority rule following.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib78.1.1">arXiv preprint arXiv:2402.17358</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib79">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Luo et al. (2024)</span>
<span class="ltx_bibblock">
Ziyang Luo, Can Xu, Pu Zhao, Qingfeng Sun, Xiubo Geng, Wenxiang Hu, Chongyang Tao, Jing Ma, Qingwei Lin, and Daxin Jiang. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://openreview.net/forum?id=UnUwSIgK5W" title="">Wizardcoder: Empowering code large language models with evol-instruct</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib79.1.1">The Twelfth International Conference on Learning Representations</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib80">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Madaan et al. (2023)</span>
<span class="ltx_bibblock">
Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, Shashank Gupta, Bodhisattwa Prasad Majumder, Katherine Hermann, Sean Welleck, Amir Yazdanbakhsh, and Peter Clark. 2023.

</span>
<span class="ltx_bibblock">Self-refine: Iterative refinement with self-feedback.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib80.1.1">arXiv preprint arXiv:2303.17651</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib81">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Miret and Krishnan (2024)</span>
<span class="ltx_bibblock">
Santiago Miret and NM Krishnan. 2024.

</span>
<span class="ltx_bibblock">Are llms ready for real-world materials discovery?

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib81.1.1">arXiv preprint arXiv:2402.05200</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib82">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Noukhovitch et al. (2024)</span>
<span class="ltx_bibblock">
Michael Noukhovitch, Samuel Lavoie, Florian Strub, and Aaron C Courville. 2024.

</span>
<span class="ltx_bibblock">Language model alignment with elastic reset.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib82.1.1">Advances in Neural Information Processing Systems</em>, 36.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib83">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ouyang et al. (2022)</span>
<span class="ltx_bibblock">
Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. 2022.

</span>
<span class="ltx_bibblock">Training language models to follow instructions with human feedback.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib83.1.1">Advances in neural information processing systems</em>, 35:27730–27744.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib84">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Packer et al. (2023)</span>
<span class="ltx_bibblock">
Charles Packer, Vivian Fang, Shishir G Patil, Kevin Lin, Sarah Wooders, and Joseph E Gonzalez. 2023.

</span>
<span class="ltx_bibblock">Memgpt: Towards llms as operating systems.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib84.1.1">arXiv preprint arXiv:2310.08560</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib85">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pang et al. (2023)</span>
<span class="ltx_bibblock">
Jing-Cheng Pang, Pengyuan Wang, Kaiyuan Li, Xiong-Hui Chen, Jiacheng Xu, Zongzhang Zhang, and Yang Yu. 2023.

</span>
<span class="ltx_bibblock">Language model self-improvement by reinforcement learning contemplation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib85.1.1">arXiv preprint arXiv:2305.14483</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib86">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Papineni et al. (2002)</span>
<span class="ltx_bibblock">
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002.

</span>
<span class="ltx_bibblock">Bleu: a method for automatic evaluation of machine translation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib86.1.1">Proceedings of the 40th annual meeting of the Association for Computational Linguistics</em>, pages 311–318.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib87">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Peng et al. (2023)</span>
<span class="ltx_bibblock">
Keqin Peng, Liang Ding, Qihuang Zhong, Yuanxin Ouyang, Wenge Rong, Zhang Xiong, and Dacheng Tao. 2023.

</span>
<span class="ltx_bibblock">Token-level self-evolution training for sequence-to-sequence learning.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib87.1.1">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</em>, pages 841–850.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib88">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Perez et al. (2022)</span>
<span class="ltx_bibblock">
Ethan Perez, Saffron Huang, Francis Song, Trevor Cai, Roman Ring, John Aslanides, Amelia Glaese, Nat McAleese, and Geoffrey Irving. 2022.

</span>
<span class="ltx_bibblock">Red teaming language models with language models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib88.1.1">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing</em>, pages 3419–3448.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib89">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qian et al. (2024)</span>
<span class="ltx_bibblock">
Cheng Qian, Shihao Liang, Yujia Qin, Yining Ye, Xin Cong, Yankai Lin, Yesai Wu, Zhiyuan Liu, and Maosong Sun. 2024.

</span>
<span class="ltx_bibblock">Investigate-consolidate-exploit: A general strategy for inter-task agent self-evolution.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib89.1.1">arXiv preprint arXiv:2401.13996</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib90">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qiao et al. (2024)</span>
<span class="ltx_bibblock">
Shuofei Qiao, Ningyu Zhang, Runnan Fang, Yujie Luo, Wangchunshu Zhou, Yuchen Eleanor Jiang, Chengfei Lv, and Huajun Chen. 2024.

</span>
<span class="ltx_bibblock">Autoact: Automatic agent learning from scratch via self-planning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib90.1.1">arXiv preprint arXiv:2401.05268</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib91">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Raffel et al. (2020)</span>
<span class="ltx_bibblock">
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. 2020.

</span>
<span class="ltx_bibblock">Exploring the limits of transfer learning with a unified text-to-text transformer.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib91.1.1">Journal of machine learning research</em>, 21(140):1–67.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib92">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ramé et al. (2024)</span>
<span class="ltx_bibblock">
Alexandre Ramé, Nino Vieillard, Léonard Hussenot, Robert Dadashi, Geoffrey Cideron, Olivier Bachem, and Johan Ferret. 2024.

</span>
<span class="ltx_bibblock">Warm: On the benefits of weight averaged reward models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib92.1.1">arXiv preprint arXiv:2401.12187</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib93">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Roziere et al. (2023)</span>
<span class="ltx_bibblock">
Baptiste Roziere, Jonas Gehring, Fabian Gloeckle, Sten Sootla, Itai Gat, Xiaoqing Ellen Tan, Yossi Adi, Jingyu Liu, Tal Remez, Jérémy Rapin, et al. 2023.

</span>
<span class="ltx_bibblock">Code llama: Open foundation models for code.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib93.1.1">arXiv preprint arXiv:2308.12950</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib94">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Saunders et al. (2022)</span>
<span class="ltx_bibblock">
William Saunders, Catherine Yeh, Jeff Wu, Steven Bills, Long Ouyang, Jonathan Ward, and Jan Leike. 2022.

</span>
<span class="ltx_bibblock">Self-critiquing models for assisting human evaluators.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib94.1.1">arXiv preprint arXiv:2206.05802</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib95">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schoenegger et al. (2024)</span>
<span class="ltx_bibblock">
Philipp Schoenegger, Peter S Park, Ezra Karger, and Philip E Tetlock. 2024.

</span>
<span class="ltx_bibblock">Ai-augmented predictions: Llm assistants improve human forecasting accuracy.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib95.1.1">arXiv preprint arXiv:2402.07862</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib96">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schön (2017)</span>
<span class="ltx_bibblock">
Donald A Schön. 2017.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib96.1.1">The reflective practitioner: How professionals think in action</em>.

</span>
<span class="ltx_bibblock">Routledge.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib97">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Searle (1986)</span>
<span class="ltx_bibblock">
John R Searle. 1986.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib97.1.1">Minds, brains and science</em>.

</span>
<span class="ltx_bibblock">Harvard university press.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib98">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shinn et al. (2024)</span>
<span class="ltx_bibblock">
Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik Narasimhan, and Shunyu Yao. 2024.

</span>
<span class="ltx_bibblock">Reflexion: Language agents with verbal reinforcement learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib98.1.1">Advances in Neural Information Processing Systems</em>, 36.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib99">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shinn et al. (2023)</span>
<span class="ltx_bibblock">
Noah Shinn, Beck Labash, and Ashwin Gopinath. 2023.

</span>
<span class="ltx_bibblock">Reflexion: an autonomous agent with dynamic memory and self-reflection.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib99.1.1">arXiv preprint arXiv:2303.11366</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib100">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shumailov et al. (2023)</span>
<span class="ltx_bibblock">
Ilia Shumailov, Zakhar Shumaylov, Yiren Zhao, Yarin Gal, Nicolas Papernot, and Ross Anderson. 2023.

</span>
<span class="ltx_bibblock">The curse of recursion: Training on generated data makes models forget.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib100.1.1">arXiv preprint arXiv:2305.17493</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib101">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Silver et al. (2016)</span>
<span class="ltx_bibblock">
David Silver, Aja Huang, Chris J Maddison, Arthur Guez, Laurent Sifre, George Van Den Driessche, Julian Schrittwieser, Ioannis Antonoglou, Veda Panneershelvam, Marc Lanctot, et al. 2016.

</span>
<span class="ltx_bibblock">Mastering the game of go with deep neural networks and tree search.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib101.1.1">nature</em>, 529(7587):484–489.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib102">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Silver et al. (2017)</span>
<span class="ltx_bibblock">
David Silver, Thomas Hubert, Julian Schrittwieser, Ioannis Antonoglou, Matthew Lai, Arthur Guez, Marc Lanctot, Laurent Sifre, Dharshan Kumaran, Thore Graepel, et al. 2017.

</span>
<span class="ltx_bibblock">Mastering chess and shogi by self-play with a general reinforcement learning algorithm.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib102.1.1">arXiv preprint arXiv:1712.01815</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib103">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Singh et al. (2023)</span>
<span class="ltx_bibblock">
Avi Singh, John D Co-Reyes, Rishabh Agarwal, Ankesh Anand, Piyush Patil, Peter J Liu, James Harrison, Jaehoon Lee, Kelvin Xu, Aaron Parisi, et al. 2023.

</span>
<span class="ltx_bibblock">Beyond human data: Scaling self-training for problem-solving with language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib103.1.1">arXiv preprint arXiv:2312.06585</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib104">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Song et al. (2023)</span>
<span class="ltx_bibblock">
Chenyang Song, Xu Han, Zheni Zeng, Kuai Li, Chen Chen, Zhiyuan Liu, Maosong Sun, and Tao Yang. 2023.

</span>
<span class="ltx_bibblock">Conpet: Continual parameter-efficient tuning for large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib104.1.1">arXiv preprint arXiv:2309.14763</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib105">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Song et al. (2024)</span>
<span class="ltx_bibblock">
Yifan Song, Da Yin, Xiang Yue, Jie Huang, Sujian Li, and Bill Yuchen Lin. 2024.

</span>
<span class="ltx_bibblock">Trial and error: Exploration-based trajectory optimization for llm agents.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib105.1.1">arXiv preprint arXiv:2403.02502</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib106">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Stammer et al. (2023)</span>
<span class="ltx_bibblock">
Wolfgang Stammer, Felix Friedrich, David Steinmann, Hikaru Shindo, and Kristian Kersting. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2309.08395" title="">Learning by self-explaining</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib107">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et al. (2023)</span>
<span class="ltx_bibblock">
Zhiqing Sun, Yikang Shen, Hongxin Zhang, Qinhong Zhou, Zhenfang Chen, David Cox, Yiming Yang, and Chuang Gan. 2023.

</span>
<span class="ltx_bibblock">Salmon: Self-alignment with principle-following reward models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib107.1.1">arXiv preprint arXiv:2310.05910</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib108">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et al. (2024)</span>
<span class="ltx_bibblock">
Zhiqing Sun, Yikang Shen, Qinhong Zhou, Hongxin Zhang, Zhenfang Chen, David Cox, Yiming Yang, and Chuang Gan. 2024.

</span>
<span class="ltx_bibblock">Principle-driven self-alignment of language models from scratch with minimal human supervision.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib108.1.1">Advances in Neural Information Processing Systems</em>, 36.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib109">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tan et al. (2023)</span>
<span class="ltx_bibblock">
Yiming Tan, Dehai Min, Yu Li, Wenbo Li, Nan Hu, Yongrui Chen, and Guilin Qi. 2023.

</span>
<span class="ltx_bibblock">Evaluation of chatgpt as a question answering system for answering complex questions.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib109.1.1">arXiv preprint arXiv:2303.07992</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib110">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tao et al. (2024a)</span>
<span class="ltx_bibblock">
Zhengwei Tao, Xiancai Chen, Zhi Jin, Xiaoying Bai, Haiyan Zhao, and Yiwei Lou. 2024a.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2404.11978" title="">Evit: Event-oriented instruction tuning for event reasoning</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib111">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tao et al. (2024b)</span>
<span class="ltx_bibblock">
Zhengwei Tao, Zhi Jin, Junqiang Huang, Xiancai Chen, Xiaoying Bai, Haiyan Zhao, Yifan Zhang, and Chongyang Tao. 2024b.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2404.10429" title="">Meel: Multi-modal event evolution learning</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib112">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Taubenfeld et al. (2024)</span>
<span class="ltx_bibblock">
Amir Taubenfeld, Yaniv Dover, Roi Reichart, and Ariel Goldstein. 2024.

</span>
<span class="ltx_bibblock">Systematic biases in llm simulations of debates.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib112.1.1">arXiv preprint arXiv:2402.04049</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib113">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Team et al. (2023)</span>
<span class="ltx_bibblock">
Gemini Team, Rohan Anil, Sebastian Borgeaud, Yonghui Wu, Jean-Baptiste Alayrac, Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew M Dai, Anja Hauth, et al. 2023.

</span>
<span class="ltx_bibblock">Gemini: a family of highly capable multimodal models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib113.1.1">arXiv preprint arXiv:2312.11805</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib114">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tong et al. (2024)</span>
<span class="ltx_bibblock">
Yongqi Tong, Dawei Li, Sizhe Wang, Yujia Wang, Fei Teng, and Jingbo Shang. 2024.

</span>
<span class="ltx_bibblock">Can llms learn from previous mistakes? investigating llms’ errors to boost for reasoning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib114.1.1">arXiv preprint arXiv:2403.20046</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib115">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et al. (2023a)</span>
<span class="ltx_bibblock">
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. 2023a.

</span>
<span class="ltx_bibblock">Llama 2: Open foundation and fine-tuned chat models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib115.1.1">arXiv preprint arXiv:2307.09288</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib116">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et al. (2023b)</span>
<span class="ltx_bibblock">
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. 2023b.

</span>
<span class="ltx_bibblock">Llama 2: Open foundation and fine-tuned chat models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib116.1.1">arXiv preprint arXiv:2307.09288</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib117">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tu et al. (2024)</span>
<span class="ltx_bibblock">
Tao Tu, Anil Palepu, Mike Schaekermann, Khaled Saab, Jan Freyberg, Ryutaro Tanno, Amy Wang, Brenna Li, Mohamed Amin, Nenad Tomasev, et al. 2024.

</span>
<span class="ltx_bibblock">Towards conversational diagnostic ai.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib117.1.1">arXiv preprint arXiv:2401.05654</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib118">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ulmer et al. (2024)</span>
<span class="ltx_bibblock">
Dennis Ulmer, Elman Mansimov, Kaixiang Lin, Justin Sun, Xibin Gao, and Yi Zhang. 2024.

</span>
<span class="ltx_bibblock">Bootstrapping llm-based task-oriented dialogue agents via self-talk.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib118.1.1">arXiv preprint arXiv:2401.05033</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib119">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wan et al. (2024)</span>
<span class="ltx_bibblock">
Fanqi Wan, Xinting Huang, Deng Cai, Xiaojun Quan, Wei Bi, and Shuming Shi. 2024.

</span>
<span class="ltx_bibblock">Knowledge fusion of large language models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib119.1.1">The Twelfth International Conference on Learning Representations</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib120">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2024a)</span>
<span class="ltx_bibblock">
Bo Wang, Tianxiang Sun, Hang Yan, Siyin Wang, Qingyuan Cheng, and Xipeng Qiu. 2024a.

</span>
<span class="ltx_bibblock">In-memory learning: A declarative learning framework for large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib120.1.1">arXiv preprint arXiv:2403.02757</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib121">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2024b)</span>
<span class="ltx_bibblock">
Boshi Wang, Hao Fang, Jason Eisner, Benjamin Van Durme, and Yu Su. 2024b.

</span>
<span class="ltx_bibblock">Llms in the imaginarium: Tool learning through simulated trial and error.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib121.1.1">arXiv preprint arXiv:2403.04746</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib122">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2024c)</span>
<span class="ltx_bibblock">
Haoyu Wang, Guozheng Ma, Ziqiao Meng, Zeyu Qin, Li Shen, Zhong Zhang, Bingzhe Wu, Liu Liu, Yatao Bian, Tingyang Xu, et al. 2024c.

</span>
<span class="ltx_bibblock">Step-on-feet tuning: Scaling self-alignment of llms via bootstrapping.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib122.1.1">arXiv preprint arXiv:2402.07610</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib123">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2024d)</span>
<span class="ltx_bibblock">
Jiuniu Wang, Zehua Du, Yuyuan Zhao, Bo Yuan, Kexiang Wang, Jian Liang, Yaxi Zhao, Yihen Lu, Gengliang Li, Junlong Gao, et al. 2024d.

</span>
<span class="ltx_bibblock">Aesopagent: Agent-driven evolutionary system on story-to-video production.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib123.1.1">arXiv preprint arXiv:2403.07952</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib124">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2023a)</span>
<span class="ltx_bibblock">
Kuan Wang, Yadong Lu, Michael Santacroce, Yeyun Gong, Chao Zhang, and Yelong Shen. 2023a.

</span>
<span class="ltx_bibblock">Adapting llm agents through communication.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib124.1.1">arXiv preprint arXiv:2310.01444</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib125">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2024e)</span>
<span class="ltx_bibblock">
Ruiyi Wang, Haofei Yu, Wenxin Zhang, Zhengyang Qi, Maarten Sap, Graham Neubig, Yonatan Bisk, and Hao Zhu. 2024e.

</span>
<span class="ltx_bibblock">Sotopia-<math alttext="\pi" class="ltx_Math" display="inline" id="bib.bib125.1.m1.1"><semantics id="bib.bib125.1.m1.1a"><mi id="bib.bib125.1.m1.1.1" xref="bib.bib125.1.m1.1.1.cmml">π</mi><annotation-xml encoding="MathML-Content" id="bib.bib125.1.m1.1b"><ci id="bib.bib125.1.m1.1.1.cmml" xref="bib.bib125.1.m1.1.1">𝜋</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib125.1.m1.1c">\pi</annotation><annotation encoding="application/x-llamapun" id="bib.bib125.1.m1.1d">italic_π</annotation></semantics></math>: Interactive learning of socially intelligent language agents.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib125.2.1">arXiv preprint arXiv:2403.08715</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib126">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2022)</span>
<span class="ltx_bibblock">
Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou. 2022.

</span>
<span class="ltx_bibblock">Self-consistency improves chain of thought reasoning in language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib126.1.1">arXiv preprint arXiv:2203.11171</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib127">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2023b)</span>
<span class="ltx_bibblock">
Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A Smith, Daniel Khashabi, and Hannaneh Hajishirzi. 2023b.

</span>
<span class="ltx_bibblock">Self-instruct: Aligning language models with self-generated instructions.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib127.1.1">The 61st Annual Meeting Of The Association For Computational Linguistics</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib128">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et al. (2022)</span>
<span class="ltx_bibblock">
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. 2022.

</span>
<span class="ltx_bibblock">Chain-of-thought prompting elicits reasoning in large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib128.1.1">Advances in neural information processing systems</em>, 35:24824–24837.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib129">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Weng et al. (2023)</span>
<span class="ltx_bibblock">
Yixuan Weng, Minjun Zhu, Fei Xia, Bin Li, Shizhu He, Shengping Liu, Bin Sun, Kang Liu, and Jun Zhao. 2023.

</span>
<span class="ltx_bibblock">Large language models are better reasoners with self-verification.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib129.1.1">Findings of the Association for Computational Linguistics: EMNLP 2023</em>, pages 2550–2575.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib130">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wortsman et al. (2022)</span>
<span class="ltx_bibblock">
Mitchell Wortsman, Gabriel Ilharco, Samir Ya Gadre, Rebecca Roelofs, Raphael Gontijo-Lopes, Ari S Morcos, Hongseok Namkoong, Ali Farhadi, Yair Carmon, Simon Kornblith, et al. 2022.

</span>
<span class="ltx_bibblock">Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib130.1.1">International conference on machine learning</em>, pages 23965–23998. PMLR.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib131">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al. (2023)</span>
<span class="ltx_bibblock">
Shengguang Wu, Keming Lu, Benfeng Xu, Junyang Lin, Qi Su, and Chang Zhou. 2023.

</span>
<span class="ltx_bibblock">Self-evolved diverse data sampling for efficient instruction tuning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib131.1.1">arXiv preprint arXiv:2311.08182</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib132">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al. (2024)</span>
<span class="ltx_bibblock">
Tongtong Wu, Linhao Luo, Yuan-Fang Li, Shirui Pan, Thuy-Trang Vu, and Gholamreza Haffari. 2024.

</span>
<span class="ltx_bibblock">Continual learning for large language models: A survey.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib132.1.1">arXiv preprint arXiv:2402.01364</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib133">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al. (2023a)</span>
<span class="ltx_bibblock">
Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu Zhao, Jiazhan Feng, Chongyang Tao, and Daxin Jiang. 2023a.

</span>
<span class="ltx_bibblock">Wizardlm: Empowering large language models to follow complex instructions.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib133.1.1">arXiv preprint arXiv:2304.12244</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib134">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al. (2024a)</span>
<span class="ltx_bibblock">
Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu Zhao, Jiazhan Feng, Chongyang Tao, Qingwei Lin, and Daxin Jiang. 2024a.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://openreview.net/forum?id=CfXh93NDgH" title="">WizardLM: Empowering large pre-trained language models to follow complex instructions</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib134.1.1">The Twelfth International Conference on Learning Representations</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib135">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al. (2024b)</span>
<span class="ltx_bibblock">
Jie Xu, Hanbo Zhang, Xinghang Li, Huaping Liu, Xuguang Lan, and Tao Kong. 2024b.

</span>
<span class="ltx_bibblock">Sinvig: A self-evolving interactive visual agent for human-robot interaction.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib135.1.1">arXiv preprint arXiv:2402.11792</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib136">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al. (2023b)</span>
<span class="ltx_bibblock">
Yuzhuang Xu, Shuo Wang, Peng Li, Fuwen Luo, Xiaolong Wang, Weidong Liu, and Yang Liu. 2023b.

</span>
<span class="ltx_bibblock">Exploring large language models for communication games: An empirical study on werewolf.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib136.1.1">arXiv preprint arXiv:2309.04658</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib137">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yadav et al. (2024)</span>
<span class="ltx_bibblock">
Prateek Yadav, Derek Tam, Leshem Choshen, Colin A Raffel, and Mohit Bansal. 2024.

</span>
<span class="ltx_bibblock">Ties-merging: Resolving interference when merging models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib137.1.1">Advances in Neural Information Processing Systems</em>, 36.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib138">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al. (2023a)</span>
<span class="ltx_bibblock">
Kevin Yang, Dan Klein, Asli Celikyilmaz, Nanyun Peng, and Yuandong Tian. 2023a.

</span>
<span class="ltx_bibblock">Rlcd: Reinforcement learning from contrastive distillation for lm alignment.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib138.1.1">The Twelfth International Conference on Learning Representations</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib139">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al. (2024a)</span>
<span class="ltx_bibblock">
Rui Yang, Lin Song, Yanwei Li, Sijie Zhao, Yixiao Ge, Xiu Li, and Ying Shan. 2024a.

</span>
<span class="ltx_bibblock">Gpt4tools: Teaching large language model to use tools via self-instruction.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib139.1.1">Advances in Neural Information Processing Systems</em>, 36.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib140">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al. (2023b)</span>
<span class="ltx_bibblock">
Zeyuan Yang, Peng Li, and Yang Liu. 2023b.

</span>
<span class="ltx_bibblock">Failures pave the way: Enhancing large language models through tuning-free rule accumulation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib140.1.1">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em>, pages 1751–1777.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib141">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al. (2024b)</span>
<span class="ltx_bibblock">
Zhaorui Yang, Qian Liu, Tianyu Pang, Han Wang, Haozhe Feng, Minfeng Zhu, and Wei Chen. 2024b.

</span>
<span class="ltx_bibblock">Self-distillation bridges distribution gap in language model fine-tuning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib141.1.1">arXiv preprint arXiv:2402.13669</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib142">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al. (2024c)</span>
<span class="ltx_bibblock">
Zonghan Yang, Peng Li, Ming Yan, Ji Zhang, Fei Huang, and Yang Liu. 2024c.

</span>
<span class="ltx_bibblock">React meets actre: Autonomous annotations of agent trajectories for contrastive self-training.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib142.1.1">arXiv preprint arXiv:2403.14589</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib143">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al. (2024d)</span>
<span class="ltx_bibblock">
Zonghan Yang, An Liu, Zijun Liu, Kaiming Liu, Fangzhou Xiong, Yile Wang, Zeyuan Yang, Qingyuan Hu, Xinrui Chen, Zhenhe Zhang, et al. 2024d.

</span>
<span class="ltx_bibblock">Towards unified alignment between agents, humans, and environment.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib143.1.1">arXiv preprint arXiv:2402.07744</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib144">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yao et al. (2024)</span>
<span class="ltx_bibblock">
Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Tom Griffiths, Yuan Cao, and Karthik Narasimhan. 2024.

</span>
<span class="ltx_bibblock">Tree of thoughts: Deliberate problem solving with large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib144.1.1">Advances in Neural Information Processing Systems</em>, 36.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib145">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yao et al. (2022)</span>
<span class="ltx_bibblock">
Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. 2022.

</span>
<span class="ltx_bibblock">React: Synergizing reasoning and acting in language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib145.1.1">arXiv preprint arXiv:2210.03629</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib146">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al. (2023a)</span>
<span class="ltx_bibblock">
Le Yu, Bowen Yu, Haiyang Yu, Fei Huang, and Yongbin Li. 2023a.

</span>
<span class="ltx_bibblock">Language models are super mario: Absorbing abilities from homologous models as a free lunch.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib146.1.1">arXiv preprint arXiv:2311.03099</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib147">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al. (2023b)</span>
<span class="ltx_bibblock">
Longhui Yu, Weisen Jiang, Han Shi, Jincheng Yu, Zhengying Liu, Yu Zhang, James T Kwok, Zhenguo Li, Adrian Weller, and Weiyang Liu. 2023b.

</span>
<span class="ltx_bibblock">Metamath: Bootstrap your own mathematical questions for large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib147.1.1">arXiv preprint arXiv:2309.12284</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib148">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yuan et al. (2024)</span>
<span class="ltx_bibblock">
Weizhe Yuan, Richard Yuanzhe Pang, Kyunghyun Cho, Sainbayar Sukhbaatar, Jing Xu, and Jason Weston. 2024.

</span>
<span class="ltx_bibblock">Self-rewarding language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib148.1.1">arXiv preprint arXiv:2401.10020</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib149">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yuan et al. (2023)</span>
<span class="ltx_bibblock">
Zheng Yuan, Hongyi Yuan, Chengpeng Li, Guanting Dong, Chuanqi Tan, and Chang Zhou. 2023.

</span>
<span class="ltx_bibblock">Scaling relationship on learning mathematical reasoning with large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib149.1.1">arXiv preprint arXiv:2308.01825</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib150">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zelikman et al. (2023)</span>
<span class="ltx_bibblock">
Eric Zelikman, Eliana Lorch, Lester Mackey, and Adam Tauman Kalai. 2023.

</span>
<span class="ltx_bibblock">Self-taught optimizer (stop): Recursively self-improving code generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib150.1.1">arXiv preprint arXiv:2310.02304</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib151">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zelikman et al. (2022)</span>
<span class="ltx_bibblock">
Eric Zelikman, Jesse Mu, Noah D Goodman, and Yuhuai Tony Wu. 2022.

</span>
<span class="ltx_bibblock">Star: Self-taught reasoner bootstrapping reasoning with reasoning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib151.1.1">Advances in Neural Information Processing Systems (NeurIPS)</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib152">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2024a)</span>
<span class="ltx_bibblock">
Ceyao Zhang, Kaijie Yang, Siyi Hu, Zihao Wang, Guanghe Li, Yihang Sun, Cheng Zhang, Zhaowei Zhang, Anji Liu, Song-Chun Zhu, et al. 2024a.

</span>
<span class="ltx_bibblock">Proagent: building proactive cooperative agents with large language models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib152.1.1">Proceedings of the AAAI Conference on Artificial Intelligence</em>, volume 38, pages 17591–17599.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib153">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2024b)</span>
<span class="ltx_bibblock">
Dan Zhang, Ziniu Hu, Sining Zhoubian, Zhengxiao Du, Kaiyu Yang, Zihan Wang, Yisong Yue, Yuxiao Dong, and Jie Tang. 2024b.

</span>
<span class="ltx_bibblock">Sciglm: Training scientific language models with self-reflective instruction annotation and tuning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib153.1.1">arXiv preprint arXiv:2401.07950</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib154">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2024c)</span>
<span class="ltx_bibblock">
Wenqi Zhang, Yongliang Shen, Linjuan Wu, Qiuying Peng, Jun Wang, Yueting Zhuang, and Weiming Lu. 2024c.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2401.02009" title="">Self-contrast: Better reflection through inconsistent solving perspectives</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib155">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2024d)</span>
<span class="ltx_bibblock">
Wenqi Zhang, Ke Tang, Hai Wu, Mengna Wang, Yongliang Shen, Guiyang Hou, Zeqi Tan, Peng Li, Yueting Zhuang, and Weiming Lu. 2024d.

</span>
<span class="ltx_bibblock">Agent-pro: Learning to evolve via policy-level reflection and optimization.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib155.1.1">arXiv preprint arXiv:2402.17574</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib156">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2024e)</span>
<span class="ltx_bibblock">
Xiaoying Zhang, Baolin Peng, Ye Tian, Jingyan Zhou, Lifeng Jin, Linfeng Song, Haitao Mi, and Helen Meng. 2024e.

</span>
<span class="ltx_bibblock">Self-alignment for factuality: Mitigating hallucinations in llms via self-evaluation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib156.1.1">arXiv preprint arXiv:2402.09267</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib157">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zheng et al. (2023)</span>
<span class="ltx_bibblock">
Haoqi Zheng, Qihuang Zhong, Liang Ding, Zhiliang Tian, Xin Niu, Changjian Wang, Dongsheng Li, and Dacheng Tao. 2023.

</span>
<span class="ltx_bibblock">Self-evolution learning for mixup: Enhance data augmentation on few-shot text classification tasks.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib157.1.1">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em>, pages 8964–8974.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib158">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zheng et al. (2024a)</span>
<span class="ltx_bibblock">
Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, et al. 2024a.

</span>
<span class="ltx_bibblock">Judging llm-as-a-judge with mt-bench and chatbot arena.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib158.1.1">Advances in Neural Information Processing Systems</em>, 36.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib159">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zheng et al. (2024b)</span>
<span class="ltx_bibblock">
Tianyu Zheng, Shuyue Guo, Xingwei Qu, Jiawei Guo, Weixu Zhang, Xinrun Du, Chenghua Lin, Wenhao Huang, Wenhu Chen, Jie Fu, et al. 2024b.

</span>
<span class="ltx_bibblock">Kun: Answer polishment for chinese self-alignment with instruction back-translation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib159.1.1">arXiv preprint arXiv:2401.06477</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib160">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhong et al. (2024a)</span>
<span class="ltx_bibblock">
Li Zhong, Zilong Wang, and Jingbo Shang. 2024a.

</span>
<span class="ltx_bibblock">Ldb: A large language model debugger via verifying runtime execution step-by-step.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib160.1.1">arXiv preprint arXiv:2402.16906</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib161">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhong et al. (2023)</span>
<span class="ltx_bibblock">
Qihuang Zhong, Liang Ding, Juhua Liu, Bo Du, and Dacheng Tao. 2023.

</span>
<span class="ltx_bibblock">Self-evolution learning for discriminative language model pretraining.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib161.1.1">Findings of the Association for Computational Linguistics: ACL 2023</em>, pages 4130–4145.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib162">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhong et al. (2024b)</span>
<span class="ltx_bibblock">
Wanjun Zhong, Lianghong Guo, Qiqi Gao, He Ye, and Yanlin Wang. 2024b.

</span>
<span class="ltx_bibblock">Memorybank: Enhancing large language models with long-term memory.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib162.1.1">Proceedings of the AAAI Conference on Artificial Intelligence</em>, volume 38, pages 19724–19731.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib163">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al. (2024)</span>
<span class="ltx_bibblock">
Chunting Zhou, Pengfei Liu, Puxin Xu, Srinivasan Iyer, Jiao Sun, Yuning Mao, Xuezhe Ma, Avia Efrat, Ping Yu, Lili Yu, et al. 2024.

</span>
<span class="ltx_bibblock">Lima: Less is more for alignment.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib163.1.1">Advances in Neural Information Processing Systems</em>, 36.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib164">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al. (2023a)</span>
<span class="ltx_bibblock">
Xuhui Zhou, Hao Zhu, Leena Mathur, Ruohong Zhang, Haofei Yu, Zhengyang Qi, Louis-Philippe Morency, Yonatan Bisk, Daniel Fried, Graham Neubig, et al. 2023a.

</span>
<span class="ltx_bibblock">Sotopia: Interactive evaluation for social intelligence in language agents.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib164.1.1">The Twelfth International Conference on Learning Representations</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib165">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al. (2023b)</span>
<span class="ltx_bibblock">
Zhehua Zhou, Jiayang Song, Kunpeng Yao, Zhan Shu, and Lei Ma. 2023b.

</span>
<span class="ltx_bibblock">Isr-llm: Iterative self-refined large language model for long-horizon sequential task planning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib165.1.1">arXiv preprint arXiv:2308.13724</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib166">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et al. (2024)</span>
<span class="ltx_bibblock">
Yuqi Zhu, Shuofei Qiao, Yixin Ou, Shumin Deng, Ningyu Zhang, Shiwei Lyu, Yue Shen, Lei Liang, Jinjie Gu, and Huajun Chen. 2024.

</span>
<span class="ltx_bibblock">Knowagent: Knowledge-augmented planning for llm-based agents.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib166.1.1">arXiv preprint arXiv:2403.03101</em>.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
</div>
</body>
</html>
