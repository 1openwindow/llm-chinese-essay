<!DOCTYPE html>

<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>“In-Context Learning” or: How I learned to stop worrying and love “Applied Information Retrieval”</title>
<!--Generated on Thu May  2 09:21:50 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="resource/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="resource/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="resource/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="resource/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="resource/bootstrap.bundle.min.js"></script>
<script src="resource/html2canvas.min.js"></script>
<script src="resource/addons_new.js"></script>
<script src="resource/feedbackOverlay.js"></script>
<meta content="Large Language Models,  In-Context Learning,  Ranking Models,  Query Performance Prediction" lang="en" name="keywords"/>
</head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="#S1" title="In “In-Context Learning” or: How I learned to stop worrying and love “Applied Information Retrieval”"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="#S2" title="In “In-Context Learning” or: How I learned to stop worrying and love “Applied Information Retrieval”"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>In-Context Learning</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="#S2.SS1" title="In 2. In-Context Learning ‣ “In-Context Learning” or: How I learned to stop worrying and love “Applied Information Retrieval”"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>A Formal Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="#S2.SS2" title="In 2. In-Context Learning ‣ “In-Context Learning” or: How I learned to stop worrying and love “Applied Information Retrieval”"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>The role of IR</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="#S3" title="In “In-Context Learning” or: How I learned to stop worrying and love “Applied Information Retrieval”"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Adaptive ICL <math alttext="\mapsto" class="ltx_Math" display="inline"><semantics><mo stretchy="false">↦</mo><annotation-xml encoding="MathML-Content"><csymbol cd="latexml">maps-to</csymbol></annotation-xml><annotation encoding="application/x-tex">\mapsto</annotation><annotation encoding="application/x-llamapun">↦</annotation></semantics></math> QPP?</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="#S3.SS1" title="In 3. Adaptive ICL ↦ QPP? ‣ “In-Context Learning” or: How I learned to stop worrying and love “Applied Information Retrieval”"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>A Variable Number of Examples</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="#S3.SS2" title="In 3. Adaptive ICL ↦ QPP? ‣ “In-Context Learning” or: How I learned to stop worrying and love “Applied Information Retrieval”"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Unsupervised Rank Cutoff</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="#S3.SS2.SSS0.Px1" title="In 3.2. Unsupervised Rank Cutoff ‣ 3. Adaptive ICL ↦ QPP? ‣ “In-Context Learning” or: How I learned to stop worrying and love “Applied Information Retrieval”"><span class="ltx_text ltx_ref_title">Score Distribution-based Models</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="#S3.SS2.SSS0.Px2" title="In 3.2. Unsupervised Rank Cutoff ‣ 3. Adaptive ICL ↦ QPP? ‣ “In-Context Learning” or: How I learned to stop worrying and love “Applied Information Retrieval”"><span class="ltx_text ltx_ref_title">QPP-based Models</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="#S3.SS3" title="In 3. Adaptive ICL ↦ QPP? ‣ “In-Context Learning” or: How I learned to stop worrying and love “Applied Information Retrieval”"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Supervised Rank Cutoff</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="#S3.SS4" title="In 3. Adaptive ICL ↦ QPP? ‣ “In-Context Learning” or: How I learned to stop worrying and love “Applied Information Retrieval”"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4 </span>Open Research Questions and Challenges</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="#S4" title="In “In-Context Learning” or: How I learned to stop worrying and love “Applied Information Retrieval”"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Rank ICL Examples <math alttext="\mapsto" class="ltx_Math" display="inline"><semantics><mo stretchy="false">↦</mo><annotation-xml encoding="MathML-Content"><csymbol cd="latexml">maps-to</csymbol></annotation-xml><annotation encoding="application/x-tex">\mapsto</annotation><annotation encoding="application/x-llamapun">↦</annotation></semantics></math> Supervised IR?</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="#S4.SS0.SSS0.Px1" title="In 4. Rank ICL Examples ↦ Supervised IR? ‣ “In-Context Learning” or: How I learned to stop worrying and love “Applied Information Retrieval”"><span class="ltx_text ltx_ref_title">Bi-Encoder architecture</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="#S4.SS0.SSS0.Px2" title="In 4. Rank ICL Examples ↦ Supervised IR? ‣ “In-Context Learning” or: How I learned to stop worrying and love “Applied Information Retrieval”"><span class="ltx_text ltx_ref_title">Cross-Encoder architecture</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="#S4.SS0.SSS0.Px3" title="In 4. Rank ICL Examples ↦ Supervised IR? ‣ “In-Context Learning” or: How I learned to stop worrying and love “Applied Information Retrieval”"><span class="ltx_text ltx_ref_title">Teacher Distillation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="#S4.SS1" title="In 4. Rank ICL Examples ↦ Supervised IR? ‣ “In-Context Learning” or: How I learned to stop worrying and love “Applied Information Retrieval”"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Combined Utility of ICL Examples</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="#S4.SS1.SSS0.Px1" title="In 4.1. Combined Utility of ICL Examples ‣ 4. Rank ICL Examples ↦ Supervised IR? ‣ “In-Context Learning” or: How I learned to stop worrying and love “Applied Information Retrieval”"><span class="ltx_text ltx_ref_title">Open research questions</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="#S5" title="In “In-Context Learning” or: How I learned to stop worrying and love “Applied Information Retrieval”"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Informative Examples <math alttext="\mapsto" class="ltx_Math" display="inline"><semantics><mo stretchy="false">↦</mo><annotation-xml encoding="MathML-Content"><csymbol cd="latexml">maps-to</csymbol></annotation-xml><annotation encoding="application/x-tex">\mapsto</annotation><annotation encoding="application/x-llamapun">↦</annotation></semantics></math> Faceted IR?</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="#S5.SS0.SSS0.Px1" title="In 5. Informative Examples ↦ Faceted IR? ‣ “In-Context Learning” or: How I learned to stop worrying and love “Applied Information Retrieval”"><span class="ltx_text ltx_ref_title">Open research questions</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="#S6" title="In “In-Context Learning” or: How I learned to stop worrying and love “Applied Information Retrieval”"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Preliminary Evaluation</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="#S6.SS1" title="In 6. Preliminary Evaluation ‣ “In-Context Learning” or: How I learned to stop worrying and love “Applied Information Retrieval”"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.1 </span>Research Questions and Dataset</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="#S6.SS1.SSS0.Px1" title="In 6.1. Research Questions and Dataset ‣ 6. Preliminary Evaluation ‣ “In-Context Learning” or: How I learned to stop worrying and love “Applied Information Retrieval”"><span class="ltx_text ltx_ref_title">Research Questions Investigated</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="#S6.SS1.SSS0.Px2" title="In 6.1. Research Questions and Dataset ‣ 6. Preliminary Evaluation ‣ “In-Context Learning” or: How I learned to stop worrying and love “Applied Information Retrieval”"><span class="ltx_text ltx_ref_title">Dataset</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="#S6.SS2" title="In 6. Preliminary Evaluation ‣ “In-Context Learning” or: How I learned to stop worrying and love “Applied Information Retrieval”"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.2 </span>Methods and Parameters</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="#S6.SS2.SSS0.Px1" title="In 6.2. Methods and Parameters ‣ 6. Preliminary Evaluation ‣ “In-Context Learning” or: How I learned to stop worrying and love “Applied Information Retrieval”"><span class="ltx_text ltx_ref_title">Our proposed methods for Adaptive ICL (AICL)</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="#S6.SS2.SSS0.Px2" title="In 6.2. Methods and Parameters ‣ 6. Preliminary Evaluation ‣ “In-Context Learning” or: How I learned to stop worrying and love “Applied Information Retrieval”"><span class="ltx_text ltx_ref_title">Baselines</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="#S6.SS2.SSS0.Px3" title="In 6.2. Methods and Parameters ‣ 6. Preliminary Evaluation ‣ “In-Context Learning” or: How I learned to stop worrying and love “Applied Information Retrieval”"><span class="ltx_text ltx_ref_title">Model and hyper-parameter settings</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="#S6.SS3" title="In 6. Preliminary Evaluation ‣ “In-Context Learning” or: How I learned to stop worrying and love “Applied Information Retrieval”"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.3 </span>Results</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="#S7" title="In “In-Context Learning” or: How I learned to stop worrying and love “Applied Information Retrieval”"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Conclusion</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">“在上下文学习”或：我如何学会不再担心并热爱“应用信息检索”</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Andrew Parry
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/1234-5678-9012" title="ORCID identifier">1234-5678-9012</a></span>
<span class="ltx_contact ltx_role_email"><a href="mailto:a.parry.1@research.gla.ac.uk">a.parry.1@research.gla.ac.uk</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id2.1.id1">University of Glasgow</span><span class="ltx_text ltx_affiliation_city" id="id3.2.id2">Glasgow</span><span class="ltx_text ltx_affiliation_country" id="id4.3.id3">UK</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Debasis Ganguly
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:Debasis.Ganguly@glasgow.ac.uk">Debasis.Ganguly@glasgow.ac.uk</a>
</span>
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/1234-5678-9012" title="ORCID identifier">1234-5678-9012</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id5.1.id1">University of Glasgow</span><span class="ltx_text ltx_affiliation_city" id="id6.2.id2">Glasgow</span><span class="ltx_text ltx_affiliation_country" id="id7.3.id3">UK</span>
</span></span></span>
<span class="ltx_author_before"> and </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Manish Chandra
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:m.chandra.1@research.gla.ac.uk">m.chandra.1@research.gla.ac.uk</a>
</span>
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/1234-5678-9012" title="ORCID identifier">1234-5678-9012</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id8.1.id1">University of Glasgow</span><span class="ltx_text ltx_affiliation_city" id="id9.2.id2">Glasgow</span><span class="ltx_text ltx_affiliation_country" id="id10.3.id3">UK</span>
</span></span></span>
</div>
<div class="ltx_dates">(2024; 20 February 2007; 12 March 2009; 5 June 2009)</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">摘要。</h6>
<p class="ltx_p" id="id1.1">随着大型语言模型（LLMs）的能力不断增强，上下文学习（ICL）已经成为自然语言处理（NLP）的新范式，其中不是通过标记的示例来微调LLM的参数特定于下游任务，而是将少量这样的示例附加到提示指令中以控制解码器的生成过程。因此，ICL在概念上类似于非参数方法，例如<math alttext="k" class="ltx_Math" display="inline" id="id1.1.m1.1"><semantics id="id1.1.m1.1a"><mi id="id1.1.m1.1.1" xref="id1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="id1.1.m1.1b"><ci id="id1.1.m1.1.1.cmml" xref="id1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="id1.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="id1.1.m1.1d">italic_k</annotation></semantics></math>-NN，其中每个实例的预测基本上取决于局部拓扑结构，即类似实例及其标签的局部集合（称为少样本示例）。

这表明ICL中的测试实例类似于IR中的查询，并且从训练集中检索的ICL中的相似示例与IR中从集合中检索的一组文档相关联。

尽管标准的无监督排名模型可用于从训练集中检索这些少样本示例，但通过重新定义与下游任务的效用相关的相关性概念，可以潜在地改善示例的有效性，即如果将其包含在提示指令中会导致正确预测，则认为示例是相关的。通过这种任务特定的相关性概念，可以训练一个监督排名模型（例如，双编码器或交叉编码器），这可能会学习以最佳方式选择少样本示例。我们相信神经排序器的最新进展可能会为更有效的下游ICL预测的优化选择示例找到用例。</p>
</div>
<div class="ltx_keywords">Large Language Models, In-Context Learning, Ranking Models, Query Performance Prediction
</div>
<span class="ltx_note ltx_note_frontmatter ltx_role_copyright" id="id1"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">copyright: </span>acmlicensed</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_journalyear" id="id2"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">journalyear: </span>2024</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_copyright" id="id3"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">copyright: </span>acmlicensed</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_conference" id="id4"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">conference: </span>Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval; July 14–18, 2024; Washington, DC, USA</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_booktitle" id="id5"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">booktitle: </span>Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR ’24), July 14–18, 2024, Washington, DC, USA</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_doi" id="id6"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">doi: </span>10.1145/3626772.3657842</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_isbn" id="id7"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">isbn: </span>979-8-4007-0431-4/24/07</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_ccs" id="id8"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Information systems Information retrieval</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_ccs" id="id9"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Computing methodologies Machine learning</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_ccs" id="id10"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Computing methodologies Natural language processing</span></span></span>
<figure class="ltx_figure" id="S0.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_portrait" height="886" id="S0.F1.g1" src="resource/x1.png" width="623"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">图1。</span>展示了三个IR研究垂直领域如何适应上下文学习工作流程的工作流程图。第<a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#S3" title="3. Adaptive ICL ↦ QPP? ‣ “In-Context Learning” or: How I learned to stop worrying and love “Applied Information Retrieval”"><span class="ltx_text ltx_ref_tag">3</span></a>节讨论了调整无监督和监督QPP方法以适应ICL示例数量的可能方式。第<a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#S4" title="4. Rank ICL Examples ↦ Supervised IR? ‣ “In-Context Learning” or: How I learned to stop worrying and love “Applied Information Retrieval”"><span class="ltx_text ltx_ref_tag">4</span></a>节讨论了如何学习示例的下游有用性的想法。第<a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#S5" title="5. Informative Examples ↦ Faceted IR? ‣ “In-Context Learning” or: How I learned to stop worrying and love “Applied Information Retrieval”"><span class="ltx_text ltx_ref_tag">5</span></a>节讨论了与ICL示例多样化相关的方法。</figcaption>
</figure>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">1. </span>介绍</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">大型语言模型（LLMs）的研究范围正在扩大，并迅速取得重大科学进展。这些语言模型是在大量文档的基础上进行预训练，以以一种通用的、与任务无关的方式捕获文本的固有语义。常见的预训练方法包括掩码语言模型（MLM），它从文本中预测随机掩码的标记，或自回归模型或因果语言模型（CLM），它仅从其前身标记预测一个标记。虽然MLM被用于BERT及其后续模型，如RoBERTa、BART等，但后一类模型，即CLM，被应用于训练GPT变体和开源的Llama和Mistral变体等。当LLMs的参数规模从数百万扩展到数十亿时，由于指示调整，它们已经证明适用于广泛的任务，这意味着它们不仅能够产生语义上正确和连贯的文本，而且能够惊人地适应输入中的小的上下文变化，通常称为提示。</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.2">这种能够适应未见数据和任务的能力，只需要少量示例与监督学习的标准概念有所不同，在监督学习中，预训练模型的参数（例如BERT <cite class="ltx_cite ltx_citemacro_citep">(Devlin et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib18" title="">2019a</a>)</cite>）通常被再次学习（通常称为“微调”）从带标签示例的训练集中。相反，在少样本学习或<span class="ltx_text ltx_font_bold" id="S1.p2.2.1">上下文学习</span>（<span class="ltx_text ltx_font_bold" id="S1.p2.2.2">ICL</span>）中，训练集中的少量带标签示例简单地附加到提示指令中，以控制文本生成的方式对下游任务有益。<cite class="ltx_cite ltx_citemacro_citep">(Mysore et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib54" title="">2023</a>; Li et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib42" title="">2022</a>; Ni et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib55" title="">2021</a>; Pradeep et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib62" title="">2023a</a>)</cite>除了利用ICL进行纯生成任务，例如问答或抽象摘要<cite class="ltx_cite ltx_citemacro_citep">(Brown et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib6" title="">2020</a>; Li et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib43" title="">2023</a>; Tang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib79" title="">2023</a>)</cite>，更常见的用途是在预测任务中，例如文本分类<cite class="ltx_cite ltx_citemacro_citep">(Lu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib47" title="">2022</a>; Milios et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib53" title="">2023</a>)</cite>，其中每个类别由一组词（通常称为语言化器<cite class="ltx_cite ltx_citemacro_citep">(Schick and Schütze, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib70" title="">2021</a>)</cite>）指定，例如，对于二元情感分类任务，积极类别可以由词组<math alttext="\{" class="ltx_Math" display="inline" id="S1.p2.1.m1.1"><semantics id="S1.p2.1.m1.1a"><mo id="S1.p2.1.m1.1.1" stretchy="false" xref="S1.p2.1.m1.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="S1.p2.1.m1.1b"><ci id="S1.p2.1.m1.1.1.cmml" xref="S1.p2.1.m1.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p2.1.m1.1c">\{</annotation><annotation encoding="application/x-llamapun" id="S1.p2.1.m1.1d">{</annotation></semantics></math>‘好’，‘伟大’，‘美好’…<math alttext="\}" class="ltx_Math" display="inline" id="S1.p2.2.m2.1"><semantics id="S1.p2.2.m2.1a"><mo id="S1.p2.2.m2.1.1" stretchy="false" xref="S1.p2.2.m2.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="S1.p2.2.m2.1b"><ci id="S1.p2.2.m2.1.1.cmml" xref="S1.p2.2.m2.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p2.2.m2.1c">\}</annotation><annotation encoding="application/x-llamapun" id="S1.p2.2.m2.1d">}</annotation></semantics></math>定义。
一旦预测任务的每个类别都被定义好，生成的文本可以通过使用解码器生成的词汇的后验概率映射到最可能的类别。</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.2">ICL在概念上与非参数方法（如<math alttext="k" class="ltx_Math" display="inline" id="S1.p3.1.m1.1"><semantics id="S1.p3.1.m1.1a"><mi id="S1.p3.1.m1.1.1" xref="S1.p3.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S1.p3.1.m1.1b"><ci id="S1.p3.1.m1.1.1.cmml" xref="S1.p3.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p3.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S1.p3.1.m1.1d">italic_k</annotation></semantics></math>-NN）有些类似，其中每个实例的预测基本上取决于局部拓扑，即一组相似实例及其标签（称为少样本示例）- ICL与<math alttext="k" class="ltx_Math" display="inline" id="S1.p3.2.m2.1"><semantics id="S1.p3.2.m2.1a"><mi id="S1.p3.2.m2.1.1" xref="S1.p3.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S1.p3.2.m2.1b"><ci id="S1.p3.2.m2.1.1.cmml" xref="S1.p3.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p3.2.m2.1c">k</annotation><annotation encoding="application/x-llamapun" id="S1.p3.2.m2.1d">italic_k</annotation></semantics></math>-NN的唯一区别在于前者涉及底层LLM的编码器-解码器参数的冻结集，因此ICL通常在任何领域仅使用少量示例即可良好工作，因为与监督模型不同，它不会在特定标记示例集上过度拟合参数。相反，示例中表达的语义可能在控制文本生成过程中发挥关键作用，以产生期望的输出-文本本身或映射到类别预测。</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">对于本地化示例的实用性，类似于基于最近邻的预测，暗示了ICL和特定IR之间的类比的强有力案例。更确切地说，ICL中的测试实例类似于IR中的查询，而从训练集中检索的ICL中的相似示例与IR中从集合中检索的一组文档相关。这种类比在ICL中引发了一些有趣的研究问题，涉及有效利用IR以提高ICL预测。在这篇展望性论文中，我们讨论了ICL的特定部分，可以映射到已知和经过深入研究的IR问题。这意味着IR社区数十年来研究的这些问题的解决方案，可能可以应用于改善ICL的有效性。此外，这也应该引起IR研究人员的兴趣，以开发针对下游预测任务的经典IR问题的新方法，例如文档检索或查询性能预测（QPP）<cite class="ltx_cite ltx_citemacro_citep">(Datta et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib15" title="">2022</a>; Roitman et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib66" title="">2020</a>; Singh et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib74" title="">2023</a>)</cite>，因此为评估新的IR方法开辟了超出检索任务的新可能性。</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">我们现在提出将核心IR思想纳入ICL的三种主要方法。首先，在ICL中的推理过程中，与其为每个实例使用恒定数量的示例，可能更好的方法是使示例数量可变。<span class="ltx_text ltx_font_bold" id="S1.p5.1.1">在IR中类似的问题是预测要检索多少篇文档（或者等效地预测排名截止阈值<cite class="ltx_cite ltx_citemacro_citep">(Arampatzis et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib3" title="">2009</a>; Bahri et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib5" title="">2020</a>)</cite>），这也与查询性能预测（QPP）<span class="ltx_text ltx_font_bold" id="S1.p5.1.2">问题密切相关<cite class="ltx_cite ltx_citemacro_citep">(Datta et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib15" title="">2022</a>; Roitman et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib66" title="">2020</a>; Singh et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib74" title="">2023</a>)</cite>。在ICL的背景下，这意味着对于一些测试实例，可以从训练集中找到更多“有用”的示例（如果将其作为提示的一部分会导致LLM进行正确预测，则可以认为示例是有用的）。相反，对于其他实例来说，很难找到这样有用的示例。因此，一个能意识到示例质量的ICL方法可能会自适应，例如如果预测示例质量较差，则可以使用更多示例。</span></span></p>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">其次，我们建议使用于计算测试实例与示例之间相似性的基本度量空间可学习。学习此相似性函数的目标是将“有用”的示例排在“不有用”的示例之前。无监督检索模型只考虑测试实例的文本内容与训练实例之间的相似性。然而，通过标准排名目标（例如，使用三元组的噪声对比损失<cite class="ltx_cite ltx_citemacro_citep">(Gutmann and Hyvärinen, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib31" title="">2010</a>)</cite>）学习的<span class="ltx_text ltx_font_bold" id="S1.p6.1.1">监督检索模型</span> - 每个三元组包括一个测试实例（查询），一个有用示例（相关文档）和一个不有用示例（不相关文档） - 可能特别捕捉特定测试实例示例的效用的固有语义。</p>
</div>
<div class="ltx_para" id="S1.p7">
<p class="ltx_p" id="S1.p7.1">第三，<span class="ltx_text ltx_font_bold" id="S1.p7.1.1">例子的多样性</span>可能会影响ICL的有效性，因为与之前选择的例子不同的例子对LLM解码器生成相关单词更具信息量，然后可以映射到正确的类别。这也可以追溯到基于方面或基于方面的IR，试图使顶部检索到的文档集满足信息需求的所有潜在方面。 <cite class="ltx_cite ltx_citemacro_citep">(Upadhyay et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib81" title="">2020</a>; Mahdi et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib50" title="">2020</a>)</cite></p>
</div>
<div class="ltx_para" id="S1.p8">
<p class="ltx_p" id="S1.p8.1">这三个IR中的核心任务，即<span class="ltx_text ltx_font_bold" id="S1.p8.1.1">QPP</span>，监督排名或<span class="ltx_text ltx_font_bold" id="S1.p8.1.2">学习排名</span>，以及<span class="ltx_text ltx_font_bold" id="S1.p8.1.3">多样化或分面IR</span>，在经历了长期的深入研究后，不断推动着这些任务可达到的最新成果的边界。在这篇展望性论文中，我们认为IR社区所获得的这些知识可以有助于进一步提高文本生成人工智能的有效性。</p>
</div>
<div class="ltx_para" id="S1.p9">
<p class="ltx_p" id="S1.p9.1">在接下来的部分（第<a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#S2" title="2. In-Context Learning ‣ “In-Context Learning” or: How I learned to stop worrying and love “Applied Information Retrieval”"><span class="ltx_text ltx_ref_tag">2</span></a>节），我们对ICL概念进行了简要的技术介绍，随后，我们将本文的其余部分构成了三个部分，详细介绍了每个特定IR任务如何应用于ICL工作流程，即自适应ICL的QPP（第<a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#S3" title="3. Adaptive ICL ↦ QPP? ‣ “In-Context Learning” or: How I learned to stop worrying and love “Applied Information Retrieval”"><span class="ltx_text ltx_ref_tag">3</span></a>节），学习排名以学习在ICL中对示例进行排序（第<a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#S4" title="4. Rank ICL Examples ↦ Supervised IR? ‣ “In-Context Learning” or: How I learned to stop worrying and love “Applied Information Retrieval”"><span class="ltx_text ltx_ref_tag">4</span></a>节），以及基于多样性和分面的IR以获取更多信息性示例在ICL中（第<a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#S5" title="5. Informative Examples ↦ Faceted IR? ‣ “In-Context Learning” or: How I learned to stop worrying and love “Applied Information Retrieval”"><span class="ltx_text ltx_ref_tag">5</span></a>节）。虽然对于改进ICL的每个独立想法进行详尽的实证验证超出了展望性论文的范围，但我们确实包括了初步评估来支持在ICL中使用QPP的用例（第<a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#S6" title="6. Preliminary Evaluation ‣ “In-Context Learning” or: How I learned to stop worrying and love “Applied Information Retrieval”"><span class="ltx_text ltx_ref_tag">6</span></a>节），在那里我们展示了以数据驱动的方式调整示例数量确实会带来显著的改进。我们相信这种专注的研究，以及提出的其他想法，会激励其他NLP研究人员应用黑盒建立的IR方法，甚至是IR研究人员调整最先进的IR方法，以特别满足ICL中的下游预测任务。</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">2. </span>上下文学习</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">首先，我们在描述如何通过将IR的核心思想纳入ICL方法来改进ICL方法之前，先对In-Context Learning（ICL）进行了简要的技术介绍。</p>
</div>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">2.1. </span>正式介绍</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.3">In-context learning (ICL),与监督学习不同，不涉及在标记的示例上训练一组参数<math alttext="\theta" class="ltx_Math" display="inline" id="S2.SS1.p1.1.m1.1"><semantics id="S2.SS1.p1.1.m1.1a"><mi id="S2.SS1.p1.1.m1.1.1" xref="S2.SS1.p1.1.m1.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.1.m1.1b"><ci id="S2.SS1.p1.1.m1.1.1.cmml" xref="S2.SS1.p1.1.m1.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.1.m1.1c">\theta</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.1.m1.1d">italic_θ</annotation></semantics></math>。 相反，后验现在是以下功能的函数：a）输入测试实例的文本，b）预训练大型语言模型（LLM）的解码器参数，c）提示指令，以及d）可选地，一组<math alttext="k" class="ltx_Math" display="inline" id="S2.SS1.p1.2.m2.1"><semantics id="S2.SS1.p1.2.m2.1a"><mi id="S2.SS1.p1.2.m2.1.1" xref="S2.SS1.p1.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.2.m2.1b"><ci id="S2.SS1.p1.2.m2.1.1.cmml" xref="S2.SS1.p1.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.2.m2.1c">k</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.2.m2.1d">italic_k</annotation></semantics></math>输入示例（通常称为<math alttext="k" class="ltx_Math" display="inline" id="S2.SS1.p1.3.m3.1"><semantics id="S2.SS1.p1.3.m3.1a"><mi id="S2.SS1.p1.3.m3.1.1" xref="S2.SS1.p1.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.3.m3.1b"><ci id="S2.SS1.p1.3.m3.1.1.cmml" xref="S2.SS1.p1.3.m3.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.3.m3.1c">k</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.3.m3.1d">italic_k</annotation></semantics></math> -shot学习）。 形式上，</p>
<table class="ltx_equation ltx_eqn_table" id="S2.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_left">(1)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="P(y|\mathbf{x})=f(\mathbf{x},\mathcal{P}_{k}(\mathbf{x});\phi_{\text{LLM}})," class="ltx_Math" display="block" id="S2.E1.m1.3"><semantics id="S2.E1.m1.3a"><mrow id="S2.E1.m1.3.3.1" xref="S2.E1.m1.3.3.1.1.cmml"><mrow id="S2.E1.m1.3.3.1.1" xref="S2.E1.m1.3.3.1.1.cmml"><mrow id="S2.E1.m1.3.3.1.1.1" xref="S2.E1.m1.3.3.1.1.1.cmml"><mi id="S2.E1.m1.3.3.1.1.1.3" xref="S2.E1.m1.3.3.1.1.1.3.cmml">P</mi><mo id="S2.E1.m1.3.3.1.1.1.2" xref="S2.E1.m1.3.3.1.1.1.2.cmml">⁢</mo><mrow id="S2.E1.m1.3.3.1.1.1.1.1" xref="S2.E1.m1.3.3.1.1.1.1.1.1.cmml"><mo id="S2.E1.m1.3.3.1.1.1.1.1.2" stretchy="false" xref="S2.E1.m1.3.3.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.E1.m1.3.3.1.1.1.1.1.1" xref="S2.E1.m1.3.3.1.1.1.1.1.1.cmml"><mi id="S2.E1.m1.3.3.1.1.1.1.1.1.2" xref="S2.E1.m1.3.3.1.1.1.1.1.1.2.cmml">y</mi><mo fence="false" id="S2.E1.m1.3.3.1.1.1.1.1.1.1" xref="S2.E1.m1.3.3.1.1.1.1.1.1.1.cmml">|</mo><mi id="S2.E1.m1.3.3.1.1.1.1.1.1.3" xref="S2.E1.m1.3.3.1.1.1.1.1.1.3.cmml">𝐱</mi></mrow><mo id="S2.E1.m1.3.3.1.1.1.1.1.3" stretchy="false" xref="S2.E1.m1.3.3.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E1.m1.3.3.1.1.4" xref="S2.E1.m1.3.3.1.1.4.cmml">=</mo><mrow id="S2.E1.m1.3.3.1.1.3" xref="S2.E1.m1.3.3.1.1.3.cmml"><mi id="S2.E1.m1.3.3.1.1.3.4" xref="S2.E1.m1.3.3.1.1.3.4.cmml">f</mi><mo id="S2.E1.m1.3.3.1.1.3.3" xref="S2.E1.m1.3.3.1.1.3.3.cmml">⁢</mo><mrow id="S2.E1.m1.3.3.1.1.3.2.2" xref="S2.E1.m1.3.3.1.1.3.2.3.cmml"><mo id="S2.E1.m1.3.3.1.1.3.2.2.3" stretchy="false" xref="S2.E1.m1.3.3.1.1.3.2.3.cmml">(</mo><mi id="S2.E1.m1.2.2" xref="S2.E1.m1.2.2.cmml">𝐱</mi><mo id="S2.E1.m1.3.3.1.1.3.2.2.4" xref="S2.E1.m1.3.3.1.1.3.2.3.cmml">,</mo><mrow id="S2.E1.m1.3.3.1.1.2.1.1.1" xref="S2.E1.m1.3.3.1.1.2.1.1.1.cmml"><msub id="S2.E1.m1.3.3.1.1.2.1.1.1.2" xref="S2.E1.m1.3.3.1.1.2.1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E1.m1.3.3.1.1.2.1.1.1.2.2" xref="S2.E1.m1.3.3.1.1.2.1.1.1.2.2.cmml">𝒫</mi><mi id="S2.E1.m1.3.3.1.1.2.1.1.1.2.3" xref="S2.E1.m1.3.3.1.1.2.1.1.1.2.3.cmml">k</mi></msub><mo id="S2.E1.m1.3.3.1.1.2.1.1.1.1" xref="S2.E1.m1.3.3.1.1.2.1.1.1.1.cmml">⁢</mo><mrow id="S2.E1.m1.3.3.1.1.2.1.1.1.3.2" xref="S2.E1.m1.3.3.1.1.2.1.1.1.cmml"><mo id="S2.E1.m1.3.3.1.1.2.1.1.1.3.2.1" stretchy="false" xref="S2.E1.m1.3.3.1.1.2.1.1.1.cmml">(</mo><mi id="S2.E1.m1.1.1" xref="S2.E1.m1.1.1.cmml">𝐱</mi><mo id="S2.E1.m1.3.3.1.1.2.1.1.1.3.2.2" stretchy="false" xref="S2.E1.m1.3.3.1.1.2.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E1.m1.3.3.1.1.3.2.2.5" xref="S2.E1.m1.3.3.1.1.3.2.3.cmml">;</mo><msub id="S2.E1.m1.3.3.1.1.3.2.2.2" xref="S2.E1.m1.3.3.1.1.3.2.2.2.cmml"><mi id="S2.E1.m1.3.3.1.1.3.2.2.2.2" xref="S2.E1.m1.3.3.1.1.3.2.2.2.2.cmml">ϕ</mi><mtext id="S2.E1.m1.3.3.1.1.3.2.2.2.3" xref="S2.E1.m1.3.3.1.1.3.2.2.2.3a.cmml">LLM</mtext></msub><mo id="S2.E1.m1.3.3.1.1.3.2.2.6" stretchy="false" xref="S2.E1.m1.3.3.1.1.3.2.3.cmml">)</mo></mrow></mrow></mrow><mo id="S2.E1.m1.3.3.1.2" xref="S2.E1.m1.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.3b"><apply id="S2.E1.m1.3.3.1.1.cmml" xref="S2.E1.m1.3.3.1"><eq id="S2.E1.m1.3.3.1.1.4.cmml" xref="S2.E1.m1.3.3.1.1.4"></eq><apply id="S2.E1.m1.3.3.1.1.1.cmml" xref="S2.E1.m1.3.3.1.1.1"><times id="S2.E1.m1.3.3.1.1.1.2.cmml" xref="S2.E1.m1.3.3.1.1.1.2"></times><ci id="S2.E1.m1.3.3.1.1.1.3.cmml" xref="S2.E1.m1.3.3.1.1.1.3">𝑃</ci><apply id="S2.E1.m1.3.3.1.1.1.1.1.1.cmml" xref="S2.E1.m1.3.3.1.1.1.1.1"><csymbol cd="latexml" id="S2.E1.m1.3.3.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.3.3.1.1.1.1.1.1.1">conditional</csymbol><ci id="S2.E1.m1.3.3.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.3.3.1.1.1.1.1.1.2">𝑦</ci><ci id="S2.E1.m1.3.3.1.1.1.1.1.1.3.cmml" xref="S2.E1.m1.3.3.1.1.1.1.1.1.3">𝐱</ci></apply></apply><apply id="S2.E1.m1.3.3.1.1.3.cmml" xref="S2.E1.m1.3.3.1.1.3"><times id="S2.E1.m1.3.3.1.1.3.3.cmml" xref="S2.E1.m1.3.3.1.1.3.3"></times><ci id="S2.E1.m1.3.3.1.1.3.4.cmml" xref="S2.E1.m1.3.3.1.1.3.4">𝑓</ci><vector id="S2.E1.m1.3.3.1.1.3.2.3.cmml" xref="S2.E1.m1.3.3.1.1.3.2.2"><ci id="S2.E1.m1.2.2.cmml" xref="S2.E1.m1.2.2">𝐱</ci><apply id="S2.E1.m1.3.3.1.1.2.1.1.1.cmml" xref="S2.E1.m1.3.3.1.1.2.1.1.1"><times id="S2.E1.m1.3.3.1.1.2.1.1.1.1.cmml" xref="S2.E1.m1.3.3.1.1.2.1.1.1.1"></times><apply id="S2.E1.m1.3.3.1.1.2.1.1.1.2.cmml" xref="S2.E1.m1.3.3.1.1.2.1.1.1.2"><csymbol cd="ambiguous" id="S2.E1.m1.3.3.1.1.2.1.1.1.2.1.cmml" xref="S2.E1.m1.3.3.1.1.2.1.1.1.2">subscript</csymbol><ci id="S2.E1.m1.3.3.1.1.2.1.1.1.2.2.cmml" xref="S2.E1.m1.3.3.1.1.2.1.1.1.2.2">𝒫</ci><ci id="S2.E1.m1.3.3.1.1.2.1.1.1.2.3.cmml" xref="S2.E1.m1.3.3.1.1.2.1.1.1.2.3">𝑘</ci></apply><ci id="S2.E1.m1.1.1.cmml" xref="S2.E1.m1.1.1">𝐱</ci></apply><apply id="S2.E1.m1.3.3.1.1.3.2.2.2.cmml" xref="S2.E1.m1.3.3.1.1.3.2.2.2"><csymbol cd="ambiguous" id="S2.E1.m1.3.3.1.1.3.2.2.2.1.cmml" xref="S2.E1.m1.3.3.1.1.3.2.2.2">subscript</csymbol><ci id="S2.E1.m1.3.3.1.1.3.2.2.2.2.cmml" xref="S2.E1.m1.3.3.1.1.3.2.2.2.2">italic-ϕ</ci><ci id="S2.E1.m1.3.3.1.1.3.2.2.2.3a.cmml" xref="S2.E1.m1.3.3.1.1.3.2.2.2.3"><mtext id="S2.E1.m1.3.3.1.1.3.2.2.2.3.cmml" mathsize="70%" xref="S2.E1.m1.3.3.1.1.3.2.2.2.3">LLM</mtext></ci></apply></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.3c">P(y|\mathbf{x})=f(\mathbf{x},\mathcal{P}_{k}(\mathbf{x});\phi_{\text{LLM}}),</annotation><annotation encoding="application/x-llamapun" id="S2.E1.m1.3d">italic_P ( italic_y | bold_x ) = italic_f ( bold_x , caligraphic_P start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( bold_x ) ; italic_ϕ start_POSTSUBSCRIPT LLM end_POSTSUBSCRIPT ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S2.SS1.p1.7">在这里，不同于监督设置，函数<math alttext="f" class="ltx_Math" display="inline" id="S2.SS1.p1.4.m1.1"><semantics id="S2.SS1.p1.4.m1.1a"><mi id="S2.SS1.p1.4.m1.1.1" xref="S2.SS1.p1.4.m1.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.4.m1.1b"><ci id="S2.SS1.p1.4.m1.1.1.cmml" xref="S2.SS1.p1.4.m1.1.1">𝑓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.4.m1.1c">f</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.4.m1.1d">italic_f</annotation></semantics></math>没有一个可以使用梯度下降训练集学习的参数化表示。函数本身取决于LLM的预训练参数<math alttext="\phi_{\text{LLM}}" class="ltx_Math" display="inline" id="S2.SS1.p1.5.m2.1"><semantics id="S2.SS1.p1.5.m2.1a"><msub id="S2.SS1.p1.5.m2.1.1" xref="S2.SS1.p1.5.m2.1.1.cmml"><mi id="S2.SS1.p1.5.m2.1.1.2" xref="S2.SS1.p1.5.m2.1.1.2.cmml">ϕ</mi><mtext id="S2.SS1.p1.5.m2.1.1.3" xref="S2.SS1.p1.5.m2.1.1.3a.cmml">LLM</mtext></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.5.m2.1b"><apply id="S2.SS1.p1.5.m2.1.1.cmml" xref="S2.SS1.p1.5.m2.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.5.m2.1.1.1.cmml" xref="S2.SS1.p1.5.m2.1.1">subscript</csymbol><ci id="S2.SS1.p1.5.m2.1.1.2.cmml" xref="S2.SS1.p1.5.m2.1.1.2">italic-ϕ</ci><ci id="S2.SS1.p1.5.m2.1.1.3a.cmml" xref="S2.SS1.p1.5.m2.1.1.3"><mtext id="S2.SS1.p1.5.m2.1.1.3.cmml" mathsize="70%" xref="S2.SS1.p1.5.m2.1.1.3">LLM</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.5.m2.1c">\phi_{\text{LLM}}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.5.m2.1d">italic_ϕ start_POSTSUBSCRIPT LLM end_POSTSUBSCRIPT</annotation></semantics></math>，当前输入要预测标签的，以及由<math alttext="\mathcal{P}_{k}(\mathbf{x})" class="ltx_Math" display="inline" id="S2.SS1.p1.7.m4.1"><semantics id="S2.SS1.p1.7.m4.1a"><mrow id="S2.SS1.p1.7.m4.1.2" xref="S2.SS1.p1.7.m4.1.2.cmml"><msub id="S2.SS1.p1.7.m4.1.2.2" xref="S2.SS1.p1.7.m4.1.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p1.7.m4.1.2.2.2" xref="S2.SS1.p1.7.m4.1.2.2.2.cmml">𝒫</mi><mi id="S2.SS1.p1.7.m4.1.2.2.3" xref="S2.SS1.p1.7.m4.1.2.2.3.cmml">k</mi></msub><mo id="S2.SS1.p1.7.m4.1.2.1" xref="S2.SS1.p1.7.m4.1.2.1.cmml">⁢</mo><mrow id="S2.SS1.p1.7.m4.1.2.3.2" xref="S2.SS1.p1.7.m4.1.2.cmml"><mo id="S2.SS1.p1.7.m4.1.2.3.2.1" stretchy="false" xref="S2.SS1.p1.7.m4.1.2.cmml">(</mo><mi id="S2.SS1.p1.7.m4.1.1" xref="S2.SS1.p1.7.m4.1.1.cmml">𝐱</mi><mo id="S2.SS1.p1.7.m4.1.2.3.2.2" stretchy="false" xref="S2.SS1.p1.7.m4.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.7.m4.1b"><apply id="S2.SS1.p1.7.m4.1.2.cmml" xref="S2.SS1.p1.7.m4.1.2"><times id="S2.SS1.p1.7.m4.1.2.1.cmml" xref="S2.SS1.p1.7.m4.1.2.1"></times><apply id="S2.SS1.p1.7.m4.1.2.2.cmml" xref="S2.SS1.p1.7.m4.1.2.2"><csymbol cd="ambiguous" id="S2.SS1.p1.7.m4.1.2.2.1.cmml" xref="S2.SS1.p1.7.m4.1.2.2">subscript</csymbol><ci id="S2.SS1.p1.7.m4.1.2.2.2.cmml" xref="S2.SS1.p1.7.m4.1.2.2.2">𝒫</ci><ci id="S2.SS1.p1.7.m4.1.2.2.3.cmml" xref="S2.SS1.p1.7.m4.1.2.2.3">𝑘</ci></apply><ci id="S2.SS1.p1.7.m4.1.1.cmml" xref="S2.SS1.p1.7.m4.1.1">𝐱</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.7.m4.1c">\mathcal{P}_{k}(\mathbf{x})</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.7.m4.1d">caligraphic_P start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( bold_x )</annotation></semantics></math>表示的一组提示文本单元。</p>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.10">由于LLM的解码器生成了一个形式为<math alttext="w_{1},\ldots,w_{N}" class="ltx_Math" display="inline" id="S2.SS1.p2.1.m1.3"><semantics id="S2.SS1.p2.1.m1.3a"><mrow id="S2.SS1.p2.1.m1.3.3.2" xref="S2.SS1.p2.1.m1.3.3.3.cmml"><msub id="S2.SS1.p2.1.m1.2.2.1.1" xref="S2.SS1.p2.1.m1.2.2.1.1.cmml"><mi id="S2.SS1.p2.1.m1.2.2.1.1.2" xref="S2.SS1.p2.1.m1.2.2.1.1.2.cmml">w</mi><mn id="S2.SS1.p2.1.m1.2.2.1.1.3" xref="S2.SS1.p2.1.m1.2.2.1.1.3.cmml">1</mn></msub><mo id="S2.SS1.p2.1.m1.3.3.2.3" xref="S2.SS1.p2.1.m1.3.3.3.cmml">,</mo><mi id="S2.SS1.p2.1.m1.1.1" mathvariant="normal" xref="S2.SS1.p2.1.m1.1.1.cmml">…</mi><mo id="S2.SS1.p2.1.m1.3.3.2.4" xref="S2.SS1.p2.1.m1.3.3.3.cmml">,</mo><msub id="S2.SS1.p2.1.m1.3.3.2.2" xref="S2.SS1.p2.1.m1.3.3.2.2.cmml"><mi id="S2.SS1.p2.1.m1.3.3.2.2.2" xref="S2.SS1.p2.1.m1.3.3.2.2.2.cmml">w</mi><mi id="S2.SS1.p2.1.m1.3.3.2.2.3" xref="S2.SS1.p2.1.m1.3.3.2.2.3.cmml">N</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.1.m1.3b"><list id="S2.SS1.p2.1.m1.3.3.3.cmml" xref="S2.SS1.p2.1.m1.3.3.2"><apply id="S2.SS1.p2.1.m1.2.2.1.1.cmml" xref="S2.SS1.p2.1.m1.2.2.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.1.m1.2.2.1.1.1.cmml" xref="S2.SS1.p2.1.m1.2.2.1.1">subscript</csymbol><ci id="S2.SS1.p2.1.m1.2.2.1.1.2.cmml" xref="S2.SS1.p2.1.m1.2.2.1.1.2">𝑤</ci><cn id="S2.SS1.p2.1.m1.2.2.1.1.3.cmml" type="integer" xref="S2.SS1.p2.1.m1.2.2.1.1.3">1</cn></apply><ci id="S2.SS1.p2.1.m1.1.1.cmml" xref="S2.SS1.p2.1.m1.1.1">…</ci><apply id="S2.SS1.p2.1.m1.3.3.2.2.cmml" xref="S2.SS1.p2.1.m1.3.3.2.2"><csymbol cd="ambiguous" id="S2.SS1.p2.1.m1.3.3.2.2.1.cmml" xref="S2.SS1.p2.1.m1.3.3.2.2">subscript</csymbol><ci id="S2.SS1.p2.1.m1.3.3.2.2.2.cmml" xref="S2.SS1.p2.1.m1.3.3.2.2.2">𝑤</ci><ci id="S2.SS1.p2.1.m1.3.3.2.2.3.cmml" xref="S2.SS1.p2.1.m1.3.3.2.2.3">𝑁</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.1.m1.3c">w_{1},\ldots,w_{N}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p2.1.m1.3d">italic_w start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_w start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT</annotation></semantics></math>的词序列（<math alttext="N" class="ltx_Math" display="inline" id="S2.SS1.p2.2.m2.1"><semantics id="S2.SS1.p2.2.m2.1a"><mi id="S2.SS1.p2.2.m2.1.1" xref="S2.SS1.p2.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.2.m2.1b"><ci id="S2.SS1.p2.2.m2.1.1.cmml" xref="S2.SS1.p2.2.m2.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.2.m2.1c">N</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p2.2.m2.1d">italic_N</annotation></semantics></math>是序列的最大长度），类后验概率是以以下方式计算的。一组类别（比如对于一个<math alttext="p" class="ltx_Math" display="inline" id="S2.SS1.p2.3.m3.1"><semantics id="S2.SS1.p2.3.m3.1a"><mi id="S2.SS1.p2.3.m3.1.1" xref="S2.SS1.p2.3.m3.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.3.m3.1b"><ci id="S2.SS1.p2.3.m3.1.1.cmml" xref="S2.SS1.p2.3.m3.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.3.m3.1c">p</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p2.3.m3.1d">italic_p</annotation></semantics></math>分类问题）被映射到<math alttext="p" class="ltx_Math" display="inline" id="S2.SS1.p2.4.m4.1"><semantics id="S2.SS1.p2.4.m4.1a"><mi id="S2.SS1.p2.4.m4.1.1" xref="S2.SS1.p2.4.m4.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.4.m4.1b"><ci id="S2.SS1.p2.4.m4.1.1.cmml" xref="S2.SS1.p2.4.m4.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.4.m4.1c">p</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p2.4.m4.1d">italic_p</annotation></semantics></math>个不同的等价词组，比如<math alttext="V(y)" class="ltx_Math" display="inline" id="S2.SS1.p2.5.m5.1"><semantics id="S2.SS1.p2.5.m5.1a"><mrow id="S2.SS1.p2.5.m5.1.2" xref="S2.SS1.p2.5.m5.1.2.cmml"><mi id="S2.SS1.p2.5.m5.1.2.2" xref="S2.SS1.p2.5.m5.1.2.2.cmml">V</mi><mo id="S2.SS1.p2.5.m5.1.2.1" xref="S2.SS1.p2.5.m5.1.2.1.cmml">⁢</mo><mrow id="S2.SS1.p2.5.m5.1.2.3.2" xref="S2.SS1.p2.5.m5.1.2.cmml"><mo id="S2.SS1.p2.5.m5.1.2.3.2.1" stretchy="false" xref="S2.SS1.p2.5.m5.1.2.cmml">(</mo><mi id="S2.SS1.p2.5.m5.1.1" xref="S2.SS1.p2.5.m5.1.1.cmml">y</mi><mo id="S2.SS1.p2.5.m5.1.2.3.2.2" stretchy="false" xref="S2.SS1.p2.5.m5.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.5.m5.1b"><apply id="S2.SS1.p2.5.m5.1.2.cmml" xref="S2.SS1.p2.5.m5.1.2"><times id="S2.SS1.p2.5.m5.1.2.1.cmml" xref="S2.SS1.p2.5.m5.1.2.1"></times><ci id="S2.SS1.p2.5.m5.1.2.2.cmml" xref="S2.SS1.p2.5.m5.1.2.2">𝑉</ci><ci id="S2.SS1.p2.5.m5.1.1.cmml" xref="S2.SS1.p2.5.m5.1.1">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.5.m5.1c">V(y)</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p2.5.m5.1d">italic_V ( italic_y )</annotation></semantics></math>，其中<math alttext="y\in\mathbb{Z}_{p}" class="ltx_Math" display="inline" id="S2.SS1.p2.6.m6.1"><semantics id="S2.SS1.p2.6.m6.1a"><mrow id="S2.SS1.p2.6.m6.1.1" xref="S2.SS1.p2.6.m6.1.1.cmml"><mi id="S2.SS1.p2.6.m6.1.1.2" xref="S2.SS1.p2.6.m6.1.1.2.cmml">y</mi><mo id="S2.SS1.p2.6.m6.1.1.1" xref="S2.SS1.p2.6.m6.1.1.1.cmml">∈</mo><msub id="S2.SS1.p2.6.m6.1.1.3" xref="S2.SS1.p2.6.m6.1.1.3.cmml"><mi id="S2.SS1.p2.6.m6.1.1.3.2" xref="S2.SS1.p2.6.m6.1.1.3.2.cmml">ℤ</mi><mi id="S2.SS1.p2.6.m6.1.1.3.3" xref="S2.SS1.p2.6.m6.1.1.3.3.cmml">p</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.6.m6.1b"><apply id="S2.SS1.p2.6.m6.1.1.cmml" xref="S2.SS1.p2.6.m6.1.1"><in id="S2.SS1.p2.6.m6.1.1.1.cmml" xref="S2.SS1.p2.6.m6.1.1.1"></in><ci id="S2.SS1.p2.6.m6.1.1.2.cmml" xref="S2.SS1.p2.6.m6.1.1.2">𝑦</ci><apply id="S2.SS1.p2.6.m6.1.1.3.cmml" xref="S2.SS1.p2.6.m6.1.1.3"><csymbol cd="ambiguous" id="S2.SS1.p2.6.m6.1.1.3.1.cmml" xref="S2.SS1.p2.6.m6.1.1.3">subscript</csymbol><ci id="S2.SS1.p2.6.m6.1.1.3.2.cmml" xref="S2.SS1.p2.6.m6.1.1.3.2">ℤ</ci><ci id="S2.SS1.p2.6.m6.1.1.3.3.cmml" xref="S2.SS1.p2.6.m6.1.1.3.3">𝑝</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.6.m6.1c">y\in\mathbb{Z}_{p}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p2.6.m6.1d">italic_y ∈ blackboard_Z start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT</annotation></semantics></math>，通常这些集合被称为词汇化者<cite class="ltx_cite ltx_citemacro_citep">(Hu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib33" title="">2021</a>)</cite>。例如，对于一个二元分类问题（例如，如图<a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#S2.F2" title="Figure 2 ‣ 2.1. A Formal Introduction ‣ 2. In-Context Learning ‣ “In-Context Learning” or: How I learned to stop worrying and love “Applied Information Retrieval”"><span class="ltx_text ltx_ref_tag">2</span></a>所示的电影评论），<math alttext="p=2" class="ltx_Math" display="inline" id="S2.SS1.p2.7.m7.1"><semantics id="S2.SS1.p2.7.m7.1a"><mrow id="S2.SS1.p2.7.m7.1.1" xref="S2.SS1.p2.7.m7.1.1.cmml"><mi id="S2.SS1.p2.7.m7.1.1.2" xref="S2.SS1.p2.7.m7.1.1.2.cmml">p</mi><mo id="S2.SS1.p2.7.m7.1.1.1" xref="S2.SS1.p2.7.m7.1.1.1.cmml">=</mo><mn id="S2.SS1.p2.7.m7.1.1.3" xref="S2.SS1.p2.7.m7.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.7.m7.1b"><apply id="S2.SS1.p2.7.m7.1.1.cmml" xref="S2.SS1.p2.7.m7.1.1"><eq id="S2.SS1.p2.7.m7.1.1.1.cmml" xref="S2.SS1.p2.7.m7.1.1.1"></eq><ci id="S2.SS1.p2.7.m7.1.1.2.cmml" xref="S2.SS1.p2.7.m7.1.1.2">𝑝</ci><cn id="S2.SS1.p2.7.m7.1.1.3.cmml" type="integer" xref="S2.SS1.p2.7.m7.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.7.m7.1c">p=2</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p2.7.m7.1d">italic_p = 2</annotation></semantics></math>（即<math alttext="y\in\{0,1\}" class="ltx_Math" display="inline" id="S2.SS1.p2.8.m8.2"><semantics id="S2.SS1.p2.8.m8.2a"><mrow id="S2.SS1.p2.8.m8.2.3" xref="S2.SS1.p2.8.m8.2.3.cmml"><mi id="S2.SS1.p2.8.m8.2.3.2" xref="S2.SS1.p2.8.m8.2.3.2.cmml">y</mi><mo id="S2.SS1.p2.8.m8.2.3.1" xref="S2.SS1.p2.8.m8.2.3.1.cmml">∈</mo><mrow id="S2.SS1.p2.8.m8.2.3.3.2" xref="S2.SS1.p2.8.m8.2.3.3.1.cmml"><mo id="S2.SS1.p2.8.m8.2.3.3.2.1" stretchy="false" xref="S2.SS1.p2.8.m8.2.3.3.1.cmml">{</mo><mn id="S2.SS1.p2.8.m8.1.1" xref="S2.SS1.p2.8.m8.1.1.cmml">0</mn><mo id="S2.SS1.p2.8.m8.2.3.3.2.2" xref="S2.SS1.p2.8.m8.2.3.3.1.cmml">,</mo><mn id="S2.SS1.p2.8.m8.2.2" xref="S2.SS1.p2.8.m8.2.2.cmml">1</mn><mo id="S2.SS1.p2.8.m8.2.3.3.2.3" stretchy="false" xref="S2.SS1.p2.8.m8.2.3.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.8.m8.2b"><apply id="S2.SS1.p2.8.m8.2.3.cmml" xref="S2.SS1.p2.8.m8.2.3"><in id="S2.SS1.p2.8.m8.2.3.1.cmml" xref="S2.SS1.p2.8.m8.2.3.1"></in><ci id="S2.SS1.p2.8.m8.2.3.2.cmml" xref="S2.SS1.p2.8.m8.2.3.2">𝑦</ci><set id="S2.SS1.p2.8.m8.2.3.3.1.cmml" xref="S2.SS1.p2.8.m8.2.3.3.2"><cn id="S2.SS1.p2.8.m8.1.1.cmml" type="integer" xref="S2.SS1.p2.8.m8.1.1">0</cn><cn id="S2.SS1.p2.8.m8.2.2.cmml" type="integer" xref="S2.SS1.p2.8.m8.2.2">1</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.8.m8.2c">y\in\{0,1\}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p2.8.m8.2d">italic_y ∈ { 0 , 1 }</annotation></semantics></math>），定义词汇化者集合的一个合理方式可能是通过以下词语：<math alttext="V(0)=\{\text{`false'},\text{`negative'}\}" class="ltx_Math" display="inline" id="S2.SS1.p2.9.m9.3"><semantics id="S2.SS1.p2.9.m9.3a"><mrow id="S2.SS1.p2.9.m9.3.4" xref="S2.SS1.p2.9.m9.3.4.cmml"><mrow id="S2.SS1.p2.9.m9.3.4.2" xref="S2.SS1.p2.9.m9.3.4.2.cmml"><mi id="S2.SS1.p2.9.m9.3.4.2.2" xref="S2.SS1.p2.9.m9.3.4.2.2.cmml">V</mi><mo id="S2.SS1.p2.9.m9.3.4.2.1" xref="S2.SS1.p2.9.m9.3.4.2.1.cmml">⁢</mo><mrow id="S2.SS1.p2.9.m9.3.4.2.3.2" xref="S2.SS1.p2.9.m9.3.4.2.cmml"><mo id="S2.SS1.p2.9.m9.3.4.2.3.2.1" stretchy="false" xref="S2.SS1.p2.9.m9.3.4.2.cmml">(</mo><mn id="S2.SS1.p2.9.m9.1.1" xref="S2.SS1.p2.9.m9.1.1.cmml">0</mn><mo id="S2.SS1.p2.9.m9.3.4.2.3.2.2" stretchy="false" xref="S2.SS1.p2.9.m9.3.4.2.cmml">)</mo></mrow></mrow><mo id="S2.SS1.p2.9.m9.3.4.1" xref="S2.SS1.p2.9.m9.3.4.1.cmml">=</mo><mrow id="S2.SS1.p2.9.m9.3.4.3.2" xref="S2.SS1.p2.9.m9.3.4.3.1.cmml"><mo id="S2.SS1.p2.9.m9.3.4.3.2.1" stretchy="false" xref="S2.SS1.p2.9.m9.3.4.3.1.cmml">{</mo><mtext id="S2.SS1.p2.9.m9.2.2" xref="S2.SS1.p2.9.m9.2.2a.cmml">‘false’</mtext><mo id="S2.SS1.p2.9.m9.3.4.3.2.2" xref="S2.SS1.p2.9.m9.3.4.3.1.cmml">,</mo><mtext id="S2.SS1.p2.9.m9.3.3" xref="S2.SS1.p2.9.m9.3.3a.cmml">‘negative’</mtext><mo id="S2.SS1.p2.9.m9.3.4.3.2.3" stretchy="false" xref="S2.SS1.p2.9.m9.3.4.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.9.m9.3b"><apply id="S2.SS1.p2.9.m9.3.4.cmml" xref="S2.SS1.p2.9.m9.3.4"><eq id="S2.SS1.p2.9.m9.3.4.1.cmml" xref="S2.SS1.p2.9.m9.3.4.1"></eq><apply id="S2.SS1.p2.9.m9.3.4.2.cmml" xref="S2.SS1.p2.9.m9.3.4.2"><times id="S2.SS1.p2.9.m9.3.4.2.1.cmml" xref="S2.SS1.p2.9.m9.3.4.2.1"></times><ci id="S2.SS1.p2.9.m9.3.4.2.2.cmml" xref="S2.SS1.p2.9.m9.3.4.2.2">𝑉</ci><cn id="S2.SS1.p2.9.m9.1.1.cmml" type="integer" xref="S2.SS1.p2.9.m9.1.1">0</cn></apply><set id="S2.SS1.p2.9.m9.3.4.3.1.cmml" xref="S2.SS1.p2.9.m9.3.4.3.2"><ci id="S2.SS1.p2.9.m9.2.2a.cmml" xref="S2.SS1.p2.9.m9.2.2"><mtext id="S2.SS1.p2.9.m9.2.2.cmml" xref="S2.SS1.p2.9.m9.2.2">‘false’</mtext></ci><ci id="S2.SS1.p2.9.m9.3.3a.cmml" xref="S2.SS1.p2.9.m9.3.3"><mtext id="S2.SS1.p2.9.m9.3.3.cmml" xref="S2.SS1.p2.9.m9.3.3">‘negative’</mtext></ci></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.9.m9.3c">V(0)=\{\text{`false'},\text{`negative'}\}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p2.9.m9.3d">italic_V ( 0 ) = { ‘false’ , ‘negative’ }</annotation></semantics></math>和<math alttext="V(1)=\{\text{`true'},\text{`positive'}\}" class="ltx_Math" display="inline" id="S2.SS1.p2.10.m10.3"><semantics id="S2.SS1.p2.10.m10.3a"><mrow id="S2.SS1.p2.10.m10.3.4" xref="S2.SS1.p2.10.m10.3.4.cmml"><mrow id="S2.SS1.p2.10.m10.3.4.2" xref="S2.SS1.p2.10.m10.3.4.2.cmml"><mi id="S2.SS1.p2.10.m10.3.4.2.2" xref="S2.SS1.p2.10.m10.3.4.2.2.cmml">V</mi><mo id="S2.SS1.p2.10.m10.3.4.2.1" xref="S2.SS1.p2.10.m10.3.4.2.1.cmml">⁢</mo><mrow id="S2.SS1.p2.10.m10.3.4.2.3.2" xref="S2.SS1.p2.10.m10.3.4.2.cmml"><mo id="S2.SS1.p2.10.m10.3.4.2.3.2.1" stretchy="false" xref="S2.SS1.p2.10.m10.3.4.2.cmml">(</mo><mn id="S2.SS1.p2.10.m10.1.1" xref="S2.SS1.p2.10.m10.1.1.cmml">1</mn><mo id="S2.SS1.p2.10.m10.3.4.2.3.2.2" stretchy="false" xref="S2.SS1.p2.10.m10.3.4.2.cmml">)</mo></mrow></mrow><mo id="S2.SS1.p2.10.m10.3.4.1" xref="S2.SS1.p2.10.m10.3.4.1.cmml">=</mo><mrow id="S2.SS1.p2.10.m10.3.4.3.2" xref="S2.SS1.p2.10.m10.3.4.3.1.cmml"><mo id="S2.SS1.p2.10.m10.3.4.3.2.1" stretchy="false" xref="S2.SS1.p2.10.m10.3.4.3.1.cmml">{</mo><mtext id="S2.SS1.p2.10.m10.2.2" xref="S2.SS1.p2.10.m10.2.2a.cmml">‘true’</mtext><mo id="S2.SS1.p2.10.m10.3.4.3.2.2" xref="S2.SS1.p2.10.m10.3.4.3.1.cmml">,</mo><mtext id="S2.SS1.p2.10.m10.3.3" xref="S2.SS1.p2.10.m10.3.3a.cmml">‘positive’</mtext><mo id="S2.SS1.p2.10.m10.3.4.3.2.3" stretchy="false" xref="S2.SS1.p2.10.m10.3.4.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.10.m10.3b"><apply id="S2.SS1.p2.10.m10.3.4.cmml" xref="S2.SS1.p2.10.m10.3.4"><eq id="S2.SS1.p2.10.m10.3.4.1.cmml" xref="S2.SS1.p2.10.m10.3.4.1"></eq><apply id="S2.SS1.p2.10.m10.3.4.2.cmml" xref="S2.SS1.p2.10.m10.3.4.2"><times id="S2.SS1.p2.10.m10.3.4.2.1.cmml" xref="S2.SS1.p2.10.m10.3.4.2.1"></times><ci id="S2.SS1.p2.10.m10.3.4.2.2.cmml" xref="S2.SS1.p2.10.m10.3.4.2.2">𝑉</ci><cn id="S2.SS1.p2.10.m10.1.1.cmml" type="integer" xref="S2.SS1.p2.10.m10.1.1">1</cn></apply><set id="S2.SS1.p2.10.m10.3.4.3.1.cmml" xref="S2.SS1.p2.10.m10.3.4.3.2"><ci id="S2.SS1.p2.10.m10.2.2a.cmml" xref="S2.SS1.p2.10.m10.2.2"><mtext id="S2.SS1.p2.10.m10.2.2.cmml" xref="S2.SS1.p2.10.m10.2.2">‘true’</mtext></ci><ci id="S2.SS1.p2.10.m10.3.3a.cmml" xref="S2.SS1.p2.10.m10.3.3"><mtext id="S2.SS1.p2.10.m10.3.3.cmml" xref="S2.SS1.p2.10.m10.3.3">‘positive’</mtext></ci></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.10.m10.3c">V(1)=\{\text{`true'},\text{`positive'}\}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p2.10.m10.3d">italic_V ( 1 ) = { ‘true’ , ‘positive’ }</annotation></semantics></math>。</p>
</div>
<div class="ltx_para" id="S2.SS1.p3">
<p class="ltx_p" id="S2.SS1.p3.1">请注意，ICL中的“学习”一词是一个误称，因为LLM的解码器参数没有更新。有关ICL的更多细节，请参考这些优秀的调查。 <cite class="ltx_cite ltx_citemacro_citep">(Dong et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib21" title="">2023</a>; Luo et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib48" title="">2024</a>)</cite></p>
</div>
<figure class="ltx_figure" id="S2.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="314" id="S2.F2.g1" src="resource/x2.png" width="1245"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">图2。 </span>情感分类的上下文学习示例工作流程。这个说明性的示例展示了一个样本测试实例，其中单个演示（从训练集中检索）并没有导致正确的预测（顶部显示的预测）。该示例还显示，将演示数量从一个增加到两个会导致正确的预测（底部显示）。提示中包含的演示以蓝色显示。</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">2.2. </span>信息检索的作用</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.2">ICL（如图<a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#S2.F2" title="Figure 2 ‣ 2.1. A Formal Introduction ‣ 2. In-Context Learning ‣ “In-Context Learning” or: How I learned to stop worrying and love “Applied Information Retrieval”"><span class="ltx_text ltx_ref_tag">2</span></a>所示）中最重要的组成部分之一是搜索组件，它从训练集中输出一个顶级<math alttext="k" class="ltx_Math" display="inline" id="S2.SS2.p1.1.m1.1"><semantics id="S2.SS2.p1.1.m1.1a"><mi id="S2.SS2.p1.1.m1.1.1" xref="S2.SS2.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.1.m1.1b"><ci id="S2.SS2.p1.1.m1.1.1.cmml" xref="S2.SS2.p1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p1.1.m1.1d">italic_k</annotation></semantics></math>候选集，即方程<a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#S2.E1" title="In 2.1. A Formal Introduction ‣ 2. In-Context Learning ‣ “In-Context Learning” or: How I learned to stop worrying and love “Applied Information Retrieval”"><span class="ltx_text ltx_ref_tag">1</span></a>的<span class="ltx_text ltx_font_italic" id="S2.SS2.p1.2.1">相似</span>实例。尽管原则上可以在提示中包含训练集中的随机示例，但已经证明，局部化示例（即与当前实例在主题上相似的示例）能够获得更好的性能<cite class="ltx_cite ltx_citemacro_citep">(Liu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib45" title="">2022</a>; Luo et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib48" title="">2024</a>)</cite>。这能够起作用的原因可以追溯到再生核希尔伯特空间（RKHS）机器学习的基本原则 - 预测函数是围绕训练数据实例的参数化核函数的聚合<cite class="ltx_cite ltx_citemacro_citep">(Paulsen and Raghupathi, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib61" title="">2016</a>)</cite>。</p>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1">因此，从训练集中检索尽可能多的相关示例对于效率原因施加实际约束非常关键-IR临时检索中召回和精度的经典权衡；唯一的区别是ICL的相关性需要以示例对正确预测的效用或有用性来定义。</p>
</div>
<div class="ltx_para" id="S2.SS2.p3">
<p class="ltx_p" id="S2.SS2.p3.1">在信息检索中探讨的一个类似问题是在排名列表中停止阅读的位置，因为由于在特定排名截止点之后找到相关文档的概率较低，检索文档的效用很小 <cite class="ltx_cite ltx_citemacro_citep">(Arampatzis et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib3" title="">2009</a>; Bahri et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib5" title="">2020</a>)</cite>。更具挑战性的是，这个排名截止点取决于收集中出现的相关文档数量，也就是说，尽管一些具有明确定义信息需求的查询与满足特定相关性标准的少量相关文档相关联，但其他具有更广泛信息需求的查询通常与更多相关文档相关联 <cite class="ltx_cite ltx_citemacro_citep">(Carterette et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib7" title="">[n. d.]</a>)</cite>。在核心信息检索研究中，这个问题通常通过估计查询的检索质量来解决 - 假设是良好定义的查询产生更好的检索结果（精确度和召回率），而定义不明确的查询由于信息需求的明显歧义而受到检索质量的影响。这种动机为接下来的部分铺平了道路，在那里我们讨论了查询性能预测（QPP）如何对检索ICL中类似示例的相关问题也有益。</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">3. </span>自适应ICL <math alttext="\mapsto" class="ltx_Math" display="inline" id="S3.1.m1.1"><semantics id="S3.1.m1.1b"><mo id="S3.1.m1.1.1" stretchy="false" xref="S3.1.m1.1.1.cmml">↦</mo><annotation-xml encoding="MathML-Content" id="S3.1.m1.1c"><csymbol cd="latexml" id="S3.1.m1.1.1.cmml" xref="S3.1.m1.1.1">maps-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.1.m1.1d">\mapsto</annotation><annotation encoding="application/x-llamapun" id="S3.1.m1.1e">↦</annotation></semantics></math> QPP？</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">在这一部分，我们描述了一种自适应的方法来选择ICL示例。我们概述了IR文献中的类似原则，可以应用于更广泛的任务。</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">3.1. </span>可变数量的示例</h3>
<figure class="ltx_figure" id="S3.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="412" id="S3.F3.g1" src="resource/x3.png" width="540"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">图3。</span>
使用可变大小邻域进行<math alttext="k" class="ltx_Math" display="inline" id="S3.F3.2.m1.1"><semantics id="S3.F3.2.m1.1b"><mi id="S3.F3.2.m1.1.1" xref="S3.F3.2.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.F3.2.m1.1c"><ci id="S3.F3.2.m1.1.1.cmml" xref="S3.F3.2.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.2.m1.1d">k</annotation><annotation encoding="application/x-llamapun" id="S3.F3.2.m1.1e">italic_k</annotation></semantics></math>-NN分类<cite class="ltx_cite ltx_citemacro_citep">(Zhang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib88" title="">2017</a>)</cite>的动机：接近决策边界的实例（黑色'?'）很可能在其类分布中具有更高的异质性，因此需要更大的邻域来进行有效分类。</figcaption>
</figure>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">在信息检索领域观察到不同查询展现出不同的检索性能水平，可以用于信息检索学习，我们可以通过类比得出一些测试实例与更好的训练示例相关联（即，将它们作为提示的一部分导致正确预测的示例），因此包含其中的少量示例应该是足够的。另一方面，对于一些测试实例（用作信息检索学习的查询），检索质量并不产生良好的候选项。因此，需要进一步查看排名列表以收集有用的示例。</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.6">我们将使用不同数量的演示来进行ICL推理方法，并将其命名为“<span class="ltx_text ltx_font_bold" id="S3.SS1.p2.6.1">自适应上下文学习</span>”，简称AICL。
AICL的核心思想是以数据驱动的方式选择上下文<math alttext="\mathcal{P}_{k}(\mathbf{x})" class="ltx_Math" display="inline" id="S3.SS1.p2.1.m1.1"><semantics id="S3.SS1.p2.1.m1.1a"><mrow id="S3.SS1.p2.1.m1.1.2" xref="S3.SS1.p2.1.m1.1.2.cmml"><msub id="S3.SS1.p2.1.m1.1.2.2" xref="S3.SS1.p2.1.m1.1.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p2.1.m1.1.2.2.2" xref="S3.SS1.p2.1.m1.1.2.2.2.cmml">𝒫</mi><mi id="S3.SS1.p2.1.m1.1.2.2.3" xref="S3.SS1.p2.1.m1.1.2.2.3.cmml">k</mi></msub><mo id="S3.SS1.p2.1.m1.1.2.1" xref="S3.SS1.p2.1.m1.1.2.1.cmml">⁢</mo><mrow id="S3.SS1.p2.1.m1.1.2.3.2" xref="S3.SS1.p2.1.m1.1.2.cmml"><mo id="S3.SS1.p2.1.m1.1.2.3.2.1" stretchy="false" xref="S3.SS1.p2.1.m1.1.2.cmml">(</mo><mi id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml">𝐱</mi><mo id="S3.SS1.p2.1.m1.1.2.3.2.2" stretchy="false" xref="S3.SS1.p2.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><apply id="S3.SS1.p2.1.m1.1.2.cmml" xref="S3.SS1.p2.1.m1.1.2"><times id="S3.SS1.p2.1.m1.1.2.1.cmml" xref="S3.SS1.p2.1.m1.1.2.1"></times><apply id="S3.SS1.p2.1.m1.1.2.2.cmml" xref="S3.SS1.p2.1.m1.1.2.2"><csymbol cd="ambiguous" id="S3.SS1.p2.1.m1.1.2.2.1.cmml" xref="S3.SS1.p2.1.m1.1.2.2">subscript</csymbol><ci id="S3.SS1.p2.1.m1.1.2.2.2.cmml" xref="S3.SS1.p2.1.m1.1.2.2.2">𝒫</ci><ci id="S3.SS1.p2.1.m1.1.2.2.3.cmml" xref="S3.SS1.p2.1.m1.1.2.2.3">𝑘</ci></apply><ci id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">𝐱</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">\mathcal{P}_{k}(\mathbf{x})</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.1.m1.1d">caligraphic_P start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( bold_x )</annotation></semantics></math>，即将<math alttext="k" class="ltx_Math" display="inline" id="S3.SS1.p2.2.m2.1"><semantics id="S3.SS1.p2.2.m2.1a"><mi id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.1b"><ci id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.2.m2.1d">italic_k</annotation></semantics></math>作为数据（当前实例<math alttext="\mathbf{x}" class="ltx_Math" display="inline" id="S3.SS1.p2.3.m3.1"><semantics id="S3.SS1.p2.3.m3.1a"><mi id="S3.SS1.p2.3.m3.1.1" xref="S3.SS1.p2.3.m3.1.1.cmml">𝐱</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m3.1b"><ci id="S3.SS1.p2.3.m3.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1">𝐱</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m3.1c">\mathbf{x}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.3.m3.1d">bold_x</annotation></semantics></math>）本身的函数。这在某种程度上类似于为基于<math alttext="k" class="ltx_Math" display="inline" id="S3.SS1.p2.5.m5.1"><semantics id="S3.SS1.p2.5.m5.1a"><mi id="S3.SS1.p2.5.m5.1.1" xref="S3.SS1.p2.5.m5.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.5.m5.1b"><ci id="S3.SS1.p2.5.m5.1.1.cmml" xref="S3.SS1.p2.5.m5.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.5.m5.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.5.m5.1d">italic_k</annotation></semantics></math>-NN的非参数建模选择不同的<math alttext="k" class="ltx_Math" display="inline" id="S3.SS1.p2.4.m4.1"><semantics id="S3.SS1.p2.4.m4.1a"><mi id="S3.SS1.p2.4.m4.1.1" xref="S3.SS1.p2.4.m4.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.4.m4.1b"><ci id="S3.SS1.p2.4.m4.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.4.m4.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.4.m4.1d">italic_k</annotation></semantics></math>值<cite class="ltx_cite ltx_citemacro_citep">(Zhang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib88" title="">2017</a>)</cite>，如图<a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#S3.F3" title="Figure 3 ‣ 3.1. A Variable Number of Examples ‣ 3. Adaptive ICL ↦ QPP? ‣ “In-Context Learning” or: How I learned to stop worrying and love “Applied Information Retrieval”"><span class="ltx_text ltx_ref_tag">3</span></a>所示。动机是对一些实例进行分类可能比其他实例更困难，在这种情况下，它们可能会受益于更大的<math alttext="k" class="ltx_Math" display="inline" id="S3.SS1.p2.6.m6.1"><semantics id="S3.SS1.p2.6.m6.1a"><mi id="S3.SS1.p2.6.m6.1.1" xref="S3.SS1.p2.6.m6.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.6.m6.1b"><ci id="S3.SS1.p2.6.m6.1.1.cmml" xref="S3.SS1.p2.6.m6.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.6.m6.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.6.m6.1d">italic_k</annotation></semantics></math>值（更多上下文）。另一方面，对于相对简单的数据实例，过多的上下文可能会对有效预测产生不利影响。</p>
</div>
<div class="ltx_para" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.2">严格来说，AICL与ICL的不同之处（方程<a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#S2.E1" title="In 2.1. A Formal Introduction ‣ 2. In-Context Learning ‣ “In-Context Learning” or: How I learned to stop worrying and love “Applied Information Retrieval”"><span class="ltx_text ltx_ref_tag">1</span></a>）在于，表示邻域大小的值<math alttext="k" class="ltx_Math" display="inline" id="S3.SS1.p3.1.m1.1"><semantics id="S3.SS1.p3.1.m1.1a"><mi id="S3.SS1.p3.1.m1.1.1" xref="S3.SS1.p3.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.1.m1.1b"><ci id="S3.SS1.p3.1.m1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.1.m1.1d">italic_k</annotation></semantics></math>不再是一个常数。相反，我们用参数化函数<math alttext="\kappa(\mathbf{x})" class="ltx_Math" display="inline" id="S3.SS1.p3.2.m2.1"><semantics id="S3.SS1.p3.2.m2.1a"><mrow id="S3.SS1.p3.2.m2.1.2" xref="S3.SS1.p3.2.m2.1.2.cmml"><mi id="S3.SS1.p3.2.m2.1.2.2" xref="S3.SS1.p3.2.m2.1.2.2.cmml">κ</mi><mo id="S3.SS1.p3.2.m2.1.2.1" xref="S3.SS1.p3.2.m2.1.2.1.cmml">⁢</mo><mrow id="S3.SS1.p3.2.m2.1.2.3.2" xref="S3.SS1.p3.2.m2.1.2.cmml"><mo id="S3.SS1.p3.2.m2.1.2.3.2.1" stretchy="false" xref="S3.SS1.p3.2.m2.1.2.cmml">(</mo><mi id="S3.SS1.p3.2.m2.1.1" xref="S3.SS1.p3.2.m2.1.1.cmml">𝐱</mi><mo id="S3.SS1.p3.2.m2.1.2.3.2.2" stretchy="false" xref="S3.SS1.p3.2.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.2.m2.1b"><apply id="S3.SS1.p3.2.m2.1.2.cmml" xref="S3.SS1.p3.2.m2.1.2"><times id="S3.SS1.p3.2.m2.1.2.1.cmml" xref="S3.SS1.p3.2.m2.1.2.1"></times><ci id="S3.SS1.p3.2.m2.1.2.2.cmml" xref="S3.SS1.p3.2.m2.1.2.2">𝜅</ci><ci id="S3.SS1.p3.2.m2.1.1.cmml" xref="S3.SS1.p3.2.m2.1.1">𝐱</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.2.m2.1c">\kappa(\mathbf{x})</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.2.m2.1d">italic_κ ( bold_x )</annotation></semantics></math>来表示它。</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_left">(2)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="P(y|\mathbf{x})=f(\mathbf{x},\mathcal{P}_{\kappa(\mathbf{x})}(\mathbf{x});\phi%
_{\text{LLM}})," class="ltx_Math" display="block" id="S3.E2.m1.4"><semantics id="S3.E2.m1.4a"><mrow id="S3.E2.m1.4.4.1" xref="S3.E2.m1.4.4.1.1.cmml"><mrow id="S3.E2.m1.4.4.1.1" xref="S3.E2.m1.4.4.1.1.cmml"><mrow id="S3.E2.m1.4.4.1.1.1" xref="S3.E2.m1.4.4.1.1.1.cmml"><mi id="S3.E2.m1.4.4.1.1.1.3" xref="S3.E2.m1.4.4.1.1.1.3.cmml">P</mi><mo id="S3.E2.m1.4.4.1.1.1.2" xref="S3.E2.m1.4.4.1.1.1.2.cmml">⁢</mo><mrow id="S3.E2.m1.4.4.1.1.1.1.1" xref="S3.E2.m1.4.4.1.1.1.1.1.1.cmml"><mo id="S3.E2.m1.4.4.1.1.1.1.1.2" stretchy="false" xref="S3.E2.m1.4.4.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E2.m1.4.4.1.1.1.1.1.1" xref="S3.E2.m1.4.4.1.1.1.1.1.1.cmml"><mi id="S3.E2.m1.4.4.1.1.1.1.1.1.2" xref="S3.E2.m1.4.4.1.1.1.1.1.1.2.cmml">y</mi><mo fence="false" id="S3.E2.m1.4.4.1.1.1.1.1.1.1" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.cmml">|</mo><mi id="S3.E2.m1.4.4.1.1.1.1.1.1.3" xref="S3.E2.m1.4.4.1.1.1.1.1.1.3.cmml">𝐱</mi></mrow><mo id="S3.E2.m1.4.4.1.1.1.1.1.3" stretchy="false" xref="S3.E2.m1.4.4.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.4.4.1.1.4" xref="S3.E2.m1.4.4.1.1.4.cmml">=</mo><mrow id="S3.E2.m1.4.4.1.1.3" xref="S3.E2.m1.4.4.1.1.3.cmml"><mi id="S3.E2.m1.4.4.1.1.3.4" xref="S3.E2.m1.4.4.1.1.3.4.cmml">f</mi><mo id="S3.E2.m1.4.4.1.1.3.3" xref="S3.E2.m1.4.4.1.1.3.3.cmml">⁢</mo><mrow id="S3.E2.m1.4.4.1.1.3.2.2" xref="S3.E2.m1.4.4.1.1.3.2.3.cmml"><mo id="S3.E2.m1.4.4.1.1.3.2.2.3" stretchy="false" xref="S3.E2.m1.4.4.1.1.3.2.3.cmml">(</mo><mi id="S3.E2.m1.3.3" xref="S3.E2.m1.3.3.cmml">𝐱</mi><mo id="S3.E2.m1.4.4.1.1.3.2.2.4" xref="S3.E2.m1.4.4.1.1.3.2.3.cmml">,</mo><mrow id="S3.E2.m1.4.4.1.1.2.1.1.1" xref="S3.E2.m1.4.4.1.1.2.1.1.1.cmml"><msub id="S3.E2.m1.4.4.1.1.2.1.1.1.2" xref="S3.E2.m1.4.4.1.1.2.1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.4.4.1.1.2.1.1.1.2.2" xref="S3.E2.m1.4.4.1.1.2.1.1.1.2.2.cmml">𝒫</mi><mrow id="S3.E2.m1.1.1.1" xref="S3.E2.m1.1.1.1.cmml"><mi id="S3.E2.m1.1.1.1.3" xref="S3.E2.m1.1.1.1.3.cmml">κ</mi><mo id="S3.E2.m1.1.1.1.2" xref="S3.E2.m1.1.1.1.2.cmml">⁢</mo><mrow id="S3.E2.m1.1.1.1.4.2" xref="S3.E2.m1.1.1.1.cmml"><mo id="S3.E2.m1.1.1.1.4.2.1" stretchy="false" xref="S3.E2.m1.1.1.1.cmml">(</mo><mi id="S3.E2.m1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.cmml">𝐱</mi><mo id="S3.E2.m1.1.1.1.4.2.2" stretchy="false" xref="S3.E2.m1.1.1.1.cmml">)</mo></mrow></mrow></msub><mo id="S3.E2.m1.4.4.1.1.2.1.1.1.1" xref="S3.E2.m1.4.4.1.1.2.1.1.1.1.cmml">⁢</mo><mrow id="S3.E2.m1.4.4.1.1.2.1.1.1.3.2" xref="S3.E2.m1.4.4.1.1.2.1.1.1.cmml"><mo id="S3.E2.m1.4.4.1.1.2.1.1.1.3.2.1" stretchy="false" xref="S3.E2.m1.4.4.1.1.2.1.1.1.cmml">(</mo><mi id="S3.E2.m1.2.2" xref="S3.E2.m1.2.2.cmml">𝐱</mi><mo id="S3.E2.m1.4.4.1.1.2.1.1.1.3.2.2" stretchy="false" xref="S3.E2.m1.4.4.1.1.2.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.4.4.1.1.3.2.2.5" xref="S3.E2.m1.4.4.1.1.3.2.3.cmml">;</mo><msub id="S3.E2.m1.4.4.1.1.3.2.2.2" xref="S3.E2.m1.4.4.1.1.3.2.2.2.cmml"><mi id="S3.E2.m1.4.4.1.1.3.2.2.2.2" xref="S3.E2.m1.4.4.1.1.3.2.2.2.2.cmml">ϕ</mi><mtext id="S3.E2.m1.4.4.1.1.3.2.2.2.3" xref="S3.E2.m1.4.4.1.1.3.2.2.2.3a.cmml">LLM</mtext></msub><mo id="S3.E2.m1.4.4.1.1.3.2.2.6" stretchy="false" xref="S3.E2.m1.4.4.1.1.3.2.3.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E2.m1.4.4.1.2" xref="S3.E2.m1.4.4.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.4b"><apply id="S3.E2.m1.4.4.1.1.cmml" xref="S3.E2.m1.4.4.1"><eq id="S3.E2.m1.4.4.1.1.4.cmml" xref="S3.E2.m1.4.4.1.1.4"></eq><apply id="S3.E2.m1.4.4.1.1.1.cmml" xref="S3.E2.m1.4.4.1.1.1"><times id="S3.E2.m1.4.4.1.1.1.2.cmml" xref="S3.E2.m1.4.4.1.1.1.2"></times><ci id="S3.E2.m1.4.4.1.1.1.3.cmml" xref="S3.E2.m1.4.4.1.1.1.3">𝑃</ci><apply id="S3.E2.m1.4.4.1.1.1.1.1.1.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1"><csymbol cd="latexml" id="S3.E2.m1.4.4.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1">conditional</csymbol><ci id="S3.E2.m1.4.4.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1.1.2">𝑦</ci><ci id="S3.E2.m1.4.4.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1.1.3">𝐱</ci></apply></apply><apply id="S3.E2.m1.4.4.1.1.3.cmml" xref="S3.E2.m1.4.4.1.1.3"><times id="S3.E2.m1.4.4.1.1.3.3.cmml" xref="S3.E2.m1.4.4.1.1.3.3"></times><ci id="S3.E2.m1.4.4.1.1.3.4.cmml" xref="S3.E2.m1.4.4.1.1.3.4">𝑓</ci><vector id="S3.E2.m1.4.4.1.1.3.2.3.cmml" xref="S3.E2.m1.4.4.1.1.3.2.2"><ci id="S3.E2.m1.3.3.cmml" xref="S3.E2.m1.3.3">𝐱</ci><apply id="S3.E2.m1.4.4.1.1.2.1.1.1.cmml" xref="S3.E2.m1.4.4.1.1.2.1.1.1"><times id="S3.E2.m1.4.4.1.1.2.1.1.1.1.cmml" xref="S3.E2.m1.4.4.1.1.2.1.1.1.1"></times><apply id="S3.E2.m1.4.4.1.1.2.1.1.1.2.cmml" xref="S3.E2.m1.4.4.1.1.2.1.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.4.4.1.1.2.1.1.1.2.1.cmml" xref="S3.E2.m1.4.4.1.1.2.1.1.1.2">subscript</csymbol><ci id="S3.E2.m1.4.4.1.1.2.1.1.1.2.2.cmml" xref="S3.E2.m1.4.4.1.1.2.1.1.1.2.2">𝒫</ci><apply id="S3.E2.m1.1.1.1.cmml" xref="S3.E2.m1.1.1.1"><times id="S3.E2.m1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.2"></times><ci id="S3.E2.m1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.3">𝜅</ci><ci id="S3.E2.m1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1">𝐱</ci></apply></apply><ci id="S3.E2.m1.2.2.cmml" xref="S3.E2.m1.2.2">𝐱</ci></apply><apply id="S3.E2.m1.4.4.1.1.3.2.2.2.cmml" xref="S3.E2.m1.4.4.1.1.3.2.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.4.4.1.1.3.2.2.2.1.cmml" xref="S3.E2.m1.4.4.1.1.3.2.2.2">subscript</csymbol><ci id="S3.E2.m1.4.4.1.1.3.2.2.2.2.cmml" xref="S3.E2.m1.4.4.1.1.3.2.2.2.2">italic-ϕ</ci><ci id="S3.E2.m1.4.4.1.1.3.2.2.2.3a.cmml" xref="S3.E2.m1.4.4.1.1.3.2.2.2.3"><mtext id="S3.E2.m1.4.4.1.1.3.2.2.2.3.cmml" mathsize="70%" xref="S3.E2.m1.4.4.1.1.3.2.2.2.3">LLM</mtext></ci></apply></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.4c">P(y|\mathbf{x})=f(\mathbf{x},\mathcal{P}_{\kappa(\mathbf{x})}(\mathbf{x});\phi%
_{\text{LLM}}),</annotation><annotation encoding="application/x-llamapun" id="S3.E2.m1.4d">italic_P ( italic_y | bold_x ) = italic_f ( bold_x , caligraphic_P start_POSTSUBSCRIPT italic_κ ( bold_x ) end_POSTSUBSCRIPT ( bold_x ) ; italic_ϕ start_POSTSUBSCRIPT LLM end_POSTSUBSCRIPT ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.p3.5">在<math alttext="\kappa:\mathbf{x}\mapsto\{0,\ldots,M\}" class="ltx_Math" display="inline" id="S3.SS1.p3.3.m1.3"><semantics id="S3.SS1.p3.3.m1.3a"><mrow id="S3.SS1.p3.3.m1.3.4" xref="S3.SS1.p3.3.m1.3.4.cmml"><mi id="S3.SS1.p3.3.m1.3.4.2" xref="S3.SS1.p3.3.m1.3.4.2.cmml">κ</mi><mo id="S3.SS1.p3.3.m1.3.4.1" lspace="0.278em" rspace="0.278em" xref="S3.SS1.p3.3.m1.3.4.1.cmml">:</mo><mrow id="S3.SS1.p3.3.m1.3.4.3" xref="S3.SS1.p3.3.m1.3.4.3.cmml"><mi id="S3.SS1.p3.3.m1.3.4.3.2" xref="S3.SS1.p3.3.m1.3.4.3.2.cmml">𝐱</mi><mo id="S3.SS1.p3.3.m1.3.4.3.1" stretchy="false" xref="S3.SS1.p3.3.m1.3.4.3.1.cmml">↦</mo><mrow id="S3.SS1.p3.3.m1.3.4.3.3.2" xref="S3.SS1.p3.3.m1.3.4.3.3.1.cmml"><mo id="S3.SS1.p3.3.m1.3.4.3.3.2.1" stretchy="false" xref="S3.SS1.p3.3.m1.3.4.3.3.1.cmml">{</mo><mn id="S3.SS1.p3.3.m1.1.1" xref="S3.SS1.p3.3.m1.1.1.cmml">0</mn><mo id="S3.SS1.p3.3.m1.3.4.3.3.2.2" xref="S3.SS1.p3.3.m1.3.4.3.3.1.cmml">,</mo><mi id="S3.SS1.p3.3.m1.2.2" mathvariant="normal" xref="S3.SS1.p3.3.m1.2.2.cmml">…</mi><mo id="S3.SS1.p3.3.m1.3.4.3.3.2.3" xref="S3.SS1.p3.3.m1.3.4.3.3.1.cmml">,</mo><mi id="S3.SS1.p3.3.m1.3.3" xref="S3.SS1.p3.3.m1.3.3.cmml">M</mi><mo id="S3.SS1.p3.3.m1.3.4.3.3.2.4" stretchy="false" xref="S3.SS1.p3.3.m1.3.4.3.3.1.cmml">}</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.3.m1.3b"><apply id="S3.SS1.p3.3.m1.3.4.cmml" xref="S3.SS1.p3.3.m1.3.4"><ci id="S3.SS1.p3.3.m1.3.4.1.cmml" xref="S3.SS1.p3.3.m1.3.4.1">:</ci><ci id="S3.SS1.p3.3.m1.3.4.2.cmml" xref="S3.SS1.p3.3.m1.3.4.2">𝜅</ci><apply id="S3.SS1.p3.3.m1.3.4.3.cmml" xref="S3.SS1.p3.3.m1.3.4.3"><csymbol cd="latexml" id="S3.SS1.p3.3.m1.3.4.3.1.cmml" xref="S3.SS1.p3.3.m1.3.4.3.1">maps-to</csymbol><ci id="S3.SS1.p3.3.m1.3.4.3.2.cmml" xref="S3.SS1.p3.3.m1.3.4.3.2">𝐱</ci><set id="S3.SS1.p3.3.m1.3.4.3.3.1.cmml" xref="S3.SS1.p3.3.m1.3.4.3.3.2"><cn id="S3.SS1.p3.3.m1.1.1.cmml" type="integer" xref="S3.SS1.p3.3.m1.1.1">0</cn><ci id="S3.SS1.p3.3.m1.2.2.cmml" xref="S3.SS1.p3.3.m1.2.2">…</ci><ci id="S3.SS1.p3.3.m1.3.3.cmml" xref="S3.SS1.p3.3.m1.3.3">𝑀</ci></set></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.3.m1.3c">\kappa:\mathbf{x}\mapsto\{0,\ldots,M\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.3.m1.3d">italic_κ : bold_x ↦ { 0 , … , italic_M }</annotation></semantics></math>的情况下，
<math alttext="M" class="ltx_Math" display="inline" id="S3.SS1.p3.4.m2.1"><semantics id="S3.SS1.p3.4.m2.1a"><mi id="S3.SS1.p3.4.m2.1.1" xref="S3.SS1.p3.4.m2.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.4.m2.1b"><ci id="S3.SS1.p3.4.m2.1.1.cmml" xref="S3.SS1.p3.4.m2.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.4.m2.1c">M</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.4.m2.1d">italic_M</annotation></semantics></math>是示例实例数量的上限。
我们现在建议如何应用无监督或监督方法来选择排名截止<math alttext="\kappa" class="ltx_Math" display="inline" id="S3.SS1.p3.5.m3.1"><semantics id="S3.SS1.p3.5.m3.1a"><mi id="S3.SS1.p3.5.m3.1.1" xref="S3.SS1.p3.5.m3.1.1.cmml">κ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.5.m3.1b"><ci id="S3.SS1.p3.5.m3.1.1.cmml" xref="S3.SS1.p3.5.m3.1.1">𝜅</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.5.m3.1c">\kappa</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.5.m3.1d">italic_κ</annotation></semantics></math>。</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">3.2. </span>无监督排名截断</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">在无监督方法中，IR研究中的两个主要思想可以用来确定ICL中的示例数量。</p>
</div>
<section class="ltx_paragraph" id="S3.SS2.SSS0.Px1">
<h4 class="ltx_title ltx_font_bold ltx_title_paragraph">Score Distribution-based Models</h4>
<div class="ltx_para" id="S3.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="S3.SS2.SSS0.Px1.p1.1">第一条工作线基于一个假设，即相关和非相关文档的分数遵循不同的统计分布，例如，<cite class="ltx_cite ltx_citemacro_citeauthor"><a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib3" title="">Arampatzis et al<span class="ltx_text">.</span></a></cite>建议使用正态-指数分布的混合分布 - 用于相关文档的正态分布和用于非相关文档的指数分布 - 来建模排名靠前的文档的分数分布。 <cite class="ltx_cite ltx_citemacro_citep">(Arampatzis et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib3" title="">2009</a>)</cite>的工作使用期望最大化（EM）来估计这种混合分布的参数，从而预测最可能的截止排名，在这之后找到相关文档的概率会显著降低。利用相关和非相关文档的分数分布之间的特征差异的这种想法也被用于查询性能预测（QPP）<cite class="ltx_cite ltx_citemacro_citep">(Cummins, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib13" title="">2014</a>)</cite>。</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS0.Px1.p2">
<p class="ltx_p" id="S3.SS2.SSS0.Px1.p2.1">虽然来自检索分数的EM允许应用可变数量的示例，但以下是一些需要研究的ICL特定挑战。</p>
<ul class="ltx_itemize" id="S3.I1">
<li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I1.i1.p1">
<p class="ltx_p" id="S3.I1.i1.p1.1">随着相关性概念被改变为<span class="ltx_text ltx_font_bold" id="S3.I1.i1.p1.1.1">‘下游效用’</span>，有用和无用示例的分数分布可能不会遵循正态-指数的混合分布，如在<cite class="ltx_cite ltx_citemacro_citep">(Arampatzis et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib3" title="">2009</a>; Cummins, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib13" title="">2014</a>)</cite>中所报道的那样。在ICL的背景下，研究相似分数与示例的下游效用之间的潜在关系将是一个有趣的未来研究方向。</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I1.i2.p1">
<p class="ltx_p" id="S3.I1.i2.p1.1">在得分分布上设置阈值，很难将截止值限制在最大值，这对于LLM的输入大小有最大限制而言是必不可少的。</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I1.i3.p1">
<p class="ltx_p" id="S3.I1.i3.p1.1">基于分数分布的方法并未明确考虑来自查询本身的信息（等效地，ICL中的测试实例）。</p>
</div>
</li>
</ul>
<p class="ltx_p" id="S3.SS2.SSS0.Px1.p2.2">我们现在描述了信息检索研究中的另一线索，可能有助于缓解最后两个限制。</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS2.SSS0.Px2">
<h4 class="ltx_title ltx_font_bold ltx_title_paragraph">基于QPP的模型</h4>
<div class="ltx_para" id="S3.SS2.SSS0.Px2.p1">
<p class="ltx_p" id="S3.SS2.SSS0.Px2.p1.1">不同于排名截止策略，查询性能预测（QPP）模型旨在估计查询的检索质量。直接类比的是，这些方法可以应用于ICL中检索到的前几个相似示例，其不同目标是预测示例的有用性。</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS0.Px2.p2">
<p class="ltx_p" id="S3.SS2.SSS0.Px2.p2.1">大多数QPP中的经典作品涉及无监督方法，利用从一组最高检索文档中提取的信息来估计最高检索文档与集合其余部分的主题区别 - 一个大的差异表明潜在更好的检索质量。<cite class="ltx_cite ltx_citemacro_citep">(Cronen-Townsend et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib11" title="">2002</a>)</cite>从最高检索文档中提取的各种证据已被证明对不同的后检索QPP估计方法是有用的。这包括i）Clarity中最高检索文档的语言模型与集合模型之间的KL散度<cite class="ltx_cite ltx_citemacro_citep">(Cronen-Townsend et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib11" title="">2002</a>)</cite>，ii）WIG（加权信息增益）中每个最高检索文档相对于集合的信息增益的聚合值<cite class="ltx_cite ltx_citemacro_citep">(Zhou and Croft, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib89" title="">2007</a>)</cite>，iii）NQC（标准化查询承诺）中用方差测量的RSV（检索状态值）的偏斜<cite class="ltx_cite ltx_citemacro_citep">(Shtok et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib73" title="">2012</a>)</cite>，iv）基于成对文档相似性矩阵的聚类假设的思想<cite class="ltx_cite ltx_citemacro_citep">(Diaz, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib20" title="">2007</a>)</cite>，以及，最近，v）文档和查询的嵌入空间的特征<cite class="ltx_cite ltx_citemacro_citep">(Roy et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib67" title="">2019</a>; Faggioli et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib22" title="">2023</a>)</cite>。</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS0.Px2.p3">
<p class="ltx_p" id="S3.SS2.SSS0.Px2.p3.1">适当地改编这些现有技术可以应用于两阶段流水线中，以确定ICL中示例的数量。作为第一步，可以采用QPP方法来预测一组有序示例的检索质量（有用性），高值可能表明有用的示例可能位于顶部排名，因此，可能少量的示例应该能够很好地工作。另一方面，低QPP估计可能表明顶级排名的示例不太可能对下游预测有用，在这种情况下，最好使用大量的示例。选择排名截止（具有上限）作为QPP分数的函数的方法已经应用于确定稳健检索评估所需的可变深度的相关性评估<cite class="ltx_cite ltx_citemacro_citep">(Ganguly and Yilmaz, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib26" title="">2023</a>)</cite>。</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">3.3. </span>监督排序截断</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.4">相对于设计启发式来预测用于测试实例<math alttext="\mathbf{x}" class="ltx_Math" display="inline" id="S3.SS3.p1.1.m1.1"><semantics id="S3.SS3.p1.1.m1.1a"><mi id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml">𝐱</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><ci id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">𝐱</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">\mathbf{x}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.1.m1.1d">bold_x</annotation></semantics></math>的训练示例数量，即<math alttext="\kappa(\mathbf{x})" class="ltx_Math" display="inline" id="S3.SS3.p1.2.m2.1"><semantics id="S3.SS3.p1.2.m2.1a"><mrow id="S3.SS3.p1.2.m2.1.2" xref="S3.SS3.p1.2.m2.1.2.cmml"><mi id="S3.SS3.p1.2.m2.1.2.2" xref="S3.SS3.p1.2.m2.1.2.2.cmml">κ</mi><mo id="S3.SS3.p1.2.m2.1.2.1" xref="S3.SS3.p1.2.m2.1.2.1.cmml">⁢</mo><mrow id="S3.SS3.p1.2.m2.1.2.3.2" xref="S3.SS3.p1.2.m2.1.2.cmml"><mo id="S3.SS3.p1.2.m2.1.2.3.2.1" stretchy="false" xref="S3.SS3.p1.2.m2.1.2.cmml">(</mo><mi id="S3.SS3.p1.2.m2.1.1" xref="S3.SS3.p1.2.m2.1.1.cmml">𝐱</mi><mo id="S3.SS3.p1.2.m2.1.2.3.2.2" stretchy="false" xref="S3.SS3.p1.2.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.1b"><apply id="S3.SS3.p1.2.m2.1.2.cmml" xref="S3.SS3.p1.2.m2.1.2"><times id="S3.SS3.p1.2.m2.1.2.1.cmml" xref="S3.SS3.p1.2.m2.1.2.1"></times><ci id="S3.SS3.p1.2.m2.1.2.2.cmml" xref="S3.SS3.p1.2.m2.1.2.2">𝜅</ci><ci id="S3.SS3.p1.2.m2.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1">𝐱</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.1c">\kappa(\mathbf{x})</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.2.m2.1d">italic_κ ( bold_x )</annotation></semantics></math>，可以应用监督方法来解决这个问题，即<math alttext="\kappa\equiv\text{Softmax}(\mathbf{x}^{\mathrm{T}}\theta)" class="ltx_Math" display="inline" id="S3.SS3.p1.3.m3.1"><semantics id="S3.SS3.p1.3.m3.1a"><mrow id="S3.SS3.p1.3.m3.1.1" xref="S3.SS3.p1.3.m3.1.1.cmml"><mi id="S3.SS3.p1.3.m3.1.1.3" xref="S3.SS3.p1.3.m3.1.1.3.cmml">κ</mi><mo id="S3.SS3.p1.3.m3.1.1.2" xref="S3.SS3.p1.3.m3.1.1.2.cmml">≡</mo><mrow id="S3.SS3.p1.3.m3.1.1.1" xref="S3.SS3.p1.3.m3.1.1.1.cmml"><mtext id="S3.SS3.p1.3.m3.1.1.1.3" xref="S3.SS3.p1.3.m3.1.1.1.3a.cmml">Softmax</mtext><mo id="S3.SS3.p1.3.m3.1.1.1.2" xref="S3.SS3.p1.3.m3.1.1.1.2.cmml">⁢</mo><mrow id="S3.SS3.p1.3.m3.1.1.1.1.1" xref="S3.SS3.p1.3.m3.1.1.1.1.1.1.cmml"><mo id="S3.SS3.p1.3.m3.1.1.1.1.1.2" stretchy="false" xref="S3.SS3.p1.3.m3.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS3.p1.3.m3.1.1.1.1.1.1" xref="S3.SS3.p1.3.m3.1.1.1.1.1.1.cmml"><msup id="S3.SS3.p1.3.m3.1.1.1.1.1.1.2" xref="S3.SS3.p1.3.m3.1.1.1.1.1.1.2.cmml"><mi id="S3.SS3.p1.3.m3.1.1.1.1.1.1.2.2" xref="S3.SS3.p1.3.m3.1.1.1.1.1.1.2.2.cmml">𝐱</mi><mi id="S3.SS3.p1.3.m3.1.1.1.1.1.1.2.3" mathvariant="normal" xref="S3.SS3.p1.3.m3.1.1.1.1.1.1.2.3.cmml">T</mi></msup><mo id="S3.SS3.p1.3.m3.1.1.1.1.1.1.1" xref="S3.SS3.p1.3.m3.1.1.1.1.1.1.1.cmml">⁢</mo><mi id="S3.SS3.p1.3.m3.1.1.1.1.1.1.3" xref="S3.SS3.p1.3.m3.1.1.1.1.1.1.3.cmml">θ</mi></mrow><mo id="S3.SS3.p1.3.m3.1.1.1.1.1.3" stretchy="false" xref="S3.SS3.p1.3.m3.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.3.m3.1b"><apply id="S3.SS3.p1.3.m3.1.1.cmml" xref="S3.SS3.p1.3.m3.1.1"><equivalent id="S3.SS3.p1.3.m3.1.1.2.cmml" xref="S3.SS3.p1.3.m3.1.1.2"></equivalent><ci id="S3.SS3.p1.3.m3.1.1.3.cmml" xref="S3.SS3.p1.3.m3.1.1.3">𝜅</ci><apply id="S3.SS3.p1.3.m3.1.1.1.cmml" xref="S3.SS3.p1.3.m3.1.1.1"><times id="S3.SS3.p1.3.m3.1.1.1.2.cmml" xref="S3.SS3.p1.3.m3.1.1.1.2"></times><ci id="S3.SS3.p1.3.m3.1.1.1.3a.cmml" xref="S3.SS3.p1.3.m3.1.1.1.3"><mtext id="S3.SS3.p1.3.m3.1.1.1.3.cmml" xref="S3.SS3.p1.3.m3.1.1.1.3">Softmax</mtext></ci><apply id="S3.SS3.p1.3.m3.1.1.1.1.1.1.cmml" xref="S3.SS3.p1.3.m3.1.1.1.1.1"><times id="S3.SS3.p1.3.m3.1.1.1.1.1.1.1.cmml" xref="S3.SS3.p1.3.m3.1.1.1.1.1.1.1"></times><apply id="S3.SS3.p1.3.m3.1.1.1.1.1.1.2.cmml" xref="S3.SS3.p1.3.m3.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p1.3.m3.1.1.1.1.1.1.2.1.cmml" xref="S3.SS3.p1.3.m3.1.1.1.1.1.1.2">superscript</csymbol><ci id="S3.SS3.p1.3.m3.1.1.1.1.1.1.2.2.cmml" xref="S3.SS3.p1.3.m3.1.1.1.1.1.1.2.2">𝐱</ci><ci id="S3.SS3.p1.3.m3.1.1.1.1.1.1.2.3.cmml" xref="S3.SS3.p1.3.m3.1.1.1.1.1.1.2.3">T</ci></apply><ci id="S3.SS3.p1.3.m3.1.1.1.1.1.1.3.cmml" xref="S3.SS3.p1.3.m3.1.1.1.1.1.1.3">𝜃</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.3.m3.1c">\kappa\equiv\text{Softmax}(\mathbf{x}^{\mathrm{T}}\theta)</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.3.m3.1d">italic_κ ≡ Softmax ( bold_x start_POSTSUPERSCRIPT roman_T end_POSTSUPERSCRIPT italic_θ )</annotation></semantics></math>，其中<math alttext="\theta" class="ltx_Math" display="inline" id="S3.SS3.p1.4.m4.1"><semantics id="S3.SS3.p1.4.m4.1a"><mi id="S3.SS3.p1.4.m4.1.1" xref="S3.SS3.p1.4.m4.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.4.m4.1b"><ci id="S3.SS3.p1.4.m4.1.1.cmml" xref="S3.SS3.p1.4.m4.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.4.m4.1c">\theta</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.4.m4.1d">italic_θ</annotation></semantics></math>是一组参数层。基本假设是，如果我们提供足够的训练数据，构成了一定范围内的最佳示例数量，我们应该能够学会在推断时预测未见文本应该使用的示例数量。</p>
</div>
<div class="ltx_para" id="S3.SS3.p2">
<p class="ltx_p" id="S3.SS3.p2.9">为了训练一个将文本映射到1到<math alttext="M" class="ltx_Math" display="inline" id="S3.SS3.p2.1.m1.1"><semantics id="S3.SS3.p2.1.m1.1a"><mi id="S3.SS3.p2.1.m1.1.1" xref="S3.SS3.p2.1.m1.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.1.m1.1b"><ci id="S3.SS3.p2.1.m1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.1.m1.1c">M</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.1.m1.1d">italic_M</annotation></semantics></math>之间的数字的分类器，有必要获得地面真相标签，即每个训练集实例的最佳样本数。我们建议通过以下方法获得这个：
给定一个训练集实例<math alttext="\mathbf{x}" class="ltx_Math" display="inline" id="S3.SS3.p2.2.m2.1"><semantics id="S3.SS3.p2.2.m2.1a"><mi id="S3.SS3.p2.2.m2.1.1" xref="S3.SS3.p2.2.m2.1.1.cmml">𝐱</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.2.m2.1b"><ci id="S3.SS3.p2.2.m2.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1">𝐱</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.2.m2.1c">\mathbf{x}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.2.m2.1d">bold_x</annotation></semantics></math>，可以使用相似性函数（例如BM25）来检索<math alttext="M" class="ltx_Math" display="inline" id="S3.SS3.p2.3.m3.1"><semantics id="S3.SS3.p2.3.m3.1a"><mi id="S3.SS3.p2.3.m3.1.1" xref="S3.SS3.p2.3.m3.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.3.m3.1b"><ci id="S3.SS3.p2.3.m3.1.1.cmml" xref="S3.SS3.p2.3.m3.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.3.m3.1c">M</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.3.m3.1d">italic_M</annotation></semantics></math>个示例的候选集-<math alttext="\{\mathbf{z}_{1},\ldots,\mathbf{z}_{M}\}" class="ltx_Math" display="inline" id="S3.SS3.p2.4.m4.3"><semantics id="S3.SS3.p2.4.m4.3a"><mrow id="S3.SS3.p2.4.m4.3.3.2" xref="S3.SS3.p2.4.m4.3.3.3.cmml"><mo id="S3.SS3.p2.4.m4.3.3.2.3" stretchy="false" xref="S3.SS3.p2.4.m4.3.3.3.cmml">{</mo><msub id="S3.SS3.p2.4.m4.2.2.1.1" xref="S3.SS3.p2.4.m4.2.2.1.1.cmml"><mi id="S3.SS3.p2.4.m4.2.2.1.1.2" xref="S3.SS3.p2.4.m4.2.2.1.1.2.cmml">𝐳</mi><mn id="S3.SS3.p2.4.m4.2.2.1.1.3" xref="S3.SS3.p2.4.m4.2.2.1.1.3.cmml">1</mn></msub><mo id="S3.SS3.p2.4.m4.3.3.2.4" xref="S3.SS3.p2.4.m4.3.3.3.cmml">,</mo><mi id="S3.SS3.p2.4.m4.1.1" mathvariant="normal" xref="S3.SS3.p2.4.m4.1.1.cmml">…</mi><mo id="S3.SS3.p2.4.m4.3.3.2.5" xref="S3.SS3.p2.4.m4.3.3.3.cmml">,</mo><msub id="S3.SS3.p2.4.m4.3.3.2.2" xref="S3.SS3.p2.4.m4.3.3.2.2.cmml"><mi id="S3.SS3.p2.4.m4.3.3.2.2.2" xref="S3.SS3.p2.4.m4.3.3.2.2.2.cmml">𝐳</mi><mi id="S3.SS3.p2.4.m4.3.3.2.2.3" xref="S3.SS3.p2.4.m4.3.3.2.2.3.cmml">M</mi></msub><mo id="S3.SS3.p2.4.m4.3.3.2.6" stretchy="false" xref="S3.SS3.p2.4.m4.3.3.3.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.4.m4.3b"><set id="S3.SS3.p2.4.m4.3.3.3.cmml" xref="S3.SS3.p2.4.m4.3.3.2"><apply id="S3.SS3.p2.4.m4.2.2.1.1.cmml" xref="S3.SS3.p2.4.m4.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.4.m4.2.2.1.1.1.cmml" xref="S3.SS3.p2.4.m4.2.2.1.1">subscript</csymbol><ci id="S3.SS3.p2.4.m4.2.2.1.1.2.cmml" xref="S3.SS3.p2.4.m4.2.2.1.1.2">𝐳</ci><cn id="S3.SS3.p2.4.m4.2.2.1.1.3.cmml" type="integer" xref="S3.SS3.p2.4.m4.2.2.1.1.3">1</cn></apply><ci id="S3.SS3.p2.4.m4.1.1.cmml" xref="S3.SS3.p2.4.m4.1.1">…</ci><apply id="S3.SS3.p2.4.m4.3.3.2.2.cmml" xref="S3.SS3.p2.4.m4.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS3.p2.4.m4.3.3.2.2.1.cmml" xref="S3.SS3.p2.4.m4.3.3.2.2">subscript</csymbol><ci id="S3.SS3.p2.4.m4.3.3.2.2.2.cmml" xref="S3.SS3.p2.4.m4.3.3.2.2.2">𝐳</ci><ci id="S3.SS3.p2.4.m4.3.3.2.2.3.cmml" xref="S3.SS3.p2.4.m4.3.3.2.2.3">𝑀</ci></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.4.m4.3c">\{\mathbf{z}_{1},\ldots,\mathbf{z}_{M}\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.4.m4.3d">{ bold_z start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , bold_z start_POSTSUBSCRIPT italic_M end_POSTSUBSCRIPT }</annotation></semantics></math>。由于<math alttext="\mathbf{x}" class="ltx_Math" display="inline" id="S3.SS3.p2.5.m5.1"><semantics id="S3.SS3.p2.5.m5.1a"><mi id="S3.SS3.p2.5.m5.1.1" xref="S3.SS3.p2.5.m5.1.1.cmml">𝐱</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.5.m5.1b"><ci id="S3.SS3.p2.5.m5.1.1.cmml" xref="S3.SS3.p2.5.m5.1.1">𝐱</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.5.m5.1c">\mathbf{x}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.5.m5.1d">bold_x</annotation></semantics></math>是训练集中的一个实例，我们可以利用它的标签来检查使用LLM的<math alttext="k" class="ltx_Math" display="inline" id="S3.SS3.p2.6.m6.1"><semantics id="S3.SS3.p2.6.m6.1a"><mi id="S3.SS3.p2.6.m6.1.1" xref="S3.SS3.p2.6.m6.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.6.m6.1b"><ci id="S3.SS3.p2.6.m6.1.1.cmml" xref="S3.SS3.p2.6.m6.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.6.m6.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.6.m6.1d">italic_k</annotation></semantics></math>次预测是否正确。可能会发生正确的预测对于<math alttext="k\in\{1,\ldots,M\}" class="ltx_Math" display="inline" id="S3.SS3.p2.7.m7.3"><semantics id="S3.SS3.p2.7.m7.3a"><mrow id="S3.SS3.p2.7.m7.3.4" xref="S3.SS3.p2.7.m7.3.4.cmml"><mi id="S3.SS3.p2.7.m7.3.4.2" xref="S3.SS3.p2.7.m7.3.4.2.cmml">k</mi><mo id="S3.SS3.p2.7.m7.3.4.1" xref="S3.SS3.p2.7.m7.3.4.1.cmml">∈</mo><mrow id="S3.SS3.p2.7.m7.3.4.3.2" xref="S3.SS3.p2.7.m7.3.4.3.1.cmml"><mo id="S3.SS3.p2.7.m7.3.4.3.2.1" stretchy="false" xref="S3.SS3.p2.7.m7.3.4.3.1.cmml">{</mo><mn id="S3.SS3.p2.7.m7.1.1" xref="S3.SS3.p2.7.m7.1.1.cmml">1</mn><mo id="S3.SS3.p2.7.m7.3.4.3.2.2" xref="S3.SS3.p2.7.m7.3.4.3.1.cmml">,</mo><mi id="S3.SS3.p2.7.m7.2.2" mathvariant="normal" xref="S3.SS3.p2.7.m7.2.2.cmml">…</mi><mo id="S3.SS3.p2.7.m7.3.4.3.2.3" xref="S3.SS3.p2.7.m7.3.4.3.1.cmml">,</mo><mi id="S3.SS3.p2.7.m7.3.3" xref="S3.SS3.p2.7.m7.3.3.cmml">M</mi><mo id="S3.SS3.p2.7.m7.3.4.3.2.4" stretchy="false" xref="S3.SS3.p2.7.m7.3.4.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.7.m7.3b"><apply id="S3.SS3.p2.7.m7.3.4.cmml" xref="S3.SS3.p2.7.m7.3.4"><in id="S3.SS3.p2.7.m7.3.4.1.cmml" xref="S3.SS3.p2.7.m7.3.4.1"></in><ci id="S3.SS3.p2.7.m7.3.4.2.cmml" xref="S3.SS3.p2.7.m7.3.4.2">𝑘</ci><set id="S3.SS3.p2.7.m7.3.4.3.1.cmml" xref="S3.SS3.p2.7.m7.3.4.3.2"><cn id="S3.SS3.p2.7.m7.1.1.cmml" type="integer" xref="S3.SS3.p2.7.m7.1.1">1</cn><ci id="S3.SS3.p2.7.m7.2.2.cmml" xref="S3.SS3.p2.7.m7.2.2">…</ci><ci id="S3.SS3.p2.7.m7.3.3.cmml" xref="S3.SS3.p2.7.m7.3.3">𝑀</ci></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.7.m7.3c">k\in\{1,\ldots,M\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.7.m7.3d">italic_k ∈ { 1 , … , italic_M }</annotation></semantics></math>的几个值而言。可以采用几种策略来定义地面真相的示例数。例如，可以提前停止并简单地选择导致正确预测的最小<math alttext="k" class="ltx_Math" display="inline" id="S3.SS3.p2.8.m8.1"><semantics id="S3.SS3.p2.8.m8.1a"><mi id="S3.SS3.p2.8.m8.1.1" xref="S3.SS3.p2.8.m8.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.8.m8.1b"><ci id="S3.SS3.p2.8.m8.1.1.cmml" xref="S3.SS3.p2.8.m8.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.8.m8.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.8.m8.1d">italic_k</annotation></semantics></math>。或者，可能更稳健的程序是通过彻底检查所有可能的<math alttext="k=1,\ldots,M" class="ltx_Math" display="inline" id="S3.SS3.p2.9.m9.3"><semantics id="S3.SS3.p2.9.m9.3a"><mrow id="S3.SS3.p2.9.m9.3.4" xref="S3.SS3.p2.9.m9.3.4.cmml"><mi id="S3.SS3.p2.9.m9.3.4.2" xref="S3.SS3.p2.9.m9.3.4.2.cmml">k</mi><mo id="S3.SS3.p2.9.m9.3.4.1" xref="S3.SS3.p2.9.m9.3.4.1.cmml">=</mo><mrow id="S3.SS3.p2.9.m9.3.4.3.2" xref="S3.SS3.p2.9.m9.3.4.3.1.cmml"><mn id="S3.SS3.p2.9.m9.1.1" xref="S3.SS3.p2.9.m9.1.1.cmml">1</mn><mo id="S3.SS3.p2.9.m9.3.4.3.2.1" xref="S3.SS3.p2.9.m9.3.4.3.1.cmml">,</mo><mi id="S3.SS3.p2.9.m9.2.2" mathvariant="normal" xref="S3.SS3.p2.9.m9.2.2.cmml">…</mi><mo id="S3.SS3.p2.9.m9.3.4.3.2.2" xref="S3.SS3.p2.9.m9.3.4.3.1.cmml">,</mo><mi id="S3.SS3.p2.9.m9.3.3" xref="S3.SS3.p2.9.m9.3.3.cmml">M</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.9.m9.3b"><apply id="S3.SS3.p2.9.m9.3.4.cmml" xref="S3.SS3.p2.9.m9.3.4"><eq id="S3.SS3.p2.9.m9.3.4.1.cmml" xref="S3.SS3.p2.9.m9.3.4.1"></eq><ci id="S3.SS3.p2.9.m9.3.4.2.cmml" xref="S3.SS3.p2.9.m9.3.4.2">𝑘</ci><list id="S3.SS3.p2.9.m9.3.4.3.1.cmml" xref="S3.SS3.p2.9.m9.3.4.3.2"><cn id="S3.SS3.p2.9.m9.1.1.cmml" type="integer" xref="S3.SS3.p2.9.m9.1.1">1</cn><ci id="S3.SS3.p2.9.m9.2.2.cmml" xref="S3.SS3.p2.9.m9.2.2">…</ci><ci id="S3.SS3.p2.9.m9.3.3.cmml" xref="S3.SS3.p2.9.m9.3.3">𝑀</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.9.m9.3c">k=1,\ldots,M</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.9.m9.3d">italic_k = 1 , … , italic_M</annotation></semantics></math>值，并选择导致最小不确定性的正确预测的值。 <cite class="ltx_cite ltx_citemacro_citep">(Rubin et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib68" title="">2022</a>; Sorensen et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib76" title="">2022</a>)</cite></p>
</div>
<div class="ltx_para" id="S3.SS3.p3">
<p class="ltx_p" id="S3.SS3.p3.1">这种基于最小不确定性的ICL示例数量选择的工作流程在算法<a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#algorithm2" title="In 3.3. Supervised Rank Cutoff ‣ 3. Adaptive ICL ↦ QPP? ‣ “In-Context Learning” or: How I learned to stop worrying and love “Applied Information Retrieval”"><span class="ltx_text ltx_ref_tag">2</span></a>中显示。在地面真相构建过程中调用的算法<a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#algorithm1" title="In 3.3. Supervised Rank Cutoff ‣ 3. Adaptive ICL ↦ QPP? ‣ “In-Context Learning” or: How I learned to stop worrying and love “Applied Information Retrieval”"><span class="ltx_text ltx_ref_tag">1</span></a>显示了文本分类的样本提示模板。</p>
</div>
<figure class="ltx_float ltx_algorithm" id="algorithm1">
<div class="ltx_listing ltx_lst_numbers_left ltx_listing" id="algorithm1.14">
<div class="ltx_listingline" id="algorithm1.1.1">
<span class="ltx_text" id="algorithm1.1.1.1" style="font-size:90%;"><span class="ltx_text ltx_font_bold" id="algorithm1.1.1.1.1">Input:</span> </span><math alttext="\mathbf{x}" class="ltx_Math" display="inline" id="algorithm1.1.1.m1.1"><semantics id="algorithm1.1.1.m1.1a"><mi id="algorithm1.1.1.m1.1.1" mathsize="90%" xref="algorithm1.1.1.m1.1.1.cmml">𝐱</mi><annotation-xml encoding="MathML-Content" id="algorithm1.1.1.m1.1b"><ci id="algorithm1.1.1.m1.1.1.cmml" xref="algorithm1.1.1.m1.1.1">𝐱</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.1.1.m1.1c">\mathbf{x}</annotation><annotation encoding="application/x-llamapun" id="algorithm1.1.1.m1.1d">bold_x</annotation></semantics></math><span class="ltx_text" id="algorithm1.1.1.2" style="font-size:90%;"> – an instance from the training set</span>
</div>
<div class="ltx_listingline" id="algorithm1.3.3">
<span class="ltx_text" id="algorithm1.3.3.1" style="font-size:90%;">
</span><span class="ltx_text" id="algorithm1.3.3.2" style="font-size:90%;"><span class="ltx_text ltx_font_bold" id="algorithm1.3.3.2.1">Input:</span> </span><math alttext="k(&lt;M)" class="ltx_Math" display="inline" id="algorithm1.2.2.m1.1"><semantics id="algorithm1.2.2.m1.1a"><mrow id="algorithm1.2.2.m1.1.1" xref="algorithm1.2.2.m1.1.1.cmml"><mi id="algorithm1.2.2.m1.1.1.3" mathsize="90%" xref="algorithm1.2.2.m1.1.1.3.cmml">k</mi><mspace id="algorithm1.2.2.m1.1.1a" width="0.3888888888888889em" xref="algorithm1.2.2.m1.1.1.cmml"></mspace><mrow id="algorithm1.2.2.m1.1.1.1.1" xref="algorithm1.2.2.m1.1.1.1.1.1.cmml"><mo id="algorithm1.2.2.m1.1.1.1.1.2" maxsize="90%" minsize="90%" xref="algorithm1.2.2.m1.1.1.1.1.1.cmml">(</mo><mrow id="algorithm1.2.2.m1.1.1.1.1.1" xref="algorithm1.2.2.m1.1.1.1.1.1.cmml"><mi id="algorithm1.2.2.m1.1.1.1.1.1.2" xref="algorithm1.2.2.m1.1.1.1.1.1.2.cmml"></mi><mo id="algorithm1.2.2.m1.1.1.1.1.1.1" mathsize="90%" xref="algorithm1.2.2.m1.1.1.1.1.1.1.cmml">&lt;</mo><mi id="algorithm1.2.2.m1.1.1.1.1.1.3" mathsize="90%" xref="algorithm1.2.2.m1.1.1.1.1.1.3.cmml">M</mi></mrow><mo id="algorithm1.2.2.m1.1.1.1.1.3" maxsize="90%" minsize="90%" xref="algorithm1.2.2.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.2.2.m1.1b"><apply id="algorithm1.2.2.m1.1.1.cmml" xref="algorithm1.2.2.m1.1.1"><csymbol cd="latexml" id="algorithm1.2.2.m1.1.1.2.cmml" xref="algorithm1.2.2.m1.1.1">annotated</csymbol><ci id="algorithm1.2.2.m1.1.1.3.cmml" xref="algorithm1.2.2.m1.1.1.3">𝑘</ci><apply id="algorithm1.2.2.m1.1.1.1.1.1.cmml" xref="algorithm1.2.2.m1.1.1.1.1"><lt id="algorithm1.2.2.m1.1.1.1.1.1.1.cmml" xref="algorithm1.2.2.m1.1.1.1.1.1.1"></lt><csymbol cd="latexml" id="algorithm1.2.2.m1.1.1.1.1.1.2.cmml" xref="algorithm1.2.2.m1.1.1.1.1.1.2">absent</csymbol><ci id="algorithm1.2.2.m1.1.1.1.1.1.3.cmml" xref="algorithm1.2.2.m1.1.1.1.1.1.3">𝑀</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.2.2.m1.1c">k(&lt;M)</annotation><annotation encoding="application/x-llamapun" id="algorithm1.2.2.m1.1d">italic_k ( &lt; italic_M )</annotation></semantics></math><span class="ltx_text" id="algorithm1.3.3.3" style="font-size:90%;"> – number of examples (max </span><math alttext="M" class="ltx_Math" display="inline" id="algorithm1.3.3.m2.1"><semantics id="algorithm1.3.3.m2.1a"><mi id="algorithm1.3.3.m2.1.1" mathsize="90%" xref="algorithm1.3.3.m2.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="algorithm1.3.3.m2.1b"><ci id="algorithm1.3.3.m2.1.1.cmml" xref="algorithm1.3.3.m2.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.3.3.m2.1c">M</annotation><annotation encoding="application/x-llamapun" id="algorithm1.3.3.m2.1d">italic_M</annotation></semantics></math><span class="ltx_text" id="algorithm1.3.3.4" style="font-size:90%;">)</span>
</div>
<div class="ltx_listingline" id="algorithm1.4.4">
<span class="ltx_text" id="algorithm1.4.4.1" style="font-size:90%;">
</span><span class="ltx_text" id="algorithm1.4.4.2" style="font-size:90%;"><span class="ltx_text ltx_font_bold" id="algorithm1.4.4.2.1">Output:</span> </span><math alttext="\Delta_{p}" class="ltx_Math" display="inline" id="algorithm1.4.4.m1.1"><semantics id="algorithm1.4.4.m1.1a"><msub id="algorithm1.4.4.m1.1.1" xref="algorithm1.4.4.m1.1.1.cmml"><mi id="algorithm1.4.4.m1.1.1.2" mathsize="90%" mathvariant="normal" xref="algorithm1.4.4.m1.1.1.2.cmml">Δ</mi><mi id="algorithm1.4.4.m1.1.1.3" mathsize="90%" xref="algorithm1.4.4.m1.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="algorithm1.4.4.m1.1b"><apply id="algorithm1.4.4.m1.1.1.cmml" xref="algorithm1.4.4.m1.1.1"><csymbol cd="ambiguous" id="algorithm1.4.4.m1.1.1.1.cmml" xref="algorithm1.4.4.m1.1.1">subscript</csymbol><ci id="algorithm1.4.4.m1.1.1.2.cmml" xref="algorithm1.4.4.m1.1.1.2">Δ</ci><ci id="algorithm1.4.4.m1.1.1.3.cmml" xref="algorithm1.4.4.m1.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.4.4.m1.1c">\Delta_{p}</annotation><annotation encoding="application/x-llamapun" id="algorithm1.4.4.m1.1d">roman_Δ start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="algorithm1.4.4.3" style="font-size:90%;"> – Softmax posteriors</span>
</div>
<div class="ltx_listingline" id="algorithm1.14.15">
<span class="ltx_text" id="algorithm1.14.15.1" style="font-size:90%;">
</span><span class="ltx_text ltx_font_bold" id="algorithm1.14.15.2" style="font-size:90%;">begin</span>
</div>
<div class="ltx_listingline" id="algorithm1.5.5">
<span class="ltx_text" id="algorithm1.5.5.1" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm1.5.5.2" style="font-size:90%;">   </span><span class="ltx_text" id="algorithm1.5.5.3" style="font-size:90%;">
</span><math alttext="N_{k}(\mathbf{x})\leftarrow\{\mathbf{z}_{1},\ldots,\mathbf{z}_{k}\}" class="ltx_Math" display="inline" id="algorithm1.5.5.m1.4"><semantics id="algorithm1.5.5.m1.4a"><mrow id="algorithm1.5.5.m1.4.4" xref="algorithm1.5.5.m1.4.4.cmml"><mrow id="algorithm1.5.5.m1.4.4.4" xref="algorithm1.5.5.m1.4.4.4.cmml"><msub id="algorithm1.5.5.m1.4.4.4.2" xref="algorithm1.5.5.m1.4.4.4.2.cmml"><mi id="algorithm1.5.5.m1.4.4.4.2.2" mathsize="90%" xref="algorithm1.5.5.m1.4.4.4.2.2.cmml">N</mi><mi id="algorithm1.5.5.m1.4.4.4.2.3" mathsize="90%" xref="algorithm1.5.5.m1.4.4.4.2.3.cmml">k</mi></msub><mo id="algorithm1.5.5.m1.4.4.4.1" xref="algorithm1.5.5.m1.4.4.4.1.cmml">⁢</mo><mrow id="algorithm1.5.5.m1.4.4.4.3.2" xref="algorithm1.5.5.m1.4.4.4.cmml"><mo id="algorithm1.5.5.m1.4.4.4.3.2.1" maxsize="90%" minsize="90%" xref="algorithm1.5.5.m1.4.4.4.cmml">(</mo><mi id="algorithm1.5.5.m1.1.1" mathsize="90%" xref="algorithm1.5.5.m1.1.1.cmml">𝐱</mi><mo id="algorithm1.5.5.m1.4.4.4.3.2.2" maxsize="90%" minsize="90%" xref="algorithm1.5.5.m1.4.4.4.cmml">)</mo></mrow></mrow><mo id="algorithm1.5.5.m1.4.4.3" mathsize="90%" stretchy="false" xref="algorithm1.5.5.m1.4.4.3.cmml">←</mo><mrow id="algorithm1.5.5.m1.4.4.2.2" xref="algorithm1.5.5.m1.4.4.2.3.cmml"><mo id="algorithm1.5.5.m1.4.4.2.2.3" maxsize="90%" minsize="90%" xref="algorithm1.5.5.m1.4.4.2.3.cmml">{</mo><msub id="algorithm1.5.5.m1.3.3.1.1.1" xref="algorithm1.5.5.m1.3.3.1.1.1.cmml"><mi id="algorithm1.5.5.m1.3.3.1.1.1.2" mathsize="90%" xref="algorithm1.5.5.m1.3.3.1.1.1.2.cmml">𝐳</mi><mn id="algorithm1.5.5.m1.3.3.1.1.1.3" mathsize="90%" xref="algorithm1.5.5.m1.3.3.1.1.1.3.cmml">1</mn></msub><mo id="algorithm1.5.5.m1.4.4.2.2.4" mathsize="90%" xref="algorithm1.5.5.m1.4.4.2.3.cmml">,</mo><mi id="algorithm1.5.5.m1.2.2" mathsize="90%" mathvariant="normal" xref="algorithm1.5.5.m1.2.2.cmml">…</mi><mo id="algorithm1.5.5.m1.4.4.2.2.5" mathsize="90%" xref="algorithm1.5.5.m1.4.4.2.3.cmml">,</mo><msub id="algorithm1.5.5.m1.4.4.2.2.2" xref="algorithm1.5.5.m1.4.4.2.2.2.cmml"><mi id="algorithm1.5.5.m1.4.4.2.2.2.2" mathsize="90%" xref="algorithm1.5.5.m1.4.4.2.2.2.2.cmml">𝐳</mi><mi id="algorithm1.5.5.m1.4.4.2.2.2.3" mathsize="90%" xref="algorithm1.5.5.m1.4.4.2.2.2.3.cmml">k</mi></msub><mo id="algorithm1.5.5.m1.4.4.2.2.6" maxsize="90%" minsize="90%" xref="algorithm1.5.5.m1.4.4.2.3.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.5.5.m1.4b"><apply id="algorithm1.5.5.m1.4.4.cmml" xref="algorithm1.5.5.m1.4.4"><ci id="algorithm1.5.5.m1.4.4.3.cmml" xref="algorithm1.5.5.m1.4.4.3">←</ci><apply id="algorithm1.5.5.m1.4.4.4.cmml" xref="algorithm1.5.5.m1.4.4.4"><times id="algorithm1.5.5.m1.4.4.4.1.cmml" xref="algorithm1.5.5.m1.4.4.4.1"></times><apply id="algorithm1.5.5.m1.4.4.4.2.cmml" xref="algorithm1.5.5.m1.4.4.4.2"><csymbol cd="ambiguous" id="algorithm1.5.5.m1.4.4.4.2.1.cmml" xref="algorithm1.5.5.m1.4.4.4.2">subscript</csymbol><ci id="algorithm1.5.5.m1.4.4.4.2.2.cmml" xref="algorithm1.5.5.m1.4.4.4.2.2">𝑁</ci><ci id="algorithm1.5.5.m1.4.4.4.2.3.cmml" xref="algorithm1.5.5.m1.4.4.4.2.3">𝑘</ci></apply><ci id="algorithm1.5.5.m1.1.1.cmml" xref="algorithm1.5.5.m1.1.1">𝐱</ci></apply><set id="algorithm1.5.5.m1.4.4.2.3.cmml" xref="algorithm1.5.5.m1.4.4.2.2"><apply id="algorithm1.5.5.m1.3.3.1.1.1.cmml" xref="algorithm1.5.5.m1.3.3.1.1.1"><csymbol cd="ambiguous" id="algorithm1.5.5.m1.3.3.1.1.1.1.cmml" xref="algorithm1.5.5.m1.3.3.1.1.1">subscript</csymbol><ci id="algorithm1.5.5.m1.3.3.1.1.1.2.cmml" xref="algorithm1.5.5.m1.3.3.1.1.1.2">𝐳</ci><cn id="algorithm1.5.5.m1.3.3.1.1.1.3.cmml" type="integer" xref="algorithm1.5.5.m1.3.3.1.1.1.3">1</cn></apply><ci id="algorithm1.5.5.m1.2.2.cmml" xref="algorithm1.5.5.m1.2.2">…</ci><apply id="algorithm1.5.5.m1.4.4.2.2.2.cmml" xref="algorithm1.5.5.m1.4.4.2.2.2"><csymbol cd="ambiguous" id="algorithm1.5.5.m1.4.4.2.2.2.1.cmml" xref="algorithm1.5.5.m1.4.4.2.2.2">subscript</csymbol><ci id="algorithm1.5.5.m1.4.4.2.2.2.2.cmml" xref="algorithm1.5.5.m1.4.4.2.2.2.2">𝐳</ci><ci id="algorithm1.5.5.m1.4.4.2.2.2.3.cmml" xref="algorithm1.5.5.m1.4.4.2.2.2.3">𝑘</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.5.5.m1.4c">N_{k}(\mathbf{x})\leftarrow\{\mathbf{z}_{1},\ldots,\mathbf{z}_{k}\}</annotation><annotation encoding="application/x-llamapun" id="algorithm1.5.5.m1.4d">italic_N start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( bold_x ) ← { bold_z start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , bold_z start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT }</annotation></semantics></math><span class="ltx_text" id="algorithm1.5.5.4" style="font-size:90%;">
</span>
</div>
<div class="ltx_listingline" id="algorithm1.8.8">
<span class="ltx_text" id="algorithm1.8.8.1" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm1.8.8.2" style="font-size:90%;">   </span><span class="ltx_text ltx_font_typewriter" id="algorithm1.8.8.3" style="font-size:90%;">Instruction</span><span class="ltx_text" id="algorithm1.8.8.4" style="font-size:90%;"> </span><math alttext="\leftarrow" class="ltx_Math" display="inline" id="algorithm1.6.6.m1.1"><semantics id="algorithm1.6.6.m1.1a"><mo id="algorithm1.6.6.m1.1.1" mathsize="90%" stretchy="false" xref="algorithm1.6.6.m1.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="algorithm1.6.6.m1.1b"><ci id="algorithm1.6.6.m1.1.1.cmml" xref="algorithm1.6.6.m1.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.6.6.m1.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="algorithm1.6.6.m1.1d">←</annotation></semantics></math><span class="ltx_text" id="algorithm1.8.8.5" style="font-size:90%;">
“Predict the type of </span><math alttext="\langle\mathbf{x}\rangle" class="ltx_Math" display="inline" id="algorithm1.7.7.m2.1"><semantics id="algorithm1.7.7.m2.1a"><mrow id="algorithm1.7.7.m2.1.2.2" xref="algorithm1.7.7.m2.1.2.1.cmml"><mo id="algorithm1.7.7.m2.1.2.2.1" maxsize="90%" minsize="90%" xref="algorithm1.7.7.m2.1.2.1.1.cmml">⟨</mo><mi id="algorithm1.7.7.m2.1.1" mathsize="90%" xref="algorithm1.7.7.m2.1.1.cmml">𝐱</mi><mo id="algorithm1.7.7.m2.1.2.2.2" maxsize="90%" minsize="90%" xref="algorithm1.7.7.m2.1.2.1.1.cmml">⟩</mo></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.7.7.m2.1b"><apply id="algorithm1.7.7.m2.1.2.1.cmml" xref="algorithm1.7.7.m2.1.2.2"><csymbol cd="latexml" id="algorithm1.7.7.m2.1.2.1.1.cmml" xref="algorithm1.7.7.m2.1.2.2.1">delimited-⟨⟩</csymbol><ci id="algorithm1.7.7.m2.1.1.cmml" xref="algorithm1.7.7.m2.1.1">𝐱</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.7.7.m2.1c">\langle\mathbf{x}\rangle</annotation><annotation encoding="application/x-llamapun" id="algorithm1.7.7.m2.1d">⟨ bold_x ⟩</annotation></semantics></math><span class="ltx_text" id="algorithm1.8.8.6" style="font-size:90%;"> as one of </span><math alttext="\{\langle C_{0}\rangle,\ldots,\langle C_{p-1}\rangle\}" class="ltx_Math" display="inline" id="algorithm1.8.8.m3.3"><semantics id="algorithm1.8.8.m3.3a"><mrow id="algorithm1.8.8.m3.3.3.2" xref="algorithm1.8.8.m3.3.3.3.cmml"><mo id="algorithm1.8.8.m3.3.3.2.3" maxsize="90%" minsize="90%" xref="algorithm1.8.8.m3.3.3.3.cmml">{</mo><mrow id="algorithm1.8.8.m3.2.2.1.1.1" xref="algorithm1.8.8.m3.2.2.1.1.2.cmml"><mo id="algorithm1.8.8.m3.2.2.1.1.1.2" maxsize="90%" minsize="90%" xref="algorithm1.8.8.m3.2.2.1.1.2.1.cmml">⟨</mo><msub id="algorithm1.8.8.m3.2.2.1.1.1.1" xref="algorithm1.8.8.m3.2.2.1.1.1.1.cmml"><mi id="algorithm1.8.8.m3.2.2.1.1.1.1.2" mathsize="90%" xref="algorithm1.8.8.m3.2.2.1.1.1.1.2.cmml">C</mi><mn id="algorithm1.8.8.m3.2.2.1.1.1.1.3" mathsize="90%" xref="algorithm1.8.8.m3.2.2.1.1.1.1.3.cmml">0</mn></msub><mo id="algorithm1.8.8.m3.2.2.1.1.1.3" maxsize="90%" minsize="90%" xref="algorithm1.8.8.m3.2.2.1.1.2.1.cmml">⟩</mo></mrow><mo id="algorithm1.8.8.m3.3.3.2.4" mathsize="90%" xref="algorithm1.8.8.m3.3.3.3.cmml">,</mo><mi id="algorithm1.8.8.m3.1.1" mathsize="90%" mathvariant="normal" xref="algorithm1.8.8.m3.1.1.cmml">…</mi><mo id="algorithm1.8.8.m3.3.3.2.5" mathsize="90%" xref="algorithm1.8.8.m3.3.3.3.cmml">,</mo><mrow id="algorithm1.8.8.m3.3.3.2.2.1" xref="algorithm1.8.8.m3.3.3.2.2.2.cmml"><mo id="algorithm1.8.8.m3.3.3.2.2.1.2" maxsize="90%" minsize="90%" xref="algorithm1.8.8.m3.3.3.2.2.2.1.cmml">⟨</mo><msub id="algorithm1.8.8.m3.3.3.2.2.1.1" xref="algorithm1.8.8.m3.3.3.2.2.1.1.cmml"><mi id="algorithm1.8.8.m3.3.3.2.2.1.1.2" mathsize="90%" xref="algorithm1.8.8.m3.3.3.2.2.1.1.2.cmml">C</mi><mrow id="algorithm1.8.8.m3.3.3.2.2.1.1.3" xref="algorithm1.8.8.m3.3.3.2.2.1.1.3.cmml"><mi id="algorithm1.8.8.m3.3.3.2.2.1.1.3.2" mathsize="90%" xref="algorithm1.8.8.m3.3.3.2.2.1.1.3.2.cmml">p</mi><mo id="algorithm1.8.8.m3.3.3.2.2.1.1.3.1" mathsize="90%" xref="algorithm1.8.8.m3.3.3.2.2.1.1.3.1.cmml">−</mo><mn id="algorithm1.8.8.m3.3.3.2.2.1.1.3.3" mathsize="90%" xref="algorithm1.8.8.m3.3.3.2.2.1.1.3.3.cmml">1</mn></mrow></msub><mo id="algorithm1.8.8.m3.3.3.2.2.1.3" maxsize="90%" minsize="90%" xref="algorithm1.8.8.m3.3.3.2.2.2.1.cmml">⟩</mo></mrow><mo id="algorithm1.8.8.m3.3.3.2.6" maxsize="90%" minsize="90%" xref="algorithm1.8.8.m3.3.3.3.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.8.8.m3.3b"><set id="algorithm1.8.8.m3.3.3.3.cmml" xref="algorithm1.8.8.m3.3.3.2"><apply id="algorithm1.8.8.m3.2.2.1.1.2.cmml" xref="algorithm1.8.8.m3.2.2.1.1.1"><csymbol cd="latexml" id="algorithm1.8.8.m3.2.2.1.1.2.1.cmml" xref="algorithm1.8.8.m3.2.2.1.1.1.2">delimited-⟨⟩</csymbol><apply id="algorithm1.8.8.m3.2.2.1.1.1.1.cmml" xref="algorithm1.8.8.m3.2.2.1.1.1.1"><csymbol cd="ambiguous" id="algorithm1.8.8.m3.2.2.1.1.1.1.1.cmml" xref="algorithm1.8.8.m3.2.2.1.1.1.1">subscript</csymbol><ci id="algorithm1.8.8.m3.2.2.1.1.1.1.2.cmml" xref="algorithm1.8.8.m3.2.2.1.1.1.1.2">𝐶</ci><cn id="algorithm1.8.8.m3.2.2.1.1.1.1.3.cmml" type="integer" xref="algorithm1.8.8.m3.2.2.1.1.1.1.3">0</cn></apply></apply><ci id="algorithm1.8.8.m3.1.1.cmml" xref="algorithm1.8.8.m3.1.1">…</ci><apply id="algorithm1.8.8.m3.3.3.2.2.2.cmml" xref="algorithm1.8.8.m3.3.3.2.2.1"><csymbol cd="latexml" id="algorithm1.8.8.m3.3.3.2.2.2.1.cmml" xref="algorithm1.8.8.m3.3.3.2.2.1.2">delimited-⟨⟩</csymbol><apply id="algorithm1.8.8.m3.3.3.2.2.1.1.cmml" xref="algorithm1.8.8.m3.3.3.2.2.1.1"><csymbol cd="ambiguous" id="algorithm1.8.8.m3.3.3.2.2.1.1.1.cmml" xref="algorithm1.8.8.m3.3.3.2.2.1.1">subscript</csymbol><ci id="algorithm1.8.8.m3.3.3.2.2.1.1.2.cmml" xref="algorithm1.8.8.m3.3.3.2.2.1.1.2">𝐶</ci><apply id="algorithm1.8.8.m3.3.3.2.2.1.1.3.cmml" xref="algorithm1.8.8.m3.3.3.2.2.1.1.3"><minus id="algorithm1.8.8.m3.3.3.2.2.1.1.3.1.cmml" xref="algorithm1.8.8.m3.3.3.2.2.1.1.3.1"></minus><ci id="algorithm1.8.8.m3.3.3.2.2.1.1.3.2.cmml" xref="algorithm1.8.8.m3.3.3.2.2.1.1.3.2">𝑝</ci><cn id="algorithm1.8.8.m3.3.3.2.2.1.1.3.3.cmml" type="integer" xref="algorithm1.8.8.m3.3.3.2.2.1.1.3.3">1</cn></apply></apply></apply></set></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.8.8.m3.3c">\{\langle C_{0}\rangle,\ldots,\langle C_{p-1}\rangle\}</annotation><annotation encoding="application/x-llamapun" id="algorithm1.8.8.m3.3d">{ ⟨ italic_C start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ⟩ , … , ⟨ italic_C start_POSTSUBSCRIPT italic_p - 1 end_POSTSUBSCRIPT ⟩ }</annotation></semantics></math><span class="ltx_text" id="algorithm1.8.8.7" style="font-size:90%;"> given the following example”.</span>
</div>
<div class="ltx_listingline" id="algorithm1.10.10">
<span class="ltx_text" id="algorithm1.10.10.3" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm1.10.10.4" style="font-size:90%;">   </span><span class="ltx_text" id="algorithm1.10.10.5" style="font-size:90%;">
</span><span class="ltx_text ltx_font_bold" id="algorithm1.10.10.6" style="font-size:90%;">for</span><span class="ltx_text" id="algorithm1.10.10.7" style="font-size:90%;"> </span><em class="ltx_emph ltx_font_italic" id="algorithm1.10.10.2" style="font-size:90%;"><math alttext="i\leftarrow 1" class="ltx_Math" display="inline" id="algorithm1.9.9.1.m1.1"><semantics id="algorithm1.9.9.1.m1.1a"><mrow id="algorithm1.9.9.1.m1.1.1" xref="algorithm1.9.9.1.m1.1.1.cmml"><mi id="algorithm1.9.9.1.m1.1.1.2" xref="algorithm1.9.9.1.m1.1.1.2.cmml">i</mi><mo id="algorithm1.9.9.1.m1.1.1.1" stretchy="false" xref="algorithm1.9.9.1.m1.1.1.1.cmml">←</mo><mn id="algorithm1.9.9.1.m1.1.1.3" xref="algorithm1.9.9.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.9.9.1.m1.1b"><apply id="algorithm1.9.9.1.m1.1.1.cmml" xref="algorithm1.9.9.1.m1.1.1"><ci id="algorithm1.9.9.1.m1.1.1.1.cmml" xref="algorithm1.9.9.1.m1.1.1.1">←</ci><ci id="algorithm1.9.9.1.m1.1.1.2.cmml" xref="algorithm1.9.9.1.m1.1.1.2">𝑖</ci><cn id="algorithm1.9.9.1.m1.1.1.3.cmml" type="integer" xref="algorithm1.9.9.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.9.9.1.m1.1c">i\leftarrow 1</annotation><annotation encoding="application/x-llamapun" id="algorithm1.9.9.1.m1.1d">italic_i ← 1</annotation></semantics></math> to <math alttext="k" class="ltx_Math" display="inline" id="algorithm1.10.10.2.m2.1"><semantics id="algorithm1.10.10.2.m2.1a"><mi id="algorithm1.10.10.2.m2.1.1" xref="algorithm1.10.10.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="algorithm1.10.10.2.m2.1b"><ci id="algorithm1.10.10.2.m2.1.1.cmml" xref="algorithm1.10.10.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.10.10.2.m2.1c">k</annotation><annotation encoding="application/x-llamapun" id="algorithm1.10.10.2.m2.1d">italic_k</annotation></semantics></math></em><span class="ltx_text" id="algorithm1.10.10.8" style="font-size:90%;"> </span><span class="ltx_text ltx_font_bold" id="algorithm1.10.10.9" style="font-size:90%;">do</span>
</div>
<div class="ltx_listingline" id="algorithm1.12.12">
<span class="ltx_text" id="algorithm1.12.12.1" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm1.12.12.2" style="font-size:90%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm1.12.12.3" style="font-size:90%;">   </span><span class="ltx_text" id="algorithm1.12.12.4" style="font-size:90%;">
</span><span class="ltx_text ltx_font_typewriter" id="algorithm1.12.12.5" style="font-size:90%;">Instruction.append(</span><span class="ltx_text" id="algorithm1.12.12.6" style="font-size:90%;">“Example: </span><math alttext="\langle\mathbf{z}_{i}\rangle" class="ltx_Math" display="inline" id="algorithm1.11.11.m1.1"><semantics id="algorithm1.11.11.m1.1a"><mrow id="algorithm1.11.11.m1.1.1.1" xref="algorithm1.11.11.m1.1.1.2.cmml"><mo id="algorithm1.11.11.m1.1.1.1.2" maxsize="90%" minsize="90%" xref="algorithm1.11.11.m1.1.1.2.1.cmml">⟨</mo><msub id="algorithm1.11.11.m1.1.1.1.1" xref="algorithm1.11.11.m1.1.1.1.1.cmml"><mi id="algorithm1.11.11.m1.1.1.1.1.2" mathsize="90%" xref="algorithm1.11.11.m1.1.1.1.1.2.cmml">𝐳</mi><mi id="algorithm1.11.11.m1.1.1.1.1.3" mathsize="90%" xref="algorithm1.11.11.m1.1.1.1.1.3.cmml">i</mi></msub><mo id="algorithm1.11.11.m1.1.1.1.3" maxsize="90%" minsize="90%" xref="algorithm1.11.11.m1.1.1.2.1.cmml">⟩</mo></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.11.11.m1.1b"><apply id="algorithm1.11.11.m1.1.1.2.cmml" xref="algorithm1.11.11.m1.1.1.1"><csymbol cd="latexml" id="algorithm1.11.11.m1.1.1.2.1.cmml" xref="algorithm1.11.11.m1.1.1.1.2">delimited-⟨⟩</csymbol><apply id="algorithm1.11.11.m1.1.1.1.1.cmml" xref="algorithm1.11.11.m1.1.1.1.1"><csymbol cd="ambiguous" id="algorithm1.11.11.m1.1.1.1.1.1.cmml" xref="algorithm1.11.11.m1.1.1.1.1">subscript</csymbol><ci id="algorithm1.11.11.m1.1.1.1.1.2.cmml" xref="algorithm1.11.11.m1.1.1.1.1.2">𝐳</ci><ci id="algorithm1.11.11.m1.1.1.1.1.3.cmml" xref="algorithm1.11.11.m1.1.1.1.1.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.11.11.m1.1c">\langle\mathbf{z}_{i}\rangle</annotation><annotation encoding="application/x-llamapun" id="algorithm1.11.11.m1.1d">⟨ bold_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ⟩</annotation></semantics></math><span class="ltx_text" id="algorithm1.12.12.7" style="font-size:90%;"> is a representative of class </span><math alttext="\langle y(\mathbf{z}_{i})\rangle" class="ltx_Math" display="inline" id="algorithm1.12.12.m2.1"><semantics id="algorithm1.12.12.m2.1a"><mrow id="algorithm1.12.12.m2.1.1.1" xref="algorithm1.12.12.m2.1.1.2.cmml"><mo id="algorithm1.12.12.m2.1.1.1.2" maxsize="90%" minsize="90%" xref="algorithm1.12.12.m2.1.1.2.1.cmml">⟨</mo><mrow id="algorithm1.12.12.m2.1.1.1.1" xref="algorithm1.12.12.m2.1.1.1.1.cmml"><mi id="algorithm1.12.12.m2.1.1.1.1.3" mathsize="90%" xref="algorithm1.12.12.m2.1.1.1.1.3.cmml">y</mi><mo id="algorithm1.12.12.m2.1.1.1.1.2" xref="algorithm1.12.12.m2.1.1.1.1.2.cmml">⁢</mo><mrow id="algorithm1.12.12.m2.1.1.1.1.1.1" xref="algorithm1.12.12.m2.1.1.1.1.1.1.1.cmml"><mo id="algorithm1.12.12.m2.1.1.1.1.1.1.2" maxsize="90%" minsize="90%" xref="algorithm1.12.12.m2.1.1.1.1.1.1.1.cmml">(</mo><msub id="algorithm1.12.12.m2.1.1.1.1.1.1.1" xref="algorithm1.12.12.m2.1.1.1.1.1.1.1.cmml"><mi id="algorithm1.12.12.m2.1.1.1.1.1.1.1.2" mathsize="90%" xref="algorithm1.12.12.m2.1.1.1.1.1.1.1.2.cmml">𝐳</mi><mi id="algorithm1.12.12.m2.1.1.1.1.1.1.1.3" mathsize="90%" xref="algorithm1.12.12.m2.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="algorithm1.12.12.m2.1.1.1.1.1.1.3" maxsize="90%" minsize="90%" xref="algorithm1.12.12.m2.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="algorithm1.12.12.m2.1.1.1.3" maxsize="90%" minsize="90%" xref="algorithm1.12.12.m2.1.1.2.1.cmml">⟩</mo></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.12.12.m2.1b"><apply id="algorithm1.12.12.m2.1.1.2.cmml" xref="algorithm1.12.12.m2.1.1.1"><csymbol cd="latexml" id="algorithm1.12.12.m2.1.1.2.1.cmml" xref="algorithm1.12.12.m2.1.1.1.2">delimited-⟨⟩</csymbol><apply id="algorithm1.12.12.m2.1.1.1.1.cmml" xref="algorithm1.12.12.m2.1.1.1.1"><times id="algorithm1.12.12.m2.1.1.1.1.2.cmml" xref="algorithm1.12.12.m2.1.1.1.1.2"></times><ci id="algorithm1.12.12.m2.1.1.1.1.3.cmml" xref="algorithm1.12.12.m2.1.1.1.1.3">𝑦</ci><apply id="algorithm1.12.12.m2.1.1.1.1.1.1.1.cmml" xref="algorithm1.12.12.m2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="algorithm1.12.12.m2.1.1.1.1.1.1.1.1.cmml" xref="algorithm1.12.12.m2.1.1.1.1.1.1">subscript</csymbol><ci id="algorithm1.12.12.m2.1.1.1.1.1.1.1.2.cmml" xref="algorithm1.12.12.m2.1.1.1.1.1.1.1.2">𝐳</ci><ci id="algorithm1.12.12.m2.1.1.1.1.1.1.1.3.cmml" xref="algorithm1.12.12.m2.1.1.1.1.1.1.1.3">𝑖</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.12.12.m2.1c">\langle y(\mathbf{z}_{i})\rangle</annotation><annotation encoding="application/x-llamapun" id="algorithm1.12.12.m2.1d">⟨ italic_y ( bold_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) ⟩</annotation></semantics></math><span class="ltx_text" id="algorithm1.12.12.8" style="font-size:90%;">”</span><span class="ltx_text ltx_font_typewriter" id="algorithm1.12.12.9" style="font-size:90%;">)</span>
</div>
<div class="ltx_listingline" id="algorithm1.14.16">
<span class="ltx_text" id="algorithm1.14.16.1" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm1.14.16.2" style="font-size:90%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm1.14.16.3" style="font-size:90%;">   </span><span class="ltx_text" id="algorithm1.14.16.4" style="font-size:90%;">
</span>
</div>
<div class="ltx_listingline" id="algorithm1.13.13">
<span class="ltx_text" id="algorithm1.13.13.1" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm1.13.13.2" style="font-size:90%;">   </span><math alttext="\Delta_{p}\leftarrow" class="ltx_Math" display="inline" id="algorithm1.13.13.m1.1"><semantics id="algorithm1.13.13.m1.1a"><mrow id="algorithm1.13.13.m1.1.1" xref="algorithm1.13.13.m1.1.1.cmml"><msub id="algorithm1.13.13.m1.1.1.2" xref="algorithm1.13.13.m1.1.1.2.cmml"><mi id="algorithm1.13.13.m1.1.1.2.2" mathsize="90%" mathvariant="normal" xref="algorithm1.13.13.m1.1.1.2.2.cmml">Δ</mi><mi id="algorithm1.13.13.m1.1.1.2.3" mathsize="90%" xref="algorithm1.13.13.m1.1.1.2.3.cmml">p</mi></msub><mo id="algorithm1.13.13.m1.1.1.1" mathsize="90%" stretchy="false" xref="algorithm1.13.13.m1.1.1.1.cmml">←</mo><mi id="algorithm1.13.13.m1.1.1.3" xref="algorithm1.13.13.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.13.13.m1.1b"><apply id="algorithm1.13.13.m1.1.1.cmml" xref="algorithm1.13.13.m1.1.1"><ci id="algorithm1.13.13.m1.1.1.1.cmml" xref="algorithm1.13.13.m1.1.1.1">←</ci><apply id="algorithm1.13.13.m1.1.1.2.cmml" xref="algorithm1.13.13.m1.1.1.2"><csymbol cd="ambiguous" id="algorithm1.13.13.m1.1.1.2.1.cmml" xref="algorithm1.13.13.m1.1.1.2">subscript</csymbol><ci id="algorithm1.13.13.m1.1.1.2.2.cmml" xref="algorithm1.13.13.m1.1.1.2.2">Δ</ci><ci id="algorithm1.13.13.m1.1.1.2.3.cmml" xref="algorithm1.13.13.m1.1.1.2.3">𝑝</ci></apply><csymbol cd="latexml" id="algorithm1.13.13.m1.1.1.3.cmml" xref="algorithm1.13.13.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.13.13.m1.1c">\Delta_{p}\leftarrow</annotation><annotation encoding="application/x-llamapun" id="algorithm1.13.13.m1.1d">roman_Δ start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ←</annotation></semantics></math><span class="ltx_text" id="algorithm1.13.13.3" style="font-size:90%;"> </span><span class="ltx_text ltx_font_typewriter" id="algorithm1.13.13.4" style="font-size:90%;">LLM(Instruction)</span>
</div>
<div class="ltx_listingline" id="algorithm1.14.14">
<span class="ltx_text" id="algorithm1.14.14.2" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm1.14.14.3" style="font-size:90%;">   </span><span class="ltx_text" id="algorithm1.14.14.4" style="font-size:90%;">
</span><span class="ltx_text ltx_font_bold" id="algorithm1.14.14.5" style="font-size:90%;">return</span><span class="ltx_text" id="algorithm1.14.14.6" style="font-size:90%;"> </span><em class="ltx_emph ltx_font_italic" id="algorithm1.14.14.1" style="font-size:90%;"><math alttext="\Delta_{p}" class="ltx_Math" display="inline" id="algorithm1.14.14.1.m1.1"><semantics id="algorithm1.14.14.1.m1.1a"><msub id="algorithm1.14.14.1.m1.1.1" xref="algorithm1.14.14.1.m1.1.1.cmml"><mi id="algorithm1.14.14.1.m1.1.1.2" mathvariant="normal" xref="algorithm1.14.14.1.m1.1.1.2.cmml">Δ</mi><mi id="algorithm1.14.14.1.m1.1.1.3" xref="algorithm1.14.14.1.m1.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="algorithm1.14.14.1.m1.1b"><apply id="algorithm1.14.14.1.m1.1.1.cmml" xref="algorithm1.14.14.1.m1.1.1"><csymbol cd="ambiguous" id="algorithm1.14.14.1.m1.1.1.1.cmml" xref="algorithm1.14.14.1.m1.1.1">subscript</csymbol><ci id="algorithm1.14.14.1.m1.1.1.2.cmml" xref="algorithm1.14.14.1.m1.1.1.2">Δ</ci><ci id="algorithm1.14.14.1.m1.1.1.3.cmml" xref="algorithm1.14.14.1.m1.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.14.14.1.m1.1c">\Delta_{p}</annotation><annotation encoding="application/x-llamapun" id="algorithm1.14.14.1.m1.1d">roman_Δ start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT</annotation></semantics></math></em><span class="ltx_text" id="algorithm1.14.14.7" style="font-size:90%;">
</span>
</div>
<div class="ltx_listingline" id="algorithm1.14.17">
<span class="ltx_text" id="algorithm1.14.17.1" style="font-size:90%;">
</span>
</div>
</div>
<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_bold" id="algorithm1.21.1.1">算法1</span> </span>LLM <math alttext="k" class="ltx_Math" display="inline" id="algorithm1.16.m1.1"><semantics id="algorithm1.16.m1.1b"><mi id="algorithm1.16.m1.1.1" xref="algorithm1.16.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="algorithm1.16.m1.1c"><ci id="algorithm1.16.m1.1.1.cmml" xref="algorithm1.16.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.16.m1.1d">k</annotation><annotation encoding="application/x-llamapun" id="algorithm1.16.m1.1e">italic_k</annotation></semantics></math>-shot 预测</figcaption>
</figure>
<figure class="ltx_float ltx_algorithm" id="algorithm2">
<div class="ltx_listing ltx_lst_numbers_left ltx_listing" id="algorithm2.19">
<div class="ltx_listingline" id="algorithm2.1.1">
<span class="ltx_text" id="algorithm2.1.1.1" style="font-size:90%;"><span class="ltx_text ltx_font_bold" id="algorithm2.1.1.1.1">Input:</span> </span><math alttext="\mathcal{T}" class="ltx_Math" display="inline" id="algorithm2.1.1.m1.1"><semantics id="algorithm2.1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="algorithm2.1.1.m1.1.1" mathsize="90%" xref="algorithm2.1.1.m1.1.1.cmml">𝒯</mi><annotation-xml encoding="MathML-Content" id="algorithm2.1.1.m1.1b"><ci id="algorithm2.1.1.m1.1.1.cmml" xref="algorithm2.1.1.m1.1.1">𝒯</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.1.1.m1.1c">\mathcal{T}</annotation><annotation encoding="application/x-llamapun" id="algorithm2.1.1.m1.1d">caligraphic_T</annotation></semantics></math><span class="ltx_text" id="algorithm2.1.1.2" style="font-size:90%;"> – a training set of labelled instances</span>
</div>
<div class="ltx_listingline" id="algorithm2.3.3">
<span class="ltx_text" id="algorithm2.3.3.1" style="font-size:90%;">
</span><span class="ltx_text" id="algorithm2.3.3.2" style="font-size:90%;"><span class="ltx_text ltx_font_bold" id="algorithm2.3.3.2.1">Output:</span> </span><math alttext="\mathcal{K}=\cup_{\mathbf{x}\in\mathcal{T}}k^{*}(\mathbf{x})" class="ltx_Math" display="inline" id="algorithm2.2.2.m1.1"><semantics id="algorithm2.2.2.m1.1a"><mrow id="algorithm2.2.2.m1.1.2" xref="algorithm2.2.2.m1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="algorithm2.2.2.m1.1.2.2" mathsize="90%" xref="algorithm2.2.2.m1.1.2.2.cmml">𝒦</mi><mo id="algorithm2.2.2.m1.1.2.1" mathsize="90%" rspace="0em" xref="algorithm2.2.2.m1.1.2.1.cmml">=</mo><mrow id="algorithm2.2.2.m1.1.2.3" xref="algorithm2.2.2.m1.1.2.3.cmml"><msub id="algorithm2.2.2.m1.1.2.3.1" xref="algorithm2.2.2.m1.1.2.3.1.cmml"><mo id="algorithm2.2.2.m1.1.2.3.1.2" lspace="0em" mathsize="90%" xref="algorithm2.2.2.m1.1.2.3.1.2.cmml">∪</mo><mrow id="algorithm2.2.2.m1.1.2.3.1.3" xref="algorithm2.2.2.m1.1.2.3.1.3.cmml"><mi id="algorithm2.2.2.m1.1.2.3.1.3.2" mathsize="90%" xref="algorithm2.2.2.m1.1.2.3.1.3.2.cmml">𝐱</mi><mo id="algorithm2.2.2.m1.1.2.3.1.3.1" mathsize="90%" xref="algorithm2.2.2.m1.1.2.3.1.3.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="algorithm2.2.2.m1.1.2.3.1.3.3" mathsize="90%" xref="algorithm2.2.2.m1.1.2.3.1.3.3.cmml">𝒯</mi></mrow></msub><mrow id="algorithm2.2.2.m1.1.2.3.2" xref="algorithm2.2.2.m1.1.2.3.2.cmml"><msup id="algorithm2.2.2.m1.1.2.3.2.2" xref="algorithm2.2.2.m1.1.2.3.2.2.cmml"><mi id="algorithm2.2.2.m1.1.2.3.2.2.2" mathsize="90%" xref="algorithm2.2.2.m1.1.2.3.2.2.2.cmml">k</mi><mo id="algorithm2.2.2.m1.1.2.3.2.2.3" mathsize="90%" xref="algorithm2.2.2.m1.1.2.3.2.2.3.cmml">∗</mo></msup><mo id="algorithm2.2.2.m1.1.2.3.2.1" xref="algorithm2.2.2.m1.1.2.3.2.1.cmml">⁢</mo><mrow id="algorithm2.2.2.m1.1.2.3.2.3.2" xref="algorithm2.2.2.m1.1.2.3.2.cmml"><mo id="algorithm2.2.2.m1.1.2.3.2.3.2.1" maxsize="90%" minsize="90%" xref="algorithm2.2.2.m1.1.2.3.2.cmml">(</mo><mi id="algorithm2.2.2.m1.1.1" mathsize="90%" xref="algorithm2.2.2.m1.1.1.cmml">𝐱</mi><mo id="algorithm2.2.2.m1.1.2.3.2.3.2.2" maxsize="90%" minsize="90%" xref="algorithm2.2.2.m1.1.2.3.2.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="algorithm2.2.2.m1.1b"><apply id="algorithm2.2.2.m1.1.2.cmml" xref="algorithm2.2.2.m1.1.2"><eq id="algorithm2.2.2.m1.1.2.1.cmml" xref="algorithm2.2.2.m1.1.2.1"></eq><ci id="algorithm2.2.2.m1.1.2.2.cmml" xref="algorithm2.2.2.m1.1.2.2">𝒦</ci><apply id="algorithm2.2.2.m1.1.2.3.cmml" xref="algorithm2.2.2.m1.1.2.3"><apply id="algorithm2.2.2.m1.1.2.3.1.cmml" xref="algorithm2.2.2.m1.1.2.3.1"><csymbol cd="ambiguous" id="algorithm2.2.2.m1.1.2.3.1.1.cmml" xref="algorithm2.2.2.m1.1.2.3.1">subscript</csymbol><union id="algorithm2.2.2.m1.1.2.3.1.2.cmml" xref="algorithm2.2.2.m1.1.2.3.1.2"></union><apply id="algorithm2.2.2.m1.1.2.3.1.3.cmml" xref="algorithm2.2.2.m1.1.2.3.1.3"><in id="algorithm2.2.2.m1.1.2.3.1.3.1.cmml" xref="algorithm2.2.2.m1.1.2.3.1.3.1"></in><ci id="algorithm2.2.2.m1.1.2.3.1.3.2.cmml" xref="algorithm2.2.2.m1.1.2.3.1.3.2">𝐱</ci><ci id="algorithm2.2.2.m1.1.2.3.1.3.3.cmml" xref="algorithm2.2.2.m1.1.2.3.1.3.3">𝒯</ci></apply></apply><apply id="algorithm2.2.2.m1.1.2.3.2.cmml" xref="algorithm2.2.2.m1.1.2.3.2"><times id="algorithm2.2.2.m1.1.2.3.2.1.cmml" xref="algorithm2.2.2.m1.1.2.3.2.1"></times><apply id="algorithm2.2.2.m1.1.2.3.2.2.cmml" xref="algorithm2.2.2.m1.1.2.3.2.2"><csymbol cd="ambiguous" id="algorithm2.2.2.m1.1.2.3.2.2.1.cmml" xref="algorithm2.2.2.m1.1.2.3.2.2">superscript</csymbol><ci id="algorithm2.2.2.m1.1.2.3.2.2.2.cmml" xref="algorithm2.2.2.m1.1.2.3.2.2.2">𝑘</ci><times id="algorithm2.2.2.m1.1.2.3.2.2.3.cmml" xref="algorithm2.2.2.m1.1.2.3.2.2.3"></times></apply><ci id="algorithm2.2.2.m1.1.1.cmml" xref="algorithm2.2.2.m1.1.1">𝐱</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.2.2.m1.1c">\mathcal{K}=\cup_{\mathbf{x}\in\mathcal{T}}k^{*}(\mathbf{x})</annotation><annotation encoding="application/x-llamapun" id="algorithm2.2.2.m1.1d">caligraphic_K = ∪ start_POSTSUBSCRIPT bold_x ∈ caligraphic_T end_POSTSUBSCRIPT italic_k start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT ( bold_x )</annotation></semantics></math><span class="ltx_text" id="algorithm2.3.3.3" style="font-size:90%;"> – Number of examples yielding the most confident and correct predictions for each instance </span><math alttext="\mathbf{x}\in\mathcal{T}" class="ltx_Math" display="inline" id="algorithm2.3.3.m2.1"><semantics id="algorithm2.3.3.m2.1a"><mrow id="algorithm2.3.3.m2.1.1" xref="algorithm2.3.3.m2.1.1.cmml"><mi id="algorithm2.3.3.m2.1.1.2" mathsize="90%" xref="algorithm2.3.3.m2.1.1.2.cmml">𝐱</mi><mo id="algorithm2.3.3.m2.1.1.1" mathsize="90%" xref="algorithm2.3.3.m2.1.1.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="algorithm2.3.3.m2.1.1.3" mathsize="90%" xref="algorithm2.3.3.m2.1.1.3.cmml">𝒯</mi></mrow><annotation-xml encoding="MathML-Content" id="algorithm2.3.3.m2.1b"><apply id="algorithm2.3.3.m2.1.1.cmml" xref="algorithm2.3.3.m2.1.1"><in id="algorithm2.3.3.m2.1.1.1.cmml" xref="algorithm2.3.3.m2.1.1.1"></in><ci id="algorithm2.3.3.m2.1.1.2.cmml" xref="algorithm2.3.3.m2.1.1.2">𝐱</ci><ci id="algorithm2.3.3.m2.1.1.3.cmml" xref="algorithm2.3.3.m2.1.1.3">𝒯</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.3.3.m2.1c">\mathbf{x}\in\mathcal{T}</annotation><annotation encoding="application/x-llamapun" id="algorithm2.3.3.m2.1d">bold_x ∈ caligraphic_T</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="algorithm2.19.20">
<span class="ltx_text" id="algorithm2.19.20.1" style="font-size:90%;">
</span><span class="ltx_text ltx_font_bold" id="algorithm2.19.20.2" style="font-size:90%;">begin</span>
</div>
<div class="ltx_listingline" id="algorithm2.19.21">
<span class="ltx_text" id="algorithm2.19.21.1" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.19.21.2" style="font-size:90%;">   </span><span class="ltx_text" id="algorithm2.19.21.3" style="font-size:90%;">
</span>
</div>
<div class="ltx_listingline" id="algorithm2.4.4">
<span class="ltx_text" id="algorithm2.4.4.2" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.4.4.3" style="font-size:90%;">   </span><span class="ltx_text ltx_font_bold" id="algorithm2.4.4.4" style="font-size:90%;">for</span><span class="ltx_text" id="algorithm2.4.4.5" style="font-size:90%;"> </span><em class="ltx_emph ltx_font_italic" id="algorithm2.4.4.1" style="font-size:90%;"><math alttext="\mathbf{x}\in\mathcal{T}" class="ltx_Math" display="inline" id="algorithm2.4.4.1.m1.1"><semantics id="algorithm2.4.4.1.m1.1a"><mrow id="algorithm2.4.4.1.m1.1.1" xref="algorithm2.4.4.1.m1.1.1.cmml"><mi id="algorithm2.4.4.1.m1.1.1.2" xref="algorithm2.4.4.1.m1.1.1.2.cmml">𝐱</mi><mo id="algorithm2.4.4.1.m1.1.1.1" xref="algorithm2.4.4.1.m1.1.1.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="algorithm2.4.4.1.m1.1.1.3" xref="algorithm2.4.4.1.m1.1.1.3.cmml">𝒯</mi></mrow><annotation-xml encoding="MathML-Content" id="algorithm2.4.4.1.m1.1b"><apply id="algorithm2.4.4.1.m1.1.1.cmml" xref="algorithm2.4.4.1.m1.1.1"><in id="algorithm2.4.4.1.m1.1.1.1.cmml" xref="algorithm2.4.4.1.m1.1.1.1"></in><ci id="algorithm2.4.4.1.m1.1.1.2.cmml" xref="algorithm2.4.4.1.m1.1.1.2">𝐱</ci><ci id="algorithm2.4.4.1.m1.1.1.3.cmml" xref="algorithm2.4.4.1.m1.1.1.3">𝒯</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.4.4.1.m1.1c">\mathbf{x}\in\mathcal{T}</annotation><annotation encoding="application/x-llamapun" id="algorithm2.4.4.1.m1.1d">bold_x ∈ caligraphic_T</annotation></semantics></math></em><span class="ltx_text" id="algorithm2.4.4.6" style="font-size:90%;"> </span><span class="ltx_text ltx_font_bold" id="algorithm2.4.4.7" style="font-size:90%;">do</span>
</div>
<div class="ltx_listingline" id="algorithm2.19.22">
<span class="ltx_text" id="algorithm2.19.22.1" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.19.22.2" style="font-size:90%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.19.22.3" style="font-size:90%;">   </span><span class="ltx_text" id="algorithm2.19.22.4" style="font-size:90%;">
</span>
</div>
<div class="ltx_listingline" id="algorithm2.6.6">
<span class="ltx_text" id="algorithm2.6.6.3" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.6.6.4" style="font-size:90%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.6.6.5" style="font-size:90%;">   </span><span class="ltx_text ltx_font_typewriter" id="algorithm2.6.6.2" style="font-size:90%;">max_confidence <math alttext="\leftarrow" class="ltx_Math" display="inline" id="algorithm2.5.5.1.m1.1"><semantics id="algorithm2.5.5.1.m1.1a"><mo id="algorithm2.5.5.1.m1.1.1" stretchy="false" xref="algorithm2.5.5.1.m1.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="algorithm2.5.5.1.m1.1b"><ci id="algorithm2.5.5.1.m1.1.1.cmml" xref="algorithm2.5.5.1.m1.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.5.5.1.m1.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="algorithm2.5.5.1.m1.1d">←</annotation></semantics></math> 0; <math alttext="k^{*}\leftarrow 1" class="ltx_Math" display="inline" id="algorithm2.6.6.2.m2.1"><semantics id="algorithm2.6.6.2.m2.1a"><mrow id="algorithm2.6.6.2.m2.1.1" xref="algorithm2.6.6.2.m2.1.1.cmml"><msup id="algorithm2.6.6.2.m2.1.1.2" xref="algorithm2.6.6.2.m2.1.1.2.cmml"><mi id="algorithm2.6.6.2.m2.1.1.2.2" xref="algorithm2.6.6.2.m2.1.1.2.2.cmml">k</mi><mo id="algorithm2.6.6.2.m2.1.1.2.3" xref="algorithm2.6.6.2.m2.1.1.2.3.cmml">∗</mo></msup><mo id="algorithm2.6.6.2.m2.1.1.1" stretchy="false" xref="algorithm2.6.6.2.m2.1.1.1.cmml">←</mo><mn id="algorithm2.6.6.2.m2.1.1.3" xref="algorithm2.6.6.2.m2.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="algorithm2.6.6.2.m2.1b"><apply id="algorithm2.6.6.2.m2.1.1.cmml" xref="algorithm2.6.6.2.m2.1.1"><ci id="algorithm2.6.6.2.m2.1.1.1.cmml" xref="algorithm2.6.6.2.m2.1.1.1">←</ci><apply id="algorithm2.6.6.2.m2.1.1.2.cmml" xref="algorithm2.6.6.2.m2.1.1.2"><csymbol cd="ambiguous" id="algorithm2.6.6.2.m2.1.1.2.1.cmml" xref="algorithm2.6.6.2.m2.1.1.2">superscript</csymbol><ci id="algorithm2.6.6.2.m2.1.1.2.2.cmml" xref="algorithm2.6.6.2.m2.1.1.2.2">𝑘</ci><times id="algorithm2.6.6.2.m2.1.1.2.3.cmml" xref="algorithm2.6.6.2.m2.1.1.2.3"></times></apply><cn id="algorithm2.6.6.2.m2.1.1.3.cmml" type="integer" xref="algorithm2.6.6.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.6.6.2.m2.1c">k^{*}\leftarrow 1</annotation><annotation encoding="application/x-llamapun" id="algorithm2.6.6.2.m2.1d">italic_k start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT ← 1</annotation></semantics></math></span><span class="ltx_text" id="algorithm2.6.6.6" style="font-size:90%;">
</span>
</div>
<div class="ltx_listingline" id="algorithm2.8.8">
<span class="ltx_text" id="algorithm2.8.8.3" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.8.8.4" style="font-size:90%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.8.8.5" style="font-size:90%;">   </span><span class="ltx_text ltx_font_bold" id="algorithm2.8.8.6" style="font-size:90%;">for</span><span class="ltx_text" id="algorithm2.8.8.7" style="font-size:90%;"> </span><em class="ltx_emph ltx_font_italic" id="algorithm2.8.8.2" style="font-size:90%;"><math alttext="j\leftarrow 0" class="ltx_Math" display="inline" id="algorithm2.7.7.1.m1.1"><semantics id="algorithm2.7.7.1.m1.1a"><mrow id="algorithm2.7.7.1.m1.1.1" xref="algorithm2.7.7.1.m1.1.1.cmml"><mi id="algorithm2.7.7.1.m1.1.1.2" xref="algorithm2.7.7.1.m1.1.1.2.cmml">j</mi><mo id="algorithm2.7.7.1.m1.1.1.1" stretchy="false" xref="algorithm2.7.7.1.m1.1.1.1.cmml">←</mo><mn id="algorithm2.7.7.1.m1.1.1.3" xref="algorithm2.7.7.1.m1.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="algorithm2.7.7.1.m1.1b"><apply id="algorithm2.7.7.1.m1.1.1.cmml" xref="algorithm2.7.7.1.m1.1.1"><ci id="algorithm2.7.7.1.m1.1.1.1.cmml" xref="algorithm2.7.7.1.m1.1.1.1">←</ci><ci id="algorithm2.7.7.1.m1.1.1.2.cmml" xref="algorithm2.7.7.1.m1.1.1.2">𝑗</ci><cn id="algorithm2.7.7.1.m1.1.1.3.cmml" type="integer" xref="algorithm2.7.7.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.7.7.1.m1.1c">j\leftarrow 0</annotation><annotation encoding="application/x-llamapun" id="algorithm2.7.7.1.m1.1d">italic_j ← 0</annotation></semantics></math> to <math alttext="M" class="ltx_Math" display="inline" id="algorithm2.8.8.2.m2.1"><semantics id="algorithm2.8.8.2.m2.1a"><mi id="algorithm2.8.8.2.m2.1.1" xref="algorithm2.8.8.2.m2.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="algorithm2.8.8.2.m2.1b"><ci id="algorithm2.8.8.2.m2.1.1.cmml" xref="algorithm2.8.8.2.m2.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.8.8.2.m2.1c">M</annotation><annotation encoding="application/x-llamapun" id="algorithm2.8.8.2.m2.1d">italic_M</annotation></semantics></math></em><span class="ltx_text" id="algorithm2.8.8.8" style="font-size:90%;"> </span><span class="ltx_text ltx_font_bold" id="algorithm2.8.8.9" style="font-size:90%;">do</span>
</div>
<div class="ltx_listingline" id="algorithm2.11.11">
<span class="ltx_text" id="algorithm2.11.11.3" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.11.11.4" style="font-size:90%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.11.11.5" style="font-size:90%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.11.11.6" style="font-size:90%;">   </span><span class="ltx_text" id="algorithm2.11.11.7" style="font-size:90%;">
</span><math alttext="\Delta_{p}\leftarrow" class="ltx_Math" display="inline" id="algorithm2.9.9.m1.1"><semantics id="algorithm2.9.9.m1.1a"><mrow id="algorithm2.9.9.m1.1.1" xref="algorithm2.9.9.m1.1.1.cmml"><msub id="algorithm2.9.9.m1.1.1.2" xref="algorithm2.9.9.m1.1.1.2.cmml"><mi id="algorithm2.9.9.m1.1.1.2.2" mathsize="90%" mathvariant="normal" xref="algorithm2.9.9.m1.1.1.2.2.cmml">Δ</mi><mi id="algorithm2.9.9.m1.1.1.2.3" mathsize="90%" xref="algorithm2.9.9.m1.1.1.2.3.cmml">p</mi></msub><mo id="algorithm2.9.9.m1.1.1.1" mathsize="90%" stretchy="false" xref="algorithm2.9.9.m1.1.1.1.cmml">←</mo><mi id="algorithm2.9.9.m1.1.1.3" xref="algorithm2.9.9.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="algorithm2.9.9.m1.1b"><apply id="algorithm2.9.9.m1.1.1.cmml" xref="algorithm2.9.9.m1.1.1"><ci id="algorithm2.9.9.m1.1.1.1.cmml" xref="algorithm2.9.9.m1.1.1.1">←</ci><apply id="algorithm2.9.9.m1.1.1.2.cmml" xref="algorithm2.9.9.m1.1.1.2"><csymbol cd="ambiguous" id="algorithm2.9.9.m1.1.1.2.1.cmml" xref="algorithm2.9.9.m1.1.1.2">subscript</csymbol><ci id="algorithm2.9.9.m1.1.1.2.2.cmml" xref="algorithm2.9.9.m1.1.1.2.2">Δ</ci><ci id="algorithm2.9.9.m1.1.1.2.3.cmml" xref="algorithm2.9.9.m1.1.1.2.3">𝑝</ci></apply><csymbol cd="latexml" id="algorithm2.9.9.m1.1.1.3.cmml" xref="algorithm2.9.9.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.9.9.m1.1c">\Delta_{p}\leftarrow</annotation><annotation encoding="application/x-llamapun" id="algorithm2.9.9.m1.1d">roman_Δ start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ←</annotation></semantics></math><span class="ltx_text" id="algorithm2.11.11.8" style="font-size:90%;"> </span><span class="ltx_text ltx_font_typewriter" id="algorithm2.11.11.2" style="font-size:90%;">LLM <math alttext="k" class="ltx_Math" display="inline" id="algorithm2.10.10.1.m1.1"><semantics id="algorithm2.10.10.1.m1.1a"><mi id="algorithm2.10.10.1.m1.1.1" xref="algorithm2.10.10.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="algorithm2.10.10.1.m1.1b"><ci id="algorithm2.10.10.1.m1.1.1.cmml" xref="algorithm2.10.10.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.10.10.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="algorithm2.10.10.1.m1.1d">italic_k</annotation></semantics></math>-shot predictions(<math alttext="\mathbf{x},j" class="ltx_Math" display="inline" id="algorithm2.11.11.2.m2.2"><semantics id="algorithm2.11.11.2.m2.2a"><mrow id="algorithm2.11.11.2.m2.2.3.2" xref="algorithm2.11.11.2.m2.2.3.1.cmml"><mi id="algorithm2.11.11.2.m2.1.1" xref="algorithm2.11.11.2.m2.1.1.cmml">𝐱</mi><mo id="algorithm2.11.11.2.m2.2.3.2.1" xref="algorithm2.11.11.2.m2.2.3.1.cmml">,</mo><mi id="algorithm2.11.11.2.m2.2.2" xref="algorithm2.11.11.2.m2.2.2.cmml">j</mi></mrow><annotation-xml encoding="MathML-Content" id="algorithm2.11.11.2.m2.2b"><list id="algorithm2.11.11.2.m2.2.3.1.cmml" xref="algorithm2.11.11.2.m2.2.3.2"><ci id="algorithm2.11.11.2.m2.1.1.cmml" xref="algorithm2.11.11.2.m2.1.1">𝐱</ci><ci id="algorithm2.11.11.2.m2.2.2.cmml" xref="algorithm2.11.11.2.m2.2.2">𝑗</ci></list></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.11.11.2.m2.2c">\mathbf{x},j</annotation><annotation encoding="application/x-llamapun" id="algorithm2.11.11.2.m2.2d">bold_x , italic_j</annotation></semantics></math>)</span><span class="ltx_text" id="algorithm2.11.11.9" style="font-size:90%;"> </span>
</div>
<div class="ltx_listingline" id="algorithm2.12.12">
<span class="ltx_text" id="algorithm2.12.12.2" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.12.12.3" style="font-size:90%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.12.12.4" style="font-size:90%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.12.12.5" style="font-size:90%;">   </span><span class="ltx_text" id="algorithm2.12.12.6" style="font-size:90%;">  </span><span class="ltx_text ltx_font_typewriter" id="algorithm2.12.12.7" style="font-size:90%;">// </span><span class="ltx_text ltx_font_typewriter" id="algorithm2.12.12.1" style="font-size:80%;">Call Algorithm <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#algorithm1" title="In 3.3. Supervised Rank Cutoff ‣ 3. Adaptive ICL ↦ QPP? ‣ “In-Context Learning” or: How I learned to stop worrying and love “Applied Information Retrieval”"><span class="ltx_text ltx_ref_tag">1</span></a>, i.e., try to predict with <math alttext="j" class="ltx_Math" display="inline" id="algorithm2.12.12.1.m1.1"><semantics id="algorithm2.12.12.1.m1.1a"><mi id="algorithm2.12.12.1.m1.1.1" xref="algorithm2.12.12.1.m1.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="algorithm2.12.12.1.m1.1b"><ci id="algorithm2.12.12.1.m1.1.1.cmml" xref="algorithm2.12.12.1.m1.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.12.12.1.m1.1c">j</annotation><annotation encoding="application/x-llamapun" id="algorithm2.12.12.1.m1.1d">italic_j</annotation></semantics></math> examples</span>
</div>
<div class="ltx_listingline" id="algorithm2.19.23">
<span class="ltx_text" id="algorithm2.19.23.1" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.19.23.2" style="font-size:90%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.19.23.3" style="font-size:90%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.19.23.4" style="font-size:90%;">   </span><span class="ltx_text" id="algorithm2.19.23.5" style="font-size:90%;">
</span>
</div>
<div class="ltx_listingline" id="algorithm2.13.13">
<span class="ltx_text" id="algorithm2.13.13.1" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.13.13.2" style="font-size:90%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.13.13.3" style="font-size:90%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.13.13.4" style="font-size:90%;">   </span><math alttext="\hat{y}(\mathbf{x})\leftarrow\text{argmax}\Delta_{p}" class="ltx_Math" display="inline" id="algorithm2.13.13.m1.1"><semantics id="algorithm2.13.13.m1.1a"><mrow id="algorithm2.13.13.m1.1.2" xref="algorithm2.13.13.m1.1.2.cmml"><mrow id="algorithm2.13.13.m1.1.2.2" xref="algorithm2.13.13.m1.1.2.2.cmml"><mover accent="true" id="algorithm2.13.13.m1.1.2.2.2" xref="algorithm2.13.13.m1.1.2.2.2.cmml"><mi id="algorithm2.13.13.m1.1.2.2.2.2" mathsize="90%" xref="algorithm2.13.13.m1.1.2.2.2.2.cmml">y</mi><mo id="algorithm2.13.13.m1.1.2.2.2.1" mathsize="90%" xref="algorithm2.13.13.m1.1.2.2.2.1.cmml">^</mo></mover><mo id="algorithm2.13.13.m1.1.2.2.1" xref="algorithm2.13.13.m1.1.2.2.1.cmml">⁢</mo><mrow id="algorithm2.13.13.m1.1.2.2.3.2" xref="algorithm2.13.13.m1.1.2.2.cmml"><mo id="algorithm2.13.13.m1.1.2.2.3.2.1" maxsize="90%" minsize="90%" xref="algorithm2.13.13.m1.1.2.2.cmml">(</mo><mi id="algorithm2.13.13.m1.1.1" mathsize="90%" xref="algorithm2.13.13.m1.1.1.cmml">𝐱</mi><mo id="algorithm2.13.13.m1.1.2.2.3.2.2" maxsize="90%" minsize="90%" xref="algorithm2.13.13.m1.1.2.2.cmml">)</mo></mrow></mrow><mo id="algorithm2.13.13.m1.1.2.1" mathsize="90%" stretchy="false" xref="algorithm2.13.13.m1.1.2.1.cmml">←</mo><mrow id="algorithm2.13.13.m1.1.2.3" xref="algorithm2.13.13.m1.1.2.3.cmml"><mtext id="algorithm2.13.13.m1.1.2.3.2" mathsize="90%" xref="algorithm2.13.13.m1.1.2.3.2a.cmml">argmax</mtext><mo id="algorithm2.13.13.m1.1.2.3.1" xref="algorithm2.13.13.m1.1.2.3.1.cmml">⁢</mo><msub id="algorithm2.13.13.m1.1.2.3.3" xref="algorithm2.13.13.m1.1.2.3.3.cmml"><mi id="algorithm2.13.13.m1.1.2.3.3.2" mathsize="90%" mathvariant="normal" xref="algorithm2.13.13.m1.1.2.3.3.2.cmml">Δ</mi><mi id="algorithm2.13.13.m1.1.2.3.3.3" mathsize="90%" xref="algorithm2.13.13.m1.1.2.3.3.3.cmml">p</mi></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="algorithm2.13.13.m1.1b"><apply id="algorithm2.13.13.m1.1.2.cmml" xref="algorithm2.13.13.m1.1.2"><ci id="algorithm2.13.13.m1.1.2.1.cmml" xref="algorithm2.13.13.m1.1.2.1">←</ci><apply id="algorithm2.13.13.m1.1.2.2.cmml" xref="algorithm2.13.13.m1.1.2.2"><times id="algorithm2.13.13.m1.1.2.2.1.cmml" xref="algorithm2.13.13.m1.1.2.2.1"></times><apply id="algorithm2.13.13.m1.1.2.2.2.cmml" xref="algorithm2.13.13.m1.1.2.2.2"><ci id="algorithm2.13.13.m1.1.2.2.2.1.cmml" xref="algorithm2.13.13.m1.1.2.2.2.1">^</ci><ci id="algorithm2.13.13.m1.1.2.2.2.2.cmml" xref="algorithm2.13.13.m1.1.2.2.2.2">𝑦</ci></apply><ci id="algorithm2.13.13.m1.1.1.cmml" xref="algorithm2.13.13.m1.1.1">𝐱</ci></apply><apply id="algorithm2.13.13.m1.1.2.3.cmml" xref="algorithm2.13.13.m1.1.2.3"><times id="algorithm2.13.13.m1.1.2.3.1.cmml" xref="algorithm2.13.13.m1.1.2.3.1"></times><ci id="algorithm2.13.13.m1.1.2.3.2a.cmml" xref="algorithm2.13.13.m1.1.2.3.2"><mtext id="algorithm2.13.13.m1.1.2.3.2.cmml" mathsize="90%" xref="algorithm2.13.13.m1.1.2.3.2">argmax</mtext></ci><apply id="algorithm2.13.13.m1.1.2.3.3.cmml" xref="algorithm2.13.13.m1.1.2.3.3"><csymbol cd="ambiguous" id="algorithm2.13.13.m1.1.2.3.3.1.cmml" xref="algorithm2.13.13.m1.1.2.3.3">subscript</csymbol><ci id="algorithm2.13.13.m1.1.2.3.3.2.cmml" xref="algorithm2.13.13.m1.1.2.3.3.2">Δ</ci><ci id="algorithm2.13.13.m1.1.2.3.3.3.cmml" xref="algorithm2.13.13.m1.1.2.3.3.3">𝑝</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.13.13.m1.1c">\hat{y}(\mathbf{x})\leftarrow\text{argmax}\Delta_{p}</annotation><annotation encoding="application/x-llamapun" id="algorithm2.13.13.m1.1d">over^ start_ARG italic_y end_ARG ( bold_x ) ← argmax roman_Δ start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="algorithm2.13.13.5" style="font-size:90%;"> </span>
</div>
<div class="ltx_listingline" id="algorithm2.19.24">
<span class="ltx_text" id="algorithm2.19.24.1" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.19.24.2" style="font-size:90%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.19.24.3" style="font-size:90%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.19.24.4" style="font-size:90%;">   </span><span class="ltx_text" id="algorithm2.19.24.5" style="font-size:90%;">  </span><span class="ltx_text ltx_font_typewriter" id="algorithm2.19.24.6" style="font-size:90%;">// </span><span class="ltx_text ltx_font_typewriter" id="algorithm2.19.24.7" style="font-size:80%;">Get the predicted class</span>
</div>
<div class="ltx_listingline" id="algorithm2.14.14">
<span class="ltx_text" id="algorithm2.14.14.2" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.14.14.3" style="font-size:90%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.14.14.4" style="font-size:90%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.14.14.5" style="font-size:90%;">   </span><span class="ltx_text" id="algorithm2.14.14.6" style="font-size:90%;">
</span><span class="ltx_text ltx_font_typewriter" id="algorithm2.14.14.1" style="font-size:90%;">confidence<math alttext="\leftarrow\Delta_{\hat{y}(\mathbf{x})}\mathbb{I}(\hat{y}(\mathbf{x})=y(\mathbf%
{x}))" class="ltx_Math" display="inline" id="algorithm2.14.14.1.m1.4"><semantics id="algorithm2.14.14.1.m1.4a"><mrow id="algorithm2.14.14.1.m1.4.4" xref="algorithm2.14.14.1.m1.4.4.cmml"><mi id="algorithm2.14.14.1.m1.4.4.3" xref="algorithm2.14.14.1.m1.4.4.3.cmml"></mi><mo id="algorithm2.14.14.1.m1.4.4.2" stretchy="false" xref="algorithm2.14.14.1.m1.4.4.2.cmml">←</mo><mrow id="algorithm2.14.14.1.m1.4.4.1" xref="algorithm2.14.14.1.m1.4.4.1.cmml"><msub id="algorithm2.14.14.1.m1.4.4.1.3" xref="algorithm2.14.14.1.m1.4.4.1.3.cmml"><mi id="algorithm2.14.14.1.m1.4.4.1.3.2" mathvariant="normal" xref="algorithm2.14.14.1.m1.4.4.1.3.2.cmml">Δ</mi><mrow id="algorithm2.14.14.1.m1.1.1.1" xref="algorithm2.14.14.1.m1.1.1.1.cmml"><mover accent="true" id="algorithm2.14.14.1.m1.1.1.1.3" xref="algorithm2.14.14.1.m1.1.1.1.3.cmml"><mi id="algorithm2.14.14.1.m1.1.1.1.3.2" xref="algorithm2.14.14.1.m1.1.1.1.3.2.cmml">y</mi><mo id="algorithm2.14.14.1.m1.1.1.1.3.1" xref="algorithm2.14.14.1.m1.1.1.1.3.1.cmml">^</mo></mover><mo id="algorithm2.14.14.1.m1.1.1.1.2" xref="algorithm2.14.14.1.m1.1.1.1.2.cmml">⁢</mo><mrow id="algorithm2.14.14.1.m1.1.1.1.4.2" xref="algorithm2.14.14.1.m1.1.1.1.cmml"><mo id="algorithm2.14.14.1.m1.1.1.1.4.2.1" stretchy="false" xref="algorithm2.14.14.1.m1.1.1.1.cmml">(</mo><mi id="algorithm2.14.14.1.m1.1.1.1.1" xref="algorithm2.14.14.1.m1.1.1.1.1.cmml">𝐱</mi><mo id="algorithm2.14.14.1.m1.1.1.1.4.2.2" stretchy="false" xref="algorithm2.14.14.1.m1.1.1.1.cmml">)</mo></mrow></mrow></msub><mo id="algorithm2.14.14.1.m1.4.4.1.2" xref="algorithm2.14.14.1.m1.4.4.1.2.cmml">⁢</mo><mi id="algorithm2.14.14.1.m1.4.4.1.4" xref="algorithm2.14.14.1.m1.4.4.1.4.cmml">𝕀</mi><mo id="algorithm2.14.14.1.m1.4.4.1.2a" xref="algorithm2.14.14.1.m1.4.4.1.2.cmml">⁢</mo><mrow id="algorithm2.14.14.1.m1.4.4.1.1.1" xref="algorithm2.14.14.1.m1.4.4.1.1.1.1.cmml"><mo id="algorithm2.14.14.1.m1.4.4.1.1.1.2" stretchy="false" xref="algorithm2.14.14.1.m1.4.4.1.1.1.1.cmml">(</mo><mrow id="algorithm2.14.14.1.m1.4.4.1.1.1.1" xref="algorithm2.14.14.1.m1.4.4.1.1.1.1.cmml"><mrow id="algorithm2.14.14.1.m1.4.4.1.1.1.1.2" xref="algorithm2.14.14.1.m1.4.4.1.1.1.1.2.cmml"><mover accent="true" id="algorithm2.14.14.1.m1.4.4.1.1.1.1.2.2" xref="algorithm2.14.14.1.m1.4.4.1.1.1.1.2.2.cmml"><mi id="algorithm2.14.14.1.m1.4.4.1.1.1.1.2.2.2" xref="algorithm2.14.14.1.m1.4.4.1.1.1.1.2.2.2.cmml">y</mi><mo id="algorithm2.14.14.1.m1.4.4.1.1.1.1.2.2.1" xref="algorithm2.14.14.1.m1.4.4.1.1.1.1.2.2.1.cmml">^</mo></mover><mo id="algorithm2.14.14.1.m1.4.4.1.1.1.1.2.1" xref="algorithm2.14.14.1.m1.4.4.1.1.1.1.2.1.cmml">⁢</mo><mrow id="algorithm2.14.14.1.m1.4.4.1.1.1.1.2.3.2" xref="algorithm2.14.14.1.m1.4.4.1.1.1.1.2.cmml"><mo id="algorithm2.14.14.1.m1.4.4.1.1.1.1.2.3.2.1" stretchy="false" xref="algorithm2.14.14.1.m1.4.4.1.1.1.1.2.cmml">(</mo><mi id="algorithm2.14.14.1.m1.2.2" xref="algorithm2.14.14.1.m1.2.2.cmml">𝐱</mi><mo id="algorithm2.14.14.1.m1.4.4.1.1.1.1.2.3.2.2" stretchy="false" xref="algorithm2.14.14.1.m1.4.4.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="algorithm2.14.14.1.m1.4.4.1.1.1.1.1" xref="algorithm2.14.14.1.m1.4.4.1.1.1.1.1.cmml">=</mo><mrow id="algorithm2.14.14.1.m1.4.4.1.1.1.1.3" xref="algorithm2.14.14.1.m1.4.4.1.1.1.1.3.cmml"><mi id="algorithm2.14.14.1.m1.4.4.1.1.1.1.3.2" xref="algorithm2.14.14.1.m1.4.4.1.1.1.1.3.2.cmml">y</mi><mo id="algorithm2.14.14.1.m1.4.4.1.1.1.1.3.1" xref="algorithm2.14.14.1.m1.4.4.1.1.1.1.3.1.cmml">⁢</mo><mrow id="algorithm2.14.14.1.m1.4.4.1.1.1.1.3.3.2" xref="algorithm2.14.14.1.m1.4.4.1.1.1.1.3.cmml"><mo id="algorithm2.14.14.1.m1.4.4.1.1.1.1.3.3.2.1" stretchy="false" xref="algorithm2.14.14.1.m1.4.4.1.1.1.1.3.cmml">(</mo><mi id="algorithm2.14.14.1.m1.3.3" xref="algorithm2.14.14.1.m1.3.3.cmml">𝐱</mi><mo id="algorithm2.14.14.1.m1.4.4.1.1.1.1.3.3.2.2" stretchy="false" xref="algorithm2.14.14.1.m1.4.4.1.1.1.1.3.cmml">)</mo></mrow></mrow></mrow><mo id="algorithm2.14.14.1.m1.4.4.1.1.1.3" stretchy="false" xref="algorithm2.14.14.1.m1.4.4.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="algorithm2.14.14.1.m1.4b"><apply id="algorithm2.14.14.1.m1.4.4.cmml" xref="algorithm2.14.14.1.m1.4.4"><ci id="algorithm2.14.14.1.m1.4.4.2.cmml" xref="algorithm2.14.14.1.m1.4.4.2">←</ci><csymbol cd="latexml" id="algorithm2.14.14.1.m1.4.4.3.cmml" xref="algorithm2.14.14.1.m1.4.4.3">absent</csymbol><apply id="algorithm2.14.14.1.m1.4.4.1.cmml" xref="algorithm2.14.14.1.m1.4.4.1"><times id="algorithm2.14.14.1.m1.4.4.1.2.cmml" xref="algorithm2.14.14.1.m1.4.4.1.2"></times><apply id="algorithm2.14.14.1.m1.4.4.1.3.cmml" xref="algorithm2.14.14.1.m1.4.4.1.3"><csymbol cd="ambiguous" id="algorithm2.14.14.1.m1.4.4.1.3.1.cmml" xref="algorithm2.14.14.1.m1.4.4.1.3">subscript</csymbol><ci id="algorithm2.14.14.1.m1.4.4.1.3.2.cmml" xref="algorithm2.14.14.1.m1.4.4.1.3.2">Δ</ci><apply id="algorithm2.14.14.1.m1.1.1.1.cmml" xref="algorithm2.14.14.1.m1.1.1.1"><times id="algorithm2.14.14.1.m1.1.1.1.2.cmml" xref="algorithm2.14.14.1.m1.1.1.1.2"></times><apply id="algorithm2.14.14.1.m1.1.1.1.3.cmml" xref="algorithm2.14.14.1.m1.1.1.1.3"><ci id="algorithm2.14.14.1.m1.1.1.1.3.1.cmml" xref="algorithm2.14.14.1.m1.1.1.1.3.1">^</ci><ci id="algorithm2.14.14.1.m1.1.1.1.3.2.cmml" xref="algorithm2.14.14.1.m1.1.1.1.3.2">𝑦</ci></apply><ci id="algorithm2.14.14.1.m1.1.1.1.1.cmml" xref="algorithm2.14.14.1.m1.1.1.1.1">𝐱</ci></apply></apply><ci id="algorithm2.14.14.1.m1.4.4.1.4.cmml" xref="algorithm2.14.14.1.m1.4.4.1.4">𝕀</ci><apply id="algorithm2.14.14.1.m1.4.4.1.1.1.1.cmml" xref="algorithm2.14.14.1.m1.4.4.1.1.1"><eq id="algorithm2.14.14.1.m1.4.4.1.1.1.1.1.cmml" xref="algorithm2.14.14.1.m1.4.4.1.1.1.1.1"></eq><apply id="algorithm2.14.14.1.m1.4.4.1.1.1.1.2.cmml" xref="algorithm2.14.14.1.m1.4.4.1.1.1.1.2"><times id="algorithm2.14.14.1.m1.4.4.1.1.1.1.2.1.cmml" xref="algorithm2.14.14.1.m1.4.4.1.1.1.1.2.1"></times><apply id="algorithm2.14.14.1.m1.4.4.1.1.1.1.2.2.cmml" xref="algorithm2.14.14.1.m1.4.4.1.1.1.1.2.2"><ci id="algorithm2.14.14.1.m1.4.4.1.1.1.1.2.2.1.cmml" xref="algorithm2.14.14.1.m1.4.4.1.1.1.1.2.2.1">^</ci><ci id="algorithm2.14.14.1.m1.4.4.1.1.1.1.2.2.2.cmml" xref="algorithm2.14.14.1.m1.4.4.1.1.1.1.2.2.2">𝑦</ci></apply><ci id="algorithm2.14.14.1.m1.2.2.cmml" xref="algorithm2.14.14.1.m1.2.2">𝐱</ci></apply><apply id="algorithm2.14.14.1.m1.4.4.1.1.1.1.3.cmml" xref="algorithm2.14.14.1.m1.4.4.1.1.1.1.3"><times id="algorithm2.14.14.1.m1.4.4.1.1.1.1.3.1.cmml" xref="algorithm2.14.14.1.m1.4.4.1.1.1.1.3.1"></times><ci id="algorithm2.14.14.1.m1.4.4.1.1.1.1.3.2.cmml" xref="algorithm2.14.14.1.m1.4.4.1.1.1.1.3.2">𝑦</ci><ci id="algorithm2.14.14.1.m1.3.3.cmml" xref="algorithm2.14.14.1.m1.3.3">𝐱</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.14.14.1.m1.4c">\leftarrow\Delta_{\hat{y}(\mathbf{x})}\mathbb{I}(\hat{y}(\mathbf{x})=y(\mathbf%
{x}))</annotation><annotation encoding="application/x-llamapun" id="algorithm2.14.14.1.m1.4d">← roman_Δ start_POSTSUBSCRIPT over^ start_ARG italic_y end_ARG ( bold_x ) end_POSTSUBSCRIPT blackboard_I ( over^ start_ARG italic_y end_ARG ( bold_x ) = italic_y ( bold_x ) )</annotation></semantics></math></span><span class="ltx_text" id="algorithm2.14.14.7" style="font-size:90%;"> </span>
</div>
<div class="ltx_listingline" id="algorithm2.19.25">
<span class="ltx_text" id="algorithm2.19.25.1" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.19.25.2" style="font-size:90%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.19.25.3" style="font-size:90%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.19.25.4" style="font-size:90%;">   </span><span class="ltx_text" id="algorithm2.19.25.5" style="font-size:90%;">  </span><span class="ltx_text ltx_font_typewriter" id="algorithm2.19.25.6" style="font-size:90%;">// </span><span class="ltx_text ltx_font_typewriter" id="algorithm2.19.25.7" style="font-size:80%;">Check if the predicted class is the correct one and record the prediction confidence</span>
</div>
<div class="ltx_listingline" id="algorithm2.19.26">
<span class="ltx_text" id="algorithm2.19.26.1" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.19.26.2" style="font-size:90%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.19.26.3" style="font-size:90%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.19.26.4" style="font-size:90%;">   </span><span class="ltx_text" id="algorithm2.19.26.5" style="font-size:90%;">
</span>
</div>
<div class="ltx_listingline" id="algorithm2.15.15">
<span class="ltx_text" id="algorithm2.15.15.2" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.15.15.3" style="font-size:90%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.15.15.4" style="font-size:90%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.15.15.5" style="font-size:90%;">   </span><span class="ltx_text ltx_font_bold" id="algorithm2.15.15.6" style="font-size:90%;">if</span><span class="ltx_text" id="algorithm2.15.15.7" style="font-size:90%;"> </span><em class="ltx_emph ltx_font_typewriter ltx_font_italic" id="algorithm2.15.15.1" style="font-size:90%;">confidence <math alttext="&gt;" class="ltx_Math" display="inline" id="algorithm2.15.15.1.1.m1.1"><semantics id="algorithm2.15.15.1.1.m1.1a"><mo id="algorithm2.15.15.1.1.m1.1.1" xref="algorithm2.15.15.1.1.m1.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="algorithm2.15.15.1.1.m1.1b"><gt id="algorithm2.15.15.1.1.m1.1.1.cmml" xref="algorithm2.15.15.1.1.m1.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.15.15.1.1.m1.1c">&gt;</annotation><annotation encoding="application/x-llamapun" id="algorithm2.15.15.1.1.m1.1d">&gt;</annotation></semantics></math> max_confidence</em><span class="ltx_text" id="algorithm2.15.15.8" style="font-size:90%;"> </span><span class="ltx_text ltx_font_bold" id="algorithm2.15.15.9" style="font-size:90%;">then</span>
</div>
<div class="ltx_listingline" id="algorithm2.16.16">
<span class="ltx_text" id="algorithm2.16.16.2" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.16.16.3" style="font-size:90%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.16.16.4" style="font-size:90%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.16.16.5" style="font-size:90%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.16.16.6" style="font-size:90%;">   </span><span class="ltx_text" id="algorithm2.16.16.7" style="font-size:90%;">
</span><span class="ltx_text ltx_font_typewriter" id="algorithm2.16.16.1" style="font-size:90%;">max_confidence <math alttext="\leftarrow" class="ltx_Math" display="inline" id="algorithm2.16.16.1.m1.1"><semantics id="algorithm2.16.16.1.m1.1a"><mo id="algorithm2.16.16.1.m1.1.1" stretchy="false" xref="algorithm2.16.16.1.m1.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="algorithm2.16.16.1.m1.1b"><ci id="algorithm2.16.16.1.m1.1.1.cmml" xref="algorithm2.16.16.1.m1.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.16.16.1.m1.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="algorithm2.16.16.1.m1.1d">←</annotation></semantics></math> confidence</span><span class="ltx_text" id="algorithm2.16.16.8" style="font-size:90%;"> </span>
</div>
<div class="ltx_listingline" id="algorithm2.19.27">
<span class="ltx_text" id="algorithm2.19.27.1" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.19.27.2" style="font-size:90%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.19.27.3" style="font-size:90%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.19.27.4" style="font-size:90%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.19.27.5" style="font-size:90%;">   </span><span class="ltx_text" id="algorithm2.19.27.6" style="font-size:90%;">  </span><span class="ltx_text ltx_font_typewriter" id="algorithm2.19.27.7" style="font-size:90%;">// </span><span class="ltx_text ltx_font_typewriter" id="algorithm2.19.27.8" style="font-size:80%;">Keep track of the least uncertain correct prediction</span>
</div>
<div class="ltx_listingline" id="algorithm2.17.17">
<span class="ltx_text" id="algorithm2.17.17.1" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.17.17.2" style="font-size:90%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.17.17.3" style="font-size:90%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.17.17.4" style="font-size:90%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.17.17.5" style="font-size:90%;">   </span><span class="ltx_text" id="algorithm2.17.17.6" style="font-size:90%;">
</span><math alttext="k^{*}\leftarrow j" class="ltx_Math" display="inline" id="algorithm2.17.17.m1.1"><semantics id="algorithm2.17.17.m1.1a"><mrow id="algorithm2.17.17.m1.1.1" xref="algorithm2.17.17.m1.1.1.cmml"><msup id="algorithm2.17.17.m1.1.1.2" xref="algorithm2.17.17.m1.1.1.2.cmml"><mi id="algorithm2.17.17.m1.1.1.2.2" mathsize="90%" xref="algorithm2.17.17.m1.1.1.2.2.cmml">k</mi><mo id="algorithm2.17.17.m1.1.1.2.3" mathsize="90%" xref="algorithm2.17.17.m1.1.1.2.3.cmml">∗</mo></msup><mo id="algorithm2.17.17.m1.1.1.1" mathsize="90%" stretchy="false" xref="algorithm2.17.17.m1.1.1.1.cmml">←</mo><mi id="algorithm2.17.17.m1.1.1.3" mathsize="90%" xref="algorithm2.17.17.m1.1.1.3.cmml">j</mi></mrow><annotation-xml encoding="MathML-Content" id="algorithm2.17.17.m1.1b"><apply id="algorithm2.17.17.m1.1.1.cmml" xref="algorithm2.17.17.m1.1.1"><ci id="algorithm2.17.17.m1.1.1.1.cmml" xref="algorithm2.17.17.m1.1.1.1">←</ci><apply id="algorithm2.17.17.m1.1.1.2.cmml" xref="algorithm2.17.17.m1.1.1.2"><csymbol cd="ambiguous" id="algorithm2.17.17.m1.1.1.2.1.cmml" xref="algorithm2.17.17.m1.1.1.2">superscript</csymbol><ci id="algorithm2.17.17.m1.1.1.2.2.cmml" xref="algorithm2.17.17.m1.1.1.2.2">𝑘</ci><times id="algorithm2.17.17.m1.1.1.2.3.cmml" xref="algorithm2.17.17.m1.1.1.2.3"></times></apply><ci id="algorithm2.17.17.m1.1.1.3.cmml" xref="algorithm2.17.17.m1.1.1.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.17.17.m1.1c">k^{*}\leftarrow j</annotation><annotation encoding="application/x-llamapun" id="algorithm2.17.17.m1.1d">italic_k start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT ← italic_j</annotation></semantics></math><span class="ltx_text" id="algorithm2.17.17.7" style="font-size:90%;">
</span>
</div>
<div class="ltx_listingline" id="algorithm2.18.18">
<span class="ltx_text" id="algorithm2.18.18.1" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.18.18.2" style="font-size:90%;">     </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.18.18.3" style="font-size:90%;">   </span><math alttext="\mathcal{K}\leftarrow\mathcal{K}\cup k^{*}" class="ltx_Math" display="inline" id="algorithm2.18.18.m1.1"><semantics id="algorithm2.18.18.m1.1a"><mrow id="algorithm2.18.18.m1.1.1" xref="algorithm2.18.18.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="algorithm2.18.18.m1.1.1.2" mathsize="90%" xref="algorithm2.18.18.m1.1.1.2.cmml">𝒦</mi><mo id="algorithm2.18.18.m1.1.1.1" mathsize="90%" stretchy="false" xref="algorithm2.18.18.m1.1.1.1.cmml">←</mo><mrow id="algorithm2.18.18.m1.1.1.3" xref="algorithm2.18.18.m1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="algorithm2.18.18.m1.1.1.3.2" mathsize="90%" xref="algorithm2.18.18.m1.1.1.3.2.cmml">𝒦</mi><mo id="algorithm2.18.18.m1.1.1.3.1" mathsize="90%" xref="algorithm2.18.18.m1.1.1.3.1.cmml">∪</mo><msup id="algorithm2.18.18.m1.1.1.3.3" xref="algorithm2.18.18.m1.1.1.3.3.cmml"><mi id="algorithm2.18.18.m1.1.1.3.3.2" mathsize="90%" xref="algorithm2.18.18.m1.1.1.3.3.2.cmml">k</mi><mo id="algorithm2.18.18.m1.1.1.3.3.3" mathsize="90%" xref="algorithm2.18.18.m1.1.1.3.3.3.cmml">∗</mo></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="algorithm2.18.18.m1.1b"><apply id="algorithm2.18.18.m1.1.1.cmml" xref="algorithm2.18.18.m1.1.1"><ci id="algorithm2.18.18.m1.1.1.1.cmml" xref="algorithm2.18.18.m1.1.1.1">←</ci><ci id="algorithm2.18.18.m1.1.1.2.cmml" xref="algorithm2.18.18.m1.1.1.2">𝒦</ci><apply id="algorithm2.18.18.m1.1.1.3.cmml" xref="algorithm2.18.18.m1.1.1.3"><union id="algorithm2.18.18.m1.1.1.3.1.cmml" xref="algorithm2.18.18.m1.1.1.3.1"></union><ci id="algorithm2.18.18.m1.1.1.3.2.cmml" xref="algorithm2.18.18.m1.1.1.3.2">𝒦</ci><apply id="algorithm2.18.18.m1.1.1.3.3.cmml" xref="algorithm2.18.18.m1.1.1.3.3"><csymbol cd="ambiguous" id="algorithm2.18.18.m1.1.1.3.3.1.cmml" xref="algorithm2.18.18.m1.1.1.3.3">superscript</csymbol><ci id="algorithm2.18.18.m1.1.1.3.3.2.cmml" xref="algorithm2.18.18.m1.1.1.3.3.2">𝑘</ci><times id="algorithm2.18.18.m1.1.1.3.3.3.cmml" xref="algorithm2.18.18.m1.1.1.3.3.3"></times></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.18.18.m1.1c">\mathcal{K}\leftarrow\mathcal{K}\cup k^{*}</annotation><annotation encoding="application/x-llamapun" id="algorithm2.18.18.m1.1d">caligraphic_K ← caligraphic_K ∪ italic_k start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="algorithm2.18.18.4" style="font-size:90%;">
</span>
</div>
<div class="ltx_listingline" id="algorithm2.19.19">
<span class="ltx_text" id="algorithm2.19.19.2" style="font-size:90%;">  </span><span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span><span class="ltx_text" id="algorithm2.19.19.3" style="font-size:90%;">   </span><span class="ltx_text ltx_font_bold" id="algorithm2.19.19.4" style="font-size:90%;">return</span><span class="ltx_text" id="algorithm2.19.19.5" style="font-size:90%;"> </span><em class="ltx_emph ltx_font_italic" id="algorithm2.19.19.1" style="font-size:90%;"><math alttext="\mathcal{K}" class="ltx_Math" display="inline" id="algorithm2.19.19.1.m1.1"><semantics id="algorithm2.19.19.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="algorithm2.19.19.1.m1.1.1" xref="algorithm2.19.19.1.m1.1.1.cmml">𝒦</mi><annotation-xml encoding="MathML-Content" id="algorithm2.19.19.1.m1.1b"><ci id="algorithm2.19.19.1.m1.1.1.cmml" xref="algorithm2.19.19.1.m1.1.1">𝒦</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.19.19.1.m1.1c">\mathcal{K}</annotation><annotation encoding="application/x-llamapun" id="algorithm2.19.19.1.m1.1d">caligraphic_K</annotation></semantics></math></em><span class="ltx_text" id="algorithm2.19.19.6" style="font-size:90%;">
</span>
</div>
<div class="ltx_listingline" id="algorithm2.19.28">
<span class="ltx_text" id="algorithm2.19.28.1" style="font-size:90%;">
</span>
</div>
</div>
<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_bold" id="algorithm2.23.1.1">算法 2</span> </span>最佳示例数量</figcaption>
</figure>
<div class="ltx_para" id="S3.SS3.p4">
<p class="ltx_p" id="S3.SS3.p4.2">Content: 执行算法 <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#algorithm2" title="In 3.3. Supervised Rank Cutoff ‣ 3. Adaptive ICL ↦ QPP? ‣ “In-Context Learning” or: How I learned to stop worrying and love “Applied Information Retrieval”"><span class="ltx_text ltx_ref_tag">2</span></a> 后，我们获得一组地面真相标签 <math alttext="\mathcal{K}" class="ltx_Math" display="inline" id="S3.SS3.p4.1.m1.1"><semantics id="S3.SS3.p4.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p4.1.m1.1.1" xref="S3.SS3.p4.1.m1.1.1.cmml">𝒦</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.1.m1.1b"><ci id="S3.SS3.p4.1.m1.1.1.cmml" xref="S3.SS3.p4.1.m1.1.1">𝒦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.1.m1.1c">\mathcal{K}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p4.1.m1.1d">caligraphic_K</annotation></semantics></math>，然后可以用来训练一个由参数 <math alttext="\theta" class="ltx_Math" display="inline" id="S3.SS3.p4.2.m2.1"><semantics id="S3.SS3.p4.2.m2.1a"><mi id="S3.SS3.p4.2.m2.1.1" xref="S3.SS3.p4.2.m2.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.2.m2.1b"><ci id="S3.SS3.p4.2.m2.1.1.cmml" xref="S3.SS3.p4.2.m2.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.2.m2.1c">\theta</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p4.2.m2.1d">italic_θ</annotation></semantics></math> 参数化的分类器，通过优化：</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_left">(3)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\text{argmin}_{\theta}\sum_{\mathbf{x}\in\mathcal{T},k^{*}\in\mathcal{K}}%
\mathcal{L}(\mathbf{x}^{\mathrm{T}}\theta,k^{*})," class="ltx_Math" display="block" id="S3.E3.m1.3"><semantics id="S3.E3.m1.3a"><mrow id="S3.E3.m1.3.3.1" xref="S3.E3.m1.3.3.1.1.cmml"><mrow id="S3.E3.m1.3.3.1.1" xref="S3.E3.m1.3.3.1.1.cmml"><msub id="S3.E3.m1.3.3.1.1.4" xref="S3.E3.m1.3.3.1.1.4.cmml"><mtext id="S3.E3.m1.3.3.1.1.4.2" xref="S3.E3.m1.3.3.1.1.4.2a.cmml">argmin</mtext><mi id="S3.E3.m1.3.3.1.1.4.3" xref="S3.E3.m1.3.3.1.1.4.3.cmml">θ</mi></msub><mo id="S3.E3.m1.3.3.1.1.3" xref="S3.E3.m1.3.3.1.1.3.cmml">⁢</mo><mrow id="S3.E3.m1.3.3.1.1.2" xref="S3.E3.m1.3.3.1.1.2.cmml"><munder id="S3.E3.m1.3.3.1.1.2.3" xref="S3.E3.m1.3.3.1.1.2.3.cmml"><mo id="S3.E3.m1.3.3.1.1.2.3.2" movablelimits="false" xref="S3.E3.m1.3.3.1.1.2.3.2.cmml">∑</mo><mrow id="S3.E3.m1.2.2.2.2" xref="S3.E3.m1.2.2.2.3.cmml"><mrow id="S3.E3.m1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.cmml"><mi id="S3.E3.m1.1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.2.cmml">𝐱</mi><mo id="S3.E3.m1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.3.cmml">𝒯</mi></mrow><mo id="S3.E3.m1.2.2.2.2.3" xref="S3.E3.m1.2.2.2.3a.cmml">,</mo><mrow id="S3.E3.m1.2.2.2.2.2" xref="S3.E3.m1.2.2.2.2.2.cmml"><msup id="S3.E3.m1.2.2.2.2.2.2" xref="S3.E3.m1.2.2.2.2.2.2.cmml"><mi id="S3.E3.m1.2.2.2.2.2.2.2" xref="S3.E3.m1.2.2.2.2.2.2.2.cmml">k</mi><mo id="S3.E3.m1.2.2.2.2.2.2.3" xref="S3.E3.m1.2.2.2.2.2.2.3.cmml">∗</mo></msup><mo id="S3.E3.m1.2.2.2.2.2.1" xref="S3.E3.m1.2.2.2.2.2.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.2.2.2.2.2.3" xref="S3.E3.m1.2.2.2.2.2.3.cmml">𝒦</mi></mrow></mrow></munder><mrow id="S3.E3.m1.3.3.1.1.2.2" xref="S3.E3.m1.3.3.1.1.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.3.3.1.1.2.2.4" xref="S3.E3.m1.3.3.1.1.2.2.4.cmml">ℒ</mi><mo id="S3.E3.m1.3.3.1.1.2.2.3" xref="S3.E3.m1.3.3.1.1.2.2.3.cmml">⁢</mo><mrow id="S3.E3.m1.3.3.1.1.2.2.2.2" xref="S3.E3.m1.3.3.1.1.2.2.2.3.cmml"><mo id="S3.E3.m1.3.3.1.1.2.2.2.2.3" stretchy="false" xref="S3.E3.m1.3.3.1.1.2.2.2.3.cmml">(</mo><mrow id="S3.E3.m1.3.3.1.1.1.1.1.1.1" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.cmml"><msup id="S3.E3.m1.3.3.1.1.1.1.1.1.1.2" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E3.m1.3.3.1.1.1.1.1.1.1.2.2" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.2.2.cmml">𝐱</mi><mi id="S3.E3.m1.3.3.1.1.1.1.1.1.1.2.3" mathvariant="normal" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.2.3.cmml">T</mi></msup><mo id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.cmml">⁢</mo><mi id="S3.E3.m1.3.3.1.1.1.1.1.1.1.3" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.3.cmml">θ</mi></mrow><mo id="S3.E3.m1.3.3.1.1.2.2.2.2.4" xref="S3.E3.m1.3.3.1.1.2.2.2.3.cmml">,</mo><msup id="S3.E3.m1.3.3.1.1.2.2.2.2.2" xref="S3.E3.m1.3.3.1.1.2.2.2.2.2.cmml"><mi id="S3.E3.m1.3.3.1.1.2.2.2.2.2.2" xref="S3.E3.m1.3.3.1.1.2.2.2.2.2.2.cmml">k</mi><mo id="S3.E3.m1.3.3.1.1.2.2.2.2.2.3" xref="S3.E3.m1.3.3.1.1.2.2.2.2.2.3.cmml">∗</mo></msup><mo id="S3.E3.m1.3.3.1.1.2.2.2.2.5" stretchy="false" xref="S3.E3.m1.3.3.1.1.2.2.2.3.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S3.E3.m1.3.3.1.2" xref="S3.E3.m1.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.3b"><apply id="S3.E3.m1.3.3.1.1.cmml" xref="S3.E3.m1.3.3.1"><times id="S3.E3.m1.3.3.1.1.3.cmml" xref="S3.E3.m1.3.3.1.1.3"></times><apply id="S3.E3.m1.3.3.1.1.4.cmml" xref="S3.E3.m1.3.3.1.1.4"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.1.1.4.1.cmml" xref="S3.E3.m1.3.3.1.1.4">subscript</csymbol><ci id="S3.E3.m1.3.3.1.1.4.2a.cmml" xref="S3.E3.m1.3.3.1.1.4.2"><mtext id="S3.E3.m1.3.3.1.1.4.2.cmml" xref="S3.E3.m1.3.3.1.1.4.2">argmin</mtext></ci><ci id="S3.E3.m1.3.3.1.1.4.3.cmml" xref="S3.E3.m1.3.3.1.1.4.3">𝜃</ci></apply><apply id="S3.E3.m1.3.3.1.1.2.cmml" xref="S3.E3.m1.3.3.1.1.2"><apply id="S3.E3.m1.3.3.1.1.2.3.cmml" xref="S3.E3.m1.3.3.1.1.2.3"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.1.1.2.3.1.cmml" xref="S3.E3.m1.3.3.1.1.2.3">subscript</csymbol><sum id="S3.E3.m1.3.3.1.1.2.3.2.cmml" xref="S3.E3.m1.3.3.1.1.2.3.2"></sum><apply id="S3.E3.m1.2.2.2.3.cmml" xref="S3.E3.m1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.2.3a.cmml" xref="S3.E3.m1.2.2.2.2.3">formulae-sequence</csymbol><apply id="S3.E3.m1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1"><in id="S3.E3.m1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1"></in><ci id="S3.E3.m1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.1.2">𝐱</ci><ci id="S3.E3.m1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.1.3">𝒯</ci></apply><apply id="S3.E3.m1.2.2.2.2.2.cmml" xref="S3.E3.m1.2.2.2.2.2"><in id="S3.E3.m1.2.2.2.2.2.1.cmml" xref="S3.E3.m1.2.2.2.2.2.1"></in><apply id="S3.E3.m1.2.2.2.2.2.2.cmml" xref="S3.E3.m1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.2.2.2.2.1.cmml" xref="S3.E3.m1.2.2.2.2.2.2">superscript</csymbol><ci id="S3.E3.m1.2.2.2.2.2.2.2.cmml" xref="S3.E3.m1.2.2.2.2.2.2.2">𝑘</ci><times id="S3.E3.m1.2.2.2.2.2.2.3.cmml" xref="S3.E3.m1.2.2.2.2.2.2.3"></times></apply><ci id="S3.E3.m1.2.2.2.2.2.3.cmml" xref="S3.E3.m1.2.2.2.2.2.3">𝒦</ci></apply></apply></apply><apply id="S3.E3.m1.3.3.1.1.2.2.cmml" xref="S3.E3.m1.3.3.1.1.2.2"><times id="S3.E3.m1.3.3.1.1.2.2.3.cmml" xref="S3.E3.m1.3.3.1.1.2.2.3"></times><ci id="S3.E3.m1.3.3.1.1.2.2.4.cmml" xref="S3.E3.m1.3.3.1.1.2.2.4">ℒ</ci><interval closure="open" id="S3.E3.m1.3.3.1.1.2.2.2.3.cmml" xref="S3.E3.m1.3.3.1.1.2.2.2.2"><apply id="S3.E3.m1.3.3.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1"><times id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1"></times><apply id="S3.E3.m1.3.3.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.2">superscript</csymbol><ci id="S3.E3.m1.3.3.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.2.2">𝐱</ci><ci id="S3.E3.m1.3.3.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.2.3">T</ci></apply><ci id="S3.E3.m1.3.3.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.3">𝜃</ci></apply><apply id="S3.E3.m1.3.3.1.1.2.2.2.2.2.cmml" xref="S3.E3.m1.3.3.1.1.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.1.1.2.2.2.2.2.1.cmml" xref="S3.E3.m1.3.3.1.1.2.2.2.2.2">superscript</csymbol><ci id="S3.E3.m1.3.3.1.1.2.2.2.2.2.2.cmml" xref="S3.E3.m1.3.3.1.1.2.2.2.2.2.2">𝑘</ci><times id="S3.E3.m1.3.3.1.1.2.2.2.2.2.3.cmml" xref="S3.E3.m1.3.3.1.1.2.2.2.2.2.3"></times></apply></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.3c">\text{argmin}_{\theta}\sum_{\mathbf{x}\in\mathcal{T},k^{*}\in\mathcal{K}}%
\mathcal{L}(\mathbf{x}^{\mathrm{T}}\theta,k^{*}),</annotation><annotation encoding="application/x-llamapun" id="S3.E3.m1.3d">argmin start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ∑ start_POSTSUBSCRIPT bold_x ∈ caligraphic_T , italic_k start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT ∈ caligraphic_K end_POSTSUBSCRIPT caligraphic_L ( bold_x start_POSTSUPERSCRIPT roman_T end_POSTSUPERSCRIPT italic_θ , italic_k start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS3.p4.3">其中<math alttext="\mathcal{L}" class="ltx_Math" display="inline" id="S3.SS3.p4.3.m1.1"><semantics id="S3.SS3.p4.3.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p4.3.m1.1.1" xref="S3.SS3.p4.3.m1.1.1.cmml">ℒ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.3.m1.1b"><ci id="S3.SS3.p4.3.m1.1.1.cmml" xref="S3.SS3.p4.3.m1.1.1">ℒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.3.m1.1c">\mathcal{L}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p4.3.m1.1d">caligraphic_L</annotation></semantics></math>是一个标准损失函数，例如交叉熵。</p>
</div>
<div class="ltx_para" id="S3.SS3.p5">
<p class="ltx_p" id="S3.SS3.p5.5">在推理过程中，对于每个<math alttext="\mathbf{x}\in\mathcal{E}" class="ltx_Math" display="inline" id="S3.SS3.p5.1.m1.1"><semantics id="S3.SS3.p5.1.m1.1a"><mrow id="S3.SS3.p5.1.m1.1.1" xref="S3.SS3.p5.1.m1.1.1.cmml"><mi id="S3.SS3.p5.1.m1.1.1.2" xref="S3.SS3.p5.1.m1.1.1.2.cmml">𝐱</mi><mo id="S3.SS3.p5.1.m1.1.1.1" xref="S3.SS3.p5.1.m1.1.1.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p5.1.m1.1.1.3" xref="S3.SS3.p5.1.m1.1.1.3.cmml">ℰ</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.1.m1.1b"><apply id="S3.SS3.p5.1.m1.1.1.cmml" xref="S3.SS3.p5.1.m1.1.1"><in id="S3.SS3.p5.1.m1.1.1.1.cmml" xref="S3.SS3.p5.1.m1.1.1.1"></in><ci id="S3.SS3.p5.1.m1.1.1.2.cmml" xref="S3.SS3.p5.1.m1.1.1.2">𝐱</ci><ci id="S3.SS3.p5.1.m1.1.1.3.cmml" xref="S3.SS3.p5.1.m1.1.1.3">ℰ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.1.m1.1c">\mathbf{x}\in\mathcal{E}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p5.1.m1.1d">bold_x ∈ caligraphic_E</annotation></semantics></math>（表示评估集的<math alttext="\mathcal{E}" class="ltx_Math" display="inline" id="S3.SS3.p5.2.m2.1"><semantics id="S3.SS3.p5.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p5.2.m2.1.1" xref="S3.SS3.p5.2.m2.1.1.cmml">ℰ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.2.m2.1b"><ci id="S3.SS3.p5.2.m2.1.1.cmml" xref="S3.SS3.p5.2.m2.1.1">ℰ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.2.m2.1c">\mathcal{E}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p5.2.m2.1d">caligraphic_E</annotation></semantics></math>），我们建议应用通过方程<a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#S3.E3" title="In 3.3. Supervised Rank Cutoff ‣ 3. Adaptive ICL ↦ QPP? ‣ “In-Context Learning” or: How I learned to stop worrying and love “Applied Information Retrieval”"><span class="ltx_text ltx_ref_tag">3</span></a>训练的分类器<math alttext="\kappa:\mathbf{x}\mapsto\{1,\ldots,M\}" class="ltx_Math" display="inline" id="S3.SS3.p5.3.m3.3"><semantics id="S3.SS3.p5.3.m3.3a"><mrow id="S3.SS3.p5.3.m3.3.4" xref="S3.SS3.p5.3.m3.3.4.cmml"><mi id="S3.SS3.p5.3.m3.3.4.2" xref="S3.SS3.p5.3.m3.3.4.2.cmml">κ</mi><mo id="S3.SS3.p5.3.m3.3.4.1" lspace="0.278em" rspace="0.278em" xref="S3.SS3.p5.3.m3.3.4.1.cmml">:</mo><mrow id="S3.SS3.p5.3.m3.3.4.3" xref="S3.SS3.p5.3.m3.3.4.3.cmml"><mi id="S3.SS3.p5.3.m3.3.4.3.2" xref="S3.SS3.p5.3.m3.3.4.3.2.cmml">𝐱</mi><mo id="S3.SS3.p5.3.m3.3.4.3.1" stretchy="false" xref="S3.SS3.p5.3.m3.3.4.3.1.cmml">↦</mo><mrow id="S3.SS3.p5.3.m3.3.4.3.3.2" xref="S3.SS3.p5.3.m3.3.4.3.3.1.cmml"><mo id="S3.SS3.p5.3.m3.3.4.3.3.2.1" stretchy="false" xref="S3.SS3.p5.3.m3.3.4.3.3.1.cmml">{</mo><mn id="S3.SS3.p5.3.m3.1.1" xref="S3.SS3.p5.3.m3.1.1.cmml">1</mn><mo id="S3.SS3.p5.3.m3.3.4.3.3.2.2" xref="S3.SS3.p5.3.m3.3.4.3.3.1.cmml">,</mo><mi id="S3.SS3.p5.3.m3.2.2" mathvariant="normal" xref="S3.SS3.p5.3.m3.2.2.cmml">…</mi><mo id="S3.SS3.p5.3.m3.3.4.3.3.2.3" xref="S3.SS3.p5.3.m3.3.4.3.3.1.cmml">,</mo><mi id="S3.SS3.p5.3.m3.3.3" xref="S3.SS3.p5.3.m3.3.3.cmml">M</mi><mo id="S3.SS3.p5.3.m3.3.4.3.3.2.4" stretchy="false" xref="S3.SS3.p5.3.m3.3.4.3.3.1.cmml">}</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.3.m3.3b"><apply id="S3.SS3.p5.3.m3.3.4.cmml" xref="S3.SS3.p5.3.m3.3.4"><ci id="S3.SS3.p5.3.m3.3.4.1.cmml" xref="S3.SS3.p5.3.m3.3.4.1">:</ci><ci id="S3.SS3.p5.3.m3.3.4.2.cmml" xref="S3.SS3.p5.3.m3.3.4.2">𝜅</ci><apply id="S3.SS3.p5.3.m3.3.4.3.cmml" xref="S3.SS3.p5.3.m3.3.4.3"><csymbol cd="latexml" id="S3.SS3.p5.3.m3.3.4.3.1.cmml" xref="S3.SS3.p5.3.m3.3.4.3.1">maps-to</csymbol><ci id="S3.SS3.p5.3.m3.3.4.3.2.cmml" xref="S3.SS3.p5.3.m3.3.4.3.2">𝐱</ci><set id="S3.SS3.p5.3.m3.3.4.3.3.1.cmml" xref="S3.SS3.p5.3.m3.3.4.3.3.2"><cn id="S3.SS3.p5.3.m3.1.1.cmml" type="integer" xref="S3.SS3.p5.3.m3.1.1">1</cn><ci id="S3.SS3.p5.3.m3.2.2.cmml" xref="S3.SS3.p5.3.m3.2.2">…</ci><ci id="S3.SS3.p5.3.m3.3.3.cmml" xref="S3.SS3.p5.3.m3.3.3">𝑀</ci></set></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.3.m3.3c">\kappa:\mathbf{x}\mapsto\{1,\ldots,M\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p5.3.m3.3d">italic_κ : bold_x ↦ { 1 , … , italic_M }</annotation></semantics></math>来预测示例的数量，并最终对<math alttext="\mathbf{x}" class="ltx_Math" display="inline" id="S3.SS3.p5.5.m5.1"><semantics id="S3.SS3.p5.5.m5.1a"><mi id="S3.SS3.p5.5.m5.1.1" xref="S3.SS3.p5.5.m5.1.1.cmml">𝐱</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.5.m5.1b"><ci id="S3.SS3.p5.5.m5.1.1.cmml" xref="S3.SS3.p5.5.m5.1.1">𝐱</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.5.m5.1c">\mathbf{x}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p5.5.m5.1d">bold_x</annotation></semantics></math>（方程<a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#S3.E2" title="In 3.1. A Variable Number of Examples ‣ 3. Adaptive ICL ↦ QPP? ‣ “In-Context Learning” or: How I learned to stop worrying and love “Applied Information Retrieval”"><span class="ltx_text ltx_ref_tag">2</span></a>）进行<math alttext="\kappa(\mathbf{x})" class="ltx_Math" display="inline" id="S3.SS3.p5.4.m4.1"><semantics id="S3.SS3.p5.4.m4.1a"><mrow id="S3.SS3.p5.4.m4.1.2" xref="S3.SS3.p5.4.m4.1.2.cmml"><mi id="S3.SS3.p5.4.m4.1.2.2" xref="S3.SS3.p5.4.m4.1.2.2.cmml">κ</mi><mo id="S3.SS3.p5.4.m4.1.2.1" xref="S3.SS3.p5.4.m4.1.2.1.cmml">⁢</mo><mrow id="S3.SS3.p5.4.m4.1.2.3.2" xref="S3.SS3.p5.4.m4.1.2.cmml"><mo id="S3.SS3.p5.4.m4.1.2.3.2.1" stretchy="false" xref="S3.SS3.p5.4.m4.1.2.cmml">(</mo><mi id="S3.SS3.p5.4.m4.1.1" xref="S3.SS3.p5.4.m4.1.1.cmml">𝐱</mi><mo id="S3.SS3.p5.4.m4.1.2.3.2.2" stretchy="false" xref="S3.SS3.p5.4.m4.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.4.m4.1b"><apply id="S3.SS3.p5.4.m4.1.2.cmml" xref="S3.SS3.p5.4.m4.1.2"><times id="S3.SS3.p5.4.m4.1.2.1.cmml" xref="S3.SS3.p5.4.m4.1.2.1"></times><ci id="S3.SS3.p5.4.m4.1.2.2.cmml" xref="S3.SS3.p5.4.m4.1.2.2">𝜅</ci><ci id="S3.SS3.p5.4.m4.1.1.cmml" xref="S3.SS3.p5.4.m4.1.1">𝐱</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.4.m4.1c">\kappa(\mathbf{x})</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p5.4.m4.1d">italic_κ ( bold_x )</annotation></semantics></math>次预测。</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS4">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">3.4. </span>开放性研究问题和挑战</h3>
<div class="ltx_para" id="S3.SS4.p1">
<p class="ltx_p" id="S3.SS4.p1.1">到目前为止，在本节中，我们描述了如何将无监督和监督方法应用于动态选择用于基于ICL的预测的示例数量。在本节中，我们讨论了一些研究方向，可以探索将ICL适应其他方式以进一步提高其有效性。</p>
</div>
<div class="ltx_para" id="S3.SS4.p2">
<p class="ltx_p" id="S3.SS4.p2.1">首先，我们想指出关于生成查询变体的现有工作，作为数据增强策略的一部分，以设计相同或类似信息需求的替代表述。已经显示这能够改进排名器的效果 <cite class="ltx_cite ltx_citemacro_citep">(Gao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib29" title="">2023</a>)</cite>，查询性能预测 <cite class="ltx_cite ltx_citemacro_citep">(Zendel et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib87" title="">2019</a>; Datta et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib16" title="">2023</a>)</cite>，相关反馈 <cite class="ltx_cite ltx_citemacro_citep">(Chakraborty et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib8" title="">2020</a>)</cite>，甚至作为衡量信息检索模型一致性的工具 <cite class="ltx_cite ltx_citemacro_citep">(Sen et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib71" title="">2022</a>)</cite>。鉴于LLM具有零-shot查询生成能力的最近成功 <cite class="ltx_cite ltx_citemacro_citep">(Alaofi et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib2" title="">2023</a>; Wang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib84" title="">2023</a>)</cite>，我们相信用替代文本表示增加测试实例能够最终改进检索质量（因此潜在地改进下游ICL效果）。对于预测每个查询（测试实例）示例数量的无监督和监督方法也可能会提高ICL效果，因为现有研究结果显示变体确实有助于改进QPP <cite class="ltx_cite ltx_citemacro_citep">(Zendel et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib87" title="">2019</a>; Datta et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib16" title="">2023</a>)</cite>。

因此，我们提出以下两个沿着这个方向的研究问题。</p>
<ul class="ltx_itemize" id="S3.I2">
<li class="ltx_item" id="S3.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I2.i1.p1">
<p class="ltx_p" id="S3.I2.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I2.i1.p1.1.1">RQ-3.1</span>：LLMs生成的查询变体（或其他方式）是否可以改善每个实例使用的示例数量的预测？</p>
</div>
</li>
<li class="ltx_item" id="S3.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I2.i2.p1">
<p class="ltx_p" id="S3.I2.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I2.i2.p1.1.1">RQ-3.2</span>: 基于相关反馈的方法是否可以在使用生成的查询变体或不使用的情况下，帮助重新排序最初检索到的候选示例集，以更好地预测示例数量？</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S3.SS4.p3">
<p class="ltx_p" id="S3.SS4.p3.1">另一方面的工作方向涉及动态选择不仅是邻域大小，还有其他ICL参数。例如，基于输入实例，可以动态选择动态选择口语化器<cite class="ltx_cite ltx_citemacro_citep">(Schick and Schütze, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib70" title="">2021</a>)</cite>。此外，还可以动态选择提示 - 再次基于输入实例；一个无监督的方法已经研究了这个想法<cite class="ltx_cite ltx_citemacro_citep">(Sorensen et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib76" title="">2022</a>)</cite>。总的来说，可以潜在地探讨的研究问题是下面这个。</p>
</div>
<div class="ltx_para" id="S3.SS4.p4">
<ul class="ltx_itemize" id="S3.I3">
<li class="ltx_item" id="S3.I3.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I3.i1.p1">
<p class="ltx_p" id="S3.I3.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I3.i1.p1.1.1">RQ-3.3</span>:其他ICL参数是否也可以以数据驱动的方式选择，以达到更好的效果，例如，口语化者，提示，甚至LLM本身（类似于专家混合体）？</p>
</div>
</li>
</ul>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">4. </span>排名ICL示例 <math alttext="\mapsto" class="ltx_Math" display="inline" id="S4.1.m1.1"><semantics id="S4.1.m1.1b"><mo id="S4.1.m1.1.1" stretchy="false" xref="S4.1.m1.1.1.cmml">↦</mo><annotation-xml encoding="MathML-Content" id="S4.1.m1.1c"><csymbol cd="latexml" id="S4.1.m1.1.1.cmml" xref="S4.1.m1.1.1">maps-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.1.m1.1d">\mapsto</annotation><annotation encoding="application/x-llamapun" id="S4.1.m1.1e">↦</annotation></semantics></math> 监督IR？</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">在这一部分中，我们讨论ICL的另一个关键方面，即通过开发特别适用于不同相关性概念的排名模型可能会得到改进：<span class="ltx_text ltx_font_italic" id="S4.p1.1.1">ICL下游任务特定示例的有用性</span>。核心神经IR中有效示例的概念已经得到了深入研究，特别是在微调过程中“难”负例的概念<cite class="ltx_cite ltx_citemacro_citep">(Karpukhin et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib37" title="">2020</a>; Gao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib28" title="">2021a</a>)</cite>。这些负例已经改进了排名任务的下游精度<cite class="ltx_cite ltx_citemacro_citep">(Xiao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib85" title="">2022</a>)</cite>，更一般地说，也改进了表示学习<cite class="ltx_cite ltx_citemacro_citep">(Gao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib30" title="">2021b</a>)</cite>。</p>
</div>
<div class="ltx_para" id="S4.p2">
<p class="ltx_p" id="S4.p2.6">特定于小样本学习，<cite class="ltx_cite ltx_citemacro_citet">Rubin et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib68" title="">2022</a>)</cite> 使用了噪声对比估计（NCE）损失<cite class="ltx_cite ltx_citemacro_citep">(Gutmann and Hyvärinen, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib31" title="">2010</a>)</cite>来训练使用SBERT<cite class="ltx_cite ltx_citemacro_citep">(Reimers and Gurevych, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib65" title="">2019</a>)</cite>嵌入的基于双编码器的成对排序器。为了训练排名模型，作者以以下方式收集了实例（相关和非相关示例）对。对于每个来自训练集的主实例<math alttext="\mathbf{x}" class="ltx_Math" display="inline" id="S4.p2.1.m1.1"><semantics id="S4.p2.1.m1.1a"><mi id="S4.p2.1.m1.1.1" xref="S4.p2.1.m1.1.1.cmml">𝐱</mi><annotation-xml encoding="MathML-Content" id="S4.p2.1.m1.1b"><ci id="S4.p2.1.m1.1.1.cmml" xref="S4.p2.1.m1.1.1">𝐱</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.1.m1.1c">\mathbf{x}</annotation><annotation encoding="application/x-llamapun" id="S4.p2.1.m1.1d">bold_x</annotation></semantics></math>，作者使用BM25来构成前<math alttext="k" class="ltx_Math" display="inline" id="S4.p2.2.m2.1"><semantics id="S4.p2.2.m2.1a"><mi id="S4.p2.2.m2.1.1" xref="S4.p2.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.p2.2.m2.1b"><ci id="S4.p2.2.m2.1.1.cmml" xref="S4.p2.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.2.m2.1c">k</annotation><annotation encoding="application/x-llamapun" id="S4.p2.2.m2.1d">italic_k</annotation></semantics></math>个候选示例。然后，测试每对<math alttext="(\mathbf{x},\mathbf{z}_{i})" class="ltx_Math" display="inline" id="S4.p2.3.m3.2"><semantics id="S4.p2.3.m3.2a"><mrow id="S4.p2.3.m3.2.2.1" xref="S4.p2.3.m3.2.2.2.cmml"><mo id="S4.p2.3.m3.2.2.1.2" stretchy="false" xref="S4.p2.3.m3.2.2.2.cmml">(</mo><mi id="S4.p2.3.m3.1.1" xref="S4.p2.3.m3.1.1.cmml">𝐱</mi><mo id="S4.p2.3.m3.2.2.1.3" xref="S4.p2.3.m3.2.2.2.cmml">,</mo><msub id="S4.p2.3.m3.2.2.1.1" xref="S4.p2.3.m3.2.2.1.1.cmml"><mi id="S4.p2.3.m3.2.2.1.1.2" xref="S4.p2.3.m3.2.2.1.1.2.cmml">𝐳</mi><mi id="S4.p2.3.m3.2.2.1.1.3" xref="S4.p2.3.m3.2.2.1.1.3.cmml">i</mi></msub><mo id="S4.p2.3.m3.2.2.1.4" stretchy="false" xref="S4.p2.3.m3.2.2.2.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.p2.3.m3.2b"><interval closure="open" id="S4.p2.3.m3.2.2.2.cmml" xref="S4.p2.3.m3.2.2.1"><ci id="S4.p2.3.m3.1.1.cmml" xref="S4.p2.3.m3.1.1">𝐱</ci><apply id="S4.p2.3.m3.2.2.1.1.cmml" xref="S4.p2.3.m3.2.2.1.1"><csymbol cd="ambiguous" id="S4.p2.3.m3.2.2.1.1.1.cmml" xref="S4.p2.3.m3.2.2.1.1">subscript</csymbol><ci id="S4.p2.3.m3.2.2.1.1.2.cmml" xref="S4.p2.3.m3.2.2.1.1.2">𝐳</ci><ci id="S4.p2.3.m3.2.2.1.1.3.cmml" xref="S4.p2.3.m3.2.2.1.1.3">𝑖</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.3.m3.2c">(\mathbf{x},\mathbf{z}_{i})</annotation><annotation encoding="application/x-llamapun" id="S4.p2.3.m3.2d">( bold_x , bold_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math>以检查1-shot预测是否正确，如果是，则<math alttext="\mathbf{z}_{i}" class="ltx_Math" display="inline" id="S4.p2.5.m5.1"><semantics id="S4.p2.5.m5.1a"><msub id="S4.p2.5.m5.1.1" xref="S4.p2.5.m5.1.1.cmml"><mi id="S4.p2.5.m5.1.1.2" xref="S4.p2.5.m5.1.1.2.cmml">𝐳</mi><mi id="S4.p2.5.m5.1.1.3" xref="S4.p2.5.m5.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.p2.5.m5.1b"><apply id="S4.p2.5.m5.1.1.cmml" xref="S4.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S4.p2.5.m5.1.1.1.cmml" xref="S4.p2.5.m5.1.1">subscript</csymbol><ci id="S4.p2.5.m5.1.1.2.cmml" xref="S4.p2.5.m5.1.1.2">𝐳</ci><ci id="S4.p2.5.m5.1.1.3.cmml" xref="S4.p2.5.m5.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.5.m5.1c">\mathbf{z}_{i}</annotation><annotation encoding="application/x-llamapun" id="S4.p2.5.m5.1d">bold_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>被分类为<math alttext="\mathbf{x}" class="ltx_Math" display="inline" id="S4.p2.6.m6.1"><semantics id="S4.p2.6.m6.1a"><mi id="S4.p2.6.m6.1.1" xref="S4.p2.6.m6.1.1.cmml">𝐱</mi><annotation-xml encoding="MathML-Content" id="S4.p2.6.m6.1b"><ci id="S4.p2.6.m6.1.1.cmml" xref="S4.p2.6.m6.1.1">𝐱</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.6.m6.1c">\mathbf{x}</annotation><annotation encoding="application/x-llamapun" id="S4.p2.6.m6.1d">bold_x</annotation></semantics></math>的相关示例，否则被视为非相关示例。然后构成包含相关和非相关对的批次，以训练标准NCE损失。虽然<cite class="ltx_cite ltx_citemacro_citet">Rubin et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib68" title="">2022</a>)</cite>的工作是利用任务特定的相关性概念的明确步骤，但调查不应被视为完成。应该探索几个潜在有前途的研究方向，以进一步提高ICL的有效性。我们现在提供神经排名文献调查，介绍可能在示例选择中使用的核心范式。</p>
</div>
<section class="ltx_paragraph" id="S4.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_font_bold ltx_title_paragraph">双编码器架构</h4>
<div class="ltx_para" id="S4.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS0.SSS0.Px1.p1.1">一个双编码器架构将文本编码为在向量空间中可以比较的潜在表示；在检索任务的上下文中，这些文本将是查询和文档。虽然双编码器可以使用具有共享参数的连体网络<cite class="ltx_cite ltx_citemacro_citep">(Reimers and Gurevych, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib65" title="">2019</a>)</cite>或作为单个编码器<cite class="ltx_cite ltx_citemacro_citep">(MacAvaney et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib49" title="">2019</a>)</cite>实现，但后者在近年来变得普遍<cite class="ltx_cite ltx_citemacro_citep">(Karpukhin et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib37" title="">2020</a>; Xiao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib85" title="">2022</a>)</cite>。</p>
</div>
<div class="ltx_para" id="S4.SS0.SSS0.Px1.p2">
<p class="ltx_p" id="S4.SS0.SSS0.Px1.p2.1">神经模型在搜索中的表现得到了显著改善，BERT的发布<cite class="ltx_cite ltx_citemacro_citep">(Devlin et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib19" title="">2019b</a>)</cite>是一个重要的里程碑。首先提出了使用从BM25中挖掘出的“硬”负例来提高基于BERT的排名器的精度。然后提出了NCE目标的一个变体，“局部对比估计”，其中为每个查询采样多个负例，以解释非相关性概念的差异。这样做的同时，他们也展示了从微调的排名器中挖掘出的硬负例的有效性。为了进一步提高负样本的质量，提出模型可以在训练过程中选择负例，使得负例随着微调的进行而持续变得“更难”。</p>
</div>
<div class="ltx_para" id="S4.SS0.SSS0.Px1.p3">
<p class="ltx_p" id="S4.SS0.SSS0.Px1.p3.1">在概念层面上，双编码器通常通过使用BERT [CLS]标记的表示作为整个序列的代理来表示文本的单个嵌入。其他池化方法也是有效的，包括最大序列相似性<cite class="ltx_cite ltx_citemacro_citep">(Dai and Callan, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib14" title="">2019</a>)</cite>和晚期交互，在此方法中，对每个查询标记与文档标记的标记级相似性进行最大池化<cite class="ltx_cite ltx_citemacro_citep">(Khattab and Zaharia, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib38" title="">2020</a>)</cite>。更近期的作品改用了具有浅解码器的BERT风格编码器，这在预训练期间更加强调编码器的能力。这种架构发展不仅产生了最先进的召回率，还产生了新的预训练样式，包括词汇接地和文本重构<cite class="ltx_cite ltx_citemacro_citep">(Shen et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib72" title="">2023</a>)</cite><cite class="ltx_cite ltx_citemacro_citep">(Xiao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib85" title="">2022</a>)</cite>。</p>
</div>
<div class="ltx_para" id="S4.SS0.SSS0.Px1.p4">
<p class="ltx_p" id="S4.SS0.SSS0.Px1.p4.1">将查询和文档的分开编码允许对文档进行离线编码，这可以极大地改善在线延迟。这通常与矢量空间中的近似最近邻搜索相结合<cite class="ltx_cite ltx_citemacro_citep">(Khattab and Zaharia, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib38" title="">2020</a>; Hofstätter et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib32" title="">2020</a>)</cite>。更具体地说，在训练完毕双编码器模型后，训练模型的参数作为集合中每个文档的“嵌入”。在推断时，首先将查询嵌入为一个向量。然后在这些密集文档向量的索引表示上进行近似最近邻搜索，例如HNSW<cite class="ltx_cite ltx_citemacro_citep">(Malkov and Yashunin, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib51" title="">2020</a>)</cite>。因此，探索通过对有效的ICL进行高效、密集的端到端检索来获得潜在利益的研究方向可能是一个有趣的研究方向。</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_font_bold ltx_title_paragraph">跨编码器架构</h4>
<div class="ltx_para" id="S4.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S4.SS0.SSS0.Px2.p1.1">跨编码器在推理时联合编码查询和文档<cite class="ltx_cite ltx_citemacro_citep">(Nogueira and Cho, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib56" title="">2019</a>)</cite>，允许文本之间进行深入的交互，在双编码器架构中是不可能的。从经验上看，这些模型比双编码器更精确，代价是延迟，因为表示不能在标准设置中预先计算。已经提出了基于BERT和T5的架构<cite class="ltx_cite ltx_citemacro_citep">(Nogueira and Cho, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib56" title="">2019</a>; Nogueira et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib57" title="">2020</a>)</cite>；在BERT模型的情况下，使用前馈分类头来输出相关性类别的概率<cite class="ltx_cite ltx_citemacro_citep">(Nogueira and Cho, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib56" title="">2019</a>)</cite>。在序列到序列模型的情况下，令牌logits被视为类别概率的替代品<cite class="ltx_cite ltx_citemacro_citep">(Nogueira et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib57" title="">2020</a>)</cite>。LLM的最新发展已经促使研究这些大型仅解码器模型作为文本排序器。通常采用一种列表式方法，其中模型接收给定查询的多个文档，并输出原始排序的一个排列<cite class="ltx_cite ltx_citemacro_citep">(Sun et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib78" title="">2023</a>; Pradeep et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib63" title="">2023b</a>)</cite>。这些模型的发展还处于初期阶段，但它为研究高度精确的排名模型在简单的临时搜索之外的样本挖掘提供了机会。</p>
</div>
<div class="ltx_para" id="S4.SS0.SSS0.Px2.p2">
<p class="ltx_p" id="S4.SS0.SSS0.Px2.p2.1">因此，可以合理地假设，采用交叉编码器通过其下游有用性学习排名示例应该比基于双编码器的方法产生更好的结果。因此，一个有趣的研究方向将是在ICL管道内调查最佳架构，考虑效率和有效性的权衡。</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS0.SSS0.Px3">
<h4 class="ltx_title ltx_font_bold ltx_title_paragraph">教师蒸馏</h4>
<div class="ltx_para" id="S4.SS0.SSS0.Px3.p1">
<p class="ltx_p" id="S4.SS0.SSS0.Px3.p1.1">此外，在将更昂贵的跨编码器模型提炼为更简单的双编码器模型方面存在丰富的文献，前者充当教师模型，后者充当学生<cite class="ltx_cite ltx_citemacro_citep">(Hofstätter et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib32" title="">2020</a>)</cite>。将教师模型提炼为双编码器模型可以实现端到端的稠密检索，无需任何稀疏索引来检索候选的前<math alttext="k" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px3.p1.1.m1.1"><semantics id="S4.SS0.SSS0.Px3.p1.1.m1.1a"><mi id="S4.SS0.SSS0.Px3.p1.1.m1.1.1" xref="S4.SS0.SSS0.Px3.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px3.p1.1.m1.1b"><ci id="S4.SS0.SSS0.Px3.p1.1.m1.1.1.cmml" xref="S4.SS0.SSS0.Px3.p1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px3.p1.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px3.p1.1.m1.1d">italic_k</annotation></semantics></math>。蒸馏的两个核心范式是同质架构和异质架构蒸馏。前者通常会通过最小化最终隐藏状态<cite class="ltx_cite ltx_citemacro_citep">(Lin et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib44" title="">2021</a>)</cite>或内部状态（如注意力层）之间的差异度指标来将一个模型提炼到一个新初始化的副本中。后者通常通过三元残差（正负样本分数之间的残差）上的均方误差标准来最小化教师和学生模型之间的预测错误，从而允许进行“跨架构知识蒸馏”，因为标量相关分数不依赖于体系结构。这种方法已经成为许多最先进的稠密检索模型的核心组件，通常从使用交叉编码器教师来挖掘硬负例和教师分数开始，然后使用先前提炼的模型作为教师进行第二阶段蒸馏<cite class="ltx_cite ltx_citemacro_citep">(Xiao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib85" title="">2022</a>; Shen et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib72" title="">2023</a>)</cite>。另一个日益受到关注的工作领域是检索系统和生成模型之间的知识共享<cite class="ltx_cite ltx_citemacro_citep">(Lewis et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib41" title="">2020b</a>; Izacard and Grave, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib34" title="">2021</a>; Izacard et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib35" title="">2023</a>)</cite>。这种范式与我们的观点直接相关，最近的研究发现直接优化检索器以最大化下游QA性能<cite class="ltx_cite ltx_citemacro_citep">(Izacard et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib35" title="">2023</a>)</cite>。然而，这些系统目前还比较脆弱，<cite class="ltx_cite ltx_citemacro_citet">Cuconasu et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib12" title="">2024</a>)</cite>发现，在将与QA系统的金标签答案无关的内容添加为上下文之前，可以改善性能，这与直觉相反，这表明在这个领域还有很多工作可以做，以优化我们如何呈现ICL例子的模型。</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">4.1. </span>ICL示例的综合效用</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">在信息检索（IR）中，文档的相关性与另一个文档的相关性无关，合并后信息仍然保持相关。对于ICL来说情况更为复杂。更准确地说，在ICL中，两个有用的示例（即，当作为一次演示时产生正确预测的示例）可能在组合为两次推理时无法产生正确预测<cite class="ltx_cite ltx_citemacro_citep">(Lu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib47" title="">2022</a>)</cite>。这可能发生是因为解码器在获得太多上下文时，可能会偏向于与不正确类别描述符相对应的特定主题词簇。</p>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1">需要进行更多的研究来分析这种“非合作”现象的经验可能性，值得探讨的是在方法论层面可能需要做出什么调整，以便定义少样本ICL的理想排名。在这种情况下，目标不仅仅是在前<math alttext="k" class="ltx_Math" display="inline" id="S4.SS1.p2.1.m1.1"><semantics id="S4.SS1.p2.1.m1.1a"><mi id="S4.SS1.p2.1.m1.1.1" xref="S4.SS1.p2.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.1b"><ci id="S4.SS1.p2.1.m1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.1.m1.1d">italic_k</annotation></semantics></math>中最大化“相关文档”的数量（按照IR类比），而是要确保示例的综合有用性。朝着这个方向可能是采用一个带有这种修改后的综合相关性（有用性）概念的列表式排名模型。</p>
</div>
<div class="ltx_para" id="S4.SS1.p3">
<p class="ltx_p" id="S4.SS1.p3.5">一个更具计算效率的方法是在成对的水平上操作，即预测哪些对是一致的，哪些是不一致的。每对的元素都取一个布尔值（作为1-shot示例或非），这意味着一对可以是一致或不一致的不同方式的数量是<math alttext="16" class="ltx_Math" display="inline" id="S4.SS1.p3.2.m2.1"><semantics id="S4.SS1.p3.2.m2.1a"><mn id="S4.SS1.p3.2.m2.1.1" xref="S4.SS1.p3.2.m2.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.2.m2.1b"><cn id="S4.SS1.p3.2.m2.1.1.cmml" type="integer" xref="S4.SS1.p3.2.m2.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.2.m2.1c">16</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p3.2.m2.1d">16</annotation></semantics></math>，其中<math alttext="16" class="ltx_Math" display="inline" id="S4.SS1.p3.2.m2.1"><semantics id="S4.SS1.p3.2.m2.1a"><mn id="S4.SS1.p3.2.m2.1.1" xref="S4.SS1.p3.2.m2.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.2.m2.1b"><cn id="S4.SS1.p3.2.m2.1.1.cmml" type="integer" xref="S4.SS1.p3.2.m2.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.2.m2.1c">16</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p3.2.m2.1d">16</annotation></semantics></math>是<math alttext="2" class="ltx_Math" display="inline" id="S4.SS1.p3.1.m1.1"><semantics id="S4.SS1.p3.1.m1.1a"><mn id="S4.SS1.p3.1.m1.1.1" xref="S4.SS1.p3.1.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.1.m1.1b"><cn id="S4.SS1.p3.1.m1.1.1.cmml" type="integer" xref="S4.SS1.p3.1.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.1.m1.1c">2</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p3.1.m1.1d">2</annotation></semantics></math>个变量的可能布尔函数的数量（两个这样的示例函数是布尔OR，如果一个示例有用-组合也有用，和XNOR，如果一对示例作为1-shot有用，则是不一致的）。因此，在一般情况下，<math alttext="n" class="ltx_Math" display="inline" id="S4.SS1.p3.3.m3.1"><semantics id="S4.SS1.p3.3.m3.1a"><mi id="S4.SS1.p3.3.m3.1.1" xref="S4.SS1.p3.3.m3.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.3.m3.1b"><ci id="S4.SS1.p3.3.m3.1.1.cmml" xref="S4.SS1.p3.3.m3.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.3.m3.1c">n</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p3.3.m3.1d">italic_n</annotation></semantics></math>个变量的布尔函数的数量是<math alttext="2^{2^{n}}" class="ltx_Math" display="inline" id="S4.SS1.p3.4.m4.1"><semantics id="S4.SS1.p3.4.m4.1a"><msup id="S4.SS1.p3.4.m4.1.1" xref="S4.SS1.p3.4.m4.1.1.cmml"><mn id="S4.SS1.p3.4.m4.1.1.2" xref="S4.SS1.p3.4.m4.1.1.2.cmml">2</mn><msup id="S4.SS1.p3.4.m4.1.1.3" xref="S4.SS1.p3.4.m4.1.1.3.cmml"><mn id="S4.SS1.p3.4.m4.1.1.3.2" xref="S4.SS1.p3.4.m4.1.1.3.2.cmml">2</mn><mi id="S4.SS1.p3.4.m4.1.1.3.3" xref="S4.SS1.p3.4.m4.1.1.3.3.cmml">n</mi></msup></msup><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.4.m4.1b"><apply id="S4.SS1.p3.4.m4.1.1.cmml" xref="S4.SS1.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS1.p3.4.m4.1.1.1.cmml" xref="S4.SS1.p3.4.m4.1.1">superscript</csymbol><cn id="S4.SS1.p3.4.m4.1.1.2.cmml" type="integer" xref="S4.SS1.p3.4.m4.1.1.2">2</cn><apply id="S4.SS1.p3.4.m4.1.1.3.cmml" xref="S4.SS1.p3.4.m4.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.p3.4.m4.1.1.3.1.cmml" xref="S4.SS1.p3.4.m4.1.1.3">superscript</csymbol><cn id="S4.SS1.p3.4.m4.1.1.3.2.cmml" type="integer" xref="S4.SS1.p3.4.m4.1.1.3.2">2</cn><ci id="S4.SS1.p3.4.m4.1.1.3.3.cmml" xref="S4.SS1.p3.4.m4.1.1.3.3">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.4.m4.1c">2^{2^{n}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p3.4.m4.1d">2 start_POSTSUPERSCRIPT 2 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT</annotation></semantics></math>，使用<math alttext="n&gt;3" class="ltx_Math" display="inline" id="S4.SS1.p3.5.m5.1"><semantics id="S4.SS1.p3.5.m5.1a"><mrow id="S4.SS1.p3.5.m5.1.1" xref="S4.SS1.p3.5.m5.1.1.cmml"><mi id="S4.SS1.p3.5.m5.1.1.2" xref="S4.SS1.p3.5.m5.1.1.2.cmml">n</mi><mo id="S4.SS1.p3.5.m5.1.1.1" xref="S4.SS1.p3.5.m5.1.1.1.cmml">&gt;</mo><mn id="S4.SS1.p3.5.m5.1.1.3" xref="S4.SS1.p3.5.m5.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.5.m5.1b"><apply id="S4.SS1.p3.5.m5.1.1.cmml" xref="S4.SS1.p3.5.m5.1.1"><gt id="S4.SS1.p3.5.m5.1.1.1.cmml" xref="S4.SS1.p3.5.m5.1.1.1"></gt><ci id="S4.SS1.p3.5.m5.1.1.2.cmml" xref="S4.SS1.p3.5.m5.1.1.2">𝑛</ci><cn id="S4.SS1.p3.5.m5.1.1.3.cmml" type="integer" xref="S4.SS1.p3.5.m5.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.5.m5.1c">n&gt;3</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p3.5.m5.1d">italic_n &gt; 3</annotation></semantics></math>的列表式训练可能在计算上是禁止的。</p>
</div>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px1">
<h4 class="ltx_title ltx_font_bold ltx_title_paragraph">开放式研究问题</h4>
<div class="ltx_para" id="S4.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px1.p1.1">在结束本节之前，我们现在总结了以下IR特定研究问题在ICL中排名示例的重要性。</p>
<ul class="ltx_itemize" id="S4.I1">
<li class="ltx_item" id="S4.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i1.p1">
<p class="ltx_p" id="S4.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i1.p1.1.1">RQ-4.1</span>: ICL对神经检索模型的选择是否敏感，即我们是否可以通过使用基本的Siamese模型来改善SBERT所设想的情况？</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i2.p1">
<p class="ltx_p" id="S4.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i2.p1.1.1">RQ-4.2</span>：几个一次性有用示例的组合对ICL预测的假设有多忠实？</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i3.p1">
<p class="ltx_p" id="S4.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i3.p1.1.1">RQ-4.3</span>：如果对<span class="ltx_text ltx_font_bold" id="S4.I1.i3.p1.1.2">RQ-4.2</span>的回答是否定的，那么通过明确模拟ICL中示例的有用性的一致性（或缺乏一致性），可以显著改进标准学习排名方法。我们如何调整排名模型，以及在标准少样本基线上我们可以实现多大的改进？</p>
</div>
</li>
</ul>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">5. </span>信息性示例<math alttext="\mapsto" class="ltx_Math" display="inline" id="S5.1.m1.1"><semantics id="S5.1.m1.1b"><mo id="S5.1.m1.1.1" stretchy="false" xref="S5.1.m1.1.1.cmml">↦</mo><annotation-xml encoding="MathML-Content" id="S5.1.m1.1c"><csymbol cd="latexml" id="S5.1.m1.1.1.cmml" xref="S5.1.m1.1.1">maps-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.1.m1.1d">\mapsto</annotation><annotation encoding="application/x-llamapun" id="S5.1.m1.1e">↦</annotation></semantics></math> Faceted IR？</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">在这一部分，我们讨论了我们在图<a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#S2.F2" title="Figure 2 ‣ 2.1. A Formal Introduction ‣ 2. In-Context Learning ‣ “In-Context Learning” or: How I learned to stop worrying and love “Applied Information Retrieval”"><span class="ltx_text ltx_ref_tag">2</span></a>中概述的我们提出的有效ICL工作流程的最后一个垂直方向，即寻求为LLM提供相关但不同的上下文。更确切地说，示例的主题多样性在防止解码器偏向单一主题方面应该起重要作用。这对于文本生成任务更为真实，例如非事实问题回答，LLM解码器需要意识到不同的子主题，才能构建一个全面的答案。
即使对于分类任务，多样化的示例也有可能帮助解码器在推断过程中考虑大多数可能的主题（其口语化形式映射到密切相关类别的描述符），从而最小化误分类的风险。</p>
</div>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.1">分面搜索在信息检索领域已经被广泛研究。简单来说，分面搜索系统从检索到的顶部集合中提取信息需求的多个不同方面，并将每个检索到的文档映射到这些方面中的一个<cite class="ltx_cite ltx_citemacro_citep">(Clarke et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib10" title="">2009</a>; Ganguly and Jones, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib24" title="">2018</a>; Ganguly et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib25" title="">2013b</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib23" title="">a</a>)</cite>。分面搜索对于信息需求更广泛的查询特别有用，它可以帮助用户将他们的信息需求重新表述为更具体的方面之一，例如，将查询“除湿机”转换为“除湿机价格范围”，其中意图（信息需求方面）是购买一个<cite class="ltx_cite ltx_citemacro_citep">(Carterette et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib7" title="">[n. d.]</a>)</cite>。</p>
</div>
<div class="ltx_para" id="S5.p3">
<p class="ltx_p" id="S5.p3.1">Faceted search与多样化排名的概念密切相关，搜索系统旨在提高对更广泛信息需求的所有可能方面的检索效果，例如，对于之前关于“除湿机”的查询，检索与价格范围、技术规格、产品评论和除湿机的一般知识相关的文档。<cite class="ltx_cite ltx_citemacro_citet">Santos et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib69" title="">2010</a>)</cite>建议利用查询变体（论文称之为“子查询”）及其顶部检索列表来构建与原始查询的每个方面可能相关的文档列表。接近多样性的是公平搜索的概念，它旨在减轻对信息需求的任何特定方面的偏见，最近神经方法已成为平衡相关性与公平性的常见方法。<cite class="ltx_cite ltx_citemacro_citep">(Oosterhuis, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib58" title="">2021</a>)</cite>。</p>
</div>
<div class="ltx_para" id="S5.p4">
<p class="ltx_p" id="S5.p4.1">从搜索用户的角度来看，已经证明了多样化的检索系统在改善搜索体验方面发挥着重要作用，通过提供对主题的更广泛覆盖并减轻搜索结果中潜在偏见。同样，更广泛的主题覆盖和更少的主题偏见可能会将LLM解码器引向对下游任务更有用的上下文。事实上，<cite class="ltx_cite ltx_citemacro_citet">Levy et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib39" title="">2023</a>)</cite>表明，根据抽象语法树（AST）结构使少样本示例多样化可以改善组合泛化的下游任务。这确实显示了一个积极的研究方向，信息检索社区在多层次搜索和多样化方面开展的大量工作可能对ICL有所帮助。</p>
</div>
<div class="ltx_para" id="S5.p5">
<p class="ltx_p" id="S5.p5.1">然而，与相关性类似，对于ICL，多样性的概念也需要适当的调整。多样性的适当概念不应仅考虑输入示例之间的相似性，而更重要的是它们的类标签以及它们对LLM解码器生成路径产生影响的方式的相似性。两个输出类似的输出树的示例不应被认为是多样的。原则上，可以潜在地调整我们提出的分类方法，以学习基于最小化预测不确定性来确定给定一对示例是否多样的最佳示例数量。此外，我们认为，在下游ICL的情境中，同时考虑相关性、公平性和多样性的神经方法应该在ICL中找到用例，以帮助丰富有用的示例。</p>
</div>
<section class="ltx_paragraph" id="S5.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_font_bold ltx_title_paragraph">开放的研究问题</h4>
<div class="ltx_para" id="S5.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S5.SS0.SSS0.Px1.p1.1">根据本节的讨论，我们现在概述以下研究方向。</p>
<ul class="ltx_itemize" id="S5.I1">
<li class="ltx_item" id="S5.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I1.i1.p1">
<p class="ltx_p" id="S5.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S5.I1.i1.p1.1.1">RQ-5.1</span>: 例子的主题多样性对ICL有多敏感？</p>
</div>
</li>
<li class="ltx_item" id="S5.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I1.i2.p1">
<p class="ltx_p" id="S5.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S5.I1.i2.p1.1.1">RQ-5.2</span>: 如何可以将多样性的标准概念扩展，以考虑LLM解码器输入和输出之间的潜在依赖性，以对齐特定的下游任务？</p>
</div>
</li>
<li class="ltx_item" id="S5.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I1.i3.p1">
<p class="ltx_p" id="S5.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S5.I1.i3.p1.1.1">RQ-5.3</span>: 现有的用于多样性的IR指标（例如，<math alttext="\alpha" class="ltx_Math" display="inline" id="S5.I1.i3.p1.1.m1.1"><semantics id="S5.I1.i3.p1.1.m1.1a"><mi id="S5.I1.i3.p1.1.m1.1.1" xref="S5.I1.i3.p1.1.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S5.I1.i3.p1.1.m1.1b"><ci id="S5.I1.i3.p1.1.m1.1.1.cmml" xref="S5.I1.i3.p1.1.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.i3.p1.1.m1.1c">\alpha</annotation><annotation encoding="application/x-llamapun" id="S5.I1.i3.p1.1.m1.1d">italic_α</annotation></semantics></math>-nDCG <cite class="ltx_cite ltx_citemacro_citep">(Clarke et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib9" title="">2008</a>)</cite>）如何适应衡量下游ICL示例检索的有效性？</p>
</div>
</li>
<li class="ltx_item" id="S5.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I1.i4.p1">
<p class="ltx_p" id="S5.I1.i4.p1.1"><span class="ltx_text ltx_font_bold" id="S5.I1.i4.p1.1.1">RQ-5.4</span>：多目标神经排名模型如何训练以共同学习ICL的下游特定有用性和多样性？</p>
</div>
</li>
</ul>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">6. </span>初步评估</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">在本节中，我们报告了我们最初调查的结果，该调查旨在回答第一个垂直领域的一部分研究问题，即开发一种能够动态选择示例数量的有效自适应ICL版本。</p>
</div>
<section class="ltx_subsection" id="S6.SS1">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">6.1. </span>研究问题和数据集</h3>
<section class="ltx_paragraph" id="S6.SS1.SSS0.Px1">
<h4 class="ltx_title ltx_font_bold ltx_title_paragraph">研究问题调查</h4>
<div class="ltx_para" id="S6.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="S6.SS1.SSS0.Px1.p1.2">在第<a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#S3.SS2" title="3.2. Unsupervised Rank Cutoff ‣ 3. Adaptive ICL ↦ QPP? ‣ “In-Context Learning” or: How I learned to stop worrying and love “Applied Information Retrieval”"><span class="ltx_text ltx_ref_tag">3.2</span></a>节中，我们讨论了应用QPP启发式无监督方法来选择排名列表中的截断点的可能性。另一方面，在第<a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#S3.SS3" title="3.3. Supervised Rank Cutoff ‣ 3. Adaptive ICL ↦ QPP? ‣ “In-Context Learning” or: How I learned to stop worrying and love “Applied Information Retrieval”"><span class="ltx_text ltx_ref_tag">3.3</span></a>节中，我们提出了一种基于分类器的方法来学习最佳数量的示例。在我们的实验中，我们比较了算法<a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#algorithm2" title="In 3.3. Supervised Rank Cutoff ‣ 3. Adaptive ICL ↦ QPP? ‣ “In-Context Learning” or: How I learned to stop worrying and love “Applied Information Retrieval”"><span class="ltx_text ltx_ref_tag">2</span></a>的监督方法和基于NQC的无监督方法用于自适应<math alttext="k" class="ltx_Math" display="inline" id="S6.SS1.SSS0.Px1.p1.1.m1.1"><semantics id="S6.SS1.SSS0.Px1.p1.1.m1.1a"><mi id="S6.SS1.SSS0.Px1.p1.1.m1.1.1" xref="S6.SS1.SSS0.Px1.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS0.Px1.p1.1.m1.1b"><ci id="S6.SS1.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S6.SS1.SSS0.Px1.p1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS0.Px1.p1.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S6.SS1.SSS0.Px1.p1.1.m1.1d">italic_k</annotation></semantics></math>-shot，并将两者与标准文本分类数据集上的静态<math alttext="k" class="ltx_Math" display="inline" id="S6.SS1.SSS0.Px1.p1.2.m2.1"><semantics id="S6.SS1.SSS0.Px1.p1.2.m2.1a"><mi id="S6.SS1.SSS0.Px1.p1.2.m2.1.1" xref="S6.SS1.SSS0.Px1.p1.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS0.Px1.p1.2.m2.1b"><ci id="S6.SS1.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S6.SS1.SSS0.Px1.p1.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS0.Px1.p1.2.m2.1c">k</annotation><annotation encoding="application/x-llamapun" id="S6.SS1.SSS0.Px1.p1.2.m2.1d">italic_k</annotation></semantics></math>-shot进行比较。明确地说，我们调查了以下研究问题。</p>
<ul class="ltx_itemize" id="S6.I1">
<li class="ltx_item" id="S6.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S6.I1.i1.p1">
<p class="ltx_p" id="S6.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S6.I1.i1.p1.1.1">CRQ-1</span>: 选择ICL中例子数量是否自适应会提高下游效果？</p>
</div>
</li>
<li class="ltx_item" id="S6.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S6.I1.i2.p1">
<p class="ltx_p" id="S6.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S6.I1.i2.p1.1.1">CRQ-2</span>: 无监督方法与监督方法相比是否获得合理的性能？</p>
</div>
</li>
</ul>
<p class="ltx_p" id="S6.SS1.SSS0.Px1.p1.3">由于我们的实验回答了上述问题，它们不是开放的，不像我们在本文中阐述的问题。因此，我们在这些问题前加上“C”（封闭）。</p>
</div>
</section>
<section class="ltx_paragraph" id="S6.SS1.SSS0.Px2">
<h4 class="ltx_title ltx_font_bold ltx_title_paragraph">数据集</h4>
<div class="ltx_para" id="S6.SS1.SSS0.Px2.p1">
<p class="ltx_p" id="S6.SS1.SSS0.Px2.p1.1">我们对三个文本分类数据集进行了实验，分别是AGNews <cite class="ltx_cite ltx_citemacro_citep">(Del Corso et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib17" title="">2005</a>)</cite>，Jigsaw Toxic Comment<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge" title="">https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge</a></span></span></span>和SST2 <cite class="ltx_cite ltx_citemacro_citep">(Socher et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib75" title="">2013</a>)</cite>。下面，我们提供了每个数据集的更多详细信息。</p>
</div>
<div class="ltx_para" id="S6.SS1.SSS0.Px2.p2">
<ul class="ltx_itemize" id="S6.I2">
<li class="ltx_item" id="S6.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S6.I2.i1.p1">
<p class="ltx_p" id="S6.I2.i1.p1.4"><span class="ltx_text ltx_font_bold" id="S6.I2.i1.p1.4.1">AGNews</span>: AGNews是一个主题分类数据集，由来自网络的新闻文章组成。数据集中的每个文档属于以下4个类别之一：<span class="ltx_text ltx_font_typewriter" id="S6.I2.i1.p1.4.2">World</span>，<span class="ltx_text ltx_font_typewriter" id="S6.I2.i1.p1.4.3">Sports</span>，<span class="ltx_text ltx_font_typewriter" id="S6.I2.i1.p1.4.4">Business</span>和<span class="ltx_text ltx_font_typewriter" id="S6.I2.i1.p1.4.5">Sci/Tech</span>。训练实例的总数为<math alttext="120,000" class="ltx_Math" display="inline" id="S6.I2.i1.p1.1.m1.2"><semantics id="S6.I2.i1.p1.1.m1.2a"><mrow id="S6.I2.i1.p1.1.m1.2.3.2" xref="S6.I2.i1.p1.1.m1.2.3.1.cmml"><mn id="S6.I2.i1.p1.1.m1.1.1" xref="S6.I2.i1.p1.1.m1.1.1.cmml">120</mn><mo id="S6.I2.i1.p1.1.m1.2.3.2.1" xref="S6.I2.i1.p1.1.m1.2.3.1.cmml">,</mo><mn id="S6.I2.i1.p1.1.m1.2.2" xref="S6.I2.i1.p1.1.m1.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.I2.i1.p1.1.m1.2b"><list id="S6.I2.i1.p1.1.m1.2.3.1.cmml" xref="S6.I2.i1.p1.1.m1.2.3.2"><cn id="S6.I2.i1.p1.1.m1.1.1.cmml" type="integer" xref="S6.I2.i1.p1.1.m1.1.1">120</cn><cn id="S6.I2.i1.p1.1.m1.2.2.cmml" type="integer" xref="S6.I2.i1.p1.1.m1.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S6.I2.i1.p1.1.m1.2c">120,000</annotation><annotation encoding="application/x-llamapun" id="S6.I2.i1.p1.1.m1.2d">120 , 000</annotation></semantics></math>，而测试集的大小为<math alttext="7,600" class="ltx_Math" display="inline" id="S6.I2.i1.p1.2.m2.2"><semantics id="S6.I2.i1.p1.2.m2.2a"><mrow id="S6.I2.i1.p1.2.m2.2.3.2" xref="S6.I2.i1.p1.2.m2.2.3.1.cmml"><mn id="S6.I2.i1.p1.2.m2.1.1" xref="S6.I2.i1.p1.2.m2.1.1.cmml">7</mn><mo id="S6.I2.i1.p1.2.m2.2.3.2.1" xref="S6.I2.i1.p1.2.m2.2.3.1.cmml">,</mo><mn id="S6.I2.i1.p1.2.m2.2.2" xref="S6.I2.i1.p1.2.m2.2.2.cmml">600</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.I2.i1.p1.2.m2.2b"><list id="S6.I2.i1.p1.2.m2.2.3.1.cmml" xref="S6.I2.i1.p1.2.m2.2.3.2"><cn id="S6.I2.i1.p1.2.m2.1.1.cmml" type="integer" xref="S6.I2.i1.p1.2.m2.1.1">7</cn><cn id="S6.I2.i1.p1.2.m2.2.2.cmml" type="integer" xref="S6.I2.i1.p1.2.m2.2.2">600</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S6.I2.i1.p1.2.m2.2c">7,600</annotation><annotation encoding="application/x-llamapun" id="S6.I2.i1.p1.2.m2.2d">7 , 600</annotation></semantics></math>。每个类别包含来自训练集的<math alttext="30,000" class="ltx_Math" display="inline" id="S6.I2.i1.p1.3.m3.2"><semantics id="S6.I2.i1.p1.3.m3.2a"><mrow id="S6.I2.i1.p1.3.m3.2.3.2" xref="S6.I2.i1.p1.3.m3.2.3.1.cmml"><mn id="S6.I2.i1.p1.3.m3.1.1" xref="S6.I2.i1.p1.3.m3.1.1.cmml">30</mn><mo id="S6.I2.i1.p1.3.m3.2.3.2.1" xref="S6.I2.i1.p1.3.m3.2.3.1.cmml">,</mo><mn id="S6.I2.i1.p1.3.m3.2.2" xref="S6.I2.i1.p1.3.m3.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.I2.i1.p1.3.m3.2b"><list id="S6.I2.i1.p1.3.m3.2.3.1.cmml" xref="S6.I2.i1.p1.3.m3.2.3.2"><cn id="S6.I2.i1.p1.3.m3.1.1.cmml" type="integer" xref="S6.I2.i1.p1.3.m3.1.1">30</cn><cn id="S6.I2.i1.p1.3.m3.2.2.cmml" type="integer" xref="S6.I2.i1.p1.3.m3.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S6.I2.i1.p1.3.m3.2c">30,000</annotation><annotation encoding="application/x-llamapun" id="S6.I2.i1.p1.3.m3.2d">30 , 000</annotation></semantics></math>个样本和来自测试集的<math alttext="1,900" class="ltx_Math" display="inline" id="S6.I2.i1.p1.4.m4.2"><semantics id="S6.I2.i1.p1.4.m4.2a"><mrow id="S6.I2.i1.p1.4.m4.2.3.2" xref="S6.I2.i1.p1.4.m4.2.3.1.cmml"><mn id="S6.I2.i1.p1.4.m4.1.1" xref="S6.I2.i1.p1.4.m4.1.1.cmml">1</mn><mo id="S6.I2.i1.p1.4.m4.2.3.2.1" xref="S6.I2.i1.p1.4.m4.2.3.1.cmml">,</mo><mn id="S6.I2.i1.p1.4.m4.2.2" xref="S6.I2.i1.p1.4.m4.2.2.cmml">900</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.I2.i1.p1.4.m4.2b"><list id="S6.I2.i1.p1.4.m4.2.3.1.cmml" xref="S6.I2.i1.p1.4.m4.2.3.2"><cn id="S6.I2.i1.p1.4.m4.1.1.cmml" type="integer" xref="S6.I2.i1.p1.4.m4.1.1">1</cn><cn id="S6.I2.i1.p1.4.m4.2.2.cmml" type="integer" xref="S6.I2.i1.p1.4.m4.2.2">900</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S6.I2.i1.p1.4.m4.2c">1,900</annotation><annotation encoding="application/x-llamapun" id="S6.I2.i1.p1.4.m4.2d">1 , 900</annotation></semantics></math>个实例。</p>
</div>
</li>
<li class="ltx_item" id="S6.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S6.I2.i2.p1">
<p class="ltx_p" id="S6.I2.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S6.I2.i2.p1.1.1">Jigsaw有毒评论</span>：由于其社会影响，毒性预测是一个具有相当大的实际兴趣的问题。这个数据集由Jigsaw和Google作为Kaggle竞赛的一部分发布，由人类评估员在六个代表有毒行为的类别中对从维基百科讨论页面提取的评论进行注释：<span class="ltx_text ltx_font_typewriter" id="S6.I2.i2.p1.1.2">有毒</span>，'<span class="ltx_text ltx_font_typewriter" id="S6.I2.i2.p1.1.3">严重有毒</span>'，<span class="ltx_text ltx_font_typewriter" id="S6.I2.i2.p1.1.4">淫秽</span>，<span class="ltx_text ltx_font_typewriter" id="S6.I2.i2.p1.1.5">威胁</span>，<span class="ltx_text ltx_font_typewriter" id="S6.I2.i2.p1.1.6">侮辱</span>，和'<span class="ltx_text ltx_font_typewriter" id="S6.I2.i2.p1.1.7">身份仇恨</span>'。</p>
</div>
</li>
<li class="ltx_item" id="S6.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S6.I2.i3.p1">
<p class="ltx_p" id="S6.I2.i3.p1.2"><span class="ltx_text ltx_font_bold" id="S6.I2.i3.p1.2.1">SST2</span>：
斯坦福情感树库（SST）是一个具有完全标记的解析树的语料库，允许对语言中情感的组成效果进行完整分析。该语料库由<math alttext="11,855" class="ltx_Math" display="inline" id="S6.I2.i3.p1.1.m1.2"><semantics id="S6.I2.i3.p1.1.m1.2a"><mrow id="S6.I2.i3.p1.1.m1.2.3.2" xref="S6.I2.i3.p1.1.m1.2.3.1.cmml"><mn id="S6.I2.i3.p1.1.m1.1.1" xref="S6.I2.i3.p1.1.m1.1.1.cmml">11</mn><mo id="S6.I2.i3.p1.1.m1.2.3.2.1" xref="S6.I2.i3.p1.1.m1.2.3.1.cmml">,</mo><mn id="S6.I2.i3.p1.1.m1.2.2" xref="S6.I2.i3.p1.1.m1.2.2.cmml">855</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.I2.i3.p1.1.m1.2b"><list id="S6.I2.i3.p1.1.m1.2.3.1.cmml" xref="S6.I2.i3.p1.1.m1.2.3.2"><cn id="S6.I2.i3.p1.1.m1.1.1.cmml" type="integer" xref="S6.I2.i3.p1.1.m1.1.1">11</cn><cn id="S6.I2.i3.p1.1.m1.2.2.cmml" type="integer" xref="S6.I2.i3.p1.1.m1.2.2">855</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S6.I2.i3.p1.1.m1.2c">11,855</annotation><annotation encoding="application/x-llamapun" id="S6.I2.i3.p1.1.m1.2d">11 , 855</annotation></semantics></math>句子组成，这些句子是从电影评论中提取的。经过斯坦福解析器的解析，它构成了解析树中的<math alttext="215,154" class="ltx_Math" display="inline" id="S6.I2.i3.p1.2.m2.2"><semantics id="S6.I2.i3.p1.2.m2.2a"><mrow id="S6.I2.i3.p1.2.m2.2.3.2" xref="S6.I2.i3.p1.2.m2.2.3.1.cmml"><mn id="S6.I2.i3.p1.2.m2.1.1" xref="S6.I2.i3.p1.2.m2.1.1.cmml">215</mn><mo id="S6.I2.i3.p1.2.m2.2.3.2.1" xref="S6.I2.i3.p1.2.m2.2.3.1.cmml">,</mo><mn id="S6.I2.i3.p1.2.m2.2.2" xref="S6.I2.i3.p1.2.m2.2.2.cmml">154</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.I2.i3.p1.2.m2.2b"><list id="S6.I2.i3.p1.2.m2.2.3.1.cmml" xref="S6.I2.i3.p1.2.m2.2.3.2"><cn id="S6.I2.i3.p1.2.m2.1.1.cmml" type="integer" xref="S6.I2.i3.p1.2.m2.1.1">215</cn><cn id="S6.I2.i3.p1.2.m2.2.2.cmml" type="integer" xref="S6.I2.i3.p1.2.m2.2.2">154</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S6.I2.i3.p1.2.m2.2c">215,154</annotation><annotation encoding="application/x-llamapun" id="S6.I2.i3.p1.2.m2.2d">215 , 154</annotation></semantics></math>个独特短语，每个短语由3名人类评委注释。SST2（也称为SST二元）数据集是SST的一个子集，专门为二元分类任务准备的。更确切地说，从SST中丢弃了中性句子，并且合并了负面和正面类别，从而总共产生了两个类别。</p>
</div>
</li>
</ul>
</div>
</section>
</section>
<section class="ltx_subsection" id="S6.SS2">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">6.2. </span>方法和参数</h3>
<section class="ltx_paragraph" id="S6.SS2.SSS0.Px1">
<h4 class="ltx_title ltx_font_bold ltx_title_paragraph">我们提出的自适应ICL（AICL）方法</h4>
<div class="ltx_para" id="S6.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="S6.SS2.SSS0.Px1.p1.1">作为自适应ICL的新方法，我们采用以下方法：</p>
<ul class="ltx_itemize" id="S6.I3">
<li class="ltx_item" id="S6.I3.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S6.I3.i1.p1">
<p class="ltx_p" id="S6.I3.i1.p1.1">算法<a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#algorithm2" title="In 3.3. Supervised Rank Cutoff ‣ 3. Adaptive ICL ↦ QPP? ‣ “In-Context Learning” or: How I learned to stop worrying and love “Applied Information Retrieval”"><span class="ltx_text ltx_ref_tag">2</span></a>的监督策略，我们称之为监督自适应ICL（<span class="ltx_text ltx_font_bold" id="S6.I3.i1.p1.1.1">SAICL</span>）。</p>
</div>
</li>
<li class="ltx_item" id="S6.I3.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S6.I3.i2.p1">
<p class="ltx_p" id="S6.I3.i2.p1.5">基于QPP的无监督策略（如第<a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#S3.SS2" title="3.2. Unsupervised Rank Cutoff ‣ 3. Adaptive ICL ↦ QPP? ‣ “In-Context Learning” or: How I learned to stop worrying and love “Applied Information Retrieval”"><span class="ltx_text ltx_ref_tag">3.2</span></a>节中概述的通用方向），我们以相对简单的方式计算排名截止，如下所述。首先，给定一个候选示例的前<math alttext="M" class="ltx_Math" display="inline" id="S6.I3.i2.p1.1.m1.1"><semantics id="S6.I3.i2.p1.1.m1.1a"><mi id="S6.I3.i2.p1.1.m1.1.1" xref="S6.I3.i2.p1.1.m1.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S6.I3.i2.p1.1.m1.1b"><ci id="S6.I3.i2.p1.1.m1.1.1.cmml" xref="S6.I3.i2.p1.1.m1.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.I3.i2.p1.1.m1.1c">M</annotation><annotation encoding="application/x-llamapun" id="S6.I3.i2.p1.1.m1.1d">italic_M</annotation></semantics></math>集合，我们计算NQC估计器<cite class="ltx_cite ltx_citemacro_citep">(Shtok et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib73" title="">2012</a>)</cite>的归一化值（我们采用最大归一化，归一化常数为训练集中的最大NQC值）。
然后，将归一化值量化为<math alttext="M" class="ltx_Math" display="inline" id="S6.I3.i2.p1.2.m2.1"><semantics id="S6.I3.i2.p1.2.m2.1a"><mi id="S6.I3.i2.p1.2.m2.1.1" xref="S6.I3.i2.p1.2.m2.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S6.I3.i2.p1.2.m2.1b"><ci id="S6.I3.i2.p1.2.m2.1.1.cmml" xref="S6.I3.i2.p1.2.m2.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.I3.i2.p1.2.m2.1c">M</annotation><annotation encoding="application/x-llamapun" id="S6.I3.i2.p1.2.m2.1d">italic_M</annotation></semantics></math>个等间距区间，范围从<math alttext="0" class="ltx_Math" display="inline" id="S6.I3.i2.p1.3.m3.1"><semantics id="S6.I3.i2.p1.3.m3.1a"><mn id="S6.I3.i2.p1.3.m3.1.1" xref="S6.I3.i2.p1.3.m3.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S6.I3.i2.p1.3.m3.1b"><cn id="S6.I3.i2.p1.3.m3.1.1.cmml" type="integer" xref="S6.I3.i2.p1.3.m3.1.1">0</cn></annotation-xml></semantics></math>到最大NQC值。根据一个更高的NQC值表示更好的检索质量的假设，我们采用反线性关系，最终选择接近<math alttext="0" class="ltx_Math" display="inline" id="S6.I3.i2.p1.4.m4.1"><semantics id="S6.I3.i2.p1.4.m4.1a"><mn id="S6.I3.i2.p1.4.m4.1.1" xref="S6.I3.i2.p1.4.m4.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S6.I3.i2.p1.4.m4.1b"><cn id="S6.I3.i2.p1.4.m4.1.1.cmml" type="integer" xref="S6.I3.i2.p1.4.m4.1.1">0</cn></annotation-xml></semantics></math>的值作为更高的NQC，并选择接近<math alttext="M" class="ltx_Math" display="inline" id="S6.I3.i2.p1.5.m5.1"><semantics id="S6.I3.i2.p1.5.m5.1a"><mi id="S6.I3.i2.p1.5.m5.1.1" xref="S6.I3.i2.p1.5.m5.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S6.I3.i2.p1.5.m5.1b"><ci id="S6.I3.i2.p1.5.m5.1.1.cmml" xref="S6.I3.i2.p1.5.m5.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.I3.i2.p1.5.m5.1c">M</annotation><annotation encoding="application/x-llamapun" id="S6.I3.i2.p1.5.m5.1d">italic_M</annotation></semantics></math>的值作为较小的值。
我们将这种方法称为<span class="ltx_text ltx_font_bold" id="S6.I3.i2.p1.5.1">QPP-AICL</span>。</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_paragraph" id="S6.SS2.SSS0.Px2">
<h4 class="ltx_title ltx_font_bold ltx_title_paragraph">基线</h4>
<div class="ltx_para" id="S6.SS2.SSS0.Px2.p1">
<p class="ltx_p" id="S6.SS2.SSS0.Px2.p1.1">作为与SAICL和QPP-AICL进行比较的基准，我们采用以下内容：</p>
</div>
<div class="ltx_para" id="S6.SS2.SSS0.Px2.p2">
<ul class="ltx_itemize" id="S6.I4">
<li class="ltx_item" id="S6.I4.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S6.I4.i1.p1">
<p class="ltx_p" id="S6.I4.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S6.I4.i1.p1.1.1">0-shot</span>: 这种方法只是输入指示而不提供任何示例。</p>
</div>
</li>
<li class="ltx_item" id="S6.I4.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S6.I4.i2.p1">
<p class="ltx_p" id="S6.I4.i2.p1.5"><span class="ltx_text ltx_font_bold" id="S6.I4.i2.p1.5.1">静态ICL（SICL）</span>：这指的是提供固定数量的语义相似样本作为输入的标准方法，类似于<cite class="ltx_cite ltx_citemacro_citep">(Liu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib45" title="">2022</a>)</cite>。这与AICL不同之处在于提示中的样本数量始终固定，但是样本本身根据语义相似性对不同的测试输入变化。为了与AICL方法进行公平比较，我们报告了使用三种不同值<math alttext="k" class="ltx_Math" display="inline" id="S6.I4.i2.p1.1.m1.1"><semantics id="S6.I4.i2.p1.1.m1.1a"><mi id="S6.I4.i2.p1.1.m1.1.1" xref="S6.I4.i2.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S6.I4.i2.p1.1.m1.1b"><ci id="S6.I4.i2.p1.1.m1.1.1.cmml" xref="S6.I4.i2.p1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.I4.i2.p1.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S6.I4.i2.p1.1.m1.1d">italic_k</annotation></semantics></math>获得的结果：<math alttext="1" class="ltx_Math" display="inline" id="S6.I4.i2.p1.2.m2.1"><semantics id="S6.I4.i2.p1.2.m2.1a"><mn id="S6.I4.i2.p1.2.m2.1.1" xref="S6.I4.i2.p1.2.m2.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S6.I4.i2.p1.2.m2.1b"><cn id="S6.I4.i2.p1.2.m2.1.1.cmml" type="integer" xref="S6.I4.i2.p1.2.m2.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.I4.i2.p1.2.m2.1c">1</annotation><annotation encoding="application/x-llamapun" id="S6.I4.i2.p1.2.m2.1d">1</annotation></semantics></math>，<math alttext="\lceil\frac{M}{2}\rceil" class="ltx_Math" display="inline" id="S6.I4.i2.p1.3.m3.1"><semantics id="S6.I4.i2.p1.3.m3.1a"><mrow id="S6.I4.i2.p1.3.m3.1.2.2" xref="S6.I4.i2.p1.3.m3.1.2.1.cmml"><mo id="S6.I4.i2.p1.3.m3.1.2.2.1" stretchy="false" xref="S6.I4.i2.p1.3.m3.1.2.1.1.cmml">⌈</mo><mfrac id="S6.I4.i2.p1.3.m3.1.1" xref="S6.I4.i2.p1.3.m3.1.1.cmml"><mi id="S6.I4.i2.p1.3.m3.1.1.2" xref="S6.I4.i2.p1.3.m3.1.1.2.cmml">M</mi><mn id="S6.I4.i2.p1.3.m3.1.1.3" xref="S6.I4.i2.p1.3.m3.1.1.3.cmml">2</mn></mfrac><mo id="S6.I4.i2.p1.3.m3.1.2.2.2" stretchy="false" xref="S6.I4.i2.p1.3.m3.1.2.1.1.cmml">⌉</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.I4.i2.p1.3.m3.1b"><apply id="S6.I4.i2.p1.3.m3.1.2.1.cmml" xref="S6.I4.i2.p1.3.m3.1.2.2"><ceiling id="S6.I4.i2.p1.3.m3.1.2.1.1.cmml" xref="S6.I4.i2.p1.3.m3.1.2.2.1"></ceiling><apply id="S6.I4.i2.p1.3.m3.1.1.cmml" xref="S6.I4.i2.p1.3.m3.1.1"><divide id="S6.I4.i2.p1.3.m3.1.1.1.cmml" xref="S6.I4.i2.p1.3.m3.1.1"></divide><ci id="S6.I4.i2.p1.3.m3.1.1.2.cmml" xref="S6.I4.i2.p1.3.m3.1.1.2">𝑀</ci><cn id="S6.I4.i2.p1.3.m3.1.1.3.cmml" type="integer" xref="S6.I4.i2.p1.3.m3.1.1.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.I4.i2.p1.3.m3.1c">\lceil\frac{M}{2}\rceil</annotation><annotation encoding="application/x-llamapun" id="S6.I4.i2.p1.3.m3.1d">⌈ divide start_ARG italic_M end_ARG start_ARG 2 end_ARG ⌉</annotation></semantics></math>和<math alttext="M" class="ltx_Math" display="inline" id="S6.I4.i2.p1.4.m4.1"><semantics id="S6.I4.i2.p1.4.m4.1a"><mi id="S6.I4.i2.p1.4.m4.1.1" xref="S6.I4.i2.p1.4.m4.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S6.I4.i2.p1.4.m4.1b"><ci id="S6.I4.i2.p1.4.m4.1.1.cmml" xref="S6.I4.i2.p1.4.m4.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.I4.i2.p1.4.m4.1c">M</annotation><annotation encoding="application/x-llamapun" id="S6.I4.i2.p1.4.m4.1d">italic_M</annotation></semantics></math>，分别代表最保守（在输入大小方面）、平均和最不保守的情况。在我们的情况下，<math alttext="M=5" class="ltx_Math" display="inline" id="S6.I4.i2.p1.5.m5.1"><semantics id="S6.I4.i2.p1.5.m5.1a"><mrow id="S6.I4.i2.p1.5.m5.1.1" xref="S6.I4.i2.p1.5.m5.1.1.cmml"><mi id="S6.I4.i2.p1.5.m5.1.1.2" xref="S6.I4.i2.p1.5.m5.1.1.2.cmml">M</mi><mo id="S6.I4.i2.p1.5.m5.1.1.1" xref="S6.I4.i2.p1.5.m5.1.1.1.cmml">=</mo><mn id="S6.I4.i2.p1.5.m5.1.1.3" xref="S6.I4.i2.p1.5.m5.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.I4.i2.p1.5.m5.1b"><apply id="S6.I4.i2.p1.5.m5.1.1.cmml" xref="S6.I4.i2.p1.5.m5.1.1"><eq id="S6.I4.i2.p1.5.m5.1.1.1.cmml" xref="S6.I4.i2.p1.5.m5.1.1.1"></eq><ci id="S6.I4.i2.p1.5.m5.1.1.2.cmml" xref="S6.I4.i2.p1.5.m5.1.1.2">𝑀</ci><cn id="S6.I4.i2.p1.5.m5.1.1.3.cmml" type="integer" xref="S6.I4.i2.p1.5.m5.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.I4.i2.p1.5.m5.1c">M=5</annotation><annotation encoding="application/x-llamapun" id="S6.I4.i2.p1.5.m5.1d">italic_M = 5</annotation></semantics></math>，这意味着我们的标准ICL实验使用1-shot，3-shot和5-shot设置。</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_paragraph" id="S6.SS2.SSS0.Px3">
<h4 class="ltx_title ltx_font_bold ltx_title_paragraph">模型和超参数设置</h4>
<div class="ltx_para" id="S6.SS2.SSS0.Px3.p1">
<p class="ltx_p" id="S6.SS2.SSS0.Px3.p1.1">在相对较多的可用LLMs选择中 - 无论是开源模型还是黑盒云API - 我们特别在GPT-J <cite class="ltx_cite ltx_citemacro_citep">(Su et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib77" title="">2023</a>)</cite>上进行实验。
GPT-J是一个基于Pile数据集训练的类似GPT-3的开源模型<cite class="ltx_cite ltx_citemacro_citep">(Gao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib27" title="">2020</a>)</cite>。GPT-J-6B在各种任务上的性能与67亿参数的GPT-3（Curie）相当<cite class="ltx_cite ltx_citemacro_citep">(Wang, <a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#bib.bib82" title="">2021</a>)</cite>。GPT-J的最大上下文长度（以token数表示）为2048。</p>
</div>
<div class="ltx_para" id="S6.SS2.SSS0.Px3.p2">
<p class="ltx_p" id="S6.SS2.SSS0.Px3.p2.2">在我们的实验中，我们将<math alttext="M" class="ltx_Math" display="inline" id="S6.SS2.SSS0.Px3.p2.1.m1.1"><semantics id="S6.SS2.SSS0.Px3.p2.1.m1.1a"><mi id="S6.SS2.SSS0.Px3.p2.1.m1.1.1" xref="S6.SS2.SSS0.Px3.p2.1.m1.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS0.Px3.p2.1.m1.1b"><ci id="S6.SS2.SSS0.Px3.p2.1.m1.1.1.cmml" xref="S6.SS2.SSS0.Px3.p2.1.m1.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS0.Px3.p2.1.m1.1c">M</annotation><annotation encoding="application/x-llamapun" id="S6.SS2.SSS0.Px3.p2.1.m1.1d">italic_M</annotation></semantics></math> - 最大示例数，从1变化到5（对于静态ICL，这由<math alttext="k" class="ltx_Math" display="inline" id="S6.SS2.SSS0.Px3.p2.2.m2.1"><semantics id="S6.SS2.SSS0.Px3.p2.2.m2.1a"><mi id="S6.SS2.SSS0.Px3.p2.2.m2.1.1" xref="S6.SS2.SSS0.Px3.p2.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS0.Px3.p2.2.m2.1b"><ci id="S6.SS2.SSS0.Px3.p2.2.m2.1.1.cmml" xref="S6.SS2.SSS0.Px3.p2.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS0.Px3.p2.2.m2.1c">k</annotation><annotation encoding="application/x-llamapun" id="S6.SS2.SSS0.Px3.p2.2.m2.1d">italic_k</annotation></semantics></math>表示）。为了公平比较，我们在实验中使用相同的提示模板（如算法<a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#algorithm1" title="In 3.3. Supervised Rank Cutoff ‣ 3. Adaptive ICL ↦ QPP? ‣ “In-Context Learning” or: How I learned to stop worrying and love “Applied Information Retrieval”"><span class="ltx_text ltx_ref_tag">1</span></a>所示），并且对所有实验中使用的方法都采用了贪婪解码和相同的表达者。</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S6.SS3">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">6.3. </span>结果</h3>
<figure class="ltx_table" id="S6.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">表1。 </span>不同场景学习（ICL）方法的宏平均精度，召回率和F1分数。列<math alttext="k" class="ltx_Math" display="inline" id="S6.T1.2.m1.1"><semantics id="S6.T1.2.m1.1b"><mi id="S6.T1.2.m1.1.1" xref="S6.T1.2.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S6.T1.2.m1.1c"><ci id="S6.T1.2.m1.1.1.cmml" xref="S6.T1.2.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T1.2.m1.1d">k</annotation><annotation encoding="application/x-llamapun" id="S6.T1.2.m1.1e">italic_k</annotation></semantics></math>表示少样本示例的数量。对于AICL方法，该列表示用于相应方法的平均示例数量。‘AIS’表示以令牌数量四舍五入到最接近的整数来衡量的平均输入大小。</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S6.T1.3" style="width:308.3pt;height:360pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p class="ltx_p" id="S6.T1.3.1"><span class="ltx_text" id="S6.T1.3.1.1">
<span class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S6.T1.3.1.1.1">
<span class="ltx_tbody">
<span class="ltx_tr" id="S6.T1.3.1.1.1.2.1">
<span class="ltx_td ltx_border_tt" id="S6.T1.3.1.1.1.2.1.1"></span>
<span class="ltx_td ltx_th ltx_th_column ltx_border_tt" id="S6.T1.3.1.1.1.2.1.2"></span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt ltx_colspan ltx_colspan_5" id="S6.T1.3.1.1.1.2.1.3">评估</span></span>
<span class="ltx_tr" id="S6.T1.3.1.1.1.1">
<span class="ltx_td ltx_align_left ltx_th ltx_th_column" id="S6.T1.3.1.1.1.1.2">数据集</span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_column" id="S6.T1.3.1.1.1.1.3">方法</span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_column" id="S6.T1.3.1.1.1.1.1"><math alttext="k" class="ltx_Math" display="inline" id="S6.T1.3.1.1.1.1.1.m1.1"><semantics id="S6.T1.3.1.1.1.1.1.m1.1a"><mi id="S6.T1.3.1.1.1.1.1.m1.1.1" xref="S6.T1.3.1.1.1.1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S6.T1.3.1.1.1.1.1.m1.1b"><ci id="S6.T1.3.1.1.1.1.1.m1.1.1.cmml" xref="S6.T1.3.1.1.1.1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T1.3.1.1.1.1.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S6.T1.3.1.1.1.1.1.m1.1d">italic_k</annotation></semantics></math></span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" id="S6.T1.3.1.1.1.1.4">精度</span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" id="S6.T1.3.1.1.1.1.5">召回率</span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" id="S6.T1.3.1.1.1.1.6">F分数</span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" id="S6.T1.3.1.1.1.1.7">AIS</span></span>
<span class="ltx_tr" id="S6.T1.3.1.1.1.3.2">
<span class="ltx_td ltx_align_left ltx_border_t ltx_rowspan ltx_rowspan_6" id="S6.T1.3.1.1.1.3.2.1"><span class="ltx_text" id="S6.T1.3.1.1.1.3.2.1.1">AGNews</span></span>
<span class="ltx_td ltx_align_left ltx_border_t" id="S6.T1.3.1.1.1.3.2.2">0-shot</span>
<span class="ltx_td ltx_align_right ltx_border_t" id="S6.T1.3.1.1.1.3.2.3">0</span>
<span class="ltx_td ltx_align_right ltx_border_t" id="S6.T1.3.1.1.1.3.2.4">0.6569</span>
<span class="ltx_td ltx_align_right ltx_border_t" id="S6.T1.3.1.1.1.3.2.5">0.5932</span>
<span class="ltx_td ltx_align_right ltx_border_t" id="S6.T1.3.1.1.1.3.2.6">0.5849</span>
<span class="ltx_td ltx_align_right ltx_border_t" id="S6.T1.3.1.1.1.3.2.7">60</span></span>
<span class="ltx_tr" id="S6.T1.3.1.1.1.4.3">
<span class="ltx_td ltx_align_left" id="S6.T1.3.1.1.1.4.3.1">SICL</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.4.3.2">1</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.4.3.3">0.9015</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.4.3.4">0.9017</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.4.3.5">0.9016</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.4.3.6">125</span></span>
<span class="ltx_tr" id="S6.T1.3.1.1.1.5.4">
<span class="ltx_td ltx_align_left" id="S6.T1.3.1.1.1.5.4.1">SICL</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.5.4.2">3</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.5.4.3">0.9008</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.5.4.4">0.8997</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.5.4.5">0.8989</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.5.4.6">252</span></span>
<span class="ltx_tr" id="S6.T1.3.1.1.1.6.5">
<span class="ltx_td ltx_align_left" id="S6.T1.3.1.1.1.6.5.1">SICL</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.6.5.2">5</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.6.5.3">0.8963</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.6.5.4">0.8930</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.6.5.5">0.8917</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.6.5.6">380</span></span>
<span class="ltx_tr" id="S6.T1.3.1.1.1.7.6">
<span class="ltx_td ltx_align_left" id="S6.T1.3.1.1.1.7.6.1">QPP-AICL</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.7.6.2">3</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.7.6.3">0.8545</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.7.6.4">0.8499</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.7.6.5">0.8486</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.7.6.6">220</span></span>
<span class="ltx_tr" id="S6.T1.3.1.1.1.8.7">
<span class="ltx_td ltx_align_left" id="S6.T1.3.1.1.1.8.7.1">SAICL</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.8.7.2">1.87</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.8.7.3"><span class="ltx_text ltx_font_bold" id="S6.T1.3.1.1.1.8.7.3.1">0.9080</span></span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.8.7.4"><span class="ltx_text ltx_font_bold" id="S6.T1.3.1.1.1.8.7.4.1">0.9096</span></span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.8.7.5"><span class="ltx_text ltx_font_bold" id="S6.T1.3.1.1.1.8.7.5.1">0.9067</span></span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.8.7.6">175</span></span>
<span class="ltx_tr" id="S6.T1.3.1.1.1.9.8">
<span class="ltx_td ltx_align_left ltx_border_t ltx_rowspan ltx_rowspan_6" id="S6.T1.3.1.1.1.9.8.1"><span class="ltx_text" id="S6.T1.3.1.1.1.9.8.1.1">毒性</span></span>
<span class="ltx_td ltx_align_left ltx_border_t" id="S6.T1.3.1.1.1.9.8.2">0-shot</span>
<span class="ltx_td ltx_align_right ltx_border_t" id="S6.T1.3.1.1.1.9.8.3">0</span>
<span class="ltx_td ltx_align_right ltx_border_t" id="S6.T1.3.1.1.1.9.8.4">0.5689</span>
<span class="ltx_td ltx_align_right ltx_border_t" id="S6.T1.3.1.1.1.9.8.5">0.6238</span>
<span class="ltx_td ltx_align_right ltx_border_t" id="S6.T1.3.1.1.1.9.8.6">0.5769</span>
<span class="ltx_td ltx_align_right ltx_border_t" id="S6.T1.3.1.1.1.9.8.7">103</span></span>
<span class="ltx_tr" id="S6.T1.3.1.1.1.10.9">
<span class="ltx_td ltx_align_left" id="S6.T1.3.1.1.1.10.9.1">SICL</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.10.9.2">1</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.10.9.3">0.5760</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.10.9.4">0.6989</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.10.9.5">0.5505</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.10.9.6">195</span></span>
<span class="ltx_tr" id="S6.T1.3.1.1.1.11.10">
<span class="ltx_td ltx_align_left" id="S6.T1.3.1.1.1.11.10.1">SICL</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.11.10.2">3</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.11.10.3">0.6092</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.11.10.4">0.7180</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.11.10.5">0.6254</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.11.10.6">335</span></span>
<span class="ltx_tr" id="S6.T1.3.1.1.1.12.11">
<span class="ltx_td ltx_align_left" id="S6.T1.3.1.1.1.12.11.1">SICL</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.12.11.2">5</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.12.11.3">0.6078</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.12.11.4"><span class="ltx_text ltx_font_bold" id="S6.T1.3.1.1.1.12.11.4.1">0.7248</span></span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.12.11.5">0.6217</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.12.11.6">431</span></span>
<span class="ltx_tr" id="S6.T1.3.1.1.1.13.12">
<span class="ltx_td ltx_align_left" id="S6.T1.3.1.1.1.13.12.1">QPP-AICL</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.13.12.2">3</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.13.12.3">0.5906</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.13.12.4">0.6942</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.13.12.5">0.5977</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.13.12.6">289</span></span>
<span class="ltx_tr" id="S6.T1.3.1.1.1.14.13">
<span class="ltx_td ltx_align_left" id="S6.T1.3.1.1.1.14.13.1">SAICL</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.14.13.2">3.46</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.14.13.3"><span class="ltx_text ltx_font_bold" id="S6.T1.3.1.1.1.14.13.3.1">0.6194</span></span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.14.13.4">0.6983</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.14.13.5"><span class="ltx_text ltx_font_bold" id="S6.T1.3.1.1.1.14.13.5.1">0.6303</span></span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.14.13.6">359</span></span>
<span class="ltx_tr" id="S6.T1.3.1.1.1.15.14">
<span class="ltx_td ltx_align_left ltx_border_bb ltx_border_t ltx_rowspan ltx_rowspan_6" id="S6.T1.3.1.1.1.15.14.1"><span class="ltx_text" id="S6.T1.3.1.1.1.15.14.1.1">SST2</span></span>
<span class="ltx_td ltx_align_left ltx_border_t" id="S6.T1.3.1.1.1.15.14.2">0-shot</span>
<span class="ltx_td ltx_align_right ltx_border_t" id="S6.T1.3.1.1.1.15.14.3">0</span>
<span class="ltx_td ltx_align_right ltx_border_t" id="S6.T1.3.1.1.1.15.14.4">0.7503</span>
<span class="ltx_td ltx_align_right ltx_border_t" id="S6.T1.3.1.1.1.15.14.5">0.5022</span>
<span class="ltx_td ltx_align_right ltx_border_t" id="S6.T1.3.1.1.1.15.14.6">0.3379</span>
<span class="ltx_td ltx_align_right ltx_border_t" id="S6.T1.3.1.1.1.15.14.7">30</span></span>
<span class="ltx_tr" id="S6.T1.3.1.1.1.16.15">
<span class="ltx_td ltx_align_left" id="S6.T1.3.1.1.1.16.15.1">SICL</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.16.15.2">1</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.16.15.3">0.8703</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.16.15.4">0.8703</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.16.15.5">0.8703</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.16.15.6">61</span></span>
<span class="ltx_tr" id="S6.T1.3.1.1.1.17.16">
<span class="ltx_td ltx_align_left" id="S6.T1.3.1.1.1.17.16.1">SICL</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.17.16.2">3</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.17.16.3">0.9140</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.17.16.4">0.9137</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.17.16.5">0.9137</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.17.16.6">121</span></span>
<span class="ltx_tr" id="S6.T1.3.1.1.1.18.17">
<span class="ltx_td ltx_align_left" id="S6.T1.3.1.1.1.18.17.1">SICL</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.18.17.2">5</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.18.17.3">0.9245</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.18.17.4">0.9230</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.18.17.5">0.9230</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.18.17.6">181</span></span>
<span class="ltx_tr" id="S6.T1.3.1.1.1.19.18">
<span class="ltx_td ltx_align_left" id="S6.T1.3.1.1.1.19.18.1">QPP-AICL</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.19.18.2">3</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.19.18.3">0.8556</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.19.18.4">0.8479</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.19.18.5">0.8470</span>
<span class="ltx_td ltx_align_right" id="S6.T1.3.1.1.1.19.18.6">106</span></span>
<span class="ltx_tr" id="S6.T1.3.1.1.1.20.19">
<span class="ltx_td ltx_align_left ltx_border_bb" id="S6.T1.3.1.1.1.20.19.1">SAICL</span>
<span class="ltx_td ltx_align_right ltx_border_bb" id="S6.T1.3.1.1.1.20.19.2">4.12</span>
<span class="ltx_td ltx_align_right ltx_border_bb" id="S6.T1.3.1.1.1.20.19.3"><span class="ltx_text ltx_font_bold" id="S6.T1.3.1.1.1.20.19.3.1">0.9302</span></span>
<span class="ltx_td ltx_align_right ltx_border_bb" id="S6.T1.3.1.1.1.20.19.4"><span class="ltx_text ltx_font_bold" id="S6.T1.3.1.1.1.20.19.4.1">0.9304</span></span>
<span class="ltx_td ltx_align_right ltx_border_bb" id="S6.T1.3.1.1.1.20.19.5"><span class="ltx_text ltx_font_bold" id="S6.T1.3.1.1.1.20.19.5.1">0.9302</span></span>
<span class="ltx_td ltx_align_right ltx_border_bb" id="S6.T1.3.1.1.1.20.19.6">154</span></span>
</span>
</span></span></p>
</span></div>
</figure>
<div class="ltx_para" id="S6.SS3.p1">
<p class="ltx_p" id="S6.SS3.p1.1">表<a class="ltx_ref" href="https://arxiv.org/html/2405.01116v1#S6.T1" title="Table 1 ‣ 6.3. Results ‣ 6. Preliminary Evaluation ‣ “In-Context Learning” or: How I learned to stop worrying and love “Applied Information Retrieval”"><span class="ltx_text ltx_ref_tag">1</span></a>显示了不同ICL策略获得的结果（宏平均精度、召回率和F1）。
可以看出，SAICL在竞争对手中表现最佳。它之所以胜过最佳基准线（静态ICL），是因为SAICL能够有效地调整要使用的示例数量，从而防止自身受非相关（无用）示例的降级影响。
事实上，它学习了主题内容与引导解码器输出所需的上下文数量之间的潜在关系。此外，SAICL能够更有效地处理较小的输入大小（参见<math alttext="k" class="ltx_Math" display="inline" id="S6.SS3.p1.1.m1.1"><semantics id="S6.SS3.p1.1.m1.1a"><mi id="S6.SS3.p1.1.m1.1.1" xref="S6.SS3.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S6.SS3.p1.1.m1.1b"><ci id="S6.SS3.p1.1.m1.1.1.cmml" xref="S6.SS3.p1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.p1.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S6.SS3.p1.1.m1.1d">italic_k</annotation></semantics></math>的平均值以及以标记数表示的输入的平均大小），这意味着与静态ICL（SICL）相比，它在计算上更快。
我们的观察结果表明，<span class="ltx_text ltx_font_bold" id="S6.SS3.p1.1.1">CRQ-1</span>的答案是肯定的，即ICL中示例数量的自适应选择确实提高了下游任务的效果和效率。</p>
</div>
<div class="ltx_para" id="S6.SS3.p2">
<p class="ltx_p" id="S6.SS3.p2.1">使用无监督的QPP-based方法（QPP-AICL）得出的结果比静态ICL基准更糟糕。从更广泛的视角来看，这指向一个重要发现 - 即没有针对ICL下游任务的基本特征进行特定修改的现成IR方法可能不会直接提高ICL的效果。例如，NQC试图估计文档的相关性，正如我们之前所讨论的那样，对于ICL示例，相关性有不同的解释。虽然对QPP-AICL的观察回答了<span class="ltx_text ltx_font_bold" id="S6.SS3.p2.1.1">CRQ-2</span>的负面问题，即自适应选择ICL示例的无监督方法远远不如监督方法，但它们确实表明，未来研究人员为回答本文讨论的任何开放性研究问题开发的方法应该从根本上以稳健和有效的方式对相关性（示例的有用性）进行建模。</p>
</div>
</section>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">7. </span>结论</h2>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">在这篇观点论文中，我们讨论了生成式人工智能（特别是上下文学习或ICL）的一些最新发展如何为信息检索/自然语言处理研究人员提供了一个重新审视一些经过深入研究的信息检索主题的新视角的范围，其中文档与信息需求相关性的概念转变为少样本示例对下游人工智能任务（例如文本分类、问答等）的有用性。更具体地，我们提出了这项研究可以被构建的三个主要垂直领域 - 每个领域提供了一系列与核心信息检索研究相关的开放性问题。</p>
</div>
<div class="ltx_para" id="S7.p2">
<p class="ltx_p" id="S7.p2.1">第一个垂直旨在以数据驱动的方式选择要使用的示例数量来自适应调整ICL工作流程。在本文展望性论文中报道的初步实证调查显示，这个方向是有希望的。第二个垂直主要涉及设计新的排序模型，以更好地区分（从而以更好的排名检索）有用的少样本上下文和噪声样本。最后，第三个垂直关注少样本示例中的主题多样性，以更好地进行下游预测。</p>
</div>
<div class="ltx_para" id="S7.p3">
<p class="ltx_p" id="S7.p3.1">我们相信我们在本文中提出的研究问题将有助于研究界利用ICL和IR之间的协同作用，并最终指导新算法和技术的发展。</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References
参考文献</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Alaofi et al<span class="ltx_text" id="bib.bib2.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Marwah Alaofi, Luke Gallagher, Mark Sanderson, Falk Scholer, and Paul Thomas. 2023.

</span>
<span class="ltx_bibblock">Can Generative LLMs Create Query Variants for Test Collections? An Exploratory Study. In <em class="ltx_emph ltx_font_italic" id="bib.bib2.3.1">Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval</em> (Taipei, Taiwan) <em class="ltx_emph ltx_font_italic" id="bib.bib2.4.2">(SIGIR ’23)</em>. Association for Computing Machinery, New York, NY, USA, 1869–1873.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3539618.3591960" title="">https://doi.org/10.1145/3539618.3591960</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Arampatzis et al<span class="ltx_text" id="bib.bib3.2.2.1">.</span> (2009)</span>
<span class="ltx_bibblock">
Avi Arampatzis, Jaap Kamps, and Stephen Robertson. 2009.

</span>
<span class="ltx_bibblock">Where to Stop Reading a Ranked List? Threshold Optimization Using Truncated Score Distributions. In <em class="ltx_emph ltx_font_italic" id="bib.bib3.3.1">Proceedings of the 32nd International ACM SIGIR Conference on Research and Development in Information Retrieval</em> (Boston, MA, USA) <em class="ltx_emph ltx_font_italic" id="bib.bib3.4.2">(SIGIR ’09)</em>. Association for Computing Machinery, New York, NY, USA, 524–531.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/1571941.1572031" title="">https://doi.org/10.1145/1571941.1572031</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Arora et al<span class="ltx_text" id="bib.bib4.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Simran Arora, Avanika Narayan, Mayee F. Chen, Laurel Orr, Neel Guha, Kush Bhatia, Ines Chami, Frederic Sala, and Christopher Ré. 2022.

</span>
<span class="ltx_bibblock">Ask Me Anything: A simple strategy for prompting language models.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2210.02441 [cs.CL]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bahri et al<span class="ltx_text" id="bib.bib5.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Dara Bahri, Yi Tay, Che Zheng, Donald Metzler, and Andrew Tomkins. 2020.

</span>
<span class="ltx_bibblock">Choppy: Cut Transformer for Ranked List Truncation. In <em class="ltx_emph ltx_font_italic" id="bib.bib5.3.1">Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval</em> (Virtual Event, China) <em class="ltx_emph ltx_font_italic" id="bib.bib5.4.2">(SIGIR ’20)</em>. Association for Computing Machinery, New York, NY, USA, 1513–1516.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3397271.3401188" title="">https://doi.org/10.1145/3397271.3401188</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et al<span class="ltx_text" id="bib.bib6.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al<span class="ltx_text" id="bib.bib6.3.1">.</span> 2020.

</span>
<span class="ltx_bibblock">Language models are few-shot learners.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.4.1">Advances in neural information processing systems</em> 33 (2020), 1877–1901.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Carterette et al<span class="ltx_text" id="bib.bib7.2.2.1">.</span> ([n. d.])</span>
<span class="ltx_bibblock">
Ben Carterette, Evangelos Kanoulas, Mark M. Hall, and Paul D. Clough. [n. d.].

</span>
<span class="ltx_bibblock">Overview of the TREC 2014 Session Track. In <em class="ltx_emph ltx_font_italic" id="bib.bib7.3.1">Proc. of TREC 2014</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chakraborty et al<span class="ltx_text" id="bib.bib8.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Anirban Chakraborty, Debasis Ganguly, and Owen Conlan. 2020.

</span>
<span class="ltx_bibblock">Retrievability based Document Selection for Relevance Feedback with Automatically Generated Query Variants. In <em class="ltx_emph ltx_font_italic" id="bib.bib8.3.1">CIKM</em>. ACM, 125–134.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Clarke et al<span class="ltx_text" id="bib.bib9.2.2.1">.</span> (2008)</span>
<span class="ltx_bibblock">
Charles L.A. Clarke, Maheedhar Kolla, Gordon V. Cormack, Olga Vechtomova, Azin Ashkan, Stefan Büttcher, and Ian MacKinnon. 2008.

</span>
<span class="ltx_bibblock">Novelty and diversity in information retrieval evaluation. In <em class="ltx_emph ltx_font_italic" id="bib.bib9.3.1">Proceedings of the 31st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</em> (Singapore, Singapore) <em class="ltx_emph ltx_font_italic" id="bib.bib9.4.2">(SIGIR ’08)</em>. Association for Computing Machinery, New York, NY, USA, 659–666.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/1390334.1390446" title="">https://doi.org/10.1145/1390334.1390446</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Clarke et al<span class="ltx_text" id="bib.bib10.2.2.1">.</span> (2009)</span>
<span class="ltx_bibblock">
Charles L. A. Clarke, Nick Craswell, and Ian Soboroff. 2009.

</span>
<span class="ltx_bibblock">Overview of the TREC 2009 Web Track. In <em class="ltx_emph ltx_font_italic" id="bib.bib10.3.1">Proceedings of The Eighteenth Text REtrieval Conference, TREC 2009, Gaithersburg, Maryland, USA, November 17-20, 2009</em> <em class="ltx_emph ltx_font_italic" id="bib.bib10.4.2">(NIST Special Publication, Vol. 500-278)</em>, Ellen M. Voorhees and Lori P. Buckland (Eds.). National Institute of Standards and Technology (NIST).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="http://trec.nist.gov/pubs/trec18/papers/WEB09.OVERVIEW.pdf" title="">http://trec.nist.gov/pubs/trec18/papers/WEB09.OVERVIEW.pdf</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cronen-Townsend et al<span class="ltx_text" id="bib.bib11.2.2.1">.</span> (2002)</span>
<span class="ltx_bibblock">
Steve Cronen-Townsend, Yun Zhou, and W. Bruce Croft. 2002.

</span>
<span class="ltx_bibblock">Predicting Query Performance. In <em class="ltx_emph ltx_font_italic" id="bib.bib11.3.1">Proceedings of the 25th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</em> <em class="ltx_emph ltx_font_italic" id="bib.bib11.4.2">(SIGIR ’02)</em>. Association for Computing Machinery, New York, NY, USA, 299–306.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cuconasu et al<span class="ltx_text" id="bib.bib12.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Florin Cuconasu, Giovanni Trappolini, Federico Siciliano, Simone Filice, Cesare Campagnano, Yoelle Maarek, Nicola Tonellotto, and Fabrizio Silvestri. 2024.

</span>
<span class="ltx_bibblock">The Power of Noise: Redefining Retrieval for RAG Systems.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2401.14887 [cs.IR]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cummins (2014)</span>
<span class="ltx_bibblock">
Ronan Cummins. 2014.

</span>
<span class="ltx_bibblock">Document Score Distribution Models for Query Performance Inference and Prediction.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">ACM Trans. Inf. Syst.</em> 32, 1, Article 2 (2014), 28 pages.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dai and Callan (2019)</span>
<span class="ltx_bibblock">
Zhuyun Dai and Jamie Callan. 2019.

</span>
<span class="ltx_bibblock">Deeper Text Understanding for IR with Contextual Neural Language Modeling. In <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval</em> (Paris, France) <em class="ltx_emph ltx_font_italic" id="bib.bib14.2.2">(SIGIR’19)</em>. Association for Computing Machinery, New York, NY, USA, 985–988.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3331184.3331303" title="">https://doi.org/10.1145/3331184.3331303</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Datta et al<span class="ltx_text" id="bib.bib15.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Suchana Datta, Debasis Ganguly, Derek Greene, and Mandar Mitra. 2022.

</span>
<span class="ltx_bibblock">Deep-QPP: A Pairwise Interaction-based Deep Learning Model for Supervised Query Performance Prediction. In <em class="ltx_emph ltx_font_italic" id="bib.bib15.3.1">WSDM ’22: The Fifteenth ACM International Conference on Web Search and Data Mining, Virtual Event / Tempe, AZ, USA, February 21 - 25, 2022</em>, K. Selcuk Candan, Huan Liu, Leman Akoglu, Xin Luna Dong, and Jiliang Tang (Eds.). ACM, 201–209.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3488560.3498491" title="">https://doi.org/10.1145/3488560.3498491</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Datta et al<span class="ltx_text" id="bib.bib16.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Suchana Datta, Debasis Ganguly, Mandar Mitra, and Derek Greene. 2023.

</span>
<span class="ltx_bibblock">A Relative Information Gain-based Query Performance Prediction Framework with Generated Query Variants.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib16.3.1">ACM Trans. Inf. Syst.</em> 41, 2 (2023), 38:1–38:31.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Del Corso et al<span class="ltx_text" id="bib.bib17.2.2.1">.</span> (2005)</span>
<span class="ltx_bibblock">
Gianna M. Del Corso, Antonio Gullí, and Francesco Romani. 2005.

</span>
<span class="ltx_bibblock">Ranking a Stream of News. In <em class="ltx_emph ltx_font_italic" id="bib.bib17.3.1">Proceedings of the 14th International Conference on World Wide Web</em> (Chiba, Japan) <em class="ltx_emph ltx_font_italic" id="bib.bib17.4.2">(WWW ’05)</em>. Association for Computing Machinery, New York, NY, USA, 97–106.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/1060745.1060764" title="">https://doi.org/10.1145/1060745.1060764</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Devlin et al<span class="ltx_text" id="bib.bib18.2.2.1">.</span> (2019a)</span>
<span class="ltx_bibblock">
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019a.

</span>
<span class="ltx_bibblock">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In <em class="ltx_emph ltx_font_italic" id="bib.bib18.3.1">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</em>. Association for Computational Linguistics, Minneapolis, Minnesota, 4171–4186.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Devlin et al<span class="ltx_text" id="bib.bib19.2.2.1">.</span> (2019b)</span>
<span class="ltx_bibblock">
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019b.

</span>
<span class="ltx_bibblock">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In <em class="ltx_emph ltx_font_italic" id="bib.bib19.3.1">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</em>. Association for Computational Linguistics, Minneapolis, Minnesota, 4171–4186.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/v1/N19-1423" title="">https://doi.org/10.18653/v1/N19-1423</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Diaz (2007)</span>
<span class="ltx_bibblock">
Fernando Diaz. 2007.

</span>
<span class="ltx_bibblock">Performance Prediction Using Spatial Autocorrelation. In <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">Proceedings of the 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</em> <em class="ltx_emph ltx_font_italic" id="bib.bib20.2.2">(SIGIR ’07)</em>. Association for Computing Machinery, New York, NY, USA, 583–590.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dong et al<span class="ltx_text" id="bib.bib21.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Qingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Zhiyong Wu, Baobao Chang, Xu Sun, Jingjing Xu, Lei Li, and Zhifang Sui. 2023.

</span>
<span class="ltx_bibblock">A Survey on In-context Learning.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2301.00234 [cs.CL]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Faggioli et al<span class="ltx_text" id="bib.bib22.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Guglielmo Faggioli, Nicola Ferro, Cristina Muntean, Raffaele Perego, and Nicola Tonellotto. 2023.

</span>
<span class="ltx_bibblock">A Geometric Framework for Query Performance Prediction in Conversational Search. In <em class="ltx_emph ltx_font_italic" id="bib.bib22.3.1">Proceedings of 46th international ACM SIGIR Conference on Research &amp; Development in Information Retrieval, SIGIR 2023 July 23–27, 2023, Taipei, Taiwan</em>. ACM.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3539618.3591625" title="">https://doi.org/10.1145/3539618.3591625</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ganguly et al<span class="ltx_text" id="bib.bib23.2.2.1">.</span> (2013a)</span>
<span class="ltx_bibblock">
Debasis Ganguly, Manisha Ganguly, Johannes Leveling, and Gareth J. F. Jones. 2013a.

</span>
<span class="ltx_bibblock">TopicVis: a GUI for topic-based feedback and navigation. In <em class="ltx_emph ltx_font_italic" id="bib.bib23.3.1">SIGIR</em>. ACM, 1103–1104.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ganguly and Jones (2018)</span>
<span class="ltx_bibblock">
Debasis Ganguly and Gareth J. F. Jones. 2018.

</span>
<span class="ltx_bibblock">A non-parametric topical relevance model.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">Inf. Retr. J.</em> 21, 5 (2018), 449–479.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ganguly et al<span class="ltx_text" id="bib.bib25.2.2.1">.</span> (2013b)</span>
<span class="ltx_bibblock">
Debasis Ganguly, Johannes Leveling, and Gareth J. F. Jones. 2013b.

</span>
<span class="ltx_bibblock">An LDA-smoothed relevance model for document expansion: a case study for spoken document retrieval. In <em class="ltx_emph ltx_font_italic" id="bib.bib25.3.1">SIGIR</em>. ACM, 1057–1060.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ganguly and Yilmaz (2023)</span>
<span class="ltx_bibblock">
Debasis Ganguly and Emine Yilmaz. 2023.

</span>
<span class="ltx_bibblock">Query-specific Variable Depth Pooling via Query Performance Prediction. In <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">SIGIR</em>. ACM, 2303–2307.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et al<span class="ltx_text" id="bib.bib27.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Leo Gao, Stella Biderman, Sid Black, Laurence Golding, Travis Hoppe, Charles Foster, Jason Phang, Horace He, Anish Thite, Noa Nabeshima, Shawn Presser, and Connor Leahy. 2020.

</span>
<span class="ltx_bibblock">The Pile: An 800GB Dataset of Diverse Text for Language Modeling.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib27.3.1">arXiv preprint arXiv:2101.00027</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et al<span class="ltx_text" id="bib.bib28.2.2.1">.</span> (2021a)</span>
<span class="ltx_bibblock">
Luyu Gao, Zhuyun Dai, and Jamie Callan. 2021a.

</span>
<span class="ltx_bibblock">Rethink Training of BERT Rerankers in Multi-Stage Retrieval Pipeline.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib28.3.1">CoRR</em> abs/2101.08751 (2021).

</span>
<span class="ltx_bibblock">arXiv:2101.08751

<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2101.08751" title="">https://arxiv.org/abs/2101.08751</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et al<span class="ltx_text" id="bib.bib29.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Luyu Gao, Xueguang Ma, Jimmy Lin, and Jamie Callan. 2023.

</span>
<span class="ltx_bibblock">Precise Zero-Shot Dense Retrieval without Relevance Labels. In <em class="ltx_emph ltx_font_italic" id="bib.bib29.3.1">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023</em>, Anna Rogers, Jordan L. Boyd-Graber, and Naoaki Okazaki (Eds.). Association for Computational Linguistics, 1762–1777.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/V1/2023.ACL-LONG.99" title="">https://doi.org/10.18653/V1/2023.ACL-LONG.99</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et al<span class="ltx_text" id="bib.bib30.2.2.1">.</span> (2021b)</span>
<span class="ltx_bibblock">
Tianyu Gao, Xingcheng Yao, and Danqi Chen. 2021b.

</span>
<span class="ltx_bibblock">SimCSE: Simple Contrastive Learning of Sentence Embeddings. In <em class="ltx_emph ltx_font_italic" id="bib.bib30.3.1">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, Virtual Event / Punta Cana, Dominican Republic, 7-11 November, 2021</em>, Marie-Francine Moens, Xuanjing Huang, Lucia Specia, and Scott Wen-tau Yih (Eds.). Association for Computational Linguistics, 6894–6910.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/V1/2021.EMNLP-MAIN.552" title="">https://doi.org/10.18653/V1/2021.EMNLP-MAIN.552</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gutmann and Hyvärinen (2010)</span>
<span class="ltx_bibblock">
Michael Gutmann and Aapo Hyvärinen. 2010.

</span>
<span class="ltx_bibblock">Noise-contrastive estimation: A new estimation principle for unnormalized statistical models. In <em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics</em> <em class="ltx_emph ltx_font_italic" id="bib.bib31.2.2">(Proceedings of Machine Learning Research, Vol. 9)</em>, Yee Whye Teh and Mike Titterington (Eds.). PMLR, Chia Laguna Resort, Sardinia, Italy, 297–304.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://proceedings.mlr.press/v9/gutmann10a.html" title="">https://proceedings.mlr.press/v9/gutmann10a.html</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hofstätter et al<span class="ltx_text" id="bib.bib32.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Sebastian Hofstätter, Sophia Althammer, Michael Schröder, Mete Sertkan, and Allan Hanbury. 2020.

</span>
<span class="ltx_bibblock">Improving Efficient Neural Ranking Models with Cross-Architecture Knowledge Distillation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib32.3.1">CoRR</em> abs/2010.02666 (2020).

</span>
<span class="ltx_bibblock">arXiv:2010.02666

<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2010.02666" title="">https://arxiv.org/abs/2010.02666</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et al<span class="ltx_text" id="bib.bib33.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Shengding Hu, Ning Ding, Huadong Wang, Zhiyuan Liu, Jingang Wang, Juanzi Li, Wei Wu, and Maosong Sun. 2021.

</span>
<span class="ltx_bibblock">Knowledgeable prompt-tuning: Incorporating knowledge into prompt verbalizer for text classification.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib33.3.1">arXiv preprint arXiv:2108.02035</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Izacard and Grave (2021)</span>
<span class="ltx_bibblock">
Gautier Izacard and Edouard Grave. 2021.

</span>
<span class="ltx_bibblock">Leveraging Passage Retrieval with Generative Models for Open Domain Question Answering. In <em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, EACL 2021, Online, April 19 - 23, 2021</em>, Paola Merlo, Jörg Tiedemann, and Reut Tsarfaty (Eds.). Association for Computational Linguistics, 874–880.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/V1/2021.EACL-MAIN.74" title="">https://doi.org/10.18653/V1/2021.EACL-MAIN.74</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Izacard et al<span class="ltx_text" id="bib.bib35.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Gautier Izacard, Patrick S. H. Lewis, Maria Lomeli, Lucas Hosseini, Fabio Petroni, Timo Schick, Jane Dwivedi-Yu, Armand Joulin, Sebastian Riedel, and Edouard Grave. 2023.

</span>
<span class="ltx_bibblock">Atlas: Few-shot Learning with Retrieval Augmented Language Models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib35.3.1">J. Mach. Learn. Res.</em> 24 (2023), 251:1–251:43.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="http://jmlr.org/papers/v24/23-0037.html" title="">http://jmlr.org/papers/v24/23-0037.html</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et al<span class="ltx_text" id="bib.bib36.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Albert Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, Lélio Renard Lavaud, Marie-Anne Lachaux, Pierre Stock, Teven Le Scao, Thibaut Lavril, Thomas Wang, Timothée Lacroix, and William El Sayed. 2023.

</span>
<span class="ltx_bibblock">Mistral 7B.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2310.06825 [cs.CL]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Karpukhin et al<span class="ltx_text" id="bib.bib37.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick S. H. Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih. 2020.

</span>
<span class="ltx_bibblock">Dense Passage Retrieval for Open-Domain Question Answering. In <em class="ltx_emph ltx_font_italic" id="bib.bib37.3.1">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, EMNLP 2020, Online, November 16-20, 2020</em>, Bonnie Webber, Trevor Cohn, Yulan He, and Yang Liu (Eds.). Association for Computational Linguistics, 6769–6781.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/V1/2020.EMNLP-MAIN.550" title="">https://doi.org/10.18653/V1/2020.EMNLP-MAIN.550</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Khattab and Zaharia (2020)</span>
<span class="ltx_bibblock">
Omar Khattab and Matei Zaharia. 2020.

</span>
<span class="ltx_bibblock">ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT. In <em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">Proceedings of the 43rd International ACM SIGIR conference on research and development in Information Retrieval, SIGIR 2020, Virtual Event, China, July 25-30, 2020</em>, Jimmy X. Huang, Yi Chang, Xueqi Cheng, Jaap Kamps, Vanessa Murdock, Ji-Rong Wen, and Yiqun Liu (Eds.). ACM, 39–48.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3397271.3401075" title="">https://doi.org/10.1145/3397271.3401075</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Levy et al<span class="ltx_text" id="bib.bib39.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Itay Levy, Ben Bogin, and Jonathan Berant. 2023.

</span>
<span class="ltx_bibblock">Diverse Demonstrations Improve In-context Compositional Generalization.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2212.06800 [cs.CL]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewis et al<span class="ltx_text" id="bib.bib40.2.2.1">.</span> (2020a)</span>
<span class="ltx_bibblock">
Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer. 2020a.

</span>
<span class="ltx_bibblock">BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension. In <em class="ltx_emph ltx_font_italic" id="bib.bib40.3.1">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</em>. Association for Computational Linguistics, Online, 7871–7880.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/v1/2020.acl-main.703" title="">https://doi.org/10.18653/v1/2020.acl-main.703</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewis et al<span class="ltx_text" id="bib.bib41.2.2.1">.</span> (2020b)</span>
<span class="ltx_bibblock">
Patrick S. H. Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, Sebastian Riedel, and Douwe Kiela. 2020b.

</span>
<span class="ltx_bibblock">Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks. In <em class="ltx_emph ltx_font_italic" id="bib.bib41.3.1">Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual</em>, Hugo Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin (Eds.).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://proceedings.neurips.cc/paper/2020/hash/6b493230205f780e1bc26945df7481e5-Abstract.html" title="">https://proceedings.neurips.cc/paper/2020/hash/6b493230205f780e1bc26945df7481e5-Abstract.html</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span class="ltx_text" id="bib.bib42.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Minghan Li, Xueguang Ma, and Jimmy Lin. 2022.

</span>
<span class="ltx_bibblock">An Encoder Attribution Analysis for Dense Passage Retriever in Open-Domain Question Answering. In <em class="ltx_emph ltx_font_italic" id="bib.bib42.3.1">Proceedings of the 2nd Workshop on Trustworthy Natural Language Processing (TrustNLP 2022)</em>. Association for Computational Linguistics, Seattle, U.S.A., 1–11.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/v1/2022.trustnlp-1.1" title="">https://doi.org/10.18653/v1/2022.trustnlp-1.1</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span class="ltx_text" id="bib.bib43.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Tianle Li, Xueguang Ma, Alex Zhuang, Yu Gu, Yu Su, and Wenhu Chen. 2023.

</span>
<span class="ltx_bibblock">Few-shot In-context Learning on Knowledge Base Question Answering. In <em class="ltx_emph ltx_font_italic" id="bib.bib43.3.1">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, Anna Rogers, Jordan Boyd-Graber, and Naoaki Okazaki (Eds.). Association for Computational Linguistics, Toronto, Canada, 6966–6980.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/v1/2023.acl-long.385" title="">https://doi.org/10.18653/v1/2023.acl-long.385</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et al<span class="ltx_text" id="bib.bib44.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Sheng-Chieh Lin, Jheng-Hong Yang, and Jimmy Lin. 2021.

</span>
<span class="ltx_bibblock">In-Batch Negatives for Knowledge Distillation with Tightly-Coupled Teachers for Dense Retrieval. In <em class="ltx_emph ltx_font_italic" id="bib.bib44.3.1">Proceedings of the 6th Workshop on Representation Learning for NLP, RepL4NLP@ACL-IJCNLP 2021, Online, August 6, 2021</em>, Anna Rogers, Iacer Calixto, Ivan Vulic, Naomi Saphra, Nora Kassner, Oana-Maria Camburu, Trapit Bansal, and Vered Shwartz (Eds.). Association for Computational Linguistics, 163–173.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/V1/2021.REPL4NLP-1.17" title="">https://doi.org/10.18653/V1/2021.REPL4NLP-1.17</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al<span class="ltx_text" id="bib.bib45.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Jiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan, Lawrence Carin, and Weizhu Chen. 2022.

</span>
<span class="ltx_bibblock">What Makes Good In-Context Examples for GPT-3?. In <em class="ltx_emph ltx_font_italic" id="bib.bib45.3.1">Proceedings of Deep Learning Inside Out (DeeLIO 2022): The 3rd Workshop on Knowledge Extraction and Integration for Deep Learning Architectures</em>, Eneko Agirre, Marianna Apidianaki, and Ivan Vulić (Eds.). Association for Computational Linguistics, Dublin, Ireland and Online, 100–114.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/v1/2022.deelio-1.10" title="">https://doi.org/10.18653/v1/2022.deelio-1.10</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al<span class="ltx_text" id="bib.bib46.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019.

</span>
<span class="ltx_bibblock">RoBERTa: A Robustly Optimized BERT Pretraining Approach.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/1907.11692" title="">http://arxiv.org/abs/1907.11692</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lu et al<span class="ltx_text" id="bib.bib47.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel, and Pontus Stenetorp. 2022.

</span>
<span class="ltx_bibblock">Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. In <em class="ltx_emph ltx_font_italic" id="bib.bib47.3.1">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, Smaranda Muresan, Preslav Nakov, and Aline Villavicencio (Eds.). Association for Computational Linguistics, Dublin, Ireland, 8086–8098.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/v1/2022.acl-long.556" title="">https://doi.org/10.18653/v1/2022.acl-long.556</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Luo et al<span class="ltx_text" id="bib.bib48.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Man Luo, Xin Xu, Yue Liu, Panupong Pasupat, and Mehran Kazemi. 2024.

</span>
<span class="ltx_bibblock">In-context Learning with Retrieved Demonstrations for Language Models: A Survey.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2401.11624 [cs.CL]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">MacAvaney et al<span class="ltx_text" id="bib.bib49.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Sean MacAvaney, Andrew Yates, Arman Cohan, and Nazli Goharian. 2019.

</span>
<span class="ltx_bibblock">CEDR: Contextualized Embeddings for Document Ranking. In <em class="ltx_emph ltx_font_italic" id="bib.bib49.3.1">Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 2019, Paris, France, July 21-25, 2019</em>, Benjamin Piwowarski, Max Chevalier, Éric Gaussier, Yoelle Maarek, Jian-Yun Nie, and Falk Scholer (Eds.). ACM, 1101–1104.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3331184.3331317" title="">https://doi.org/10.1145/3331184.3331317</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mahdi et al<span class="ltx_text" id="bib.bib50.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Mohammed Najah Mahdi, Abdul Rahim Ahmad, Roslan Ismail, Hayder Natiq, and Mohammed Abdulameer Mohammed. 2020.

</span>
<span class="ltx_bibblock">Solution for Information Overload Using Faceted Search–A Review.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib50.3.1">IEEE Access</em> 8 (2020), 119554–119585.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/ACCESS.2020.3005536" title="">https://doi.org/10.1109/ACCESS.2020.3005536</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Malkov and Yashunin (2020)</span>
<span class="ltx_bibblock">
Yury A. Malkov and Dmitry A. Yashunin. 2020.

</span>
<span class="ltx_bibblock">Efficient and Robust Approximate Nearest Neighbor Search Using Hierarchical Navigable Small World Graphs.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib51.1.1">IEEE Trans. Pattern Anal. Mach. Intell.</em> 42, 4 (2020), 824–836.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/TPAMI.2018.2889473" title="">https://doi.org/10.1109/TPAMI.2018.2889473</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Maxwell et al<span class="ltx_text" id="bib.bib52.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
David Maxwell, Leif Azzopardi, and Yashar Moshfeghi. 2019.

</span>
<span class="ltx_bibblock">The impact of result diversification on search behaviour and performance.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib52.3.1">Inf. Retr. J.</em> 22, 5 (2019), 422–446.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Milios et al<span class="ltx_text" id="bib.bib53.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Aristides Milios, Siva Reddy, and Dzmitry Bahdanau. 2023.

</span>
<span class="ltx_bibblock">In-Context Learning for Text Classification with Many Labels. In <em class="ltx_emph ltx_font_italic" id="bib.bib53.3.1">Proceedings of the 1st GenBench Workshop on (Benchmarking) Generalisation in NLP</em>, Dieuwke Hupkes, Verna Dankers, Khuyagbaatar Batsuren, Koustuv Sinha, Amirhossein Kazemnejad, Christos Christodoulopoulos, Ryan Cotterell, and Elia Bruni (Eds.). Association for Computational Linguistics, Singapore, 173–184.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/v1/2023.genbench-1.14" title="">https://doi.org/10.18653/v1/2023.genbench-1.14</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mysore et al<span class="ltx_text" id="bib.bib54.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Sheshera Mysore, Andrew McCallum, and Hamed Zamani. 2023.

</span>
<span class="ltx_bibblock">Large Language Model Augmented Narrative Driven Recommendations.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2306.02250 [cs.IR]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ni et al<span class="ltx_text" id="bib.bib55.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Jianmo Ni, Chen Qu, Jing Lu, Zhuyun Dai, Gustavo Hernández Ábrego, Ji Ma, Vincent Y. Zhao, Yi Luan, Keith B. Hall, Ming-Wei Chang, and Yinfei Yang. 2021.

</span>
<span class="ltx_bibblock">Large Dual Encoders Are Generalizable Retrievers.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2112.07899 [cs.IR]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nogueira and Cho (2019)</span>
<span class="ltx_bibblock">
Rodrigo Frassetto Nogueira and Kyunghyun Cho. 2019.

</span>
<span class="ltx_bibblock">Passage Re-ranking with BERT.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib56.1.1">CoRR</em> abs/1901.04085 (2019).

</span>
<span class="ltx_bibblock">arXiv:1901.04085

<a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/1901.04085" title="">http://arxiv.org/abs/1901.04085</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nogueira et al<span class="ltx_text" id="bib.bib57.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Rodrigo Frassetto Nogueira, Zhiying Jiang, Ronak Pradeep, and Jimmy Lin. 2020.

</span>
<span class="ltx_bibblock">Document Ranking with a Pretrained Sequence-to-Sequence Model. In <em class="ltx_emph ltx_font_italic" id="bib.bib57.3.1">Findings of the Association for Computational Linguistics: EMNLP 2020, Online Event, 16-20 November 2020</em> <em class="ltx_emph ltx_font_italic" id="bib.bib57.4.2">(Findings of ACL, Vol. EMNLP 2020)</em>, Trevor Cohn, Yulan He, and Yang Liu (Eds.). Association for Computational Linguistics, 708–718.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/V1/2020.FINDINGS-EMNLP.63" title="">https://doi.org/10.18653/V1/2020.FINDINGS-EMNLP.63</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Oosterhuis (2021)</span>
<span class="ltx_bibblock">
Harrie Oosterhuis. 2021.

</span>
<span class="ltx_bibblock">Computationally Efficient Optimization of Plackett-Luce Ranking Models for Relevance and Fairness. In <em class="ltx_emph ltx_font_italic" id="bib.bib58.1.1">Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval</em> (, Virtual Event, Canada,) <em class="ltx_emph ltx_font_italic" id="bib.bib58.2.2">(SIGIR ’21)</em>. Association for Computing Machinery, New York, NY, USA, 1023–1032.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3404835.3462830" title="">https://doi.org/10.1145/3404835.3462830</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2023)</span>
<span class="ltx_bibblock">
OpenAI. 2023.

</span>
<span class="ltx_bibblock">GPT-4 Technical Report.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2303.08774 [cs.CL]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ouyang et al<span class="ltx_text" id="bib.bib60.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul F Christiano, Jan Leike, and Ryan Lowe. 2022.

</span>
<span class="ltx_bibblock">Training language models to follow instructions with human feedback. In <em class="ltx_emph ltx_font_italic" id="bib.bib60.3.1">Advances in Neural Information Processing Systems</em>, S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh (Eds.), Vol. 35. Curran Associates, Inc., 27730–27744.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://proceedings.neurips.cc/paper_files/paper/2022/file/b1efde53be364a73914f58805a001731-Paper-Conference.pdf" title="">https://proceedings.neurips.cc/paper_files/paper/2022/file/b1efde53be364a73914f58805a001731-Paper-Conference.pdf</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib61">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Paulsen and Raghupathi (2016)</span>
<span class="ltx_bibblock">
Vern I. Paulsen and Mrinal Raghupathi. 2016.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib61.1.1">An Introduction to the Theory of Reproducing Kernel Hilbert Spaces</em>.

</span>
<span class="ltx_bibblock">Cambridge University Press.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib62">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pradeep et al<span class="ltx_text" id="bib.bib62.2.2.1">.</span> (2023a)</span>
<span class="ltx_bibblock">
Ronak Pradeep, Kai Hui, Jai Gupta, Adam D. Lelkes, Honglei Zhuang, Jimmy Lin, Donald Metzler, and Vinh Q. Tran. 2023a.

</span>
<span class="ltx_bibblock">How Does Generative Retrieval Scale to Millions of Passages?

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2305.11841 [cs.IR]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib63">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pradeep et al<span class="ltx_text" id="bib.bib63.2.2.1">.</span> (2023b)</span>
<span class="ltx_bibblock">
Ronak Pradeep, Sahel Sharifymoghaddam, and Jimmy Lin. 2023b.

</span>
<span class="ltx_bibblock">RankZephyr: Effective and Robust Zero-Shot Listwise Reranking is a Breeze!

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib63.3.1">CoRR</em> abs/2312.02724 (2023).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/ARXIV.2312.02724" title="">https://doi.org/10.48550/ARXIV.2312.02724</a>
arXiv:2312.02724

</span>
</li>
<li class="ltx_bibitem" id="bib.bib64">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et al<span class="ltx_text" id="bib.bib64.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al<span class="ltx_text" id="bib.bib64.3.1">.</span> 2019.

</span>
<span class="ltx_bibblock">Language models are unsupervised multitask learners.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib64.4.1">OpenAI blog</em> 1, 8 (2019), 9.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib65">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Reimers and Gurevych (2019)</span>
<span class="ltx_bibblock">
Nils Reimers and Iryna Gurevych. 2019.

</span>
<span class="ltx_bibblock">Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:1908.10084 [cs.CL]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib66">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Roitman et al<span class="ltx_text" id="bib.bib66.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Haggai Roitman, Yosi Mass, Guy Feigenblat, and Roee Shraga. 2020.

</span>
<span class="ltx_bibblock">Query Performance Prediction for Multifield Document Retrieval. In <em class="ltx_emph ltx_font_italic" id="bib.bib66.3.1">Proceedings of the 2020 ACM SIGIR on International Conference on Theory of Information Retrieval</em> (Virtual Event, Norway) <em class="ltx_emph ltx_font_italic" id="bib.bib66.4.2">(ICTIR ’20)</em>. Association for Computing Machinery, New York, NY, USA, 49–52.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3409256.3409821" title="">https://doi.org/10.1145/3409256.3409821</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib67">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Roy et al<span class="ltx_text" id="bib.bib67.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Dwaipayan Roy, Debasis Ganguly, Mandar Mitra, and Gareth J.F. Jones. 2019.

</span>
<span class="ltx_bibblock">Estimating Gaussian mixture models in the local neighbourhood of embedded word vectors for query performance prediction.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib67.3.1">Information Processing and Management</em> 56, 3 (2019), 1026 – 1045.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib68">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rubin et al<span class="ltx_text" id="bib.bib68.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Ohad Rubin, Jonathan Herzig, and Jonathan Berant. 2022.

</span>
<span class="ltx_bibblock">Learning To Retrieve Prompts for In-Context Learning. In <em class="ltx_emph ltx_font_italic" id="bib.bib68.3.1">Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</em>, Marine Carpuat, Marie-Catherine de Marneffe, and Ivan Vladimir Meza Ruiz (Eds.). Association for Computational Linguistics, Seattle, United States, 2655–2671.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/v1/2022.naacl-main.191" title="">https://doi.org/10.18653/v1/2022.naacl-main.191</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib69">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Santos et al<span class="ltx_text" id="bib.bib69.2.2.1">.</span> (2010)</span>
<span class="ltx_bibblock">
Rodrygo L.T. Santos, Craig Macdonald, and Iadh Ounis. 2010.

</span>
<span class="ltx_bibblock">Exploiting query reformulations for web search result diversification. In <em class="ltx_emph ltx_font_italic" id="bib.bib69.3.1">Proceedings of the 19th International Conference on World Wide Web</em> (Raleigh, North Carolina, USA) <em class="ltx_emph ltx_font_italic" id="bib.bib69.4.2">(WWW ’10)</em>. Association for Computing Machinery, New York, NY, USA, 881–890.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/1772690.1772780" title="">https://doi.org/10.1145/1772690.1772780</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib70">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schick and Schütze (2021)</span>
<span class="ltx_bibblock">
Timo Schick and Hinrich Schütze. 2021.

</span>
<span class="ltx_bibblock">Exploiting Cloze-Questions for Few-Shot Text Classification and Natural Language Inference. In <em class="ltx_emph ltx_font_italic" id="bib.bib70.1.1">Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume</em>, Paola Merlo, Jorg Tiedemann, and Reut Tsarfaty (Eds.). Association for Computational Linguistics, Online, 255–269.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/v1/2021.eacl-main.20" title="">https://doi.org/10.18653/v1/2021.eacl-main.20</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib71">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sen et al<span class="ltx_text" id="bib.bib71.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Procheta Sen, Sourav Saha, Debasis Ganguly, Manisha Verma, and Dwaipayan Roy. 2022.

</span>
<span class="ltx_bibblock">Measuring and Comparing the Consistency of IR Models for Query Pairs with Similar and Different Information Needs. In <em class="ltx_emph ltx_font_italic" id="bib.bib71.3.1">CIKM</em>. ACM, 4449–4453.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib72">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shen et al<span class="ltx_text" id="bib.bib72.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Tao Shen, Xiubo Geng, Chongyang Tao, Can Xu, Xiaolong Huang, Binxing Jiao, Linjun Yang, and Daxin Jiang. 2023.

</span>
<span class="ltx_bibblock">LexMAE: Lexicon-Bottlenecked Pretraining for Large-Scale Retrieval. In <em class="ltx_emph ltx_font_italic" id="bib.bib72.3.1">The Eleventh International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023</em>. OpenReview.net.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/pdf?id=PfpEtB3-csK" title="">https://openreview.net/pdf?id=PfpEtB3-csK</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib73">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shtok et al<span class="ltx_text" id="bib.bib73.2.2.1">.</span> (2012)</span>
<span class="ltx_bibblock">
Anna Shtok, Oren Kurland, David Carmel, Fiana Raiber, and Gad Markovits. 2012.

</span>
<span class="ltx_bibblock">Predicting Query Performance by Query-Drift Estimation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib73.3.1">ACM Trans. Inf. Syst.</em> 30, 2, Article 11 (2012), 35 pages.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib74">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Singh et al<span class="ltx_text" id="bib.bib74.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Ashutosh Singh, Debasis Ganguly, Suchana Datta, and Craig MacDonald. 2023.

</span>
<span class="ltx_bibblock">Unsupervised Query Performance Prediction for Neural Models with Pairwise Rank Preferences. In <em class="ltx_emph ltx_font_italic" id="bib.bib74.3.1">Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 2023, Taipei, Taiwan, July 23-27, 2023</em>, Hsin-Hsi Chen, Wei-Jou (Edward) Duh, Hen-Hsen Huang, Makoto P. Kato, Josiane Mothe, and Barbara Poblete (Eds.). ACM, 2486–2490.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3539618.3592082" title="">https://doi.org/10.1145/3539618.3592082</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib75">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Socher et al<span class="ltx_text" id="bib.bib75.2.2.1">.</span> (2013)</span>
<span class="ltx_bibblock">
Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D. Manning, Andrew Ng, and Christopher Potts. 2013.

</span>
<span class="ltx_bibblock">Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank. In <em class="ltx_emph ltx_font_italic" id="bib.bib75.3.1">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</em>. Association for Computational Linguistics, Seattle, Washington, USA, 1631–1642.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/D13-1170" title="">https://aclanthology.org/D13-1170</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib76">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sorensen et al<span class="ltx_text" id="bib.bib76.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Taylor Sorensen, Joshua Robinson, Christopher Rytting, Alexander Shaw, Kyle Rogers, Alexia Delorey, Mahmoud Khalil, Nancy Fulda, and David Wingate. 2022.

</span>
<span class="ltx_bibblock">An Information-theoretic Approach to Prompt Engineering Without Ground Truth Labels. In <em class="ltx_emph ltx_font_italic" id="bib.bib76.3.1">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, Smaranda Muresan, Preslav Nakov, and Aline Villavicencio (Eds.). Association for Computational Linguistics, Dublin, Ireland, 819–862.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/v1/2022.acl-long.60" title="">https://doi.org/10.18653/v1/2022.acl-long.60</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib77">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Su et al<span class="ltx_text" id="bib.bib77.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Jianlin Su, Yu Lu, Shengfeng Pan, Ahmed Murtadha, Bo Wen, and Yunfeng Liu. 2023.

</span>
<span class="ltx_bibblock">RoFormer: Enhanced Transformer with Rotary Position Embedding.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2104.09864 [cs.CL]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib78">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et al<span class="ltx_text" id="bib.bib78.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Weiwei Sun, Lingyong Yan, Xinyu Ma, Shuaiqiang Wang, Pengjie Ren, Zhumin Chen, Dawei Yin, and Zhaochun Ren. 2023.

</span>
<span class="ltx_bibblock">Is ChatGPT Good at Search? Investigating Large Language Models as Re-Ranking Agents. In <em class="ltx_emph ltx_font_italic" id="bib.bib78.3.1">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, EMNLP 2023, Singapore, December 6-10, 2023</em>, Houda Bouamor, Juan Pino, and Kalika Bali (Eds.). Association for Computational Linguistics, 14918–14937.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2023.emnlp-main.923" title="">https://aclanthology.org/2023.emnlp-main.923</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib79">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tang et al<span class="ltx_text" id="bib.bib79.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Yuting Tang, Ratish Puduppully, Zhengyuan Liu, and Nancy Chen. 2023.

</span>
<span class="ltx_bibblock">In-context Learning of Large Language Models for Controlled Dialogue Summarization: A Holistic Benchmark and Empirical Analysis. In <em class="ltx_emph ltx_font_italic" id="bib.bib79.3.1">Proceedings of the 4th New Frontiers in Summarization Workshop</em>, Yue Dong, Wen Xiao, Lu Wang, Fei Liu, and Giuseppe Carenini (Eds.). Association for Computational Linguistics, Singapore, 56–67.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/v1/2023.newsum-1.6" title="">https://doi.org/10.18653/v1/2023.newsum-1.6</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib80">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et al<span class="ltx_text" id="bib.bib80.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa,
Isabel Kloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen
Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Sergey Edunov, and Thomas Scialom. 2023.

</span>
<span class="ltx_bibblock">Llama 2: Open Foundation and Fine-Tuned Chat Models.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2307.09288 [cs.CL]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib81">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Upadhyay et al<span class="ltx_text" id="bib.bib81.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Prajna Upadhyay, Srikanta Bedathur, Tanmoy Chakraborty, and Maya Ramanath. 2020.

</span>
<span class="ltx_bibblock">Aspect-based academic search using domain-specific KB. In <em class="ltx_emph ltx_font_italic" id="bib.bib81.3.1">Advances in Information Retrieval: 42nd European Conference on IR Research, ECIR 2020, Lisbon, Portugal, April 14–17, 2020, Proceedings, Part II 42</em>. Springer, 418–424.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib82">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang (2021)</span>
<span class="ltx_bibblock">
Ben Wang. 2021.

</span>
<span class="ltx_bibblock">Mesh-Transformer-JAX: Model-Parallel Implementation of Transformer Language Model with JAX.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/kingoflolz/mesh-transformer-jax" title="">https://github.com/kingoflolz/mesh-transformer-jax</a>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib83">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang and Komatsuzaki (2022)</span>
<span class="ltx_bibblock">
Ben Wang and Aran Komatsuzaki. 2022.

</span>
<span class="ltx_bibblock">GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model, 2021.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib84">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span class="ltx_text" id="bib.bib84.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Liang Wang, Nan Yang, and Furu Wei. 2023.

</span>
<span class="ltx_bibblock">Query2doc: Query Expansion with Large Language Models. In <em class="ltx_emph ltx_font_italic" id="bib.bib84.3.1">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em>, Houda Bouamor, Juan Pino, and Kalika Bali (Eds.). Association for Computational Linguistics, Singapore, 9414–9423.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/v1/2023.emnlp-main.585" title="">https://doi.org/10.18653/v1/2023.emnlp-main.585</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib85">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xiao et al<span class="ltx_text" id="bib.bib85.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Shitao Xiao, Zheng Liu, Yingxia Shao, and Zhao Cao. 2022.

</span>
<span class="ltx_bibblock">RetroMAE: Pre-Training Retrieval-oriented Language Models Via Masked Auto-Encoder. In <em class="ltx_emph ltx_font_italic" id="bib.bib85.3.1">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022</em>, Yoav Goldberg, Zornitsa Kozareva, and Yue Zhang (Eds.). Association for Computational Linguistics, 538–548.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/V1/2022.EMNLP-MAIN.35" title="">https://doi.org/10.18653/V1/2022.EMNLP-MAIN.35</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib86">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xiong et al<span class="ltx_text" id="bib.bib86.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Lee Xiong, Chenyan Xiong, Ye Li, Kwok-Fung Tang, Jialin Liu, Paul N. Bennett, Junaid Ahmed, and Arnold Overwijk. 2021.

</span>
<span class="ltx_bibblock">Approximate Nearest Neighbor Negative Contrastive Learning for Dense Text Retrieval. In <em class="ltx_emph ltx_font_italic" id="bib.bib86.3.1">9th International Conference on Learning Representations, ICLR 2021, Virtual Event, Austria, May 3-7, 2021</em>. OpenReview.net.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=zeFrfgyZln" title="">https://openreview.net/forum?id=zeFrfgyZln</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib87">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zendel et al<span class="ltx_text" id="bib.bib87.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Oleg Zendel, Anna Shtok, Fiana Raiber, Oren Kurland, and J. Shane Culpepper. 2019.

</span>
<span class="ltx_bibblock">Information Needs, Queries, and Query Performance Prediction. In <em class="ltx_emph ltx_font_italic" id="bib.bib87.3.1">Proc. of SIGIR ’19</em>. Association for Computing Machinery, New York, NY, USA, 395–404.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib88">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span class="ltx_text" id="bib.bib88.2.2.1">.</span> (2017)</span>
<span class="ltx_bibblock">
Shichao Zhang, Xuelong Li, Ming Zong, Xiaofeng Zhu, and Debo Cheng. 2017.

</span>
<span class="ltx_bibblock">Learning k for KNN Classification.

</span>
<span class="ltx_bibblock">8, 3, Article 43 (jan 2017), 19 pages.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/2990508" title="">https://doi.org/10.1145/2990508</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib89">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou and Croft (2007)</span>
<span class="ltx_bibblock">
Yun Zhou and W. Bruce Croft. 2007.

</span>
<span class="ltx_bibblock">Query Performance Prediction in Web Search Environments. In <em class="ltx_emph ltx_font_italic" id="bib.bib89.1.1">Proc. 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</em> <em class="ltx_emph ltx_font_italic" id="bib.bib89.2.2">(SIGIR ’07)</em>. Association for Computing Machinery, New York, NY, USA, 543–550.

</span>
<span class="ltx_bibblock">
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
</div>
</body>
</html>
